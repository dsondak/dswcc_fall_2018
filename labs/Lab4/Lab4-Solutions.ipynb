{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4:  Regularization\n",
    "\n",
    "## Saturday, November 3rd 2018\n",
    "\n",
    "### David Sondak and Pavlos Protopapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Lecture 3 introduced several types of regularization.  In today's lab, you will become more familiar with those regularization techniques and actually apply them to a problem.  The types of regularization that you will explore today are:\n",
    "* Penalization\n",
    "* Early stopping\n",
    "* Dropout\n",
    "There are many other types of regularization (as mentioned in lecture).  The three regularization techniques that you will explore today are very popular and used frequently in real applications.\n",
    "\n",
    "We'll begin the story by building a neural network to learn a function from some noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warming Up\n",
    "Today we'll try to fit the function $$f\\left(x\\right) = x\\sin\\left(x\\right).$$\n",
    "\n",
    "Using `keras`, build a fully-connected neural network to fit $f\\left(x\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll generate some synthetic data with some synthetic noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100 # set the number of samples to take for each toy dataset\n",
    "test_size = 0.2 # set the proportion of toy data to hold out for testing\n",
    "random_seed = 1 # set the random seed to make the experiment reproducible \n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# define a function\n",
    "f = lambda x: x * np.sin(x)\n",
    "\n",
    "# Generate the truth function (without any noise)\n",
    "X_true = np.linspace(0.0, 5.0, n_samples)\n",
    "Y_true = f(X_true)\n",
    "\n",
    "# Now sample the true function at some points\n",
    "X = np.random.permutation(X_true) # choose some points from the function - this is our toy dataset \n",
    "Y = f(X)\n",
    "\n",
    "Y = Y + np.random.normal(0.0, 1.0, len(Y)) # Add some noise from a random normal distribution\n",
    "\n",
    "# create training and testing data from this set of points\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build a network.  We choose $5$ hidden layers and $100$ nodes per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='tanh'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='tanh'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll fit the model.  \n",
    "\n",
    "Notice that we're specifying a *validation set*.  What this means is that `keras` will further split the training set into a training part and a validation part.  The neural network will only be trained on the *training* set.  Meanwhile, `keras` will report performance metrics on the *validation* set so we can get a sense of how well the model has been trained.  We will be using the validation set quite a bit in this lab.\n",
    "\n",
    "Remember, we don't want to use the test set for anything relating to the training of our models.  By withholding the validation set, we can assess the model performance on the validation set.  Later, we can see how the model performs on data it has never seen before by using in on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 5.3071 - val_loss: 3.8413\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 5.3797 - val_loss: 3.5319\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 4.9824 - val_loss: 3.4028\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 330us/step - loss: 4.6934 - val_loss: 3.5651\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 478us/step - loss: 4.7462 - val_loss: 3.4562\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 4.6230 - val_loss: 3.1192\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 4.3425 - val_loss: 2.8796\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 4.1979 - val_loss: 2.7926\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 513us/step - loss: 4.1805 - val_loss: 2.6417\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 4.0114 - val_loss: 2.4759\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 3.7488 - val_loss: 2.4863\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 3.6420 - val_loss: 2.4296\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 3.5363 - val_loss: 2.0920\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 494us/step - loss: 3.2561 - val_loss: 1.8381\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 3.1233 - val_loss: 1.7104\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 3.0269 - val_loss: 1.5981\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 405us/step - loss: 2.7905 - val_loss: 1.7546\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.7988 - val_loss: 1.5272\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.6289 - val_loss: 1.3646\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 428us/step - loss: 2.6313 - val_loss: 1.3277\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 373us/step - loss: 2.5403 - val_loss: 1.5197\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.5115 - val_loss: 1.4319\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.4168 - val_loss: 1.2210\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.3556 - val_loss: 1.1673\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.2143 - val_loss: 1.3122\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.1166 - val_loss: 1.1649\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.9522 - val_loss: 0.9949\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.8699 - val_loss: 0.9870\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.7171 - val_loss: 1.1641\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6571 - val_loss: 1.0283\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.5210 - val_loss: 0.9665\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.4840 - val_loss: 1.0768\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3537 - val_loss: 1.2096\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.3006 - val_loss: 1.0430\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2145 - val_loss: 1.1382\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.0946 - val_loss: 1.3554\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.0637 - val_loss: 1.1771\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.0539 - val_loss: 1.5593\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 0.9989 - val_loss: 1.3733\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.9472 - val_loss: 1.5649\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.9383 - val_loss: 1.7477\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.9711 - val_loss: 1.6906\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 1.0531 - val_loss: 2.4810\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2639 - val_loss: 2.0067\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5164 - val_loss: 2.2849\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.1147 - val_loss: 2.3036\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1203 - val_loss: 1.8579\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2423 - val_loss: 1.8200\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.9798 - val_loss: 2.3294\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.1834 - val_loss: 1.7207\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.9477 - val_loss: 1.5693\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1016 - val_loss: 1.5763\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.9257 - val_loss: 1.8566\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.0483 - val_loss: 1.4652\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.9155 - val_loss: 1.2863\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.0076 - val_loss: 1.2714\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.9259 - val_loss: 1.4988\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 0.9768 - val_loss: 1.3852\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.9476 - val_loss: 1.1571\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.9523 - val_loss: 1.1327\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.9668 - val_loss: 1.2620\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.9343 - val_loss: 1.3698\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.9715 - val_loss: 1.1896\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.9259 - val_loss: 1.1200\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.9615 - val_loss: 1.1754\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.9248 - val_loss: 1.3381\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.9442 - val_loss: 1.2978\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.9257 - val_loss: 1.1854\n",
      "Epoch 69/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.9269 - val_loss: 1.1992\n",
      "Epoch 70/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.9242 - val_loss: 1.3290\n",
      "Epoch 71/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.9127 - val_loss: 1.3843\n",
      "Epoch 72/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.9192 - val_loss: 1.2758\n",
      "Epoch 73/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.9033 - val_loss: 1.2606\n",
      "Epoch 74/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.9132 - val_loss: 1.3642\n",
      "Epoch 75/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.8981 - val_loss: 1.4396\n",
      "Epoch 76/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.9086 - val_loss: 1.3460\n",
      "Epoch 77/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.8964 - val_loss: 1.3272\n",
      "Epoch 78/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 0.9053 - val_loss: 1.4246\n",
      "Epoch 79/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.8964 - val_loss: 1.4712\n",
      "Epoch 80/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 0.9023 - val_loss: 1.3824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.8970 - val_loss: 1.3788\n",
      "Epoch 82/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8989 - val_loss: 1.4678\n",
      "Epoch 83/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8974 - val_loss: 1.4584\n",
      "Epoch 84/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.8955 - val_loss: 1.3793\n",
      "Epoch 85/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.8971 - val_loss: 1.3956\n",
      "Epoch 86/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8923 - val_loss: 1.4554\n",
      "Epoch 87/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8956 - val_loss: 1.3967\n",
      "Epoch 88/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.8898 - val_loss: 1.3421\n",
      "Epoch 89/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.8931 - val_loss: 1.3771\n",
      "Epoch 90/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8882 - val_loss: 1.3920\n",
      "Epoch 91/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8903 - val_loss: 1.3203\n",
      "Epoch 92/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.8878 - val_loss: 1.3045\n",
      "Epoch 93/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.8878 - val_loss: 1.3470\n",
      "Epoch 94/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.8878 - val_loss: 1.3205\n",
      "Epoch 95/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.8860 - val_loss: 1.2726\n",
      "Epoch 96/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.8875 - val_loss: 1.2951\n",
      "Epoch 97/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.8851 - val_loss: 1.3186\n",
      "Epoch 98/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8866 - val_loss: 1.2753\n",
      "Epoch 99/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8850 - val_loss: 1.2667\n",
      "Epoch 100/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.8853 - val_loss: 1.3044\n",
      "Epoch 101/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8850 - val_loss: 1.2918\n",
      "Epoch 102/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.8840 - val_loss: 1.2631\n",
      "Epoch 103/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.8846 - val_loss: 1.2887\n",
      "Epoch 104/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.8832 - val_loss: 1.3046\n",
      "Epoch 105/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.8836 - val_loss: 1.2744\n",
      "Epoch 106/2500\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.8830 - val_loss: 1.2821\n",
      "Epoch 107/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.8824 - val_loss: 1.3108\n",
      "Epoch 108/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8827 - val_loss: 1.2910\n",
      "Epoch 109/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.8818 - val_loss: 1.2853\n",
      "Epoch 110/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.8819 - val_loss: 1.3146\n",
      "Epoch 111/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8817 - val_loss: 1.3062\n",
      "Epoch 112/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8812 - val_loss: 1.2926\n",
      "Epoch 113/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 0.8814 - val_loss: 1.3163\n",
      "Epoch 114/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.8810 - val_loss: 1.3144\n",
      "Epoch 115/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8808 - val_loss: 1.2965\n",
      "Epoch 116/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 0.8809 - val_loss: 1.3132\n",
      "Epoch 117/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8805 - val_loss: 1.3133\n",
      "Epoch 118/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.8804 - val_loss: 1.2938\n",
      "Epoch 119/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.8804 - val_loss: 1.3051\n",
      "Epoch 120/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8800 - val_loss: 1.3053\n",
      "Epoch 121/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.8800 - val_loss: 1.2865\n",
      "Epoch 122/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8799 - val_loss: 1.2954\n",
      "Epoch 123/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8796 - val_loss: 1.2953\n",
      "Epoch 124/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.8796 - val_loss: 1.2788\n",
      "Epoch 125/2500\n",
      "64/64 [==============================] - 0s 433us/step - loss: 0.8795 - val_loss: 1.2874\n",
      "Epoch 126/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.8793 - val_loss: 1.2866\n",
      "Epoch 127/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.8792 - val_loss: 1.2732\n",
      "Epoch 128/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8792 - val_loss: 1.2821\n",
      "Epoch 129/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8791 - val_loss: 1.2798\n",
      "Epoch 130/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.8790 - val_loss: 1.2697\n",
      "Epoch 131/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.8789 - val_loss: 1.2790\n",
      "Epoch 132/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.8788 - val_loss: 1.2747\n",
      "Epoch 133/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8787 - val_loss: 1.2685\n",
      "Epoch 134/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.8787 - val_loss: 1.2777\n",
      "Epoch 135/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.8786 - val_loss: 1.2716\n",
      "Epoch 136/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8785 - val_loss: 1.2700\n",
      "Epoch 137/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8784 - val_loss: 1.2778\n",
      "Epoch 138/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.8784 - val_loss: 1.2707\n",
      "Epoch 139/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.8783 - val_loss: 1.2736\n",
      "Epoch 140/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8782 - val_loss: 1.2779\n",
      "Epoch 141/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8782 - val_loss: 1.2712\n",
      "Epoch 142/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.8781 - val_loss: 1.2769\n",
      "Epoch 143/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.8780 - val_loss: 1.2762\n",
      "Epoch 144/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8780 - val_loss: 1.2720\n",
      "Epoch 145/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8780 - val_loss: 1.2776\n",
      "Epoch 146/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8779 - val_loss: 1.2725\n",
      "Epoch 147/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.8778 - val_loss: 1.2725\n",
      "Epoch 148/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8778 - val_loss: 1.2749\n",
      "Epoch 149/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8777 - val_loss: 1.2690\n",
      "Epoch 150/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.8777 - val_loss: 1.2723\n",
      "Epoch 151/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.8776 - val_loss: 1.2700\n",
      "Epoch 152/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8776 - val_loss: 1.2673\n",
      "Epoch 153/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.8775 - val_loss: 1.2704\n",
      "Epoch 154/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.8775 - val_loss: 1.2655\n",
      "Epoch 155/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.8775 - val_loss: 1.2671\n",
      "Epoch 156/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8774 - val_loss: 1.2664\n",
      "Epoch 157/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8774 - val_loss: 1.2634\n",
      "Epoch 158/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.8773 - val_loss: 1.2661\n",
      "Epoch 159/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.8773 - val_loss: 1.2623\n",
      "Epoch 160/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8772 - val_loss: 1.2636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8772 - val_loss: 1.2632\n",
      "Epoch 162/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8772 - val_loss: 1.2611\n",
      "Epoch 163/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.8771 - val_loss: 1.2636\n",
      "Epoch 164/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.8771 - val_loss: 1.2607\n",
      "Epoch 165/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8771 - val_loss: 1.2624\n",
      "Epoch 166/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.8770 - val_loss: 1.2617\n",
      "Epoch 167/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8770 - val_loss: 1.2609\n",
      "Epoch 168/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8769 - val_loss: 1.2625\n",
      "Epoch 169/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8769 - val_loss: 1.2601\n",
      "Epoch 170/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 0.8769 - val_loss: 1.2621\n",
      "Epoch 171/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8768 - val_loss: 1.2602\n",
      "Epoch 172/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8768 - val_loss: 1.2608\n",
      "Epoch 173/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8768 - val_loss: 1.2605\n",
      "Epoch 174/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 0.8767 - val_loss: 1.2593\n",
      "Epoch 175/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.8767 - val_loss: 1.2604\n",
      "Epoch 176/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8766 - val_loss: 1.2582\n",
      "Epoch 177/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8766 - val_loss: 1.2596\n",
      "Epoch 178/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.8766 - val_loss: 1.2577\n",
      "Epoch 179/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.8765 - val_loss: 1.2585\n",
      "Epoch 180/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8765 - val_loss: 1.2573\n",
      "Epoch 181/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8765 - val_loss: 1.2571\n",
      "Epoch 182/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.8764 - val_loss: 1.2570\n",
      "Epoch 183/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8764 - val_loss: 1.2559\n",
      "Epoch 184/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8764 - val_loss: 1.2565\n",
      "Epoch 185/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8763 - val_loss: 1.2548\n",
      "Epoch 186/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8763 - val_loss: 1.2559\n",
      "Epoch 187/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8763 - val_loss: 1.2540\n",
      "Epoch 188/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 0.8762 - val_loss: 1.2553\n",
      "Epoch 189/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8762 - val_loss: 1.2534\n",
      "Epoch 190/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8762 - val_loss: 1.2549\n",
      "Epoch 191/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8761 - val_loss: 1.2529\n",
      "Epoch 192/2500\n",
      "64/64 [==============================] - 0s 271us/step - loss: 0.8761 - val_loss: 1.2545\n",
      "Epoch 193/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8761 - val_loss: 1.2523\n",
      "Epoch 194/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8760 - val_loss: 1.2544\n",
      "Epoch 195/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.8760 - val_loss: 1.2515\n",
      "Epoch 196/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.8760 - val_loss: 1.2544\n",
      "Epoch 197/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.8759 - val_loss: 1.2503\n",
      "Epoch 198/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8759 - val_loss: 1.2549\n",
      "Epoch 199/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.8759 - val_loss: 1.2485\n",
      "Epoch 200/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.8759 - val_loss: 1.2564\n",
      "Epoch 201/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8758 - val_loss: 1.2453\n",
      "Epoch 202/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.8758 - val_loss: 1.2599\n",
      "Epoch 203/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.8759 - val_loss: 1.2392\n",
      "Epoch 204/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.8760 - val_loss: 1.2680\n",
      "Epoch 205/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.8762 - val_loss: 1.2274\n",
      "Epoch 206/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8768 - val_loss: 1.2875\n",
      "Epoch 207/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.8781 - val_loss: 1.2040\n",
      "Epoch 208/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8810 - val_loss: 1.3367\n",
      "Epoch 209/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8873 - val_loss: 1.1634\n",
      "Epoch 210/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.9015 - val_loss: 1.4676\n",
      "Epoch 211/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.9305 - val_loss: 1.1299\n",
      "Epoch 212/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.9888 - val_loss: 1.7382\n",
      "Epoch 213/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 1.0637 - val_loss: 1.1498\n",
      "Epoch 214/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1188 - val_loss: 1.6473\n",
      "Epoch 215/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.0237 - val_loss: 1.1512\n",
      "Epoch 216/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8943 - val_loss: 1.1273\n",
      "Epoch 217/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.9062 - val_loss: 1.5343\n",
      "Epoch 218/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.9845 - val_loss: 1.0861\n",
      "Epoch 219/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.9438 - val_loss: 1.1863\n",
      "Epoch 220/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8785 - val_loss: 1.3922\n",
      "Epoch 221/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.9309 - val_loss: 1.0751\n",
      "Epoch 222/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.9443 - val_loss: 1.2347\n",
      "Epoch 223/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.8824 - val_loss: 1.3319\n",
      "Epoch 224/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.9041 - val_loss: 1.1027\n",
      "Epoch 225/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.9294 - val_loss: 1.2819\n",
      "Epoch 226/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.8837 - val_loss: 1.3283\n",
      "Epoch 227/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8909 - val_loss: 1.1491\n",
      "Epoch 228/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.9152 - val_loss: 1.3215\n",
      "Epoch 229/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.8834 - val_loss: 1.3366\n",
      "Epoch 230/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 0.8845 - val_loss: 1.1844\n",
      "Epoch 231/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.9050 - val_loss: 1.3424\n",
      "Epoch 232/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8832 - val_loss: 1.3289\n",
      "Epoch 233/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.8803 - val_loss: 1.2013\n",
      "Epoch 234/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.8972 - val_loss: 1.3471\n",
      "Epoch 235/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8835 - val_loss: 1.3102\n",
      "Epoch 236/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8778 - val_loss: 1.2098\n",
      "Epoch 237/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 0.8905 - val_loss: 1.3403\n",
      "Epoch 238/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.8826 - val_loss: 1.2920\n",
      "Epoch 239/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.8763 - val_loss: 1.2126\n",
      "Epoch 240/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.8854 - val_loss: 1.3236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8810 - val_loss: 1.2739\n",
      "Epoch 242/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 0.8757 - val_loss: 1.2075\n",
      "Epoch 243/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8822 - val_loss: 1.3013\n",
      "Epoch 244/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.8795 - val_loss: 1.2552\n",
      "Epoch 245/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.8753 - val_loss: 1.2009\n",
      "Epoch 246/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.8800 - val_loss: 1.2841\n",
      "Epoch 247/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8785 - val_loss: 1.2431\n",
      "Epoch 248/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.8751 - val_loss: 1.2030\n",
      "Epoch 249/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.8783 - val_loss: 1.2789\n",
      "Epoch 250/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8777 - val_loss: 1.2410\n",
      "Epoch 251/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.8748 - val_loss: 1.2143\n",
      "Epoch 252/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 0.8769 - val_loss: 1.2818\n",
      "Epoch 253/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.8770 - val_loss: 1.2427\n",
      "Epoch 254/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8747 - val_loss: 1.2273\n",
      "Epoch 255/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.8757 - val_loss: 1.2841\n",
      "Epoch 256/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.8764 - val_loss: 1.2412\n",
      "Epoch 257/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 0.8746 - val_loss: 1.2377\n",
      "Epoch 258/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8748 - val_loss: 1.2818\n",
      "Epoch 259/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.8758 - val_loss: 1.2372\n",
      "Epoch 260/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.8748 - val_loss: 1.2468\n",
      "Epoch 261/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.8742 - val_loss: 1.2757\n",
      "Epoch 262/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.8751 - val_loss: 1.2337\n",
      "Epoch 263/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8748 - val_loss: 1.2541\n",
      "Epoch 264/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8740 - val_loss: 1.2656\n",
      "Epoch 265/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.8744 - val_loss: 1.2305\n",
      "Epoch 266/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.8747 - val_loss: 1.2567\n",
      "Epoch 267/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.8740 - val_loss: 1.2519\n",
      "Epoch 268/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.8739 - val_loss: 1.2278\n",
      "Epoch 269/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8743 - val_loss: 1.2550\n",
      "Epoch 270/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8741 - val_loss: 1.2384\n",
      "Epoch 271/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8737 - val_loss: 1.2285\n",
      "Epoch 272/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.8739 - val_loss: 1.2518\n",
      "Epoch 273/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 0.8740 - val_loss: 1.2299\n",
      "Epoch 274/2500\n",
      "64/64 [==============================] - 0s 329us/step - loss: 0.8737 - val_loss: 1.2340\n",
      "Epoch 275/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.8735 - val_loss: 1.2482\n",
      "Epoch 276/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.8737 - val_loss: 1.2271\n",
      "Epoch 277/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 0.8737 - val_loss: 1.2411\n",
      "Epoch 278/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 0.8734 - val_loss: 1.2429\n",
      "Epoch 279/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.8734 - val_loss: 1.2285\n",
      "Epoch 280/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.8735 - val_loss: 1.2457\n",
      "Epoch 281/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.8734 - val_loss: 1.2366\n",
      "Epoch 282/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 0.8733 - val_loss: 1.2326\n",
      "Epoch 283/2500\n",
      "64/64 [==============================] - 0s 481us/step - loss: 0.8733 - val_loss: 1.2461\n",
      "Epoch 284/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.8733 - val_loss: 1.2320\n",
      "Epoch 285/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.8732 - val_loss: 1.2382\n",
      "Epoch 286/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.8731 - val_loss: 1.2423\n",
      "Epoch 287/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.8731 - val_loss: 1.2307\n",
      "Epoch 288/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.8731 - val_loss: 1.2417\n",
      "Epoch 289/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.8731 - val_loss: 1.2360\n",
      "Epoch 290/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.8730 - val_loss: 1.2319\n",
      "Epoch 291/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 0.8730 - val_loss: 1.2404\n",
      "Epoch 292/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.8730 - val_loss: 1.2300\n",
      "Epoch 293/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.8729 - val_loss: 1.2340\n",
      "Epoch 294/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8728 - val_loss: 1.2354\n",
      "Epoch 295/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8728 - val_loss: 1.2277\n",
      "Epoch 296/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8728 - val_loss: 1.2353\n",
      "Epoch 297/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8728 - val_loss: 1.2302\n",
      "Epoch 298/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.8727 - val_loss: 1.2294\n",
      "Epoch 299/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.8727 - val_loss: 1.2343\n",
      "Epoch 300/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8727 - val_loss: 1.2274\n",
      "Epoch 301/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 0.8726 - val_loss: 1.2321\n",
      "Epoch 302/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.8726 - val_loss: 1.2310\n",
      "Epoch 303/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8725 - val_loss: 1.2277\n",
      "Epoch 304/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.8725 - val_loss: 1.2329\n",
      "Epoch 305/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8725 - val_loss: 1.2278\n",
      "Epoch 306/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.8724 - val_loss: 1.2300\n",
      "Epoch 307/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8724 - val_loss: 1.2310\n",
      "Epoch 308/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.8724 - val_loss: 1.2272\n",
      "Epoch 309/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 0.8723 - val_loss: 1.2314\n",
      "Epoch 310/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.8723 - val_loss: 1.2280\n",
      "Epoch 311/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8723 - val_loss: 1.2285\n",
      "Epoch 312/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8722 - val_loss: 1.2300\n",
      "Epoch 313/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 0.8722 - val_loss: 1.2263\n",
      "Epoch 314/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.8722 - val_loss: 1.2292\n",
      "Epoch 315/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.8721 - val_loss: 1.2268\n",
      "Epoch 316/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.8721 - val_loss: 1.2265\n",
      "Epoch 317/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.8721 - val_loss: 1.2279\n",
      "Epoch 318/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.8720 - val_loss: 1.2248\n",
      "Epoch 319/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8720 - val_loss: 1.2270\n",
      "Epoch 320/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 0.8720 - val_loss: 1.2253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8719 - val_loss: 1.2249\n",
      "Epoch 322/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.8719 - val_loss: 1.2261\n",
      "Epoch 323/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8719 - val_loss: 1.2237\n",
      "Epoch 324/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 0.8718 - val_loss: 1.2255\n",
      "Epoch 325/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8718 - val_loss: 1.2241\n",
      "Epoch 326/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.8718 - val_loss: 1.2239\n",
      "Epoch 327/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.8717 - val_loss: 1.2247\n",
      "Epoch 328/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8717 - val_loss: 1.2228\n",
      "Epoch 329/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8717 - val_loss: 1.2243\n",
      "Epoch 330/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.8716 - val_loss: 1.2229\n",
      "Epoch 331/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8716 - val_loss: 1.2230\n",
      "Epoch 332/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.8716 - val_loss: 1.2234\n",
      "Epoch 333/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8715 - val_loss: 1.2220\n",
      "Epoch 334/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8715 - val_loss: 1.2231\n",
      "Epoch 335/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.8715 - val_loss: 1.2217\n",
      "Epoch 336/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.8714 - val_loss: 1.2220\n",
      "Epoch 337/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8714 - val_loss: 1.2217\n",
      "Epoch 338/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.8714 - val_loss: 1.2208\n",
      "Epoch 339/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8713 - val_loss: 1.2215\n",
      "Epoch 340/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.8713 - val_loss: 1.2202\n",
      "Epoch 341/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.8713 - val_loss: 1.2207\n",
      "Epoch 342/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.8712 - val_loss: 1.2200\n",
      "Epoch 343/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.8712 - val_loss: 1.2197\n",
      "Epoch 344/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.8712 - val_loss: 1.2199\n",
      "Epoch 345/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.8711 - val_loss: 1.2189\n",
      "Epoch 346/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8711 - val_loss: 1.2194\n",
      "Epoch 347/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.8711 - val_loss: 1.2185\n",
      "Epoch 348/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 0.8710 - val_loss: 1.2186\n",
      "Epoch 349/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8710 - val_loss: 1.2183\n",
      "Epoch 350/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 0.8710 - val_loss: 1.2178\n",
      "Epoch 351/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.8709 - val_loss: 1.2181\n",
      "Epoch 352/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8709 - val_loss: 1.2173\n",
      "Epoch 353/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 0.8709 - val_loss: 1.2176\n",
      "Epoch 354/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.8708 - val_loss: 1.2169\n",
      "Epoch 355/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8708 - val_loss: 1.2169\n",
      "Epoch 356/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.8707 - val_loss: 1.2166\n",
      "Epoch 357/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.8707 - val_loss: 1.2162\n",
      "Epoch 358/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.8707 - val_loss: 1.2162\n",
      "Epoch 359/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8706 - val_loss: 1.2156\n",
      "Epoch 360/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.8706 - val_loss: 1.2157\n",
      "Epoch 361/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.8706 - val_loss: 1.2151\n",
      "Epoch 362/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.8705 - val_loss: 1.2150\n",
      "Epoch 363/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8705 - val_loss: 1.2147\n",
      "Epoch 364/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.8705 - val_loss: 1.2144\n",
      "Epoch 365/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.8704 - val_loss: 1.2143\n",
      "Epoch 366/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8704 - val_loss: 1.2138\n",
      "Epoch 367/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8704 - val_loss: 1.2138\n",
      "Epoch 368/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.8703 - val_loss: 1.2133\n",
      "Epoch 369/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.8703 - val_loss: 1.2133\n",
      "Epoch 370/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.8703 - val_loss: 1.2128\n",
      "Epoch 371/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 0.8702 - val_loss: 1.2127\n",
      "Epoch 372/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.8702 - val_loss: 1.2124\n",
      "Epoch 373/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8702 - val_loss: 1.2121\n",
      "Epoch 374/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.8701 - val_loss: 1.2120\n",
      "Epoch 375/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8701 - val_loss: 1.2116\n",
      "Epoch 376/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.8701 - val_loss: 1.2115\n",
      "Epoch 377/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.8700 - val_loss: 1.2111\n",
      "Epoch 378/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.8700 - val_loss: 1.2110\n",
      "Epoch 379/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.8699 - val_loss: 1.2106\n",
      "Epoch 380/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.8699 - val_loss: 1.2105\n",
      "Epoch 381/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8699 - val_loss: 1.2101\n",
      "Epoch 382/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 0.8698 - val_loss: 1.2099\n",
      "Epoch 383/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8698 - val_loss: 1.2096\n",
      "Epoch 384/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8698 - val_loss: 1.2094\n",
      "Epoch 385/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8697 - val_loss: 1.2092\n",
      "Epoch 386/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.8697 - val_loss: 1.2089\n",
      "Epoch 387/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.8697 - val_loss: 1.2087\n",
      "Epoch 388/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.8696 - val_loss: 1.2084\n",
      "Epoch 389/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.8696 - val_loss: 1.2082\n",
      "Epoch 390/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8695 - val_loss: 1.2079\n",
      "Epoch 391/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8695 - val_loss: 1.2078\n",
      "Epoch 392/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.8695 - val_loss: 1.2074\n",
      "Epoch 393/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8694 - val_loss: 1.2073\n",
      "Epoch 394/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8694 - val_loss: 1.2069\n",
      "Epoch 395/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.8694 - val_loss: 1.2068\n",
      "Epoch 396/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.8693 - val_loss: 1.2064\n",
      "Epoch 397/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.8693 - val_loss: 1.2063\n",
      "Epoch 398/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8692 - val_loss: 1.2059\n",
      "Epoch 399/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.8692 - val_loss: 1.2059\n",
      "Epoch 400/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.8692 - val_loss: 1.2055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2500\n",
      "64/64 [==============================] - 0s 356us/step - loss: 0.8691 - val_loss: 1.2054\n",
      "Epoch 402/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8691 - val_loss: 1.2050\n",
      "Epoch 403/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.8691 - val_loss: 1.2049\n",
      "Epoch 404/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.8690 - val_loss: 1.2045\n",
      "Epoch 405/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8690 - val_loss: 1.2045\n",
      "Epoch 406/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 0.8689 - val_loss: 1.2040\n",
      "Epoch 407/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8689 - val_loss: 1.2041\n",
      "Epoch 408/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8689 - val_loss: 1.2034\n",
      "Epoch 409/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.8688 - val_loss: 1.2037\n",
      "Epoch 410/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.8688 - val_loss: 1.2029\n",
      "Epoch 411/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.8687 - val_loss: 1.2034\n",
      "Epoch 412/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8687 - val_loss: 1.2023\n",
      "Epoch 413/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8687 - val_loss: 1.2031\n",
      "Epoch 414/2500\n",
      "64/64 [==============================] - 0s 299us/step - loss: 0.8686 - val_loss: 1.2015\n",
      "Epoch 415/2500\n",
      "64/64 [==============================] - 0s 346us/step - loss: 0.8686 - val_loss: 1.2030\n",
      "Epoch 416/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.8685 - val_loss: 1.2006\n",
      "Epoch 417/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.8685 - val_loss: 1.2032\n",
      "Epoch 418/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 0.8685 - val_loss: 1.1993\n",
      "Epoch 419/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8684 - val_loss: 1.2039\n",
      "Epoch 420/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8684 - val_loss: 1.1974\n",
      "Epoch 421/2500\n",
      "64/64 [==============================] - 0s 922us/step - loss: 0.8684 - val_loss: 1.2055\n",
      "Epoch 422/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8683 - val_loss: 1.1942\n",
      "Epoch 423/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.8683 - val_loss: 1.2089\n",
      "Epoch 424/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.8684 - val_loss: 1.1889\n",
      "Epoch 425/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8684 - val_loss: 1.2158\n",
      "Epoch 426/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.8686 - val_loss: 1.1793\n",
      "Epoch 427/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.8690 - val_loss: 1.2300\n",
      "Epoch 428/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.8697 - val_loss: 1.1624\n",
      "Epoch 429/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.8711 - val_loss: 1.2599\n",
      "Epoch 430/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.8738 - val_loss: 1.1341\n",
      "Epoch 431/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.8792 - val_loss: 1.3245\n",
      "Epoch 432/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8890 - val_loss: 1.0957\n",
      "Epoch 433/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.9077 - val_loss: 1.4574\n",
      "Epoch 434/2500\n",
      "64/64 [==============================] - 0s 440us/step - loss: 0.9371 - val_loss: 1.0718\n",
      "Epoch 435/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.9827 - val_loss: 1.6218\n",
      "Epoch 436/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.0171 - val_loss: 1.0653\n",
      "Epoch 437/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.0213 - val_loss: 1.4573\n",
      "Epoch 438/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.9490 - val_loss: 1.1065\n",
      "Epoch 439/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8788 - val_loss: 1.0851\n",
      "Epoch 440/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8837 - val_loss: 1.3839\n",
      "Epoch 441/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.9308 - val_loss: 1.0317\n",
      "Epoch 442/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.9309 - val_loss: 1.2358\n",
      "Epoch 443/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8822 - val_loss: 1.2063\n",
      "Epoch 444/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.8742 - val_loss: 1.0660\n",
      "Epoch 445/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.9064 - val_loss: 1.3541\n",
      "Epoch 446/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.9048 - val_loss: 1.1452\n",
      "Epoch 447/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.8743 - val_loss: 1.1660\n",
      "Epoch 448/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 0.8725 - val_loss: 1.3628\n",
      "Epoch 449/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 0.8937 - val_loss: 1.1441\n",
      "Epoch 450/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8903 - val_loss: 1.2666\n",
      "Epoch 451/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8701 - val_loss: 1.2859\n",
      "Epoch 452/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 0.8729 - val_loss: 1.1475\n",
      "Epoch 453/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8867 - val_loss: 1.3167\n",
      "Epoch 454/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8803 - val_loss: 1.2028\n",
      "Epoch 455/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.8678 - val_loss: 1.1678\n",
      "Epoch 456/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8724 - val_loss: 1.3018\n",
      "Epoch 457/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.8791 - val_loss: 1.1590\n",
      "Epoch 458/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.8721 - val_loss: 1.1918\n",
      "Epoch 459/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8670 - val_loss: 1.2570\n",
      "Epoch 460/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8729 - val_loss: 1.1358\n",
      "Epoch 461/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 0.8739 - val_loss: 1.2075\n",
      "Epoch 462/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8675 - val_loss: 1.2124\n",
      "Epoch 463/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.8681 - val_loss: 1.1336\n",
      "Epoch 464/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8721 - val_loss: 1.2271\n",
      "Epoch 465/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.8694 - val_loss: 1.1872\n",
      "Epoch 466/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.8661 - val_loss: 1.1583\n",
      "Epoch 467/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.8685 - val_loss: 1.2451\n",
      "Epoch 468/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.8697 - val_loss: 1.1778\n",
      "Epoch 469/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.8669 - val_loss: 1.1916\n",
      "Epoch 470/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.8660 - val_loss: 1.2415\n",
      "Epoch 471/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.8681 - val_loss: 1.1709\n",
      "Epoch 472/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.8680 - val_loss: 1.2162\n",
      "Epoch 473/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.8659 - val_loss: 1.2166\n",
      "Epoch 474/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8659 - val_loss: 1.1708\n",
      "Epoch 475/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.8673 - val_loss: 1.2269\n",
      "Epoch 476/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.8667 - val_loss: 1.1899\n",
      "Epoch 477/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 0.8654 - val_loss: 1.1807\n",
      "Epoch 478/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8656 - val_loss: 1.2203\n",
      "Epoch 479/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.8664 - val_loss: 1.1715\n",
      "Epoch 480/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8659 - val_loss: 1.1913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 0.8651 - val_loss: 1.2014\n",
      "Epoch 482/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.8654 - val_loss: 1.1646\n",
      "Epoch 483/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.8658 - val_loss: 1.2000\n",
      "Epoch 484/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.8653 - val_loss: 1.1848\n",
      "Epoch 485/2500\n",
      "64/64 [==============================] - 0s 210us/step - loss: 0.8648 - val_loss: 1.1732\n",
      "Epoch 486/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.8651 - val_loss: 1.2057\n",
      "Epoch 487/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 0.8652 - val_loss: 1.1781\n",
      "Epoch 488/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8648 - val_loss: 1.1895\n",
      "Epoch 489/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8645 - val_loss: 1.2030\n",
      "Epoch 490/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8647 - val_loss: 1.1779\n",
      "Epoch 491/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.8648 - val_loss: 1.2009\n",
      "Epoch 492/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8645 - val_loss: 1.1928\n",
      "Epoch 493/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8643 - val_loss: 1.1821\n",
      "Epoch 494/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.8644 - val_loss: 1.2029\n",
      "Epoch 495/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8644 - val_loss: 1.1834\n",
      "Epoch 496/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.8641 - val_loss: 1.1893\n",
      "Epoch 497/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.8640 - val_loss: 1.1972\n",
      "Epoch 498/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8640 - val_loss: 1.1794\n",
      "Epoch 499/2500\n",
      "64/64 [==============================] - 0s 409us/step - loss: 0.8640 - val_loss: 1.1938\n",
      "Epoch 500/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 0.8638 - val_loss: 1.1876\n",
      "Epoch 501/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8637 - val_loss: 1.1802\n",
      "Epoch 502/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8637 - val_loss: 1.1936\n",
      "Epoch 503/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8637 - val_loss: 1.1808\n",
      "Epoch 504/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.8635 - val_loss: 1.1853\n",
      "Epoch 505/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.8634 - val_loss: 1.1911\n",
      "Epoch 506/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.8634 - val_loss: 1.1804\n",
      "Epoch 507/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.8633 - val_loss: 1.1913\n",
      "Epoch 508/2500\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.8632 - val_loss: 1.1877\n",
      "Epoch 509/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.8631 - val_loss: 1.1841\n",
      "Epoch 510/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 0.8630 - val_loss: 1.1932\n",
      "Epoch 511/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 0.8630 - val_loss: 1.1844\n",
      "Epoch 512/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8629 - val_loss: 1.1881\n",
      "Epoch 513/2500\n",
      "64/64 [==============================] - 0s 346us/step - loss: 0.8628 - val_loss: 1.1906\n",
      "Epoch 514/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8627 - val_loss: 1.1834\n",
      "Epoch 515/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 0.8626 - val_loss: 1.1905\n",
      "Epoch 516/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.8625 - val_loss: 1.1866\n",
      "Epoch 517/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8624 - val_loss: 1.1847\n",
      "Epoch 518/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 0.8623 - val_loss: 1.1898\n",
      "Epoch 519/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8623 - val_loss: 1.1833\n",
      "Epoch 520/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8622 - val_loss: 1.1865\n",
      "Epoch 521/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8621 - val_loss: 1.1868\n",
      "Epoch 522/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.8620 - val_loss: 1.1826\n",
      "Epoch 523/2500\n",
      "64/64 [==============================] - 0s 404us/step - loss: 0.8619 - val_loss: 1.1876\n",
      "Epoch 524/2500\n",
      "64/64 [==============================] - 0s 470us/step - loss: 0.8618 - val_loss: 1.1842\n",
      "Epoch 525/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8617 - val_loss: 1.1845\n",
      "Epoch 526/2500\n",
      "64/64 [==============================] - 0s 385us/step - loss: 0.8616 - val_loss: 1.1875\n",
      "Epoch 527/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8615 - val_loss: 1.1835\n",
      "Epoch 528/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 0.8614 - val_loss: 1.1868\n",
      "Epoch 529/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8613 - val_loss: 1.1860\n",
      "Epoch 530/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8612 - val_loss: 1.1842\n",
      "Epoch 531/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8611 - val_loss: 1.1874\n",
      "Epoch 532/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.8610 - val_loss: 1.1843\n",
      "Epoch 533/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 0.8609 - val_loss: 1.1855\n",
      "Epoch 534/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8608 - val_loss: 1.1863\n",
      "Epoch 535/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8607 - val_loss: 1.1838\n",
      "Epoch 536/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8606 - val_loss: 1.1862\n",
      "Epoch 537/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 0.8605 - val_loss: 1.1846\n",
      "Epoch 538/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.8604 - val_loss: 1.1842\n",
      "Epoch 539/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8603 - val_loss: 1.1857\n",
      "Epoch 540/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.8602 - val_loss: 1.1834\n",
      "Epoch 541/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8601 - val_loss: 1.1850\n",
      "Epoch 542/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 0.8600 - val_loss: 1.1846\n",
      "Epoch 543/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8599 - val_loss: 1.1837\n",
      "Epoch 544/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8597 - val_loss: 1.1854\n",
      "Epoch 545/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8596 - val_loss: 1.1839\n",
      "Epoch 546/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8595 - val_loss: 1.1847\n",
      "Epoch 547/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.8594 - val_loss: 1.1851\n",
      "Epoch 548/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8593 - val_loss: 1.1840\n",
      "Epoch 549/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8591 - val_loss: 1.1854\n",
      "Epoch 550/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8590 - val_loss: 1.1844\n",
      "Epoch 551/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 0.8589 - val_loss: 1.1846\n",
      "Epoch 552/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.8588 - val_loss: 1.1852\n",
      "Epoch 553/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8586 - val_loss: 1.1841\n",
      "Epoch 554/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.8585 - val_loss: 1.1851\n",
      "Epoch 555/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 0.8584 - val_loss: 1.1846\n",
      "Epoch 556/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.8582 - val_loss: 1.1845\n",
      "Epoch 557/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8581 - val_loss: 1.1852\n",
      "Epoch 558/2500\n",
      "64/64 [==============================] - 0s 366us/step - loss: 0.8580 - val_loss: 1.1843\n",
      "Epoch 559/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.8578 - val_loss: 1.1850\n",
      "Epoch 560/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 0.8577 - val_loss: 1.1848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8575 - val_loss: 1.1845\n",
      "Epoch 562/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.8574 - val_loss: 1.1852\n",
      "Epoch 563/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8572 - val_loss: 1.1847\n",
      "Epoch 564/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.8571 - val_loss: 1.1851\n",
      "Epoch 565/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 0.8569 - val_loss: 1.1852\n",
      "Epoch 566/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8568 - val_loss: 1.1849\n",
      "Epoch 567/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 0.8566 - val_loss: 1.1856\n",
      "Epoch 568/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8565 - val_loss: 1.1851\n",
      "Epoch 569/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8563 - val_loss: 1.1854\n",
      "Epoch 570/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8562 - val_loss: 1.1856\n",
      "Epoch 571/2500\n",
      "64/64 [==============================] - 0s 448us/step - loss: 0.8560 - val_loss: 1.1853\n",
      "Epoch 572/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.8558 - val_loss: 1.1858\n",
      "Epoch 573/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.8556 - val_loss: 1.1855\n",
      "Epoch 574/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.8555 - val_loss: 1.1856\n",
      "Epoch 575/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.8553 - val_loss: 1.1859\n",
      "Epoch 576/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8551 - val_loss: 1.1856\n",
      "Epoch 577/2500\n",
      "64/64 [==============================] - 0s 357us/step - loss: 0.8549 - val_loss: 1.1860\n",
      "Epoch 578/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8548 - val_loss: 1.1858\n",
      "Epoch 579/2500\n",
      "64/64 [==============================] - 0s 323us/step - loss: 0.8546 - val_loss: 1.1859\n",
      "Epoch 580/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8544 - val_loss: 1.1862\n",
      "Epoch 581/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 0.8542 - val_loss: 1.1860\n",
      "Epoch 582/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8540 - val_loss: 1.1863\n",
      "Epoch 583/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8538 - val_loss: 1.1863\n",
      "Epoch 584/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8536 - val_loss: 1.1864\n",
      "Epoch 585/2500\n",
      "64/64 [==============================] - 0s 329us/step - loss: 0.8534 - val_loss: 1.1866\n",
      "Epoch 586/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8532 - val_loss: 1.1865\n",
      "Epoch 587/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8530 - val_loss: 1.1867\n",
      "Epoch 588/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 0.8528 - val_loss: 1.1867\n",
      "Epoch 589/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8526 - val_loss: 1.1867\n",
      "Epoch 590/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.8524 - val_loss: 1.1869\n",
      "Epoch 591/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.8521 - val_loss: 1.1868\n",
      "Epoch 592/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8519 - val_loss: 1.1870\n",
      "Epoch 593/2500\n",
      "64/64 [==============================] - 0s 333us/step - loss: 0.8517 - val_loss: 1.1870\n",
      "Epoch 594/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.8515 - val_loss: 1.1870\n",
      "Epoch 595/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.8512 - val_loss: 1.1872\n",
      "Epoch 596/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.8510 - val_loss: 1.1872\n",
      "Epoch 597/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.8507 - val_loss: 1.1873\n",
      "Epoch 598/2500\n",
      "64/64 [==============================] - 0s 406us/step - loss: 0.8505 - val_loss: 1.1873\n",
      "Epoch 599/2500\n",
      "64/64 [==============================] - 0s 322us/step - loss: 0.8503 - val_loss: 1.1874\n",
      "Epoch 600/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.8500 - val_loss: 1.1875\n",
      "Epoch 601/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 0.8497 - val_loss: 1.1875\n",
      "Epoch 602/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.8495 - val_loss: 1.1876\n",
      "Epoch 603/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.8492 - val_loss: 1.1876\n",
      "Epoch 604/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8490 - val_loss: 1.1876\n",
      "Epoch 605/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.8487 - val_loss: 1.1878\n",
      "Epoch 606/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.8484 - val_loss: 1.1877\n",
      "Epoch 607/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8481 - val_loss: 1.1878\n",
      "Epoch 608/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8478 - val_loss: 1.1878\n",
      "Epoch 609/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 0.8475 - val_loss: 1.1878\n",
      "Epoch 610/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8473 - val_loss: 1.1879\n",
      "Epoch 611/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8470 - val_loss: 1.1879\n",
      "Epoch 612/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.8466 - val_loss: 1.1880\n",
      "Epoch 613/2500\n",
      "64/64 [==============================] - 0s 890us/step - loss: 0.8463 - val_loss: 1.1880\n",
      "Epoch 614/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.8460 - val_loss: 1.1880\n",
      "Epoch 615/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 0.8457 - val_loss: 1.1881\n",
      "Epoch 616/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8454 - val_loss: 1.1880\n",
      "Epoch 617/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8451 - val_loss: 1.1881\n",
      "Epoch 618/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 0.8447 - val_loss: 1.1881\n",
      "Epoch 619/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.8444 - val_loss: 1.1881\n",
      "Epoch 620/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8440 - val_loss: 1.1881\n",
      "Epoch 621/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.8437 - val_loss: 1.1881\n",
      "Epoch 622/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.8433 - val_loss: 1.1881\n",
      "Epoch 623/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 0.8430 - val_loss: 1.1882\n",
      "Epoch 624/2500\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.8426 - val_loss: 1.1882\n",
      "Epoch 625/2500\n",
      "64/64 [==============================] - 0s 326us/step - loss: 0.8422 - val_loss: 1.1882\n",
      "Epoch 626/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8419 - val_loss: 1.1882\n",
      "Epoch 627/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.8415 - val_loss: 1.1882\n",
      "Epoch 628/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8411 - val_loss: 1.1882\n",
      "Epoch 629/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 0.8407 - val_loss: 1.1882\n",
      "Epoch 630/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.8403 - val_loss: 1.1883\n",
      "Epoch 631/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8399 - val_loss: 1.1883\n",
      "Epoch 632/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.8395 - val_loss: 1.1883\n",
      "Epoch 633/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.8391 - val_loss: 1.1883\n",
      "Epoch 634/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.8387 - val_loss: 1.1884\n",
      "Epoch 635/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.8382 - val_loss: 1.1884\n",
      "Epoch 636/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8378 - val_loss: 1.1884\n",
      "Epoch 637/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8374 - val_loss: 1.1885\n",
      "Epoch 638/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8369 - val_loss: 1.1885\n",
      "Epoch 639/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8365 - val_loss: 1.1886\n",
      "Epoch 640/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.8360 - val_loss: 1.1886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.8355 - val_loss: 1.1887\n",
      "Epoch 642/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8351 - val_loss: 1.1887\n",
      "Epoch 643/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8346 - val_loss: 1.1888\n",
      "Epoch 644/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8341 - val_loss: 1.1889\n",
      "Epoch 645/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.8336 - val_loss: 1.1889\n",
      "Epoch 646/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.8331 - val_loss: 1.1890\n",
      "Epoch 647/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.8326 - val_loss: 1.1891\n",
      "Epoch 648/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8321 - val_loss: 1.1892\n",
      "Epoch 649/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8316 - val_loss: 1.1893\n",
      "Epoch 650/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.8311 - val_loss: 1.1894\n",
      "Epoch 651/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8306 - val_loss: 1.1895\n",
      "Epoch 652/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.8301 - val_loss: 1.1896\n",
      "Epoch 653/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8295 - val_loss: 1.1897\n",
      "Epoch 654/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.8290 - val_loss: 1.1898\n",
      "Epoch 655/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8285 - val_loss: 1.1900\n",
      "Epoch 656/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.8279 - val_loss: 1.1901\n",
      "Epoch 657/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.8274 - val_loss: 1.1903\n",
      "Epoch 658/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.8268 - val_loss: 1.1904\n",
      "Epoch 659/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8263 - val_loss: 1.1906\n",
      "Epoch 660/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.8257 - val_loss: 1.1908\n",
      "Epoch 661/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8252 - val_loss: 1.1909\n",
      "Epoch 662/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8246 - val_loss: 1.1911\n",
      "Epoch 663/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.8240 - val_loss: 1.1913\n",
      "Epoch 664/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 0.8235 - val_loss: 1.1915\n",
      "Epoch 665/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8229 - val_loss: 1.1917\n",
      "Epoch 666/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8224 - val_loss: 1.1920\n",
      "Epoch 667/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8218 - val_loss: 1.1922\n",
      "Epoch 668/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.8212 - val_loss: 1.1925\n",
      "Epoch 669/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8207 - val_loss: 1.1927\n",
      "Epoch 670/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8201 - val_loss: 1.1930\n",
      "Epoch 671/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8195 - val_loss: 1.1933\n",
      "Epoch 672/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8190 - val_loss: 1.1936\n",
      "Epoch 673/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.8184 - val_loss: 1.1939\n",
      "Epoch 674/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.8179 - val_loss: 1.1942\n",
      "Epoch 675/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.8173 - val_loss: 1.1945\n",
      "Epoch 676/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8168 - val_loss: 1.1948\n",
      "Epoch 677/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8162 - val_loss: 1.1952\n",
      "Epoch 678/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8157 - val_loss: 1.1955\n",
      "Epoch 679/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8151 - val_loss: 1.1959\n",
      "Epoch 680/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8146 - val_loss: 1.1963\n",
      "Epoch 681/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.8141 - val_loss: 1.1967\n",
      "Epoch 682/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.8136 - val_loss: 1.1971\n",
      "Epoch 683/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8131 - val_loss: 1.1975\n",
      "Epoch 684/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8126 - val_loss: 1.1980\n",
      "Epoch 685/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.8121 - val_loss: 1.1984\n",
      "Epoch 686/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 0.8116 - val_loss: 1.1989\n",
      "Epoch 687/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8112 - val_loss: 1.1994\n",
      "Epoch 688/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8107 - val_loss: 1.1999\n",
      "Epoch 689/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8103 - val_loss: 1.2004\n",
      "Epoch 690/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8098 - val_loss: 1.2009\n",
      "Epoch 691/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 0.8094 - val_loss: 1.2014\n",
      "Epoch 692/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8090 - val_loss: 1.2019\n",
      "Epoch 693/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8086 - val_loss: 1.2025\n",
      "Epoch 694/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8082 - val_loss: 1.2030\n",
      "Epoch 695/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.8078 - val_loss: 1.2036\n",
      "Epoch 696/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.8075 - val_loss: 1.2042\n",
      "Epoch 697/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8071 - val_loss: 1.2048\n",
      "Epoch 698/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.8068 - val_loss: 1.2053\n",
      "Epoch 699/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8064 - val_loss: 1.2059\n",
      "Epoch 700/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8061 - val_loss: 1.2065\n",
      "Epoch 701/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.8058 - val_loss: 1.2071\n",
      "Epoch 702/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.8055 - val_loss: 1.2077\n",
      "Epoch 703/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8052 - val_loss: 1.2083\n",
      "Epoch 704/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.8050 - val_loss: 1.2089\n",
      "Epoch 705/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.8047 - val_loss: 1.2095\n",
      "Epoch 706/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8044 - val_loss: 1.2101\n",
      "Epoch 707/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8042 - val_loss: 1.2106\n",
      "Epoch 708/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.8039 - val_loss: 1.2112\n",
      "Epoch 709/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8037 - val_loss: 1.2118\n",
      "Epoch 710/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.8035 - val_loss: 1.2123\n",
      "Epoch 711/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.8033 - val_loss: 1.2128\n",
      "Epoch 712/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8031 - val_loss: 1.2133\n",
      "Epoch 713/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.8029 - val_loss: 1.2138\n",
      "Epoch 714/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.8027 - val_loss: 1.2143\n",
      "Epoch 715/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.8025 - val_loss: 1.2148\n",
      "Epoch 716/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.8023 - val_loss: 1.2152\n",
      "Epoch 717/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 0.8021 - val_loss: 1.2157\n",
      "Epoch 718/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.8019 - val_loss: 1.2161\n",
      "Epoch 719/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.8017 - val_loss: 1.2164\n",
      "Epoch 720/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8016 - val_loss: 1.2168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8014 - val_loss: 1.2172\n",
      "Epoch 722/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.8012 - val_loss: 1.2175\n",
      "Epoch 723/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8011 - val_loss: 1.2178\n",
      "Epoch 724/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8009 - val_loss: 1.2181\n",
      "Epoch 725/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.8008 - val_loss: 1.2184\n",
      "Epoch 726/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8006 - val_loss: 1.2186\n",
      "Epoch 727/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 0.8004 - val_loss: 1.2188\n",
      "Epoch 728/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.8003 - val_loss: 1.2191\n",
      "Epoch 729/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.8001 - val_loss: 1.2193\n",
      "Epoch 730/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8000 - val_loss: 1.2195\n",
      "Epoch 731/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7998 - val_loss: 1.2197\n",
      "Epoch 732/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.7997 - val_loss: 1.2199\n",
      "Epoch 733/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.7995 - val_loss: 1.2200\n",
      "Epoch 734/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7994 - val_loss: 1.2202\n",
      "Epoch 735/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7992 - val_loss: 1.2204\n",
      "Epoch 736/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.7991 - val_loss: 1.2205\n",
      "Epoch 737/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.7989 - val_loss: 1.2207\n",
      "Epoch 738/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.7988 - val_loss: 1.2208\n",
      "Epoch 739/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7986 - val_loss: 1.2210\n",
      "Epoch 740/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7985 - val_loss: 1.2211\n",
      "Epoch 741/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 0.7983 - val_loss: 1.2212\n",
      "Epoch 742/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.7982 - val_loss: 1.2214\n",
      "Epoch 743/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.7980 - val_loss: 1.2215\n",
      "Epoch 744/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.7979 - val_loss: 1.2217\n",
      "Epoch 745/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7977 - val_loss: 1.2218\n",
      "Epoch 746/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.7976 - val_loss: 1.2220\n",
      "Epoch 747/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 0.7974 - val_loss: 1.2222\n",
      "Epoch 748/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.7973 - val_loss: 1.2223\n",
      "Epoch 749/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7971 - val_loss: 1.2225\n",
      "Epoch 750/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.7970 - val_loss: 1.2227\n",
      "Epoch 751/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.7968 - val_loss: 1.2228\n",
      "Epoch 752/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.7967 - val_loss: 1.2230\n",
      "Epoch 753/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.7965 - val_loss: 1.2232\n",
      "Epoch 754/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.7963 - val_loss: 1.2234\n",
      "Epoch 755/2500\n",
      "64/64 [==============================] - 0s 405us/step - loss: 0.7962 - val_loss: 1.2236\n",
      "Epoch 756/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7960 - val_loss: 1.2238\n",
      "Epoch 757/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.7959 - val_loss: 1.2240\n",
      "Epoch 758/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7957 - val_loss: 1.2242\n",
      "Epoch 759/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.7955 - val_loss: 1.2244\n",
      "Epoch 760/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7954 - val_loss: 1.2246\n",
      "Epoch 761/2500\n",
      "64/64 [==============================] - 0s 40us/step - loss: 0.7952 - val_loss: 1.2248\n",
      "Epoch 762/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.7950 - val_loss: 1.2250\n",
      "Epoch 763/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.7948 - val_loss: 1.2252\n",
      "Epoch 764/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7947 - val_loss: 1.2254\n",
      "Epoch 765/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.7945 - val_loss: 1.2256\n",
      "Epoch 766/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7943 - val_loss: 1.2258\n",
      "Epoch 767/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.7941 - val_loss: 1.2261\n",
      "Epoch 768/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 0.7940 - val_loss: 1.2263\n",
      "Epoch 769/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.7938 - val_loss: 1.2265\n",
      "Epoch 770/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7936 - val_loss: 1.2267\n",
      "Epoch 771/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.7934 - val_loss: 1.2269\n",
      "Epoch 772/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.7932 - val_loss: 1.2271\n",
      "Epoch 773/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7930 - val_loss: 1.2273\n",
      "Epoch 774/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7928 - val_loss: 1.2275\n",
      "Epoch 775/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.7926 - val_loss: 1.2277\n",
      "Epoch 776/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.7924 - val_loss: 1.2279\n",
      "Epoch 777/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 0.7922 - val_loss: 1.2281\n",
      "Epoch 778/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7920 - val_loss: 1.2283\n",
      "Epoch 779/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7918 - val_loss: 1.2285\n",
      "Epoch 780/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.7916 - val_loss: 1.2287\n",
      "Epoch 781/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7914 - val_loss: 1.2288\n",
      "Epoch 782/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.7912 - val_loss: 1.2290\n",
      "Epoch 783/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 0.7909 - val_loss: 1.2292\n",
      "Epoch 784/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7907 - val_loss: 1.2293\n",
      "Epoch 785/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.7905 - val_loss: 1.2295\n",
      "Epoch 786/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.7902 - val_loss: 1.2296\n",
      "Epoch 787/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.7900 - val_loss: 1.2298\n",
      "Epoch 788/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.7898 - val_loss: 1.2299\n",
      "Epoch 789/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7895 - val_loss: 1.2300\n",
      "Epoch 790/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.7893 - val_loss: 1.2301\n",
      "Epoch 791/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.7890 - val_loss: 1.2302\n",
      "Epoch 792/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.7888 - val_loss: 1.2304\n",
      "Epoch 793/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.7885 - val_loss: 1.2305\n",
      "Epoch 794/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7882 - val_loss: 1.2305\n",
      "Epoch 795/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.7880 - val_loss: 1.2307\n",
      "Epoch 796/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7877 - val_loss: 1.2307\n",
      "Epoch 797/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.7874 - val_loss: 1.2308\n",
      "Epoch 798/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.7871 - val_loss: 1.2309\n",
      "Epoch 799/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7868 - val_loss: 1.2309\n",
      "Epoch 800/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.7865 - val_loss: 1.2310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 0.7862 - val_loss: 1.2310\n",
      "Epoch 802/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.7859 - val_loss: 1.2310\n",
      "Epoch 803/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.7856 - val_loss: 1.2311\n",
      "Epoch 804/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.7853 - val_loss: 1.2311\n",
      "Epoch 805/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7850 - val_loss: 1.2311\n",
      "Epoch 806/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.7847 - val_loss: 1.2311\n",
      "Epoch 807/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.7843 - val_loss: 1.2311\n",
      "Epoch 808/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7840 - val_loss: 1.2311\n",
      "Epoch 809/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.7837 - val_loss: 1.2310\n",
      "Epoch 810/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.7833 - val_loss: 1.2310\n",
      "Epoch 811/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.7829 - val_loss: 1.2309\n",
      "Epoch 812/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.7826 - val_loss: 1.2309\n",
      "Epoch 813/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.7822 - val_loss: 1.2308\n",
      "Epoch 814/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.7818 - val_loss: 1.2307\n",
      "Epoch 815/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.7815 - val_loss: 1.2306\n",
      "Epoch 816/2500\n",
      "64/64 [==============================] - 0s 421us/step - loss: 0.7811 - val_loss: 1.2305\n",
      "Epoch 817/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.7807 - val_loss: 1.2304\n",
      "Epoch 818/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 0.7803 - val_loss: 1.2303\n",
      "Epoch 819/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.7799 - val_loss: 1.2301\n",
      "Epoch 820/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.7794 - val_loss: 1.2300\n",
      "Epoch 821/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.7790 - val_loss: 1.2298\n",
      "Epoch 822/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.7786 - val_loss: 1.2297\n",
      "Epoch 823/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7782 - val_loss: 1.2295\n",
      "Epoch 824/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.7777 - val_loss: 1.2293\n",
      "Epoch 825/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7773 - val_loss: 1.2291\n",
      "Epoch 826/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7768 - val_loss: 1.2289\n",
      "Epoch 827/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.7764 - val_loss: 1.2287\n",
      "Epoch 828/2500\n",
      "64/64 [==============================] - 0s 39us/step - loss: 0.7759 - val_loss: 1.2285\n",
      "Epoch 829/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7754 - val_loss: 1.2283\n",
      "Epoch 830/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7749 - val_loss: 1.2280\n",
      "Epoch 831/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7745 - val_loss: 1.2278\n",
      "Epoch 832/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.7740 - val_loss: 1.2276\n",
      "Epoch 833/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7735 - val_loss: 1.2274\n",
      "Epoch 834/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.7730 - val_loss: 1.2271\n",
      "Epoch 835/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.7725 - val_loss: 1.2269\n",
      "Epoch 836/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7719 - val_loss: 1.2267\n",
      "Epoch 837/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 0.7714 - val_loss: 1.2264\n",
      "Epoch 838/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.7709 - val_loss: 1.2262\n",
      "Epoch 839/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7704 - val_loss: 1.2260\n",
      "Epoch 840/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.7698 - val_loss: 1.2258\n",
      "Epoch 841/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 0.7693 - val_loss: 1.2256\n",
      "Epoch 842/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7687 - val_loss: 1.2254\n",
      "Epoch 843/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.7682 - val_loss: 1.2252\n",
      "Epoch 844/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.7676 - val_loss: 1.2250\n",
      "Epoch 845/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.7670 - val_loss: 1.2249\n",
      "Epoch 846/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.7664 - val_loss: 1.2247\n",
      "Epoch 847/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.7658 - val_loss: 1.2246\n",
      "Epoch 848/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.7653 - val_loss: 1.2244\n",
      "Epoch 849/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.7647 - val_loss: 1.2243\n",
      "Epoch 850/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7641 - val_loss: 1.2242\n",
      "Epoch 851/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.7634 - val_loss: 1.2241\n",
      "Epoch 852/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7628 - val_loss: 1.2240\n",
      "Epoch 853/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.7622 - val_loss: 1.2239\n",
      "Epoch 854/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.7616 - val_loss: 1.2239\n",
      "Epoch 855/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.7609 - val_loss: 1.2238\n",
      "Epoch 856/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.7603 - val_loss: 1.2238\n",
      "Epoch 857/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7597 - val_loss: 1.2238\n",
      "Epoch 858/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 0.7590 - val_loss: 1.2238\n",
      "Epoch 859/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7583 - val_loss: 1.2238\n",
      "Epoch 860/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.7577 - val_loss: 1.2238\n",
      "Epoch 861/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.7570 - val_loss: 1.2238\n",
      "Epoch 862/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.7563 - val_loss: 1.2238\n",
      "Epoch 863/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.7556 - val_loss: 1.2239\n",
      "Epoch 864/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.7550 - val_loss: 1.2240\n",
      "Epoch 865/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7543 - val_loss: 1.2240\n",
      "Epoch 866/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7536 - val_loss: 1.2241\n",
      "Epoch 867/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.7529 - val_loss: 1.2242\n",
      "Epoch 868/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 0.7522 - val_loss: 1.2243\n",
      "Epoch 869/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7515 - val_loss: 1.2244\n",
      "Epoch 870/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.7508 - val_loss: 1.2245\n",
      "Epoch 871/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 0.7501 - val_loss: 1.2246\n",
      "Epoch 872/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.7494 - val_loss: 1.2248\n",
      "Epoch 873/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.7487 - val_loss: 1.2249\n",
      "Epoch 874/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.7479 - val_loss: 1.2251\n",
      "Epoch 875/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7472 - val_loss: 1.2252\n",
      "Epoch 876/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7465 - val_loss: 1.2253\n",
      "Epoch 877/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.7458 - val_loss: 1.2255\n",
      "Epoch 878/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.7451 - val_loss: 1.2257\n",
      "Epoch 879/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.7444 - val_loss: 1.2258\n",
      "Epoch 880/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7437 - val_loss: 1.2260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.7430 - val_loss: 1.2261\n",
      "Epoch 882/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.7423 - val_loss: 1.2263\n",
      "Epoch 883/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7416 - val_loss: 1.2265\n",
      "Epoch 884/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.7410 - val_loss: 1.2266\n",
      "Epoch 885/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.7403 - val_loss: 1.2268\n",
      "Epoch 886/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7396 - val_loss: 1.2270\n",
      "Epoch 887/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 0.7389 - val_loss: 1.2272\n",
      "Epoch 888/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.7383 - val_loss: 1.2274\n",
      "Epoch 889/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7376 - val_loss: 1.2275\n",
      "Epoch 890/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.7370 - val_loss: 1.2278\n",
      "Epoch 891/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.7364 - val_loss: 1.2278\n",
      "Epoch 892/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.7357 - val_loss: 1.2281\n",
      "Epoch 893/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.7351 - val_loss: 1.2282\n",
      "Epoch 894/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.7345 - val_loss: 1.2284\n",
      "Epoch 895/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.7339 - val_loss: 1.2286\n",
      "Epoch 896/2500\n",
      "64/64 [==============================] - 0s 329us/step - loss: 0.7333 - val_loss: 1.2287\n",
      "Epoch 897/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.7328 - val_loss: 1.2290\n",
      "Epoch 898/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7322 - val_loss: 1.2291\n",
      "Epoch 899/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.7316 - val_loss: 1.2292\n",
      "Epoch 900/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7311 - val_loss: 1.2294\n",
      "Epoch 901/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.7305 - val_loss: 1.2295\n",
      "Epoch 902/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7300 - val_loss: 1.2297\n",
      "Epoch 903/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7295 - val_loss: 1.2298\n",
      "Epoch 904/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7290 - val_loss: 1.2298\n",
      "Epoch 905/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7285 - val_loss: 1.2300\n",
      "Epoch 906/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.7280 - val_loss: 1.2300\n",
      "Epoch 907/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.7275 - val_loss: 1.2301\n",
      "Epoch 908/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.7271 - val_loss: 1.2301\n",
      "Epoch 909/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7266 - val_loss: 1.2302\n",
      "Epoch 910/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.7262 - val_loss: 1.2302\n",
      "Epoch 911/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.7258 - val_loss: 1.2301\n",
      "Epoch 912/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.7253 - val_loss: 1.2301\n",
      "Epoch 913/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.7249 - val_loss: 1.2300\n",
      "Epoch 914/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.7245 - val_loss: 1.2300\n",
      "Epoch 915/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.7241 - val_loss: 1.2299\n",
      "Epoch 916/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 0.7237 - val_loss: 1.2298\n",
      "Epoch 917/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7234 - val_loss: 1.2296\n",
      "Epoch 918/2500\n",
      "64/64 [==============================] - 0s 210us/step - loss: 0.7230 - val_loss: 1.2295\n",
      "Epoch 919/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.7226 - val_loss: 1.2293\n",
      "Epoch 920/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7223 - val_loss: 1.2291\n",
      "Epoch 921/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.7220 - val_loss: 1.2289\n",
      "Epoch 922/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 0.7216 - val_loss: 1.2287\n",
      "Epoch 923/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.7213 - val_loss: 1.2285\n",
      "Epoch 924/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.7210 - val_loss: 1.2282\n",
      "Epoch 925/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.7207 - val_loss: 1.2279\n",
      "Epoch 926/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7204 - val_loss: 1.2276\n",
      "Epoch 927/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7201 - val_loss: 1.2273\n",
      "Epoch 928/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7198 - val_loss: 1.2269\n",
      "Epoch 929/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.7195 - val_loss: 1.2266\n",
      "Epoch 930/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.7192 - val_loss: 1.2262\n",
      "Epoch 931/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.7190 - val_loss: 1.2258\n",
      "Epoch 932/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.7187 - val_loss: 1.2254\n",
      "Epoch 933/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.7185 - val_loss: 1.2250\n",
      "Epoch 934/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7182 - val_loss: 1.2246\n",
      "Epoch 935/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 0.7180 - val_loss: 1.2241\n",
      "Epoch 936/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.7177 - val_loss: 1.2236\n",
      "Epoch 937/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7175 - val_loss: 1.2231\n",
      "Epoch 938/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.7173 - val_loss: 1.2226\n",
      "Epoch 939/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.7171 - val_loss: 1.2221\n",
      "Epoch 940/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.7168 - val_loss: 1.2216\n",
      "Epoch 941/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.7166 - val_loss: 1.2210\n",
      "Epoch 942/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7164 - val_loss: 1.2204\n",
      "Epoch 943/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.7162 - val_loss: 1.2198\n",
      "Epoch 944/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.7160 - val_loss: 1.2192\n",
      "Epoch 945/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7158 - val_loss: 1.2185\n",
      "Epoch 946/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.7156 - val_loss: 1.2179\n",
      "Epoch 947/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.7154 - val_loss: 1.2172\n",
      "Epoch 948/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.7152 - val_loss: 1.2166\n",
      "Epoch 949/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.7150 - val_loss: 1.2157\n",
      "Epoch 950/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7148 - val_loss: 1.2152\n",
      "Epoch 951/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.7146 - val_loss: 1.2142\n",
      "Epoch 952/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.7144 - val_loss: 1.2139\n",
      "Epoch 953/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.7143 - val_loss: 1.2125\n",
      "Epoch 954/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7141 - val_loss: 1.2127\n",
      "Epoch 955/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.7139 - val_loss: 1.2104\n",
      "Epoch 956/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.7137 - val_loss: 1.2120\n",
      "Epoch 957/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.7135 - val_loss: 1.2074\n",
      "Epoch 958/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.7134 - val_loss: 1.2126\n",
      "Epoch 959/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.7132 - val_loss: 1.2020\n",
      "Epoch 960/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.7130 - val_loss: 1.2172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 0.7129 - val_loss: 1.1897\n",
      "Epoch 962/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7128 - val_loss: 1.2338\n",
      "Epoch 963/2500\n",
      "64/64 [==============================] - 0s 210us/step - loss: 0.7129 - val_loss: 1.1575\n",
      "Epoch 964/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.7134 - val_loss: 1.2865\n",
      "Epoch 965/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.7154 - val_loss: 1.0695\n",
      "Epoch 966/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.7214 - val_loss: 1.4422\n",
      "Epoch 967/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7388 - val_loss: 0.8881\n",
      "Epoch 968/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.7833 - val_loss: 1.7557\n",
      "Epoch 969/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8701 - val_loss: 0.7941\n",
      "Epoch 970/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.9672 - val_loss: 1.8653\n",
      "Epoch 971/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.9752 - val_loss: 0.7893\n",
      "Epoch 972/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.7809 - val_loss: 0.9070\n",
      "Epoch 973/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.7353 - val_loss: 1.7237\n",
      "Epoch 974/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8754 - val_loss: 0.8302\n",
      "Epoch 975/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 0.8565 - val_loss: 1.3149\n",
      "Epoch 976/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.7189 - val_loss: 1.6383\n",
      "Epoch 977/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.7845 - val_loss: 0.8502\n",
      "Epoch 978/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8382 - val_loss: 1.3568\n",
      "Epoch 979/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.7256 - val_loss: 1.5138\n",
      "Epoch 980/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.7612 - val_loss: 0.8367\n",
      "Epoch 981/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.7925 - val_loss: 1.2005\n",
      "Epoch 982/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.7141 - val_loss: 1.5659\n",
      "Epoch 983/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.7723 - val_loss: 0.9400\n",
      "Epoch 984/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.7549 - val_loss: 1.1123\n",
      "Epoch 985/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.7176 - val_loss: 1.5972\n",
      "Epoch 986/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.7733 - val_loss: 1.0349\n",
      "Epoch 987/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7263 - val_loss: 0.9993\n",
      "Epoch 988/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.7314 - val_loss: 1.4979\n",
      "Epoch 989/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 0.7469 - val_loss: 1.1906\n",
      "Epoch 990/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7125 - val_loss: 0.9573\n",
      "Epoch 991/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7387 - val_loss: 1.3587\n",
      "Epoch 992/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.7208 - val_loss: 1.3667\n",
      "Epoch 993/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.7187 - val_loss: 1.0178\n",
      "Epoch 994/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.7318 - val_loss: 1.2313\n",
      "Epoch 995/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.7103 - val_loss: 1.4121\n",
      "Epoch 996/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.7271 - val_loss: 1.0751\n",
      "Epoch 997/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.7169 - val_loss: 1.0898\n",
      "Epoch 998/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.7141 - val_loss: 1.3777\n",
      "Epoch 999/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.7229 - val_loss: 1.1688\n",
      "Epoch 1000/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.7095 - val_loss: 1.0520\n",
      "Epoch 1001/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7184 - val_loss: 1.3167\n",
      "Epoch 1002/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.7133 - val_loss: 1.2868\n",
      "Epoch 1003/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.7107 - val_loss: 1.0815\n",
      "Epoch 1004/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.7163 - val_loss: 1.2386\n",
      "Epoch 1005/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.7088 - val_loss: 1.3120\n",
      "Epoch 1006/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.7125 - val_loss: 1.1040\n",
      "Epoch 1007/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7118 - val_loss: 1.1613\n",
      "Epoch 1008/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.7080 - val_loss: 1.2979\n",
      "Epoch 1009/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.7123 - val_loss: 1.1479\n",
      "Epoch 1010/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7080 - val_loss: 1.1323\n",
      "Epoch 1011/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7089 - val_loss: 1.2900\n",
      "Epoch 1012/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.7100 - val_loss: 1.1980\n",
      "Epoch 1013/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.7067 - val_loss: 1.1183\n",
      "Epoch 1014/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.7091 - val_loss: 1.2494\n",
      "Epoch 1015/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7076 - val_loss: 1.2178\n",
      "Epoch 1016/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.7066 - val_loss: 1.1109\n",
      "Epoch 1017/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.7082 - val_loss: 1.2076\n",
      "Epoch 1018/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7062 - val_loss: 1.2281\n",
      "Epoch 1019/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7065 - val_loss: 1.1296\n",
      "Epoch 1020/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.7070 - val_loss: 1.1927\n",
      "Epoch 1021/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.7053 - val_loss: 1.2344\n",
      "Epoch 1022/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.7062 - val_loss: 1.1420\n",
      "Epoch 1023/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.7057 - val_loss: 1.1709\n",
      "Epoch 1024/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7049 - val_loss: 1.2244\n",
      "Epoch 1025/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.7056 - val_loss: 1.1464\n",
      "Epoch 1026/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.7048 - val_loss: 1.1522\n",
      "Epoch 1027/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.7045 - val_loss: 1.2160\n",
      "Epoch 1028/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.7048 - val_loss: 1.1623\n",
      "Epoch 1029/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.7041 - val_loss: 1.1527\n",
      "Epoch 1030/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.7041 - val_loss: 1.2102\n",
      "Epoch 1031/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.7042 - val_loss: 1.1706\n",
      "Epoch 1032/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7035 - val_loss: 1.1505\n",
      "Epoch 1033/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.7036 - val_loss: 1.2002\n",
      "Epoch 1034/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.7035 - val_loss: 1.1696\n",
      "Epoch 1035/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 0.7030 - val_loss: 1.1462\n",
      "Epoch 1036/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7031 - val_loss: 1.1935\n",
      "Epoch 1037/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 0.7029 - val_loss: 1.1745\n",
      "Epoch 1038/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 0.7025 - val_loss: 1.1488\n",
      "Epoch 1039/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.7026 - val_loss: 1.1879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 0.7023 - val_loss: 1.1748\n",
      "Epoch 1041/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.7021 - val_loss: 1.1492\n",
      "Epoch 1042/2500\n",
      "64/64 [==============================] - 0s 284us/step - loss: 0.7021 - val_loss: 1.1809\n",
      "Epoch 1043/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.7018 - val_loss: 1.1710\n",
      "Epoch 1044/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.7016 - val_loss: 1.1498\n",
      "Epoch 1045/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.7015 - val_loss: 1.1792\n",
      "Epoch 1046/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.7013 - val_loss: 1.1714\n",
      "Epoch 1047/2500\n",
      "64/64 [==============================] - 0s 310us/step - loss: 0.7011 - val_loss: 1.1516\n",
      "Epoch 1048/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.7010 - val_loss: 1.1765\n",
      "Epoch 1049/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.7008 - val_loss: 1.1690\n",
      "Epoch 1050/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.7006 - val_loss: 1.1507\n",
      "Epoch 1051/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7005 - val_loss: 1.1709\n",
      "Epoch 1052/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7003 - val_loss: 1.1642\n",
      "Epoch 1053/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.7001 - val_loss: 1.1511\n",
      "Epoch 1054/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7000 - val_loss: 1.1701\n",
      "Epoch 1055/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.6998 - val_loss: 1.1627\n",
      "Epoch 1056/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6996 - val_loss: 1.1524\n",
      "Epoch 1057/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.6995 - val_loss: 1.1687\n",
      "Epoch 1058/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.6993 - val_loss: 1.1598\n",
      "Epoch 1059/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.6991 - val_loss: 1.1510\n",
      "Epoch 1060/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6990 - val_loss: 1.1645\n",
      "Epoch 1061/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6988 - val_loss: 1.1559\n",
      "Epoch 1062/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6986 - val_loss: 1.1509\n",
      "Epoch 1063/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.6984 - val_loss: 1.1624\n",
      "Epoch 1064/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.6982 - val_loss: 1.1534\n",
      "Epoch 1065/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6981 - val_loss: 1.1514\n",
      "Epoch 1066/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.6979 - val_loss: 1.1604\n",
      "Epoch 1067/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.6977 - val_loss: 1.1504\n",
      "Epoch 1068/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.6975 - val_loss: 1.1502\n",
      "Epoch 1069/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6973 - val_loss: 1.1570\n",
      "Epoch 1070/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6971 - val_loss: 1.1481\n",
      "Epoch 1071/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.6969 - val_loss: 1.1501\n",
      "Epoch 1072/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6968 - val_loss: 1.1543\n",
      "Epoch 1073/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 0.6966 - val_loss: 1.1463\n",
      "Epoch 1074/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6964 - val_loss: 1.1498\n",
      "Epoch 1075/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6962 - val_loss: 1.1511\n",
      "Epoch 1076/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6960 - val_loss: 1.1440\n",
      "Epoch 1077/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.6958 - val_loss: 1.1484\n",
      "Epoch 1078/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.6956 - val_loss: 1.1478\n",
      "Epoch 1079/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.6954 - val_loss: 1.1426\n",
      "Epoch 1080/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6952 - val_loss: 1.1472\n",
      "Epoch 1081/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6950 - val_loss: 1.1449\n",
      "Epoch 1082/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.6947 - val_loss: 1.1417\n",
      "Epoch 1083/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.6945 - val_loss: 1.1454\n",
      "Epoch 1084/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.6943 - val_loss: 1.1414\n",
      "Epoch 1085/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6941 - val_loss: 1.1402\n",
      "Epoch 1086/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.6939 - val_loss: 1.1429\n",
      "Epoch 1087/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.6937 - val_loss: 1.1386\n",
      "Epoch 1088/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.6935 - val_loss: 1.1390\n",
      "Epoch 1089/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.6932 - val_loss: 1.1402\n",
      "Epoch 1090/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.6930 - val_loss: 1.1363\n",
      "Epoch 1091/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.6928 - val_loss: 1.1376\n",
      "Epoch 1092/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.6925 - val_loss: 1.1370\n",
      "Epoch 1093/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6923 - val_loss: 1.1339\n",
      "Epoch 1094/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6921 - val_loss: 1.1358\n",
      "Epoch 1095/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6918 - val_loss: 1.1339\n",
      "Epoch 1096/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 0.6916 - val_loss: 1.1321\n",
      "Epoch 1097/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.6914 - val_loss: 1.1336\n",
      "Epoch 1098/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6911 - val_loss: 1.1310\n",
      "Epoch 1099/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6909 - val_loss: 1.1304\n",
      "Epoch 1100/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.6906 - val_loss: 1.1308\n",
      "Epoch 1101/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.6904 - val_loss: 1.1281\n",
      "Epoch 1102/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6901 - val_loss: 1.1286\n",
      "Epoch 1103/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6899 - val_loss: 1.1279\n",
      "Epoch 1104/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.6896 - val_loss: 1.1258\n",
      "Epoch 1105/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6894 - val_loss: 1.1266\n",
      "Epoch 1106/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6891 - val_loss: 1.1250\n",
      "Epoch 1107/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6888 - val_loss: 1.1238\n",
      "Epoch 1108/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6886 - val_loss: 1.1241\n",
      "Epoch 1109/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6883 - val_loss: 1.1220\n",
      "Epoch 1110/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6881 - val_loss: 1.1219\n",
      "Epoch 1111/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6878 - val_loss: 1.1213\n",
      "Epoch 1112/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6875 - val_loss: 1.1196\n",
      "Epoch 1113/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6872 - val_loss: 1.1199\n",
      "Epoch 1114/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.6870 - val_loss: 1.1186\n",
      "Epoch 1115/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6867 - val_loss: 1.1176\n",
      "Epoch 1116/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6864 - val_loss: 1.1175\n",
      "Epoch 1117/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6862 - val_loss: 1.1159\n",
      "Epoch 1118/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6859 - val_loss: 1.1156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1119/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 0.6856 - val_loss: 1.1149\n",
      "Epoch 1120/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.6853 - val_loss: 1.1136\n",
      "Epoch 1121/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6850 - val_loss: 1.1135\n",
      "Epoch 1122/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 0.6847 - val_loss: 1.1123\n",
      "Epoch 1123/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6845 - val_loss: 1.1115\n",
      "Epoch 1124/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.6842 - val_loss: 1.1111\n",
      "Epoch 1125/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6839 - val_loss: 1.1098\n",
      "Epoch 1126/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6836 - val_loss: 1.1095\n",
      "Epoch 1127/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6833 - val_loss: 1.1085\n",
      "Epoch 1128/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.6830 - val_loss: 1.1075\n",
      "Epoch 1129/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.6827 - val_loss: 1.1071\n",
      "Epoch 1130/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.6824 - val_loss: 1.1059\n",
      "Epoch 1131/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6821 - val_loss: 1.1053\n",
      "Epoch 1132/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.6818 - val_loss: 1.1045\n",
      "Epoch 1133/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6815 - val_loss: 1.1035\n",
      "Epoch 1134/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.6812 - val_loss: 1.1030\n",
      "Epoch 1135/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.6809 - val_loss: 1.1019\n",
      "Epoch 1136/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.6806 - val_loss: 1.1012\n",
      "Epoch 1137/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.6803 - val_loss: 1.1004\n",
      "Epoch 1138/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.6800 - val_loss: 1.0994\n",
      "Epoch 1139/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.6797 - val_loss: 1.0988\n",
      "Epoch 1140/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.6794 - val_loss: 1.0977\n",
      "Epoch 1141/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.6791 - val_loss: 1.0969\n",
      "Epoch 1142/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6788 - val_loss: 1.0962\n",
      "Epoch 1143/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.6785 - val_loss: 1.0951\n",
      "Epoch 1144/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.6782 - val_loss: 1.0945\n",
      "Epoch 1145/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6779 - val_loss: 1.0935\n",
      "Epoch 1146/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6775 - val_loss: 1.0926\n",
      "Epoch 1147/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.6772 - val_loss: 1.0918\n",
      "Epoch 1148/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.6769 - val_loss: 1.0908\n",
      "Epoch 1149/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6766 - val_loss: 1.0901\n",
      "Epoch 1150/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6763 - val_loss: 1.0891\n",
      "Epoch 1151/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6759 - val_loss: 1.0882\n",
      "Epoch 1152/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.6756 - val_loss: 1.0874\n",
      "Epoch 1153/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6753 - val_loss: 1.0864\n",
      "Epoch 1154/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6749 - val_loss: 1.0857\n",
      "Epoch 1155/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.6746 - val_loss: 1.0847\n",
      "Epoch 1156/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.6743 - val_loss: 1.0838\n",
      "Epoch 1157/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.6739 - val_loss: 1.0830\n",
      "Epoch 1158/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6736 - val_loss: 1.0820\n",
      "Epoch 1159/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6733 - val_loss: 1.0812\n",
      "Epoch 1160/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6729 - val_loss: 1.0802\n",
      "Epoch 1161/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6726 - val_loss: 1.0794\n",
      "Epoch 1162/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6722 - val_loss: 1.0785\n",
      "Epoch 1163/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6719 - val_loss: 1.0776\n",
      "Epoch 1164/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6715 - val_loss: 1.0768\n",
      "Epoch 1165/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.6712 - val_loss: 1.0759\n",
      "Epoch 1166/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.6708 - val_loss: 1.0751\n",
      "Epoch 1167/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6705 - val_loss: 1.0741\n",
      "Epoch 1168/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.6701 - val_loss: 1.0733\n",
      "Epoch 1169/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6697 - val_loss: 1.0725\n",
      "Epoch 1170/2500\n",
      "64/64 [==============================] - 0s 40us/step - loss: 0.6694 - val_loss: 1.0716\n",
      "Epoch 1171/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.6690 - val_loss: 1.0708\n",
      "Epoch 1172/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6686 - val_loss: 1.0699\n",
      "Epoch 1173/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.6682 - val_loss: 1.0691\n",
      "Epoch 1174/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6678 - val_loss: 1.0683\n",
      "Epoch 1175/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.6674 - val_loss: 1.0676\n",
      "Epoch 1176/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.6670 - val_loss: 1.0668\n",
      "Epoch 1177/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6666 - val_loss: 1.0660\n",
      "Epoch 1178/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.6662 - val_loss: 1.0653\n",
      "Epoch 1179/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6658 - val_loss: 1.0646\n",
      "Epoch 1180/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.6654 - val_loss: 1.0640\n",
      "Epoch 1181/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.6649 - val_loss: 1.0634\n",
      "Epoch 1182/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6645 - val_loss: 1.0629\n",
      "Epoch 1183/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6640 - val_loss: 1.0624\n",
      "Epoch 1184/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6636 - val_loss: 1.0621\n",
      "Epoch 1185/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6631 - val_loss: 1.0617\n",
      "Epoch 1186/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.6626 - val_loss: 1.0615\n",
      "Epoch 1187/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6621 - val_loss: 1.0614\n",
      "Epoch 1188/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6616 - val_loss: 1.0614\n",
      "Epoch 1189/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6611 - val_loss: 1.0615\n",
      "Epoch 1190/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.6606 - val_loss: 1.0618\n",
      "Epoch 1191/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6601 - val_loss: 1.0620\n",
      "Epoch 1192/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.6595 - val_loss: 1.0626\n",
      "Epoch 1193/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.6590 - val_loss: 1.0630\n",
      "Epoch 1194/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6585 - val_loss: 1.0639\n",
      "Epoch 1195/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6579 - val_loss: 1.0642\n",
      "Epoch 1196/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6574 - val_loss: 1.0656\n",
      "Epoch 1197/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6568 - val_loss: 1.0651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.6563 - val_loss: 1.0680\n",
      "Epoch 1199/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 0.6558 - val_loss: 1.0645\n",
      "Epoch 1200/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6552 - val_loss: 1.0733\n",
      "Epoch 1201/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6547 - val_loss: 1.0575\n",
      "Epoch 1202/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.6543 - val_loss: 1.0914\n",
      "Epoch 1203/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6540 - val_loss: 1.0230\n",
      "Epoch 1204/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.6547 - val_loss: 1.1735\n",
      "Epoch 1205/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.6603 - val_loss: 0.8776\n",
      "Epoch 1206/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.6857 - val_loss: 1.5181\n",
      "Epoch 1207/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7793 - val_loss: 0.7580\n",
      "Epoch 1208/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.7815 - val_loss: 1.3753\n",
      "Epoch 1209/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.7263 - val_loss: 0.8694\n",
      "Epoch 1210/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.6790 - val_loss: 1.1685\n",
      "Epoch 1211/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6633 - val_loss: 0.9293\n",
      "Epoch 1212/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6593 - val_loss: 1.1805\n",
      "Epoch 1213/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.6659 - val_loss: 0.8842\n",
      "Epoch 1214/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6798 - val_loss: 1.4433\n",
      "Epoch 1215/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.7289 - val_loss: 0.7806\n",
      "Epoch 1216/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7439 - val_loss: 1.2434\n",
      "Epoch 1217/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6749 - val_loss: 1.0026\n",
      "Epoch 1218/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6495 - val_loss: 0.9285\n",
      "Epoch 1219/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.6572 - val_loss: 1.3055\n",
      "Epoch 1220/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6965 - val_loss: 0.7901\n",
      "Epoch 1221/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.7261 - val_loss: 1.3269\n",
      "Epoch 1222/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6876 - val_loss: 0.9549\n",
      "Epoch 1223/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6599 - val_loss: 1.1098\n",
      "Epoch 1224/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6479 - val_loss: 1.0800\n",
      "Epoch 1225/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.6488 - val_loss: 0.9952\n",
      "Epoch 1226/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.6509 - val_loss: 1.2435\n",
      "Epoch 1227/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6621 - val_loss: 0.8770\n",
      "Epoch 1228/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.6763 - val_loss: 1.2889\n",
      "Epoch 1229/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6828 - val_loss: 0.8440\n",
      "Epoch 1230/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6821 - val_loss: 1.2815\n",
      "Epoch 1231/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.6829 - val_loss: 0.8996\n",
      "Epoch 1232/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.6652 - val_loss: 1.1993\n",
      "Epoch 1233/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.6564 - val_loss: 0.9575\n",
      "Epoch 1234/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6482 - val_loss: 1.0902\n",
      "Epoch 1235/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6437 - val_loss: 1.0283\n",
      "Epoch 1236/2500\n",
      "64/64 [==============================] - 0s 290us/step - loss: 0.6414 - val_loss: 1.0389\n",
      "Epoch 1237/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6409 - val_loss: 1.1150\n",
      "Epoch 1238/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 0.6423 - val_loss: 0.9764\n",
      "Epoch 1239/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.6439 - val_loss: 1.1434\n",
      "Epoch 1240/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.6474 - val_loss: 0.9208\n",
      "Epoch 1241/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6510 - val_loss: 1.2160\n",
      "Epoch 1242/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6584 - val_loss: 0.8879\n",
      "Epoch 1243/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.6668 - val_loss: 1.3033\n",
      "Epoch 1244/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6787 - val_loss: 0.8360\n",
      "Epoch 1245/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.6827 - val_loss: 1.2632\n",
      "Epoch 1246/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6707 - val_loss: 0.8969\n",
      "Epoch 1247/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6572 - val_loss: 1.1961\n",
      "Epoch 1248/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.6490 - val_loss: 0.9694\n",
      "Epoch 1249/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.6418 - val_loss: 1.1216\n",
      "Epoch 1250/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.6378 - val_loss: 1.0177\n",
      "Epoch 1251/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6349 - val_loss: 1.0599\n",
      "Epoch 1252/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.6336 - val_loss: 1.0780\n",
      "Epoch 1253/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 0.6332 - val_loss: 1.0191\n",
      "Epoch 1254/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6339 - val_loss: 1.1191\n",
      "Epoch 1255/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6351 - val_loss: 0.9786\n",
      "Epoch 1256/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6364 - val_loss: 1.1510\n",
      "Epoch 1257/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.6384 - val_loss: 0.9521\n",
      "Epoch 1258/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6405 - val_loss: 1.1976\n",
      "Epoch 1259/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6446 - val_loss: 0.9160\n",
      "Epoch 1260/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.6503 - val_loss: 1.2624\n",
      "Epoch 1261/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.6613 - val_loss: 0.8535\n",
      "Epoch 1262/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6731 - val_loss: 1.3004\n",
      "Epoch 1263/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6731 - val_loss: 0.8566\n",
      "Epoch 1264/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6671 - val_loss: 1.2270\n",
      "Epoch 1265/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.6511 - val_loss: 0.9363\n",
      "Epoch 1266/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6393 - val_loss: 1.1323\n",
      "Epoch 1267/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.6314 - val_loss: 1.0258\n",
      "Epoch 1268/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6266 - val_loss: 1.0487\n",
      "Epoch 1269/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.6255 - val_loss: 1.1158\n",
      "Epoch 1270/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 0.6271 - val_loss: 0.9859\n",
      "Epoch 1271/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6299 - val_loss: 1.1660\n",
      "Epoch 1272/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.6330 - val_loss: 0.9483\n",
      "Epoch 1273/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.6355 - val_loss: 1.1965\n",
      "Epoch 1274/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.6383 - val_loss: 0.9237\n",
      "Epoch 1275/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6405 - val_loss: 1.2165\n",
      "Epoch 1276/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6427 - val_loss: 0.9097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1277/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6447 - val_loss: 1.2377\n",
      "Epoch 1278/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6469 - val_loss: 0.8998\n",
      "Epoch 1279/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.6488 - val_loss: 1.2467\n",
      "Epoch 1280/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6487 - val_loss: 0.8956\n",
      "Epoch 1281/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6474 - val_loss: 1.2232\n",
      "Epoch 1282/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6431 - val_loss: 0.9183\n",
      "Epoch 1283/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6377 - val_loss: 1.1746\n",
      "Epoch 1284/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.6305 - val_loss: 0.9767\n",
      "Epoch 1285/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6232 - val_loss: 1.0887\n",
      "Epoch 1286/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.6177 - val_loss: 1.0741\n",
      "Epoch 1287/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6164 - val_loss: 1.0050\n",
      "Epoch 1288/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.6187 - val_loss: 1.1466\n",
      "Epoch 1289/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.6216 - val_loss: 0.9751\n",
      "Epoch 1290/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 0.6229 - val_loss: 1.1540\n",
      "Epoch 1291/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6218 - val_loss: 0.9875\n",
      "Epoch 1292/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 0.6189 - val_loss: 1.1101\n",
      "Epoch 1293/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6153 - val_loss: 1.0424\n",
      "Epoch 1294/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.6127 - val_loss: 1.0466\n",
      "Epoch 1295/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6120 - val_loss: 1.1030\n",
      "Epoch 1296/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 0.6129 - val_loss: 1.0050\n",
      "Epoch 1297/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.6139 - val_loss: 1.1254\n",
      "Epoch 1298/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.6141 - val_loss: 1.0020\n",
      "Epoch 1299/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.6132 - val_loss: 1.1118\n",
      "Epoch 1300/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.6115 - val_loss: 1.0251\n",
      "Epoch 1301/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.6096 - val_loss: 1.0722\n",
      "Epoch 1302/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 0.6081 - val_loss: 1.0625\n",
      "Epoch 1303/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.6074 - val_loss: 1.0368\n",
      "Epoch 1304/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6073 - val_loss: 1.0959\n",
      "Epoch 1305/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6074 - val_loss: 1.0208\n",
      "Epoch 1306/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.6075 - val_loss: 1.1090\n",
      "Epoch 1307/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.6072 - val_loss: 1.0195\n",
      "Epoch 1308/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6066 - val_loss: 1.1060\n",
      "Epoch 1309/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6057 - val_loss: 1.0289\n",
      "Epoch 1310/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6048 - val_loss: 1.0930\n",
      "Epoch 1311/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.6037 - val_loss: 1.0429\n",
      "Epoch 1312/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 0.6028 - val_loss: 1.0758\n",
      "Epoch 1313/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6020 - val_loss: 1.0603\n",
      "Epoch 1314/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.6013 - val_loss: 1.0623\n",
      "Epoch 1315/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 0.6007 - val_loss: 1.0764\n",
      "Epoch 1316/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.6003 - val_loss: 1.0509\n",
      "Epoch 1317/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.5999 - val_loss: 1.0876\n",
      "Epoch 1318/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.5996 - val_loss: 1.0410\n",
      "Epoch 1319/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5993 - val_loss: 1.0979\n",
      "Epoch 1320/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5991 - val_loss: 1.0304\n",
      "Epoch 1321/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5990 - val_loss: 1.1113\n",
      "Epoch 1322/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.5992 - val_loss: 1.0143\n",
      "Epoch 1323/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.5997 - val_loss: 1.1378\n",
      "Epoch 1324/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6012 - val_loss: 0.9806\n",
      "Epoch 1325/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6047 - val_loss: 1.2023\n",
      "Epoch 1326/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6141 - val_loss: 0.8755\n",
      "Epoch 1327/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6447 - val_loss: 1.4147\n",
      "Epoch 1328/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7164 - val_loss: 0.8179\n",
      "Epoch 1329/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.6776 - val_loss: 1.2653\n",
      "Epoch 1330/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.6511 - val_loss: 0.8800\n",
      "Epoch 1331/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6384 - val_loss: 1.2662\n",
      "Epoch 1332/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6390 - val_loss: 0.8245\n",
      "Epoch 1333/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6627 - val_loss: 1.2854\n",
      "Epoch 1334/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.6613 - val_loss: 0.8596\n",
      "Epoch 1335/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.6427 - val_loss: 1.2138\n",
      "Epoch 1336/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.6219 - val_loss: 0.9314\n",
      "Epoch 1337/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6165 - val_loss: 1.1656\n",
      "Epoch 1338/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6025 - val_loss: 1.0230\n",
      "Epoch 1339/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5940 - val_loss: 1.0623\n",
      "Epoch 1340/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.5914 - val_loss: 1.1455\n",
      "Epoch 1341/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5950 - val_loss: 1.0035\n",
      "Epoch 1342/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6014 - val_loss: 1.1913\n",
      "Epoch 1343/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.6020 - val_loss: 0.9880\n",
      "Epoch 1344/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5993 - val_loss: 1.1239\n",
      "Epoch 1345/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5933 - val_loss: 1.0552\n",
      "Epoch 1346/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5891 - val_loss: 1.0423\n",
      "Epoch 1347/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5894 - val_loss: 1.1286\n",
      "Epoch 1348/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5923 - val_loss: 0.9962\n",
      "Epoch 1349/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.5934 - val_loss: 1.1223\n",
      "Epoch 1350/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5917 - val_loss: 1.0300\n",
      "Epoch 1351/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5886 - val_loss: 1.0757\n",
      "Epoch 1352/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5865 - val_loss: 1.0905\n",
      "Epoch 1353/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5868 - val_loss: 1.0175\n",
      "Epoch 1354/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.5883 - val_loss: 1.1112\n",
      "Epoch 1355/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5886 - val_loss: 1.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1356/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5875 - val_loss: 1.0991\n",
      "Epoch 1357/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 0.5857 - val_loss: 1.0705\n",
      "Epoch 1358/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5845 - val_loss: 1.0505\n",
      "Epoch 1359/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5847 - val_loss: 1.1004\n",
      "Epoch 1360/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5852 - val_loss: 1.0323\n",
      "Epoch 1361/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.5854 - val_loss: 1.1038\n",
      "Epoch 1362/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.5848 - val_loss: 1.0417\n",
      "Epoch 1363/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5837 - val_loss: 1.0726\n",
      "Epoch 1364/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5828 - val_loss: 1.0715\n",
      "Epoch 1365/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 0.5825 - val_loss: 1.0530\n",
      "Epoch 1366/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5826 - val_loss: 1.0998\n",
      "Epoch 1367/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.5827 - val_loss: 1.0465\n",
      "Epoch 1368/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5826 - val_loss: 1.0990\n",
      "Epoch 1369/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5821 - val_loss: 1.0578\n",
      "Epoch 1370/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5815 - val_loss: 1.0889\n",
      "Epoch 1371/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5809 - val_loss: 1.0811\n",
      "Epoch 1372/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5805 - val_loss: 1.0712\n",
      "Epoch 1373/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 0.5803 - val_loss: 1.0944\n",
      "Epoch 1374/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5803 - val_loss: 1.0617\n",
      "Epoch 1375/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5802 - val_loss: 1.1025\n",
      "Epoch 1376/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 0.5800 - val_loss: 1.0643\n",
      "Epoch 1377/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5797 - val_loss: 1.0958\n",
      "Epoch 1378/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5793 - val_loss: 1.0703\n",
      "Epoch 1379/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5788 - val_loss: 1.0881\n",
      "Epoch 1380/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.5785 - val_loss: 1.0836\n",
      "Epoch 1381/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.5782 - val_loss: 1.0796\n",
      "Epoch 1382/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5780 - val_loss: 1.0903\n",
      "Epoch 1383/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.5778 - val_loss: 1.0721\n",
      "Epoch 1384/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5776 - val_loss: 1.0969\n",
      "Epoch 1385/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.5774 - val_loss: 1.0698\n",
      "Epoch 1386/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.5773 - val_loss: 1.0995\n",
      "Epoch 1387/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5771 - val_loss: 1.0657\n",
      "Epoch 1388/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5769 - val_loss: 1.0996\n",
      "Epoch 1389/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5767 - val_loss: 1.0633\n",
      "Epoch 1390/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.5765 - val_loss: 1.1016\n",
      "Epoch 1391/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 0.5763 - val_loss: 1.0584\n",
      "Epoch 1392/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5762 - val_loss: 1.1037\n",
      "Epoch 1393/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5761 - val_loss: 1.0519\n",
      "Epoch 1394/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5762 - val_loss: 1.1145\n",
      "Epoch 1395/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5765 - val_loss: 1.0404\n",
      "Epoch 1396/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5771 - val_loss: 1.1332\n",
      "Epoch 1397/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 0.5786 - val_loss: 1.0107\n",
      "Epoch 1398/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5820 - val_loss: 1.1841\n",
      "Epoch 1399/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5916 - val_loss: 0.9119\n",
      "Epoch 1400/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.6255 - val_loss: 1.4541\n",
      "Epoch 1401/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7713 - val_loss: 0.8834\n",
      "Epoch 1402/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.6321 - val_loss: 1.0792\n",
      "Epoch 1403/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.5863 - val_loss: 1.1136\n",
      "Epoch 1404/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.5803 - val_loss: 1.0056\n",
      "Epoch 1405/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5969 - val_loss: 1.2008\n",
      "Epoch 1406/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6197 - val_loss: 0.7560\n",
      "Epoch 1407/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.7477 - val_loss: 1.2158\n",
      "Epoch 1408/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.6012 - val_loss: 1.2169\n",
      "Epoch 1409/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5957 - val_loss: 0.8738\n",
      "Epoch 1410/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6527 - val_loss: 1.3502\n",
      "Epoch 1411/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7220 - val_loss: 0.9701\n",
      "Epoch 1412/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.6029 - val_loss: 1.0081\n",
      "Epoch 1413/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.5912 - val_loss: 1.3914\n",
      "Epoch 1414/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.6883 - val_loss: 0.8166\n",
      "Epoch 1415/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.7282 - val_loss: 0.9146\n",
      "Epoch 1416/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6390 - val_loss: 1.9100\n",
      "Epoch 1417/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.9748 - val_loss: 1.0930\n",
      "Epoch 1418/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6910 - val_loss: 0.8399\n",
      "Epoch 1419/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2243 - val_loss: 1.0361\n",
      "Epoch 1420/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.6673 - val_loss: 2.9255\n",
      "Epoch 1421/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4752 - val_loss: 1.0907\n",
      "Epoch 1422/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.6213 - val_loss: 0.7720\n",
      "Epoch 1423/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.0909 - val_loss: 0.9886\n",
      "Epoch 1424/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.6830 - val_loss: 2.2238\n",
      "Epoch 1425/2500\n",
      "64/64 [==============================] - 0s 473us/step - loss: 1.0953 - val_loss: 1.9144\n",
      "Epoch 1426/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 0.9331 - val_loss: 0.8098\n",
      "Epoch 1427/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.8070 - val_loss: 0.7294\n",
      "Epoch 1428/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.0067 - val_loss: 1.2083\n",
      "Epoch 1429/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.6425 - val_loss: 2.0175\n",
      "Epoch 1430/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.0033 - val_loss: 1.3942\n",
      "Epoch 1431/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 0.6766 - val_loss: 0.7295\n",
      "Epoch 1432/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.9644 - val_loss: 0.7254\n",
      "Epoch 1433/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7813 - val_loss: 1.4020\n",
      "Epoch 1434/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 0.7352 - val_loss: 1.4016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1435/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6903 - val_loss: 0.8459\n",
      "Epoch 1436/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6689 - val_loss: 0.6805\n",
      "Epoch 1437/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.7639 - val_loss: 1.0556\n",
      "Epoch 1438/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6473 - val_loss: 1.6946\n",
      "Epoch 1439/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.7364 - val_loss: 1.1750\n",
      "Epoch 1440/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6274 - val_loss: 0.8939\n",
      "Epoch 1441/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.6782 - val_loss: 0.9069\n",
      "Epoch 1442/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.6633 - val_loss: 1.1987\n",
      "Epoch 1443/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6263 - val_loss: 1.5187\n",
      "Epoch 1444/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6741 - val_loss: 1.2914\n",
      "Epoch 1445/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.6217 - val_loss: 0.9634\n",
      "Epoch 1446/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 0.6445 - val_loss: 1.0250\n",
      "Epoch 1447/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6309 - val_loss: 1.3741\n",
      "Epoch 1448/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.6443 - val_loss: 1.1993\n",
      "Epoch 1449/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6034 - val_loss: 0.9780\n",
      "Epoch 1450/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.6236 - val_loss: 1.0954\n",
      "Epoch 1451/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5961 - val_loss: 1.2070\n",
      "Epoch 1452/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6186 - val_loss: 0.9486\n",
      "Epoch 1453/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5980 - val_loss: 0.9220\n",
      "Epoch 1454/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.6045 - val_loss: 1.1578\n",
      "Epoch 1455/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5979 - val_loss: 1.0979\n",
      "Epoch 1456/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.5862 - val_loss: 0.9453\n",
      "Epoch 1457/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.5936 - val_loss: 1.0207\n",
      "Epoch 1458/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5813 - val_loss: 1.1239\n",
      "Epoch 1459/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5926 - val_loss: 0.9476\n",
      "Epoch 1460/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.5854 - val_loss: 0.9452\n",
      "Epoch 1461/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5831 - val_loss: 1.0913\n",
      "Epoch 1462/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5871 - val_loss: 1.0021\n",
      "Epoch 1463/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.5781 - val_loss: 0.9178\n",
      "Epoch 1464/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5841 - val_loss: 1.0279\n",
      "Epoch 1465/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5783 - val_loss: 1.0481\n",
      "Epoch 1466/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5800 - val_loss: 0.9318\n",
      "Epoch 1467/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.5798 - val_loss: 0.9639\n",
      "Epoch 1468/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.5766 - val_loss: 1.0454\n",
      "Epoch 1469/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.5793 - val_loss: 0.9724\n",
      "Epoch 1470/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5746 - val_loss: 0.9382\n",
      "Epoch 1471/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5770 - val_loss: 1.0262\n",
      "Epoch 1472/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5748 - val_loss: 1.0297\n",
      "Epoch 1473/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.5733 - val_loss: 0.9767\n",
      "Epoch 1474/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.5744 - val_loss: 1.0325\n",
      "Epoch 1475/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5719 - val_loss: 1.0793\n",
      "Epoch 1476/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5734 - val_loss: 1.0168\n",
      "Epoch 1477/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5715 - val_loss: 1.0176\n",
      "Epoch 1478/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5713 - val_loss: 1.0768\n",
      "Epoch 1479/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.5717 - val_loss: 1.0505\n",
      "Epoch 1480/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.5699 - val_loss: 1.0255\n",
      "Epoch 1481/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5707 - val_loss: 1.0705\n",
      "Epoch 1482/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5695 - val_loss: 1.0757\n",
      "Epoch 1483/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5695 - val_loss: 1.0323\n",
      "Epoch 1484/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.5694 - val_loss: 1.0486\n",
      "Epoch 1485/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.5684 - val_loss: 1.0788\n",
      "Epoch 1486/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5689 - val_loss: 1.0474\n",
      "Epoch 1487/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.5680 - val_loss: 1.0345\n",
      "Epoch 1488/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5680 - val_loss: 1.0645\n",
      "Epoch 1489/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5677 - val_loss: 1.0541\n",
      "Epoch 1490/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5671 - val_loss: 1.0309\n",
      "Epoch 1491/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5673 - val_loss: 1.0553\n",
      "Epoch 1492/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5665 - val_loss: 1.0641\n",
      "Epoch 1493/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.5665 - val_loss: 1.0372\n",
      "Epoch 1494/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5662 - val_loss: 1.0435\n",
      "Epoch 1495/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5658 - val_loss: 1.0592\n",
      "Epoch 1496/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5658 - val_loss: 1.0387\n",
      "Epoch 1497/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5653 - val_loss: 1.0348\n",
      "Epoch 1498/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.5652 - val_loss: 1.0551\n",
      "Epoch 1499/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.5650 - val_loss: 1.0459\n",
      "Epoch 1500/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.5646 - val_loss: 1.0346\n",
      "Epoch 1501/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5645 - val_loss: 1.0499\n",
      "Epoch 1502/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5642 - val_loss: 1.0468\n",
      "Epoch 1503/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5639 - val_loss: 1.0320\n",
      "Epoch 1504/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.5637 - val_loss: 1.0436\n",
      "Epoch 1505/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5634 - val_loss: 1.0490\n",
      "Epoch 1506/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5632 - val_loss: 1.0360\n",
      "Epoch 1507/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.5630 - val_loss: 1.0417\n",
      "Epoch 1508/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5627 - val_loss: 1.0502\n",
      "Epoch 1509/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.5625 - val_loss: 1.0410\n",
      "Epoch 1510/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.5622 - val_loss: 1.0442\n",
      "Epoch 1511/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5620 - val_loss: 1.0553\n",
      "Epoch 1512/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5618 - val_loss: 1.0484\n",
      "Epoch 1513/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5615 - val_loss: 1.0461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1514/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.5613 - val_loss: 1.0551\n",
      "Epoch 1515/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5611 - val_loss: 1.0512\n",
      "Epoch 1516/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5608 - val_loss: 1.0480\n",
      "Epoch 1517/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5606 - val_loss: 1.0566\n",
      "Epoch 1518/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5604 - val_loss: 1.0546\n",
      "Epoch 1519/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.5601 - val_loss: 1.0491\n",
      "Epoch 1520/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.5599 - val_loss: 1.0548\n",
      "Epoch 1521/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5597 - val_loss: 1.0540\n",
      "Epoch 1522/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5594 - val_loss: 1.0485\n",
      "Epoch 1523/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5592 - val_loss: 1.0532\n",
      "Epoch 1524/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5590 - val_loss: 1.0539\n",
      "Epoch 1525/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 0.5587 - val_loss: 1.0492\n",
      "Epoch 1526/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.5585 - val_loss: 1.0528\n",
      "Epoch 1527/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5583 - val_loss: 1.0537\n",
      "Epoch 1528/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.5580 - val_loss: 1.0492\n",
      "Epoch 1529/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5578 - val_loss: 1.0519\n",
      "Epoch 1530/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5575 - val_loss: 1.0531\n",
      "Epoch 1531/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5573 - val_loss: 1.0491\n",
      "Epoch 1532/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.5571 - val_loss: 1.0511\n",
      "Epoch 1533/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.5568 - val_loss: 1.0522\n",
      "Epoch 1534/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.5566 - val_loss: 1.0490\n",
      "Epoch 1535/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.5564 - val_loss: 1.0512\n",
      "Epoch 1536/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.5561 - val_loss: 1.0525\n",
      "Epoch 1537/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.5559 - val_loss: 1.0497\n",
      "Epoch 1538/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5556 - val_loss: 1.0511\n",
      "Epoch 1539/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5554 - val_loss: 1.0518\n",
      "Epoch 1540/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.5552 - val_loss: 1.0496\n",
      "Epoch 1541/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5549 - val_loss: 1.0515\n",
      "Epoch 1542/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.5547 - val_loss: 1.0525\n",
      "Epoch 1543/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.5544 - val_loss: 1.0509\n",
      "Epoch 1544/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5542 - val_loss: 1.0525\n",
      "Epoch 1545/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5539 - val_loss: 1.0529\n",
      "Epoch 1546/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.5537 - val_loss: 1.0516\n",
      "Epoch 1547/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5534 - val_loss: 1.0533\n",
      "Epoch 1548/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5532 - val_loss: 1.0535\n",
      "Epoch 1549/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5529 - val_loss: 1.0527\n",
      "Epoch 1550/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5527 - val_loss: 1.0544\n",
      "Epoch 1551/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5524 - val_loss: 1.0543\n",
      "Epoch 1552/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5522 - val_loss: 1.0537\n",
      "Epoch 1553/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5519 - val_loss: 1.0551\n",
      "Epoch 1554/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.5517 - val_loss: 1.0546\n",
      "Epoch 1555/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5514 - val_loss: 1.0544\n",
      "Epoch 1556/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5512 - val_loss: 1.0556\n",
      "Epoch 1557/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5509 - val_loss: 1.0549\n",
      "Epoch 1558/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 0.5507 - val_loss: 1.0550\n",
      "Epoch 1559/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5504 - val_loss: 1.0559\n",
      "Epoch 1560/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5501 - val_loss: 1.0553\n",
      "Epoch 1561/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.5499 - val_loss: 1.0559\n",
      "Epoch 1562/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.5496 - val_loss: 1.0564\n",
      "Epoch 1563/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.5494 - val_loss: 1.0558\n",
      "Epoch 1564/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5491 - val_loss: 1.0564\n",
      "Epoch 1565/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5488 - val_loss: 1.0566\n",
      "Epoch 1566/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5486 - val_loss: 1.0564\n",
      "Epoch 1567/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5483 - val_loss: 1.0572\n",
      "Epoch 1568/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.5481 - val_loss: 1.0571\n",
      "Epoch 1569/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.5478 - val_loss: 1.0571\n",
      "Epoch 1570/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.5475 - val_loss: 1.0578\n",
      "Epoch 1571/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5473 - val_loss: 1.0575\n",
      "Epoch 1572/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5470 - val_loss: 1.0579\n",
      "Epoch 1573/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5467 - val_loss: 1.0583\n",
      "Epoch 1574/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.5465 - val_loss: 1.0582\n",
      "Epoch 1575/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5462 - val_loss: 1.0588\n",
      "Epoch 1576/2500\n",
      "64/64 [==============================] - 0s 39us/step - loss: 0.5459 - val_loss: 1.0590\n",
      "Epoch 1577/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5457 - val_loss: 1.0590\n",
      "Epoch 1578/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5454 - val_loss: 1.0596\n",
      "Epoch 1579/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.5451 - val_loss: 1.0596\n",
      "Epoch 1580/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.5448 - val_loss: 1.0600\n",
      "Epoch 1581/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.5446 - val_loss: 1.0604\n",
      "Epoch 1582/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5443 - val_loss: 1.0604\n",
      "Epoch 1583/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5440 - val_loss: 1.0609\n",
      "Epoch 1584/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5437 - val_loss: 1.0610\n",
      "Epoch 1585/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5435 - val_loss: 1.0613\n",
      "Epoch 1586/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.5432 - val_loss: 1.0618\n",
      "Epoch 1587/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5429 - val_loss: 1.0618\n",
      "Epoch 1588/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5426 - val_loss: 1.0623\n",
      "Epoch 1589/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5424 - val_loss: 1.0625\n",
      "Epoch 1590/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5421 - val_loss: 1.0627\n",
      "Epoch 1591/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.5418 - val_loss: 1.0632\n",
      "Epoch 1592/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.5415 - val_loss: 1.0633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1593/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5412 - val_loss: 1.0637\n",
      "Epoch 1594/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5410 - val_loss: 1.0639\n",
      "Epoch 1595/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5407 - val_loss: 1.0641\n",
      "Epoch 1596/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.5404 - val_loss: 1.0646\n",
      "Epoch 1597/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 0.5401 - val_loss: 1.0647\n",
      "Epoch 1598/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.5398 - val_loss: 1.0651\n",
      "Epoch 1599/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5395 - val_loss: 1.0654\n",
      "Epoch 1600/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 0.5392 - val_loss: 1.0656\n",
      "Epoch 1601/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5390 - val_loss: 1.0661\n",
      "Epoch 1602/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5387 - val_loss: 1.0662\n",
      "Epoch 1603/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.5384 - val_loss: 1.0666\n",
      "Epoch 1604/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5381 - val_loss: 1.0669\n",
      "Epoch 1605/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.5378 - val_loss: 1.0672\n",
      "Epoch 1606/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5375 - val_loss: 1.0676\n",
      "Epoch 1607/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5372 - val_loss: 1.0679\n",
      "Epoch 1608/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5369 - val_loss: 1.0683\n",
      "Epoch 1609/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.5366 - val_loss: 1.0685\n",
      "Epoch 1610/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5364 - val_loss: 1.0689\n",
      "Epoch 1611/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5361 - val_loss: 1.0693\n",
      "Epoch 1612/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.5358 - val_loss: 1.0695\n",
      "Epoch 1613/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5355 - val_loss: 1.0700\n",
      "Epoch 1614/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5352 - val_loss: 1.0702\n",
      "Epoch 1615/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.5349 - val_loss: 1.0706\n",
      "Epoch 1616/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.5346 - val_loss: 1.0709\n",
      "Epoch 1617/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5343 - val_loss: 1.0713\n",
      "Epoch 1618/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5340 - val_loss: 1.0717\n",
      "Epoch 1619/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5337 - val_loss: 1.0720\n",
      "Epoch 1620/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.5334 - val_loss: 1.0724\n",
      "Epoch 1621/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5331 - val_loss: 1.0727\n",
      "Epoch 1622/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5328 - val_loss: 1.0731\n",
      "Epoch 1623/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5325 - val_loss: 1.0734\n",
      "Epoch 1624/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.5322 - val_loss: 1.0738\n",
      "Epoch 1625/2500\n",
      "64/64 [==============================] - 0s 456us/step - loss: 0.5319 - val_loss: 1.0741\n",
      "Epoch 1626/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.5316 - val_loss: 1.0745\n",
      "Epoch 1627/2500\n",
      "64/64 [==============================] - 0s 482us/step - loss: 0.5313 - val_loss: 1.0749\n",
      "Epoch 1628/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5310 - val_loss: 1.0753\n",
      "Epoch 1629/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.5307 - val_loss: 1.0756\n",
      "Epoch 1630/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5304 - val_loss: 1.0760\n",
      "Epoch 1631/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5301 - val_loss: 1.0764\n",
      "Epoch 1632/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.5298 - val_loss: 1.0767\n",
      "Epoch 1633/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5295 - val_loss: 1.0771\n",
      "Epoch 1634/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.5292 - val_loss: 1.0775\n",
      "Epoch 1635/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5289 - val_loss: 1.0779\n",
      "Epoch 1636/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5286 - val_loss: 1.0782\n",
      "Epoch 1637/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5283 - val_loss: 1.0787\n",
      "Epoch 1638/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.5280 - val_loss: 1.0790\n",
      "Epoch 1639/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.5277 - val_loss: 1.0794\n",
      "Epoch 1640/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5274 - val_loss: 1.0798\n",
      "Epoch 1641/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.5270 - val_loss: 1.0802\n",
      "Epoch 1642/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.5267 - val_loss: 1.0805\n",
      "Epoch 1643/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5264 - val_loss: 1.0811\n",
      "Epoch 1644/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.5261 - val_loss: 1.0813\n",
      "Epoch 1645/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.5258 - val_loss: 1.0819\n",
      "Epoch 1646/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5255 - val_loss: 1.0819\n",
      "Epoch 1647/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5252 - val_loss: 1.0829\n",
      "Epoch 1648/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.5249 - val_loss: 1.0824\n",
      "Epoch 1649/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5246 - val_loss: 1.0842\n",
      "Epoch 1650/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5243 - val_loss: 1.0825\n",
      "Epoch 1651/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5240 - val_loss: 1.0861\n",
      "Epoch 1652/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5237 - val_loss: 1.0816\n",
      "Epoch 1653/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5234 - val_loss: 1.0896\n",
      "Epoch 1654/2500\n",
      "64/64 [==============================] - 0s 417us/step - loss: 0.5231 - val_loss: 1.0779\n",
      "Epoch 1655/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.5228 - val_loss: 1.0976\n",
      "Epoch 1656/2500\n",
      "64/64 [==============================] - 0s 388us/step - loss: 0.5227 - val_loss: 1.0663\n",
      "Epoch 1657/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.5230 - val_loss: 1.1177\n",
      "Epoch 1658/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.5242 - val_loss: 1.0307\n",
      "Epoch 1659/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.5284 - val_loss: 1.1717\n",
      "Epoch 1660/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.5432 - val_loss: 0.9108\n",
      "Epoch 1661/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.6098 - val_loss: 1.7021\n",
      "Epoch 1662/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.8758 - val_loss: 1.7986\n",
      "Epoch 1663/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 0.8994 - val_loss: 0.9266\n",
      "Epoch 1664/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6425 - val_loss: 0.7447\n",
      "Epoch 1665/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.9766 - val_loss: 1.3049\n",
      "Epoch 1666/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.7390 - val_loss: 1.6664\n",
      "Epoch 1667/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.8435 - val_loss: 1.1100\n",
      "Epoch 1668/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5797 - val_loss: 0.7639\n",
      "Epoch 1669/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.9450 - val_loss: 0.7279\n",
      "Epoch 1670/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.8080 - val_loss: 1.3734\n",
      "Epoch 1671/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.7332 - val_loss: 1.2299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1672/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5947 - val_loss: 0.7462\n",
      "Epoch 1673/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.8021 - val_loss: 0.6155\n",
      "Epoch 1674/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.8171 - val_loss: 1.1565\n",
      "Epoch 1675/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.6709 - val_loss: 2.1095\n",
      "Epoch 1676/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 1.1425 - val_loss: 1.9973\n",
      "Epoch 1677/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.0201 - val_loss: 1.3377\n",
      "Epoch 1678/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7241 - val_loss: 0.9481\n",
      "Epoch 1679/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2953 - val_loss: 0.9667\n",
      "Epoch 1680/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 0.7033 - val_loss: 2.3851\n",
      "Epoch 1681/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1650 - val_loss: 2.6609\n",
      "Epoch 1682/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.4432 - val_loss: 1.9742\n",
      "Epoch 1683/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1160 - val_loss: 1.0796\n",
      "Epoch 1684/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.8816 - val_loss: 0.8023\n",
      "Epoch 1685/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 1.0517 - val_loss: 0.8924\n",
      "Epoch 1686/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.9787 - val_loss: 1.2054\n",
      "Epoch 1687/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 0.8925 - val_loss: 1.4834\n",
      "Epoch 1688/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.9133 - val_loss: 1.3549\n",
      "Epoch 1689/2500\n",
      "64/64 [==============================] - 0s 457us/step - loss: 0.7912 - val_loss: 1.0817\n",
      "Epoch 1690/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 0.7987 - val_loss: 0.9520\n",
      "Epoch 1691/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.7996 - val_loss: 1.1120\n",
      "Epoch 1692/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 0.6825 - val_loss: 1.2798\n",
      "Epoch 1693/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7917 - val_loss: 1.0543\n",
      "Epoch 1694/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6788 - val_loss: 0.9838\n",
      "Epoch 1695/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 0.8035 - val_loss: 1.1716\n",
      "Epoch 1696/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.6971 - val_loss: 1.4184\n",
      "Epoch 1697/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7071 - val_loss: 1.4068\n",
      "Epoch 1698/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.7122 - val_loss: 1.0786\n",
      "Epoch 1699/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.6860 - val_loss: 0.9210\n",
      "Epoch 1700/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.7212 - val_loss: 1.0654\n",
      "Epoch 1701/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6612 - val_loss: 1.3451\n",
      "Epoch 1702/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 0.6812 - val_loss: 1.3395\n",
      "Epoch 1703/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.6753 - val_loss: 1.0717\n",
      "Epoch 1704/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.6430 - val_loss: 0.9374\n",
      "Epoch 1705/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 0.6586 - val_loss: 1.1532\n",
      "Epoch 1706/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.6246 - val_loss: 1.2998\n",
      "Epoch 1707/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6545 - val_loss: 1.1187\n",
      "Epoch 1708/2500\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.6211 - val_loss: 0.8753\n",
      "Epoch 1709/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.6564 - val_loss: 1.0751\n",
      "Epoch 1710/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 0.6091 - val_loss: 1.2231\n",
      "Epoch 1711/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.6380 - val_loss: 1.0369\n",
      "Epoch 1712/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.6024 - val_loss: 0.9250\n",
      "Epoch 1713/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.6161 - val_loss: 1.1645\n",
      "Epoch 1714/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.6092 - val_loss: 1.1174\n",
      "Epoch 1715/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5971 - val_loss: 0.8948\n",
      "Epoch 1716/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.6219 - val_loss: 1.1261\n",
      "Epoch 1717/2500\n",
      "64/64 [==============================] - 0s 356us/step - loss: 0.5895 - val_loss: 1.1388\n",
      "Epoch 1718/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5906 - val_loss: 0.9330\n",
      "Epoch 1719/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.6080 - val_loss: 1.1049\n",
      "Epoch 1720/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 0.5804 - val_loss: 1.1180\n",
      "Epoch 1721/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.5817 - val_loss: 0.9396\n",
      "Epoch 1722/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.5936 - val_loss: 1.0847\n",
      "Epoch 1723/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.5772 - val_loss: 1.0852\n",
      "Epoch 1724/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5763 - val_loss: 0.9377\n",
      "Epoch 1725/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5845 - val_loss: 1.0591\n",
      "Epoch 1726/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.5724 - val_loss: 1.0415\n",
      "Epoch 1727/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.5699 - val_loss: 0.9134\n",
      "Epoch 1728/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5755 - val_loss: 1.0267\n",
      "Epoch 1729/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.5677 - val_loss: 0.9835\n",
      "Epoch 1730/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.5622 - val_loss: 0.9064\n",
      "Epoch 1731/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 0.5686 - val_loss: 1.0380\n",
      "Epoch 1732/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.5666 - val_loss: 0.9698\n",
      "Epoch 1733/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 0.5586 - val_loss: 0.9420\n",
      "Epoch 1734/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.5617 - val_loss: 1.0425\n",
      "Epoch 1735/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.5648 - val_loss: 0.9424\n",
      "Epoch 1736/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5585 - val_loss: 0.9618\n",
      "Epoch 1737/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.5560 - val_loss: 1.0218\n",
      "Epoch 1738/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5597 - val_loss: 0.9332\n",
      "Epoch 1739/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.5593 - val_loss: 1.0111\n",
      "Epoch 1740/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.5540 - val_loss: 1.0174\n",
      "Epoch 1741/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.5531 - val_loss: 0.9663\n",
      "Epoch 1742/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.5555 - val_loss: 1.0484\n",
      "Epoch 1743/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.5542 - val_loss: 0.9889\n",
      "Epoch 1744/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5505 - val_loss: 1.0020\n",
      "Epoch 1745/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.5490 - val_loss: 1.0405\n",
      "Epoch 1746/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5500 - val_loss: 0.9804\n",
      "Epoch 1747/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.5503 - val_loss: 1.0506\n",
      "Epoch 1748/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5482 - val_loss: 1.0207\n",
      "Epoch 1749/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5460 - val_loss: 1.0205\n",
      "Epoch 1750/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5454 - val_loss: 1.0565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1751/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.5459 - val_loss: 0.9977\n",
      "Epoch 1752/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.5459 - val_loss: 1.0503\n",
      "Epoch 1753/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5446 - val_loss: 1.0107\n",
      "Epoch 1754/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5429 - val_loss: 1.0238\n",
      "Epoch 1755/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5418 - val_loss: 1.0389\n",
      "Epoch 1756/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.5416 - val_loss: 1.0073\n",
      "Epoch 1757/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5417 - val_loss: 1.0547\n",
      "Epoch 1758/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5415 - val_loss: 1.0055\n",
      "Epoch 1759/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5408 - val_loss: 1.0501\n",
      "Epoch 1760/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5399 - val_loss: 1.0127\n",
      "Epoch 1761/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.5388 - val_loss: 1.0367\n",
      "Epoch 1762/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.5379 - val_loss: 1.0229\n",
      "Epoch 1763/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5371 - val_loss: 1.0255\n",
      "Epoch 1764/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5366 - val_loss: 1.0330\n",
      "Epoch 1765/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.5361 - val_loss: 1.0167\n",
      "Epoch 1766/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.5357 - val_loss: 1.0416\n",
      "Epoch 1767/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5355 - val_loss: 1.0069\n",
      "Epoch 1768/2500\n",
      "64/64 [==============================] - 0s 41us/step - loss: 0.5355 - val_loss: 1.0525\n",
      "Epoch 1769/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5357 - val_loss: 0.9943\n",
      "Epoch 1770/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.5364 - val_loss: 1.0717\n",
      "Epoch 1771/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 0.5377 - val_loss: 0.9754\n",
      "Epoch 1772/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5407 - val_loss: 1.0990\n",
      "Epoch 1773/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5436 - val_loss: 0.9511\n",
      "Epoch 1774/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 0.5490 - val_loss: 1.1185\n",
      "Epoch 1775/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5490 - val_loss: 0.9472\n",
      "Epoch 1776/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5508 - val_loss: 1.1136\n",
      "Epoch 1777/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5449 - val_loss: 0.9703\n",
      "Epoch 1778/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5426 - val_loss: 1.1019\n",
      "Epoch 1779/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 0.5386 - val_loss: 0.9842\n",
      "Epoch 1780/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.5381 - val_loss: 1.1027\n",
      "Epoch 1781/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5375 - val_loss: 0.9747\n",
      "Epoch 1782/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.5402 - val_loss: 1.1169\n",
      "Epoch 1783/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.5419 - val_loss: 0.9526\n",
      "Epoch 1784/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 0.5475 - val_loss: 1.1303\n",
      "Epoch 1785/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.5464 - val_loss: 0.9503\n",
      "Epoch 1786/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.5487 - val_loss: 1.1255\n",
      "Epoch 1787/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 0.5418 - val_loss: 0.9737\n",
      "Epoch 1788/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.5403 - val_loss: 1.1138\n",
      "Epoch 1789/2500\n",
      "64/64 [==============================] - 0s 376us/step - loss: 0.5356 - val_loss: 0.9844\n",
      "Epoch 1790/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.5358 - val_loss: 1.1111\n",
      "Epoch 1791/2500\n",
      "64/64 [==============================] - 0s 287us/step - loss: 0.5352 - val_loss: 0.9664\n",
      "Epoch 1792/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.5394 - val_loss: 1.1229\n",
      "Epoch 1793/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.5412 - val_loss: 0.9408\n",
      "Epoch 1794/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.5484 - val_loss: 1.1335\n",
      "Epoch 1795/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5444 - val_loss: 0.9494\n",
      "Epoch 1796/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 0.5461 - val_loss: 1.1267\n",
      "Epoch 1797/2500\n",
      "64/64 [==============================] - 0s 395us/step - loss: 0.5372 - val_loss: 0.9795\n",
      "Epoch 1798/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.5358 - val_loss: 1.1156\n",
      "Epoch 1799/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.5315 - val_loss: 0.9834\n",
      "Epoch 1800/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5329 - val_loss: 1.1157\n",
      "Epoch 1801/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5331 - val_loss: 0.9576\n",
      "Epoch 1802/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.5396 - val_loss: 1.1313\n",
      "Epoch 1803/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5408 - val_loss: 0.9354\n",
      "Epoch 1804/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5490 - val_loss: 1.1399\n",
      "Epoch 1805/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5416 - val_loss: 0.9562\n",
      "Epoch 1806/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 0.5423 - val_loss: 1.1288\n",
      "Epoch 1807/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5320 - val_loss: 0.9916\n",
      "Epoch 1808/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.5300 - val_loss: 1.1152\n",
      "Epoch 1809/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 0.5263 - val_loss: 0.9906\n",
      "Epoch 1810/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5279 - val_loss: 1.1175\n",
      "Epoch 1811/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.5294 - val_loss: 0.9556\n",
      "Epoch 1812/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5380 - val_loss: 1.1403\n",
      "Epoch 1813/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.5405 - val_loss: 0.9291\n",
      "Epoch 1814/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5513 - val_loss: 1.1507\n",
      "Epoch 1815/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5405 - val_loss: 0.9615\n",
      "Epoch 1816/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5401 - val_loss: 1.1328\n",
      "Epoch 1817/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5267 - val_loss: 1.0110\n",
      "Epoch 1818/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.5229 - val_loss: 1.1090\n",
      "Epoch 1819/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.5193 - val_loss: 1.0092\n",
      "Epoch 1820/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5198 - val_loss: 1.1061\n",
      "Epoch 1821/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5218 - val_loss: 0.9651\n",
      "Epoch 1822/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.5307 - val_loss: 1.1417\n",
      "Epoch 1823/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.5388 - val_loss: 0.9115\n",
      "Epoch 1824/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.5592 - val_loss: 1.1736\n",
      "Epoch 1825/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.5500 - val_loss: 0.9345\n",
      "Epoch 1826/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5530 - val_loss: 1.1472\n",
      "Epoch 1827/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.5263 - val_loss: 1.0329\n",
      "Epoch 1828/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5170 - val_loss: 1.0982\n",
      "Epoch 1829/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5115 - val_loss: 1.0619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1830/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5099 - val_loss: 1.0488\n",
      "Epoch 1831/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5094 - val_loss: 1.0678\n",
      "Epoch 1832/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.5102 - val_loss: 1.0034\n",
      "Epoch 1833/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5136 - val_loss: 1.1117\n",
      "Epoch 1834/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.5216 - val_loss: 0.9330\n",
      "Epoch 1835/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5464 - val_loss: 1.2000\n",
      "Epoch 1836/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.5662 - val_loss: 0.8630\n",
      "Epoch 1837/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5981 - val_loss: 1.1758\n",
      "Epoch 1838/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.5408 - val_loss: 1.0171\n",
      "Epoch 1839/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.5216 - val_loss: 1.1042\n",
      "Epoch 1840/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5072 - val_loss: 1.1294\n",
      "Epoch 1841/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5126 - val_loss: 0.9704\n",
      "Epoch 1842/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5380 - val_loss: 1.2057\n",
      "Epoch 1843/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5689 - val_loss: 0.8386\n",
      "Epoch 1844/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.6045 - val_loss: 1.1193\n",
      "Epoch 1845/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.5245 - val_loss: 1.1216\n",
      "Epoch 1846/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5128 - val_loss: 0.9422\n",
      "Epoch 1847/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 0.5626 - val_loss: 1.2642\n",
      "Epoch 1848/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5812 - val_loss: 0.9074\n",
      "Epoch 1849/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.5754 - val_loss: 1.1190\n",
      "Epoch 1850/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5166 - val_loss: 1.1325\n",
      "Epoch 1851/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5224 - val_loss: 0.8944\n",
      "Epoch 1852/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5785 - val_loss: 1.2154\n",
      "Epoch 1853/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.5519 - val_loss: 0.9971\n",
      "Epoch 1854/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.5279 - val_loss: 1.0938\n",
      "Epoch 1855/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.5048 - val_loss: 1.1593\n",
      "Epoch 1856/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5244 - val_loss: 0.8822\n",
      "Epoch 1857/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5768 - val_loss: 1.1629\n",
      "Epoch 1858/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5336 - val_loss: 1.0211\n",
      "Epoch 1859/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.5104 - val_loss: 1.0573\n",
      "Epoch 1860/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.5037 - val_loss: 1.1664\n",
      "Epoch 1861/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.5252 - val_loss: 0.9125\n",
      "Epoch 1862/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5659 - val_loss: 1.1843\n",
      "Epoch 1863/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.5431 - val_loss: 0.9698\n",
      "Epoch 1864/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.5285 - val_loss: 1.0681\n",
      "Epoch 1865/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.5022 - val_loss: 1.1884\n",
      "Epoch 1866/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.5387 - val_loss: 0.8415\n",
      "Epoch 1867/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6215 - val_loss: 1.1852\n",
      "Epoch 1868/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5356 - val_loss: 1.0557\n",
      "Epoch 1869/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5071 - val_loss: 1.0175\n",
      "Epoch 1870/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.5127 - val_loss: 1.1715\n",
      "Epoch 1871/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.5234 - val_loss: 0.9681\n",
      "Epoch 1872/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5362 - val_loss: 1.1409\n",
      "Epoch 1873/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5134 - val_loss: 1.0416\n",
      "Epoch 1874/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5024 - val_loss: 1.0445\n",
      "Epoch 1875/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.5022 - val_loss: 1.1291\n",
      "Epoch 1876/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5084 - val_loss: 0.9888\n",
      "Epoch 1877/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.5199 - val_loss: 1.1455\n",
      "Epoch 1878/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5149 - val_loss: 1.0052\n",
      "Epoch 1879/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.5092 - val_loss: 1.0935\n",
      "Epoch 1880/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4993 - val_loss: 1.0833\n",
      "Epoch 1881/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4966 - val_loss: 1.0345\n",
      "Epoch 1882/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5011 - val_loss: 1.1425\n",
      "Epoch 1883/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.5103 - val_loss: 0.9767\n",
      "Epoch 1884/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5250 - val_loss: 1.1693\n",
      "Epoch 1885/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5302 - val_loss: 0.9310\n",
      "Epoch 1886/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5458 - val_loss: 1.1492\n",
      "Epoch 1887/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.5149 - val_loss: 1.0406\n",
      "Epoch 1888/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5006 - val_loss: 1.1062\n",
      "Epoch 1889/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.4944 - val_loss: 1.1116\n",
      "Epoch 1890/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4949 - val_loss: 1.0380\n",
      "Epoch 1891/2500\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.5003 - val_loss: 1.1419\n",
      "Epoch 1892/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.5086 - val_loss: 0.9721\n",
      "Epoch 1893/2500\n",
      "64/64 [==============================] - 0s 862us/step - loss: 0.5219 - val_loss: 1.1417\n",
      "Epoch 1894/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.5084 - val_loss: 1.0304\n",
      "Epoch 1895/2500\n",
      "64/64 [==============================] - 0s 357us/step - loss: 0.5020 - val_loss: 1.1248\n",
      "Epoch 1896/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4951 - val_loss: 1.0791\n",
      "Epoch 1897/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4918 - val_loss: 1.0948\n",
      "Epoch 1898/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.4904 - val_loss: 1.0900\n",
      "Epoch 1899/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.4902 - val_loss: 1.0573\n",
      "Epoch 1900/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4907 - val_loss: 1.1028\n",
      "Epoch 1901/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 0.4927 - val_loss: 1.0244\n",
      "Epoch 1902/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4989 - val_loss: 1.1546\n",
      "Epoch 1903/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5118 - val_loss: 0.9428\n",
      "Epoch 1904/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5461 - val_loss: 1.2180\n",
      "Epoch 1905/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5633 - val_loss: 0.8668\n",
      "Epoch 1906/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.6088 - val_loss: 1.2018\n",
      "Epoch 1907/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5401 - val_loss: 1.0087\n",
      "Epoch 1908/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5162 - val_loss: 1.1343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1909/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4896 - val_loss: 1.1706\n",
      "Epoch 1910/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4977 - val_loss: 0.9898\n",
      "Epoch 1911/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.5335 - val_loss: 1.2236\n",
      "Epoch 1912/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5445 - val_loss: 0.9242\n",
      "Epoch 1913/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5571 - val_loss: 1.1333\n",
      "Epoch 1914/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4984 - val_loss: 1.1557\n",
      "Epoch 1915/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.5003 - val_loss: 0.9556\n",
      "Epoch 1916/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.5552 - val_loss: 1.2540\n",
      "Epoch 1917/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5542 - val_loss: 0.9690\n",
      "Epoch 1918/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.5392 - val_loss: 1.1042\n",
      "Epoch 1919/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4926 - val_loss: 1.2451\n",
      "Epoch 1920/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5532 - val_loss: 0.8199\n",
      "Epoch 1921/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6758 - val_loss: 1.1074\n",
      "Epoch 1922/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4908 - val_loss: 1.4201\n",
      "Epoch 1923/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.7204 - val_loss: 0.9021\n",
      "Epoch 1924/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.5732 - val_loss: 0.9732\n",
      "Epoch 1925/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5127 - val_loss: 1.2894\n",
      "Epoch 1926/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6564 - val_loss: 0.9206\n",
      "Epoch 1927/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5494 - val_loss: 1.0211\n",
      "Epoch 1928/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.5005 - val_loss: 1.2995\n",
      "Epoch 1929/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.6095 - val_loss: 0.8822\n",
      "Epoch 1930/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6017 - val_loss: 1.0768\n",
      "Epoch 1931/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4927 - val_loss: 1.2856\n",
      "Epoch 1932/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.6230 - val_loss: 0.8305\n",
      "Epoch 1933/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.6443 - val_loss: 1.0162\n",
      "Epoch 1934/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5068 - val_loss: 1.3788\n",
      "Epoch 1935/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6879 - val_loss: 0.9979\n",
      "Epoch 1936/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 0.5214 - val_loss: 0.9122\n",
      "Epoch 1937/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5840 - val_loss: 1.3129\n",
      "Epoch 1938/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.5947 - val_loss: 1.0710\n",
      "Epoch 1939/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5047 - val_loss: 0.9759\n",
      "Epoch 1940/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 0.5474 - val_loss: 1.2502\n",
      "Epoch 1941/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.5348 - val_loss: 1.1080\n",
      "Epoch 1942/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4949 - val_loss: 0.9856\n",
      "Epoch 1943/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 0.5182 - val_loss: 1.1137\n",
      "Epoch 1944/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4949 - val_loss: 1.1448\n",
      "Epoch 1945/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.5054 - val_loss: 0.9711\n",
      "Epoch 1946/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.5174 - val_loss: 1.0683\n",
      "Epoch 1947/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.4890 - val_loss: 1.1851\n",
      "Epoch 1948/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5219 - val_loss: 0.9591\n",
      "Epoch 1949/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 0.5290 - val_loss: 1.0703\n",
      "Epoch 1950/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4878 - val_loss: 1.2072\n",
      "Epoch 1951/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5429 - val_loss: 0.8977\n",
      "Epoch 1952/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5717 - val_loss: 1.0887\n",
      "Epoch 1953/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 0.4872 - val_loss: 1.2177\n",
      "Epoch 1954/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.5631 - val_loss: 0.8346\n",
      "Epoch 1955/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6456 - val_loss: 1.0784\n",
      "Epoch 1956/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4888 - val_loss: 1.3540\n",
      "Epoch 1957/2500\n",
      "64/64 [==============================] - 0s 330us/step - loss: 0.6752 - val_loss: 0.8958\n",
      "Epoch 1958/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5834 - val_loss: 0.9820\n",
      "Epoch 1959/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5165 - val_loss: 1.3002\n",
      "Epoch 1960/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.6176 - val_loss: 0.9850\n",
      "Epoch 1961/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 0.5259 - val_loss: 0.9705\n",
      "Epoch 1962/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.5440 - val_loss: 1.3046\n",
      "Epoch 1963/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.5669 - val_loss: 1.1165\n",
      "Epoch 1964/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4974 - val_loss: 0.9750\n",
      "Epoch 1965/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5485 - val_loss: 1.2048\n",
      "Epoch 1966/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5093 - val_loss: 1.2436\n",
      "Epoch 1967/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5338 - val_loss: 0.9608\n",
      "Epoch 1968/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.5456 - val_loss: 1.0484\n",
      "Epoch 1969/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5013 - val_loss: 1.2416\n",
      "Epoch 1970/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5362 - val_loss: 1.0688\n",
      "Epoch 1971/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4952 - val_loss: 0.9950\n",
      "Epoch 1972/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.5226 - val_loss: 1.1919\n",
      "Epoch 1973/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5062 - val_loss: 1.1419\n",
      "Epoch 1974/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4939 - val_loss: 0.9725\n",
      "Epoch 1975/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5104 - val_loss: 1.0520\n",
      "Epoch 1976/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.4845 - val_loss: 1.1553\n",
      "Epoch 1977/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.5148 - val_loss: 0.9799\n",
      "Epoch 1978/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5087 - val_loss: 1.0517\n",
      "Epoch 1979/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4850 - val_loss: 1.1869\n",
      "Epoch 1980/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.5206 - val_loss: 0.9890\n",
      "Epoch 1981/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5138 - val_loss: 1.0688\n",
      "Epoch 1982/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4830 - val_loss: 1.1978\n",
      "Epoch 1983/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5270 - val_loss: 0.9678\n",
      "Epoch 1984/2500\n",
      "64/64 [==============================] - 0s 334us/step - loss: 0.5245 - val_loss: 1.0780\n",
      "Epoch 1985/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4808 - val_loss: 1.2144\n",
      "Epoch 1986/2500\n",
      "64/64 [==============================] - 0s 562us/step - loss: 0.5313 - val_loss: 0.9700\n",
      "Epoch 1987/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.5343 - val_loss: 1.1130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1988/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4807 - val_loss: 1.2565\n",
      "Epoch 1989/2500\n",
      "64/64 [==============================] - 0s 334us/step - loss: 0.5365 - val_loss: 0.9861\n",
      "Epoch 1990/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.5347 - val_loss: 1.1110\n",
      "Epoch 1991/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 0.4826 - val_loss: 1.2568\n",
      "Epoch 1992/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.5358 - val_loss: 1.0081\n",
      "Epoch 1993/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5212 - val_loss: 1.0921\n",
      "Epoch 1994/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4880 - val_loss: 1.2607\n",
      "Epoch 1995/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.5250 - val_loss: 1.0867\n",
      "Epoch 1996/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4909 - val_loss: 1.0497\n",
      "Epoch 1997/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.5036 - val_loss: 1.2241\n",
      "Epoch 1998/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 0.5056 - val_loss: 1.1476\n",
      "Epoch 1999/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4816 - val_loss: 1.0361\n",
      "Epoch 2000/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.5001 - val_loss: 1.1347\n",
      "Epoch 2001/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4798 - val_loss: 1.1860\n",
      "Epoch 2002/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4951 - val_loss: 1.0493\n",
      "Epoch 2003/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4922 - val_loss: 1.0838\n",
      "Epoch 2004/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4810 - val_loss: 1.1867\n",
      "Epoch 2005/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.4984 - val_loss: 1.0639\n",
      "Epoch 2006/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4839 - val_loss: 1.0659\n",
      "Epoch 2007/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4816 - val_loss: 1.1669\n",
      "Epoch 2008/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4952 - val_loss: 1.0551\n",
      "Epoch 2009/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4825 - val_loss: 1.0729\n",
      "Epoch 2010/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4773 - val_loss: 1.1645\n",
      "Epoch 2011/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4927 - val_loss: 1.0488\n",
      "Epoch 2012/2500\n",
      "64/64 [==============================] - 0s 370us/step - loss: 0.4870 - val_loss: 1.0993\n",
      "Epoch 2013/2500\n",
      "64/64 [==============================] - 0s 442us/step - loss: 0.4735 - val_loss: 1.1762\n",
      "Epoch 2014/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4925 - val_loss: 1.0368\n",
      "Epoch 2015/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4956 - val_loss: 1.1183\n",
      "Epoch 2016/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.4720 - val_loss: 1.1830\n",
      "Epoch 2017/2500\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.4926 - val_loss: 1.0267\n",
      "Epoch 2018/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5045 - val_loss: 1.1385\n",
      "Epoch 2019/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4720 - val_loss: 1.1998\n",
      "Epoch 2020/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.4937 - val_loss: 1.0249\n",
      "Epoch 2021/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.5126 - val_loss: 1.1537\n",
      "Epoch 2022/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4724 - val_loss: 1.2115\n",
      "Epoch 2023/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4977 - val_loss: 1.0100\n",
      "Epoch 2024/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.5227 - val_loss: 1.1539\n",
      "Epoch 2025/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4726 - val_loss: 1.2221\n",
      "Epoch 2026/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5064 - val_loss: 0.9863\n",
      "Epoch 2027/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5403 - val_loss: 1.1547\n",
      "Epoch 2028/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.4732 - val_loss: 1.2476\n",
      "Epoch 2029/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5291 - val_loss: 0.9320\n",
      "Epoch 2030/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5931 - val_loss: 1.1520\n",
      "Epoch 2031/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4773 - val_loss: 1.2865\n",
      "Epoch 2032/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.5938 - val_loss: 0.8346\n",
      "Epoch 2033/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7273 - val_loss: 0.9696\n",
      "Epoch 2034/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5884 - val_loss: 1.6030\n",
      "Epoch 2035/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.8901 - val_loss: 1.5534\n",
      "Epoch 2036/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.8941 - val_loss: 1.0931\n",
      "Epoch 2037/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.6784 - val_loss: 0.8125\n",
      "Epoch 2038/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.9742 - val_loss: 0.8224\n",
      "Epoch 2039/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6191 - val_loss: 1.4964\n",
      "Epoch 2040/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7748 - val_loss: 1.5651\n",
      "Epoch 2041/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.7679 - val_loss: 0.9134\n",
      "Epoch 2042/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6610 - val_loss: 0.7126\n",
      "Epoch 2043/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.8153 - val_loss: 0.8068\n",
      "Epoch 2044/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6495 - val_loss: 1.1068\n",
      "Epoch 2045/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.6562 - val_loss: 1.5387\n",
      "Epoch 2046/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.7936 - val_loss: 1.4090\n",
      "Epoch 2047/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.7367 - val_loss: 1.0469\n",
      "Epoch 2048/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.6713 - val_loss: 0.8974\n",
      "Epoch 2049/2500\n",
      "64/64 [==============================] - 0s 280us/step - loss: 0.7249 - val_loss: 0.9629\n",
      "Epoch 2050/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.6434 - val_loss: 1.2814\n",
      "Epoch 2051/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.6284 - val_loss: 1.4070\n",
      "Epoch 2052/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 0.6152 - val_loss: 1.1388\n",
      "Epoch 2053/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6002 - val_loss: 0.9724\n",
      "Epoch 2054/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.6339 - val_loss: 1.0632\n",
      "Epoch 2055/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.5426 - val_loss: 1.1112\n",
      "Epoch 2056/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.5888 - val_loss: 0.9109\n",
      "Epoch 2057/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5553 - val_loss: 0.7909\n",
      "Epoch 2058/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5746 - val_loss: 0.9048\n",
      "Epoch 2059/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 0.5337 - val_loss: 1.1766\n",
      "Epoch 2060/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.5316 - val_loss: 1.2660\n",
      "Epoch 2061/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5191 - val_loss: 1.1119\n",
      "Epoch 2062/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5499 - val_loss: 1.1957\n",
      "Epoch 2063/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 0.5174 - val_loss: 1.3146\n",
      "Epoch 2064/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.5557 - val_loss: 1.0606\n",
      "Epoch 2065/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5057 - val_loss: 0.9870\n",
      "Epoch 2066/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5177 - val_loss: 1.1136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2067/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.5026 - val_loss: 1.1218\n",
      "Epoch 2068/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5072 - val_loss: 0.9999\n",
      "Epoch 2069/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5105 - val_loss: 1.0476\n",
      "Epoch 2070/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.5013 - val_loss: 1.1914\n",
      "Epoch 2071/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5066 - val_loss: 1.1562\n",
      "Epoch 2072/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4860 - val_loss: 1.0827\n",
      "Epoch 2073/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4976 - val_loss: 1.1513\n",
      "Epoch 2074/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4824 - val_loss: 1.2106\n",
      "Epoch 2075/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.4932 - val_loss: 1.1647\n",
      "Epoch 2076/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4830 - val_loss: 1.1473\n",
      "Epoch 2077/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4899 - val_loss: 1.2338\n",
      "Epoch 2078/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4803 - val_loss: 1.2646\n",
      "Epoch 2079/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 0.4852 - val_loss: 1.1792\n",
      "Epoch 2080/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.4829 - val_loss: 1.1523\n",
      "Epoch 2081/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4782 - val_loss: 1.1688\n",
      "Epoch 2082/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.4814 - val_loss: 1.1062\n",
      "Epoch 2083/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.4738 - val_loss: 1.0728\n",
      "Epoch 2084/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4786 - val_loss: 1.1236\n",
      "Epoch 2085/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4739 - val_loss: 1.1359\n",
      "Epoch 2086/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4723 - val_loss: 1.1127\n",
      "Epoch 2087/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.4748 - val_loss: 1.1558\n",
      "Epoch 2088/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4704 - val_loss: 1.1778\n",
      "Epoch 2089/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4733 - val_loss: 1.1252\n",
      "Epoch 2090/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4733 - val_loss: 1.1399\n",
      "Epoch 2091/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.4686 - val_loss: 1.1567\n",
      "Epoch 2092/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4723 - val_loss: 1.0989\n",
      "Epoch 2093/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.4728 - val_loss: 1.1257\n",
      "Epoch 2094/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.4672 - val_loss: 1.1427\n",
      "Epoch 2095/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4699 - val_loss: 1.0925\n",
      "Epoch 2096/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4722 - val_loss: 1.1343\n",
      "Epoch 2097/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4663 - val_loss: 1.1433\n",
      "Epoch 2098/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.4670 - val_loss: 1.0975\n",
      "Epoch 2099/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4707 - val_loss: 1.1464\n",
      "Epoch 2100/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4670 - val_loss: 1.1325\n",
      "Epoch 2101/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.4645 - val_loss: 1.1126\n",
      "Epoch 2102/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.4668 - val_loss: 1.1581\n",
      "Epoch 2103/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 0.4667 - val_loss: 1.1322\n",
      "Epoch 2104/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4642 - val_loss: 1.1375\n",
      "Epoch 2105/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4635 - val_loss: 1.1596\n",
      "Epoch 2106/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.4650 - val_loss: 1.1193\n",
      "Epoch 2107/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.4649 - val_loss: 1.1388\n",
      "Epoch 2108/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.4630 - val_loss: 1.1319\n",
      "Epoch 2109/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4626 - val_loss: 1.1095\n",
      "Epoch 2110/2500\n",
      "64/64 [==============================] - 0s 296us/step - loss: 0.4636 - val_loss: 1.1404\n",
      "Epoch 2111/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.4632 - val_loss: 1.1246\n",
      "Epoch 2112/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4619 - val_loss: 1.1321\n",
      "Epoch 2113/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4616 - val_loss: 1.1502\n",
      "Epoch 2114/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4621 - val_loss: 1.1262\n",
      "Epoch 2115/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.4622 - val_loss: 1.1436\n",
      "Epoch 2116/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4612 - val_loss: 1.1351\n",
      "Epoch 2117/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4607 - val_loss: 1.1228\n",
      "Epoch 2118/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.4609 - val_loss: 1.1407\n",
      "Epoch 2119/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4610 - val_loss: 1.1236\n",
      "Epoch 2120/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 0.4605 - val_loss: 1.1348\n",
      "Epoch 2121/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4600 - val_loss: 1.1382\n",
      "Epoch 2122/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4599 - val_loss: 1.1262\n",
      "Epoch 2123/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4600 - val_loss: 1.1412\n",
      "Epoch 2124/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 0.4598 - val_loss: 1.1272\n",
      "Epoch 2125/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4593 - val_loss: 1.1318\n",
      "Epoch 2126/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4590 - val_loss: 1.1353\n",
      "Epoch 2127/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4589 - val_loss: 1.1255\n",
      "Epoch 2128/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.4589 - val_loss: 1.1388\n",
      "Epoch 2129/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4587 - val_loss: 1.1289\n",
      "Epoch 2130/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4584 - val_loss: 1.1328\n",
      "Epoch 2131/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.4581 - val_loss: 1.1335\n",
      "Epoch 2132/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4579 - val_loss: 1.1247\n",
      "Epoch 2133/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4579 - val_loss: 1.1335\n",
      "Epoch 2134/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4577 - val_loss: 1.1243\n",
      "Epoch 2135/2500\n",
      "64/64 [==============================] - 0s 499us/step - loss: 0.4575 - val_loss: 1.1312\n",
      "Epoch 2136/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 0.4572 - val_loss: 1.1310\n",
      "Epoch 2137/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4570 - val_loss: 1.1294\n",
      "Epoch 2138/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4569 - val_loss: 1.1360\n",
      "Epoch 2139/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 0.4568 - val_loss: 1.1281\n",
      "Epoch 2140/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.4566 - val_loss: 1.1346\n",
      "Epoch 2141/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4564 - val_loss: 1.1283\n",
      "Epoch 2142/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.4562 - val_loss: 1.1306\n",
      "Epoch 2143/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4560 - val_loss: 1.1308\n",
      "Epoch 2144/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.4558 - val_loss: 1.1283\n",
      "Epoch 2145/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4557 - val_loss: 1.1334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2146/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4555 - val_loss: 1.1278\n",
      "Epoch 2147/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.4554 - val_loss: 1.1337\n",
      "Epoch 2148/2500\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.4552 - val_loss: 1.1282\n",
      "Epoch 2149/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4550 - val_loss: 1.1327\n",
      "Epoch 2150/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.4548 - val_loss: 1.1303\n",
      "Epoch 2151/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4546 - val_loss: 1.1325\n",
      "Epoch 2152/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4545 - val_loss: 1.1332\n",
      "Epoch 2153/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4543 - val_loss: 1.1323\n",
      "Epoch 2154/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 0.4541 - val_loss: 1.1348\n",
      "Epoch 2155/2500\n",
      "64/64 [==============================] - 0s 396us/step - loss: 0.4540 - val_loss: 1.1313\n",
      "Epoch 2156/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.4538 - val_loss: 1.1351\n",
      "Epoch 2157/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.4537 - val_loss: 1.1306\n",
      "Epoch 2158/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4535 - val_loss: 1.1359\n",
      "Epoch 2159/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.4534 - val_loss: 1.1313\n",
      "Epoch 2160/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4532 - val_loss: 1.1377\n",
      "Epoch 2161/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4530 - val_loss: 1.1324\n",
      "Epoch 2162/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 0.4529 - val_loss: 1.1395\n",
      "Epoch 2163/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4527 - val_loss: 1.1325\n",
      "Epoch 2164/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4526 - val_loss: 1.1409\n",
      "Epoch 2165/2500\n",
      "64/64 [==============================] - 0s 399us/step - loss: 0.4525 - val_loss: 1.1315\n",
      "Epoch 2166/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4524 - val_loss: 1.1430\n",
      "Epoch 2167/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4523 - val_loss: 1.1294\n",
      "Epoch 2168/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.4524 - val_loss: 1.1467\n",
      "Epoch 2169/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4525 - val_loss: 1.1253\n",
      "Epoch 2170/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4529 - val_loss: 1.1528\n",
      "Epoch 2171/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.4535 - val_loss: 1.1172\n",
      "Epoch 2172/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4550 - val_loss: 1.1625\n",
      "Epoch 2173/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.4568 - val_loss: 1.1039\n",
      "Epoch 2174/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.4609 - val_loss: 1.1745\n",
      "Epoch 2175/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4633 - val_loss: 1.0928\n",
      "Epoch 2176/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4678 - val_loss: 1.1784\n",
      "Epoch 2177/2500\n",
      "64/64 [==============================] - 0s 334us/step - loss: 0.4645 - val_loss: 1.1042\n",
      "Epoch 2178/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4623 - val_loss: 1.1707\n",
      "Epoch 2179/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4567 - val_loss: 1.1287\n",
      "Epoch 2180/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 0.4533 - val_loss: 1.1597\n",
      "Epoch 2181/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4509 - val_loss: 1.1492\n",
      "Epoch 2182/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4499 - val_loss: 1.1459\n",
      "Epoch 2183/2500\n",
      "64/64 [==============================] - 0s 311us/step - loss: 0.4500 - val_loss: 1.1608\n",
      "Epoch 2184/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4507 - val_loss: 1.1310\n",
      "Epoch 2185/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4521 - val_loss: 1.1678\n",
      "Epoch 2186/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 0.4534 - val_loss: 1.1203\n",
      "Epoch 2187/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4554 - val_loss: 1.1737\n",
      "Epoch 2188/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4562 - val_loss: 1.1145\n",
      "Epoch 2189/2500\n",
      "64/64 [==============================] - 0s 330us/step - loss: 0.4579 - val_loss: 1.1758\n",
      "Epoch 2190/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4576 - val_loss: 1.1120\n",
      "Epoch 2191/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4583 - val_loss: 1.1732\n",
      "Epoch 2192/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.4569 - val_loss: 1.1133\n",
      "Epoch 2193/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4567 - val_loss: 1.1697\n",
      "Epoch 2194/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4550 - val_loss: 1.1174\n",
      "Epoch 2195/2500\n",
      "64/64 [==============================] - 0s 393us/step - loss: 0.4545 - val_loss: 1.1677\n",
      "Epoch 2196/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4532 - val_loss: 1.1212\n",
      "Epoch 2197/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.4530 - val_loss: 1.1669\n",
      "Epoch 2198/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 0.4522 - val_loss: 1.1228\n",
      "Epoch 2199/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4524 - val_loss: 1.1676\n",
      "Epoch 2200/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4520 - val_loss: 1.1227\n",
      "Epoch 2201/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 0.4526 - val_loss: 1.1703\n",
      "Epoch 2202/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4525 - val_loss: 1.1214\n",
      "Epoch 2203/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4534 - val_loss: 1.1736\n",
      "Epoch 2204/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 0.4535 - val_loss: 1.1183\n",
      "Epoch 2205/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4548 - val_loss: 1.1758\n",
      "Epoch 2206/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4548 - val_loss: 1.1156\n",
      "Epoch 2207/2500\n",
      "64/64 [==============================] - 0s 382us/step - loss: 0.4558 - val_loss: 1.1768\n",
      "Epoch 2208/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4552 - val_loss: 1.1164\n",
      "Epoch 2209/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.4555 - val_loss: 1.1770\n",
      "Epoch 2210/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.4542 - val_loss: 1.1207\n",
      "Epoch 2211/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4539 - val_loss: 1.1763\n",
      "Epoch 2212/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4525 - val_loss: 1.1254\n",
      "Epoch 2213/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.4521 - val_loss: 1.1751\n",
      "Epoch 2214/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4510 - val_loss: 1.1283\n",
      "Epoch 2215/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4509 - val_loss: 1.1744\n",
      "Epoch 2216/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.4502 - val_loss: 1.1285\n",
      "Epoch 2217/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 0.4506 - val_loss: 1.1752\n",
      "Epoch 2218/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4505 - val_loss: 1.1253\n",
      "Epoch 2219/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.4517 - val_loss: 1.1778\n",
      "Epoch 2220/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.4523 - val_loss: 1.1192\n",
      "Epoch 2221/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4544 - val_loss: 1.1818\n",
      "Epoch 2222/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4553 - val_loss: 1.1134\n",
      "Epoch 2223/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4576 - val_loss: 1.1846\n",
      "Epoch 2224/2500\n",
      "64/64 [==============================] - 0s 347us/step - loss: 0.4572 - val_loss: 1.1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2225/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4575 - val_loss: 1.1836\n",
      "Epoch 2226/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4548 - val_loss: 1.1236\n",
      "Epoch 2227/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 0.4530 - val_loss: 1.1799\n",
      "Epoch 2228/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4500 - val_loss: 1.1359\n",
      "Epoch 2229/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4482 - val_loss: 1.1753\n",
      "Epoch 2230/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4463 - val_loss: 1.1442\n",
      "Epoch 2231/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.4453 - val_loss: 1.1709\n",
      "Epoch 2232/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4444 - val_loss: 1.1468\n",
      "Epoch 2233/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4440 - val_loss: 1.1692\n",
      "Epoch 2234/2500\n",
      "64/64 [==============================] - 0s 754us/step - loss: 0.4438 - val_loss: 1.1448\n",
      "Epoch 2235/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4441 - val_loss: 1.1723\n",
      "Epoch 2236/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4448 - val_loss: 1.1351\n",
      "Epoch 2237/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4471 - val_loss: 1.1814\n",
      "Epoch 2238/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4510 - val_loss: 1.1102\n",
      "Epoch 2239/2500\n",
      "64/64 [==============================] - 0s 271us/step - loss: 0.4604 - val_loss: 1.1955\n",
      "Epoch 2240/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4693 - val_loss: 1.0827\n",
      "Epoch 2241/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.4794 - val_loss: 1.1895\n",
      "Epoch 2242/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 0.4649 - val_loss: 1.1181\n",
      "Epoch 2243/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4541 - val_loss: 1.1787\n",
      "Epoch 2244/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4451 - val_loss: 1.1634\n",
      "Epoch 2245/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 0.4416 - val_loss: 1.1683\n",
      "Epoch 2246/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4414 - val_loss: 1.1844\n",
      "Epoch 2247/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.4434 - val_loss: 1.1391\n",
      "Epoch 2248/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4476 - val_loss: 1.1869\n",
      "Epoch 2249/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4519 - val_loss: 1.1193\n",
      "Epoch 2250/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.4559 - val_loss: 1.1934\n",
      "Epoch 2251/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.4550 - val_loss: 1.1318\n",
      "Epoch 2252/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4526 - val_loss: 1.1951\n",
      "Epoch 2253/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.4486 - val_loss: 1.1477\n",
      "Epoch 2254/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.4455 - val_loss: 1.1831\n",
      "Epoch 2255/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4429 - val_loss: 1.1522\n",
      "Epoch 2256/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4414 - val_loss: 1.1724\n",
      "Epoch 2257/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4405 - val_loss: 1.1547\n",
      "Epoch 2258/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.4400 - val_loss: 1.1725\n",
      "Epoch 2259/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.4398 - val_loss: 1.1524\n",
      "Epoch 2260/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4404 - val_loss: 1.1769\n",
      "Epoch 2261/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4420 - val_loss: 1.1321\n",
      "Epoch 2262/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.4472 - val_loss: 1.1898\n",
      "Epoch 2263/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4582 - val_loss: 1.0852\n",
      "Epoch 2264/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4811 - val_loss: 1.1996\n",
      "Epoch 2265/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4779 - val_loss: 1.0921\n",
      "Epoch 2266/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.4752 - val_loss: 1.1901\n",
      "Epoch 2267/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4506 - val_loss: 1.1605\n",
      "Epoch 2268/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4400 - val_loss: 1.1746\n",
      "Epoch 2269/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 0.4388 - val_loss: 1.2040\n",
      "Epoch 2270/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4443 - val_loss: 1.1379\n",
      "Epoch 2271/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.4543 - val_loss: 1.2060\n",
      "Epoch 2272/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.4613 - val_loss: 1.1161\n",
      "Epoch 2273/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4594 - val_loss: 1.1896\n",
      "Epoch 2274/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.4484 - val_loss: 1.1615\n",
      "Epoch 2275/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.4399 - val_loss: 1.1866\n",
      "Epoch 2276/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4375 - val_loss: 1.2076\n",
      "Epoch 2277/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.4401 - val_loss: 1.1592\n",
      "Epoch 2278/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.4461 - val_loss: 1.2054\n",
      "Epoch 2279/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4524 - val_loss: 1.1204\n",
      "Epoch 2280/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.4562 - val_loss: 1.1889\n",
      "Epoch 2281/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4522 - val_loss: 1.1356\n",
      "Epoch 2282/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.4469 - val_loss: 1.1945\n",
      "Epoch 2283/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4420 - val_loss: 1.1640\n",
      "Epoch 2284/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4394 - val_loss: 1.1896\n",
      "Epoch 2285/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4380 - val_loss: 1.1561\n",
      "Epoch 2286/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.4376 - val_loss: 1.1737\n",
      "Epoch 2287/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.4380 - val_loss: 1.1420\n",
      "Epoch 2288/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.4399 - val_loss: 1.1874\n",
      "Epoch 2289/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4438 - val_loss: 1.1302\n",
      "Epoch 2290/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4546 - val_loss: 1.2137\n",
      "Epoch 2291/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 0.4689 - val_loss: 1.0929\n",
      "Epoch 2292/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4831 - val_loss: 1.1942\n",
      "Epoch 2293/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4649 - val_loss: 1.1238\n",
      "Epoch 2294/2500\n",
      "64/64 [==============================] - 0s 345us/step - loss: 0.4494 - val_loss: 1.1844\n",
      "Epoch 2295/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4375 - val_loss: 1.1926\n",
      "Epoch 2296/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.4350 - val_loss: 1.1791\n",
      "Epoch 2297/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 0.4395 - val_loss: 1.2195\n",
      "Epoch 2298/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4479 - val_loss: 1.1316\n",
      "Epoch 2299/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 0.4554 - val_loss: 1.1946\n",
      "Epoch 2300/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4547 - val_loss: 1.1339\n",
      "Epoch 2301/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4473 - val_loss: 1.1972\n",
      "Epoch 2302/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 0.4384 - val_loss: 1.1932\n",
      "Epoch 2303/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4343 - val_loss: 1.1983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2304/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4344 - val_loss: 1.2091\n",
      "Epoch 2305/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4371 - val_loss: 1.1484\n",
      "Epoch 2306/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4431 - val_loss: 1.1912\n",
      "Epoch 2307/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4505 - val_loss: 1.1141\n",
      "Epoch 2308/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4595 - val_loss: 1.2043\n",
      "Epoch 2309/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 0.4592 - val_loss: 1.1321\n",
      "Epoch 2310/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4576 - val_loss: 1.2128\n",
      "Epoch 2311/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4522 - val_loss: 1.1433\n",
      "Epoch 2312/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4467 - val_loss: 1.1929\n",
      "Epoch 2313/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.4414 - val_loss: 1.1513\n",
      "Epoch 2314/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4378 - val_loss: 1.1893\n",
      "Epoch 2315/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4349 - val_loss: 1.1761\n",
      "Epoch 2316/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 0.4333 - val_loss: 1.1964\n",
      "Epoch 2317/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4323 - val_loss: 1.1858\n",
      "Epoch 2318/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4317 - val_loss: 1.1865\n",
      "Epoch 2319/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4313 - val_loss: 1.1790\n",
      "Epoch 2320/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4310 - val_loss: 1.1808\n",
      "Epoch 2321/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4307 - val_loss: 1.1825\n",
      "Epoch 2322/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 0.4304 - val_loss: 1.1862\n",
      "Epoch 2323/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.4301 - val_loss: 1.1835\n",
      "Epoch 2324/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4300 - val_loss: 1.1815\n",
      "Epoch 2325/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.4298 - val_loss: 1.1711\n",
      "Epoch 2326/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4298 - val_loss: 1.1798\n",
      "Epoch 2327/2500\n",
      "64/64 [==============================] - 0s 367us/step - loss: 0.4306 - val_loss: 1.1550\n",
      "Epoch 2328/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4353 - val_loss: 1.2060\n",
      "Epoch 2329/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4552 - val_loss: 1.0725\n",
      "Epoch 2330/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.5144 - val_loss: 1.2037\n",
      "Epoch 2331/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5034 - val_loss: 1.0597\n",
      "Epoch 2332/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5277 - val_loss: 1.1972\n",
      "Epoch 2333/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4357 - val_loss: 1.2431\n",
      "Epoch 2334/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 0.4673 - val_loss: 1.0457\n",
      "Epoch 2335/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5863 - val_loss: 1.1984\n",
      "Epoch 2336/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5485 - val_loss: 1.0612\n",
      "Epoch 2337/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.5776 - val_loss: 1.2351\n",
      "Epoch 2338/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4411 - val_loss: 1.2949\n",
      "Epoch 2339/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5624 - val_loss: 0.9215\n",
      "Epoch 2340/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.7621 - val_loss: 1.0959\n",
      "Epoch 2341/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 0.5163 - val_loss: 1.3341\n",
      "Epoch 2342/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7934 - val_loss: 1.0945\n",
      "Epoch 2343/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4725 - val_loss: 1.0208\n",
      "Epoch 2344/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.5750 - val_loss: 1.1802\n",
      "Epoch 2345/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.5248 - val_loss: 1.1571\n",
      "Epoch 2346/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4517 - val_loss: 1.1670\n",
      "Epoch 2347/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4797 - val_loss: 1.2775\n",
      "Epoch 2348/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4899 - val_loss: 1.1786\n",
      "Epoch 2349/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4431 - val_loss: 1.0604\n",
      "Epoch 2350/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4994 - val_loss: 1.1466\n",
      "Epoch 2351/2500\n",
      "64/64 [==============================] - 0s 332us/step - loss: 0.5004 - val_loss: 1.1578\n",
      "Epoch 2352/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 0.4421 - val_loss: 1.1269\n",
      "Epoch 2353/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.5106 - val_loss: 1.2953\n",
      "Epoch 2354/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.5604 - val_loss: 1.1974\n",
      "Epoch 2355/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 0.4427 - val_loss: 1.1046\n",
      "Epoch 2356/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.5340 - val_loss: 1.2951\n",
      "Epoch 2357/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.7077 - val_loss: 1.1592\n",
      "Epoch 2358/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4484 - val_loss: 0.8945\n",
      "Epoch 2359/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.7549 - val_loss: 1.3564\n",
      "Epoch 2360/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4907 - val_loss: 1.4058\n",
      "Epoch 2361/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6090 - val_loss: 1.0788\n",
      "Epoch 2362/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.5072 - val_loss: 1.0378\n",
      "Epoch 2363/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.4592 - val_loss: 1.0877\n",
      "Epoch 2364/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.5057 - val_loss: 1.1365\n",
      "Epoch 2365/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4546 - val_loss: 1.2561\n",
      "Epoch 2366/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4724 - val_loss: 1.4031\n",
      "Epoch 2367/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 0.5072 - val_loss: 1.2924\n",
      "Epoch 2368/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4811 - val_loss: 1.0924\n",
      "Epoch 2369/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4819 - val_loss: 1.1026\n",
      "Epoch 2370/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 0.4509 - val_loss: 1.1661\n",
      "Epoch 2371/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.4633 - val_loss: 1.1931\n",
      "Epoch 2372/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4424 - val_loss: 1.2146\n",
      "Epoch 2373/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4561 - val_loss: 1.2677\n",
      "Epoch 2374/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4578 - val_loss: 1.1874\n",
      "Epoch 2375/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 0.4413 - val_loss: 1.0865\n",
      "Epoch 2376/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4657 - val_loss: 1.1596\n",
      "Epoch 2377/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4512 - val_loss: 1.2047\n",
      "Epoch 2378/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 0.4439 - val_loss: 1.1916\n",
      "Epoch 2379/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4628 - val_loss: 1.2829\n",
      "Epoch 2380/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4377 - val_loss: 1.2805\n",
      "Epoch 2381/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 0.4476 - val_loss: 1.1560\n",
      "Epoch 2382/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 0.4509 - val_loss: 1.1642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2383/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4339 - val_loss: 1.1732\n",
      "Epoch 2384/2500\n",
      "64/64 [==============================] - 0s 277us/step - loss: 0.4417 - val_loss: 1.1372\n",
      "Epoch 2385/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4448 - val_loss: 1.2071\n",
      "Epoch 2386/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4317 - val_loss: 1.2159\n",
      "Epoch 2387/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.4332 - val_loss: 1.1487\n",
      "Epoch 2388/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.4434 - val_loss: 1.1728\n",
      "Epoch 2389/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4396 - val_loss: 1.1239\n",
      "Epoch 2390/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4307 - val_loss: 1.1371\n",
      "Epoch 2391/2500\n",
      "64/64 [==============================] - 0s 390us/step - loss: 0.4293 - val_loss: 1.1892\n",
      "Epoch 2392/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4352 - val_loss: 1.1605\n",
      "Epoch 2393/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.4416 - val_loss: 1.2173\n",
      "Epoch 2394/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4363 - val_loss: 1.1657\n",
      "Epoch 2395/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.4302 - val_loss: 1.1634\n",
      "Epoch 2396/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.4265 - val_loss: 1.1610\n",
      "Epoch 2397/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.4276 - val_loss: 1.1438\n",
      "Epoch 2398/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.4314 - val_loss: 1.1982\n",
      "Epoch 2399/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4349 - val_loss: 1.1584\n",
      "Epoch 2400/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4393 - val_loss: 1.2095\n",
      "Epoch 2401/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4370 - val_loss: 1.1513\n",
      "Epoch 2402/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.4360 - val_loss: 1.1833\n",
      "Epoch 2403/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.4296 - val_loss: 1.1673\n",
      "Epoch 2404/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4257 - val_loss: 1.1910\n",
      "Epoch 2405/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4242 - val_loss: 1.2119\n",
      "Epoch 2406/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 0.4250 - val_loss: 1.1962\n",
      "Epoch 2407/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4275 - val_loss: 1.2164\n",
      "Epoch 2408/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.4308 - val_loss: 1.1572\n",
      "Epoch 2409/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 0.4371 - val_loss: 1.1949\n",
      "Epoch 2410/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4366 - val_loss: 1.1526\n",
      "Epoch 2411/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4371 - val_loss: 1.2100\n",
      "Epoch 2412/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.4309 - val_loss: 1.1905\n",
      "Epoch 2413/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 0.4280 - val_loss: 1.2212\n",
      "Epoch 2414/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4253 - val_loss: 1.1968\n",
      "Epoch 2415/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4238 - val_loss: 1.2016\n",
      "Epoch 2416/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4229 - val_loss: 1.1896\n",
      "Epoch 2417/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 0.4224 - val_loss: 1.2004\n",
      "Epoch 2418/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 0.4219 - val_loss: 1.2033\n",
      "Epoch 2419/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 0.4216 - val_loss: 1.2104\n",
      "Epoch 2420/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.4214 - val_loss: 1.2018\n",
      "Epoch 2421/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.4213 - val_loss: 1.1994\n",
      "Epoch 2422/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4213 - val_loss: 1.1826\n",
      "Epoch 2423/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4219 - val_loss: 1.1991\n",
      "Epoch 2424/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4243 - val_loss: 1.1672\n",
      "Epoch 2425/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4334 - val_loss: 1.2235\n",
      "Epoch 2426/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.4513 - val_loss: 1.1229\n",
      "Epoch 2427/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4797 - val_loss: 1.2051\n",
      "Epoch 2428/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4365 - val_loss: 1.1822\n",
      "Epoch 2429/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4232 - val_loss: 1.2003\n",
      "Epoch 2430/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4219 - val_loss: 1.2432\n",
      "Epoch 2431/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.4306 - val_loss: 1.1813\n",
      "Epoch 2432/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.4517 - val_loss: 1.2442\n",
      "Epoch 2433/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4545 - val_loss: 1.1562\n",
      "Epoch 2434/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4454 - val_loss: 1.1982\n",
      "Epoch 2435/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 0.4247 - val_loss: 1.2166\n",
      "Epoch 2436/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.4236 - val_loss: 1.2002\n",
      "Epoch 2437/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4384 - val_loss: 1.2691\n",
      "Epoch 2438/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.4450 - val_loss: 1.1921\n",
      "Epoch 2439/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4409 - val_loss: 1.2224\n",
      "Epoch 2440/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4271 - val_loss: 1.1991\n",
      "Epoch 2441/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 0.4204 - val_loss: 1.2073\n",
      "Epoch 2442/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.4216 - val_loss: 1.2528\n",
      "Epoch 2443/2500\n",
      "64/64 [==============================] - 0s 346us/step - loss: 0.4286 - val_loss: 1.2026\n",
      "Epoch 2444/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4419 - val_loss: 1.2471\n",
      "Epoch 2445/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4444 - val_loss: 1.1564\n",
      "Epoch 2446/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.4455 - val_loss: 1.2004\n",
      "Epoch 2447/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4333 - val_loss: 1.1757\n",
      "Epoch 2448/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4254 - val_loss: 1.2262\n",
      "Epoch 2449/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.4201 - val_loss: 1.2322\n",
      "Epoch 2450/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4186 - val_loss: 1.2302\n",
      "Epoch 2451/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4179 - val_loss: 1.2154\n",
      "Epoch 2452/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4179 - val_loss: 1.1852\n",
      "Epoch 2453/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.4199 - val_loss: 1.2088\n",
      "Epoch 2454/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4243 - val_loss: 1.1747\n",
      "Epoch 2455/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4378 - val_loss: 1.2467\n",
      "Epoch 2456/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4555 - val_loss: 1.1455\n",
      "Epoch 2457/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.4742 - val_loss: 1.2142\n",
      "Epoch 2458/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.4337 - val_loss: 1.1840\n",
      "Epoch 2459/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4195 - val_loss: 1.2022\n",
      "Epoch 2460/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4183 - val_loss: 1.2509\n",
      "Epoch 2461/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.4278 - val_loss: 1.1920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2462/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4488 - val_loss: 1.2522\n",
      "Epoch 2463/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4560 - val_loss: 1.1540\n",
      "Epoch 2464/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4484 - val_loss: 1.1988\n",
      "Epoch 2465/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.4226 - val_loss: 1.2207\n",
      "Epoch 2466/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4198 - val_loss: 1.2095\n",
      "Epoch 2467/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4372 - val_loss: 1.2826\n",
      "Epoch 2468/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4492 - val_loss: 1.1881\n",
      "Epoch 2469/2500\n",
      "64/64 [==============================] - 0s 354us/step - loss: 0.4457 - val_loss: 1.2186\n",
      "Epoch 2470/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 0.4274 - val_loss: 1.1940\n",
      "Epoch 2471/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4178 - val_loss: 1.2106\n",
      "Epoch 2472/2500\n",
      "64/64 [==============================] - 0s 329us/step - loss: 0.4196 - val_loss: 1.2703\n",
      "Epoch 2473/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4301 - val_loss: 1.2109\n",
      "Epoch 2474/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4459 - val_loss: 1.2530\n",
      "Epoch 2475/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4439 - val_loss: 1.1667\n",
      "Epoch 2476/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 0.4364 - val_loss: 1.2037\n",
      "Epoch 2477/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4233 - val_loss: 1.2080\n",
      "Epoch 2478/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4163 - val_loss: 1.2460\n",
      "Epoch 2479/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4151 - val_loss: 1.2650\n",
      "Epoch 2480/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.4174 - val_loss: 1.2128\n",
      "Epoch 2481/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4238 - val_loss: 1.2229\n",
      "Epoch 2482/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4374 - val_loss: 1.1374\n",
      "Epoch 2483/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4578 - val_loss: 1.2154\n",
      "Epoch 2484/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.4472 - val_loss: 1.1855\n",
      "Epoch 2485/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4353 - val_loss: 1.2543\n",
      "Epoch 2486/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4216 - val_loss: 1.2335\n",
      "Epoch 2487/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 0.4165 - val_loss: 1.2338\n",
      "Epoch 2488/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 0.4142 - val_loss: 1.2160\n",
      "Epoch 2489/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.4138 - val_loss: 1.2089\n",
      "Epoch 2490/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4140 - val_loss: 1.2305\n",
      "Epoch 2491/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4150 - val_loss: 1.2166\n",
      "Epoch 2492/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4198 - val_loss: 1.2543\n",
      "Epoch 2493/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 0.4311 - val_loss: 1.1638\n",
      "Epoch 2494/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.4626 - val_loss: 1.2257\n",
      "Epoch 2495/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4599 - val_loss: 1.1496\n",
      "Epoch 2496/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4495 - val_loss: 1.2203\n",
      "Epoch 2497/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.4236 - val_loss: 1.2269\n",
      "Epoch 2498/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.4145 - val_loss: 1.2556\n",
      "Epoch 2499/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4131 - val_loss: 1.2611\n",
      "Epoch 2500/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4149 - val_loss: 1.2071\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "no_reg = model.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is trained.  Let's see what the solution looks like.\n",
    "\n",
    "We will also get the validation data set that `keras` created for us.  By plotting the validation data, we will gain some insight into how well the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "X_val = no_reg.validation_data[0]\n",
    "Y_val = no_reg.validation_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(0.0, 5, 1000)\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Now plot everything\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,8))\n",
    "ax.plot(X_true, Y_true, ls='-.', lw=4, label='True function')\n",
    "ax.plot(X_train, Y_train, '.', label='Training data')\n",
    "ax.plot(X_val, Y_val, '.', label='Validation data')\n",
    "ax.plot(X_range, y_pred, lw=4, label='Prediction')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction looks pretty bad.  The neural network model is trying to go through all the training points.  This is a classic case of overfitting.  The solution has a lot of oscillations and it rarely fits the validation data.  It may be a good idea to use some kind of regularization.\n",
    "\n",
    "Let's begin with some penalization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalization\n",
    "As mentioned in lecture, the loss function can be augmented by an additional term called the penalization term.  Mathematicall, the goal is to find the set of weights $W$ that minimize the functional $$J_{R}\\left(W; X, y\\right) = J\\left(W; X, y\\right) + \\alpha\\Omega\\left(W\\right)$$\n",
    "where $\\alpha$ is called the regularization (or penalization) parameter.  In this lab, $\\displaystyle J\\left(W; X, y\\right)$ is the MSE loss function.\n",
    "\n",
    "Next, we consider the effect of two different forms for the penalization term: $L_{1}$ and $L_{2}$ penalization.  For reference, \n",
    "$$\\Omega_{L_{1}} = \\frac{1}{2}\\left\\|W\\right\\|_{1}$$\n",
    "and \n",
    "$$\\Omega_{L_{2}} = \\frac{1}{2}\\|W\\|^{2}_{2}.$$\n",
    "\n",
    "Note that the biases are not being penalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Fit the same network as above ($5$ hidden layers, $100$ nodes per layer, linear output layer), but this time use $L_{2}$ and $L_{1}$ regularization.\n",
    "\n",
    "**Deliverables:**\n",
    "* Make two figures, one on top of the other.\n",
    "* The first figure should contain the following:\n",
    "  - True solution\n",
    "  - Training data\n",
    "  - Validation data\n",
    "  - Neural network prediction without regularization\n",
    "  - Neural network prediction with $L_{2}$ regularization\n",
    "* The second figure should contain the following:\n",
    "  - True solution\n",
    "  - Training data\n",
    "  - Validation data\n",
    "  - Neural network prediction without regularization\n",
    "  - Neural network prediction with $L_{1}$ regularization\n",
    "* **Make sure everything is clearly labeled!**\n",
    "* Discuss the results.\n",
    "\n",
    "**Hints:**\n",
    "* Use `kernel_regularizer=regularizers.l2(alpha)` after the `activation` argument in each of your layers.\n",
    "* Choose a value for `alpha` that you think works well.  You may need to play around with this a little bit.\n",
    "* See the `Keras` documentation on regularization:  [Usage of regularizers](https://keras.io/regularizers/)\n",
    "* Here's some pseudo-code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras import regularizers\n",
    "\n",
    "num_layers = 5\n",
    "N = 100\n",
    "alpha = \n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "### Create network\n",
    "model_L2 = \n",
    "model_L2.add()\n",
    "\n",
    "\n",
    "### Compile network\n",
    "model_L2.compile()\n",
    "\n",
    "### Fit model\n",
    "L2_reg = model_L2.fit()\n",
    "\n",
    "### Extract validation data\n",
    "X_val_L2 = \n",
    "Y_val_L2 = \n",
    "\n",
    "### REPEAT FOR L1\n",
    "###\n",
    "###\n",
    "###\n",
    "\n",
    "# PLOT\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20,14), sharex=True)\n",
    "\n",
    "ax[0].plot() # Top plots\n",
    "### ...\n",
    "\n",
    "ax[0].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[0].tick_params(labelsize=20)\n",
    "ax[0].legend(loc=1, fontsize=20)\n",
    "\n",
    "\n",
    "ax[1].plot() # Bottom plots\n",
    "### ...\n",
    "ax[1].set_xlabel(r'$Y$', fontsize=20)\n",
    "ax[1].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[1].tick_params(labelsize=20)\n",
    "ax[1].legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L_{2}$ Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "num_layers = 5\n",
    "N = 100\n",
    "alpha = 0.005\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model_L2 = models.Sequential()\n",
    "\n",
    "model_L2.add(layers.Dense(N, input_dim=input_dim, kernel_initializer='normal', activation='tanh', \n",
    "                          kernel_regularizer=regularizers.l2(alpha)))\n",
    "\n",
    "for h in range(num_layers):\n",
    "    model_L2.add(layers.Dense(N, activation='tanh', kernel_regularizer=regularizers.l2(alpha)))\n",
    "    \n",
    "model_L2.add(layers.Dense(1, activation='linear', kernel_regularizer=regularizers.l2(alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_L2.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 8.4886 - val_loss: 6.2358\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 7.4515 - val_loss: 5.9139\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 7.2431 - val_loss: 5.9499\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 7.3601 - val_loss: 5.8686\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 7.2813 - val_loss: 5.7245\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 7.0958 - val_loss: 5.6628\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 6.9832 - val_loss: 5.6946\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 6.9764 - val_loss: 5.7203\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 6.9847 - val_loss: 5.6696\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 6.9353 - val_loss: 5.5457\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 6.8278 - val_loss: 5.3877\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 6.6995 - val_loss: 5.2377\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 6.5906 - val_loss: 5.1212\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 6.5213 - val_loss: 5.0309\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 6.4722 - val_loss: 4.9357\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 365us/step - loss: 6.3988 - val_loss: 4.8247\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 6.2850 - val_loss: 4.7240\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 6.1632 - val_loss: 4.6628\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 308us/step - loss: 6.0734 - val_loss: 4.6270\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 6.0215 - val_loss: 4.5576\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 5.9572 - val_loss: 4.4280\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 5.8626 - val_loss: 4.2943\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 5.7918 - val_loss: 4.2288\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 5.7939 - val_loss: 4.2133\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 5.8043 - val_loss: 4.2303\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 5.7889 - val_loss: 4.3150\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 5.8207 - val_loss: 4.3596\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 5.8482 - val_loss: 4.2931\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 5.8134 - val_loss: 4.2169\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 5.7848 - val_loss: 4.1761\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 5.7612 - val_loss: 4.1517\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 5.7072 - val_loss: 4.1567\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 363us/step - loss: 5.6662 - val_loss: 4.1787\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 5.6504 - val_loss: 4.1781\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 5.6360 - val_loss: 4.1511\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 5.6163 - val_loss: 4.1248\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 397us/step - loss: 5.6066 - val_loss: 4.1137\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 375us/step - loss: 5.6073 - val_loss: 4.1120\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 5.6025 - val_loss: 4.1150\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 5.5880 - val_loss: 4.1233\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 5.5739 - val_loss: 4.1278\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 369us/step - loss: 5.5623 - val_loss: 4.1126\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 5.5447 - val_loss: 4.0757\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 5.5201 - val_loss: 4.0335\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 5.4978 - val_loss: 4.0005\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 5.4796 - val_loss: 3.9803\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 5.4583 - val_loss: 3.9750\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 5.4385 - val_loss: 3.9757\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 5.4262 - val_loss: 3.9588\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 5.4119 - val_loss: 3.9242\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 5.3955 - val_loss: 3.8970\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 5.3830 - val_loss: 3.8862\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 5.3642 - val_loss: 3.8898\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 5.3429 - val_loss: 3.8857\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 5.3223 - val_loss: 3.8560\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 5.2962 - val_loss: 3.8264\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 5.2737 - val_loss: 3.8159\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 293us/step - loss: 5.2497 - val_loss: 3.8218\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 5.2258 - val_loss: 3.8162\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 5.2031 - val_loss: 3.7847\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 5.1761 - val_loss: 3.7590\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 5.1490 - val_loss: 3.7520\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 5.1155 - val_loss: 3.7369\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 5.0809 - val_loss: 3.6856\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 5.0403 - val_loss: 3.6532\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 4.9975 - val_loss: 3.6456\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 4.9532 - val_loss: 3.5809\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 4.9017 - val_loss: 3.5631\n",
      "Epoch 69/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 4.8440 - val_loss: 3.5187\n",
      "Epoch 70/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 4.7777 - val_loss: 3.4740\n",
      "Epoch 71/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 4.7012 - val_loss: 3.4645\n",
      "Epoch 72/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 4.6169 - val_loss: 3.3547\n",
      "Epoch 73/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 4.5623 - val_loss: 4.1158\n",
      "Epoch 74/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 4.9100 - val_loss: 3.5501\n",
      "Epoch 75/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 4.9353 - val_loss: 3.2319\n",
      "Epoch 76/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 4.3585 - val_loss: 4.2026\n",
      "Epoch 77/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 4.8602 - val_loss: 3.2604\n",
      "Epoch 78/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 4.1864 - val_loss: 3.3890\n",
      "Epoch 79/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 4.7171 - val_loss: 3.1304\n",
      "Epoch 80/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 4.0677 - val_loss: 4.0435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 4.5799 - val_loss: 3.0802\n",
      "Epoch 82/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 3.9516 - val_loss: 3.2071\n",
      "Epoch 83/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 4.4136 - val_loss: 3.0998\n",
      "Epoch 84/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 3.8356 - val_loss: 3.8705\n",
      "Epoch 85/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 4.2507 - val_loss: 2.9260\n",
      "Epoch 86/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 3.7712 - val_loss: 2.9918\n",
      "Epoch 87/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 3.9861 - val_loss: 3.4189\n",
      "Epoch 88/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 3.7670 - val_loss: 3.2593\n",
      "Epoch 89/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 3.6119 - val_loss: 2.9235\n",
      "Epoch 90/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 3.8425 - val_loss: 2.9606\n",
      "Epoch 91/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 3.3545 - val_loss: 3.5371\n",
      "Epoch 92/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 3.5837 - val_loss: 2.8733\n",
      "Epoch 93/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 3.6944 - val_loss: 3.0764\n",
      "Epoch 94/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 3.1976 - val_loss: 3.2700\n",
      "Epoch 95/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 3.2225 - val_loss: 2.9474\n",
      "Epoch 96/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 3.6870 - val_loss: 4.0833\n",
      "Epoch 97/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 3.5958 - val_loss: 2.7650\n",
      "Epoch 98/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 3.1079 - val_loss: 2.8151\n",
      "Epoch 99/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 2.9607 - val_loss: 3.8935\n",
      "Epoch 100/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 3.3355 - val_loss: 3.0629\n",
      "Epoch 101/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 3.7179 - val_loss: 3.8392\n",
      "Epoch 102/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 3.2487 - val_loss: 2.9667\n",
      "Epoch 103/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.8668 - val_loss: 2.8389\n",
      "Epoch 104/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 3.1485 - val_loss: 4.0337\n",
      "Epoch 105/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 3.3135 - val_loss: 2.8414\n",
      "Epoch 106/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 2.9972 - val_loss: 2.9013\n",
      "Epoch 107/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.8727 - val_loss: 3.7802\n",
      "Epoch 108/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 3.1392 - val_loss: 2.8407\n",
      "Epoch 109/2500\n",
      "64/64 [==============================] - 0s 469us/step - loss: 3.0531 - val_loss: 2.9777\n",
      "Epoch 110/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.8299 - val_loss: 3.5825\n",
      "Epoch 111/2500\n",
      "64/64 [==============================] - 0s 287us/step - loss: 3.0319 - val_loss: 2.8124\n",
      "Epoch 112/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 3.0030 - val_loss: 2.9506\n",
      "Epoch 113/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 2.8184 - val_loss: 3.4961\n",
      "Epoch 114/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.9867 - val_loss: 2.8052\n",
      "Epoch 115/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 2.9212 - val_loss: 2.8858\n",
      "Epoch 116/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.8187 - val_loss: 3.4381\n",
      "Epoch 117/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.9534 - val_loss: 2.8282\n",
      "Epoch 118/2500\n",
      "64/64 [==============================] - 0s 327us/step - loss: 2.8411 - val_loss: 2.8254\n",
      "Epoch 119/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.8340 - val_loss: 3.3229\n",
      "Epoch 120/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.8975 - val_loss: 2.8878\n",
      "Epoch 121/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 2.7910 - val_loss: 2.7905\n",
      "Epoch 122/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.8434 - val_loss: 3.1752\n",
      "Epoch 123/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 2.8308 - val_loss: 2.9790\n",
      "Epoch 124/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 2.7770 - val_loss: 2.7892\n",
      "Epoch 125/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 2.8294 - val_loss: 3.0564\n",
      "Epoch 126/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.7814 - val_loss: 3.0596\n",
      "Epoch 127/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.7773 - val_loss: 2.8059\n",
      "Epoch 128/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 2.8021 - val_loss: 2.9814\n",
      "Epoch 129/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.7548 - val_loss: 3.0949\n",
      "Epoch 130/2500\n",
      "64/64 [==============================] - 0s 536us/step - loss: 2.7726 - val_loss: 2.8233\n",
      "Epoch 131/2500\n",
      "64/64 [==============================] - 0s 389us/step - loss: 2.7745 - val_loss: 2.9413\n",
      "Epoch 132/2500\n",
      "64/64 [==============================] - 0s 399us/step - loss: 2.7403 - val_loss: 3.0965\n",
      "Epoch 133/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.7608 - val_loss: 2.8401\n",
      "Epoch 134/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.7528 - val_loss: 2.9283\n",
      "Epoch 135/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 2.7290 - val_loss: 3.0845\n",
      "Epoch 136/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.7455 - val_loss: 2.8530\n",
      "Epoch 137/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.7360 - val_loss: 2.9266\n",
      "Epoch 138/2500\n",
      "64/64 [==============================] - 0s 426us/step - loss: 2.7177 - val_loss: 3.0607\n",
      "Epoch 139/2500\n",
      "64/64 [==============================] - 0s 438us/step - loss: 2.7295 - val_loss: 2.8534\n",
      "Epoch 140/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.7217 - val_loss: 2.9216\n",
      "Epoch 141/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 2.7063 - val_loss: 3.0275\n",
      "Epoch 142/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 2.7139 - val_loss: 2.8460\n",
      "Epoch 143/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 2.7083 - val_loss: 2.9145\n",
      "Epoch 144/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.6950 - val_loss: 2.9947\n",
      "Epoch 145/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 2.6992 - val_loss: 2.8386\n",
      "Epoch 146/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.6954 - val_loss: 2.9074\n",
      "Epoch 147/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.6838 - val_loss: 2.9641\n",
      "Epoch 148/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 2.6854 - val_loss: 2.8300\n",
      "Epoch 149/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.6827 - val_loss: 2.8973\n",
      "Epoch 150/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.6729 - val_loss: 2.9338\n",
      "Epoch 151/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.6725 - val_loss: 2.8200\n",
      "Epoch 152/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 2.6704 - val_loss: 2.8867\n",
      "Epoch 153/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.6620 - val_loss: 2.9070\n",
      "Epoch 154/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 2.6601 - val_loss: 2.8129\n",
      "Epoch 155/2500\n",
      "64/64 [==============================] - 0s 392us/step - loss: 2.6584 - val_loss: 2.8802\n",
      "Epoch 156/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.6513 - val_loss: 2.8848\n",
      "Epoch 157/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 2.6481 - val_loss: 2.8090\n",
      "Epoch 158/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 2.6465 - val_loss: 2.8760\n",
      "Epoch 159/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 2.6406 - val_loss: 2.8629\n",
      "Epoch 160/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 2.6364 - val_loss: 2.8064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.6346 - val_loss: 2.8708\n",
      "Epoch 162/2500\n",
      "64/64 [==============================] - 0s 426us/step - loss: 2.6299 - val_loss: 2.8417\n",
      "Epoch 163/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.6251 - val_loss: 2.8062\n",
      "Epoch 164/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 2.6227 - val_loss: 2.8648\n",
      "Epoch 165/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 2.6191 - val_loss: 2.8225\n",
      "Epoch 166/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.6143 - val_loss: 2.8093\n",
      "Epoch 167/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.6111 - val_loss: 2.8550\n",
      "Epoch 168/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 2.6081 - val_loss: 2.8051\n",
      "Epoch 169/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.6038 - val_loss: 2.8132\n",
      "Epoch 170/2500\n",
      "64/64 [==============================] - 0s 353us/step - loss: 2.5998 - val_loss: 2.8384\n",
      "Epoch 171/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 2.5968 - val_loss: 2.7904\n",
      "Epoch 172/2500\n",
      "64/64 [==============================] - 0s 349us/step - loss: 2.5932 - val_loss: 2.8152\n",
      "Epoch 173/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.5890 - val_loss: 2.8164\n",
      "Epoch 174/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 2.5855 - val_loss: 2.7812\n",
      "Epoch 175/2500\n",
      "64/64 [==============================] - 0s 210us/step - loss: 2.5823 - val_loss: 2.8134\n",
      "Epoch 176/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 2.5785 - val_loss: 2.7930\n",
      "Epoch 177/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 2.5746 - val_loss: 2.7779\n",
      "Epoch 178/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 2.5712 - val_loss: 2.8040\n",
      "Epoch 179/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.5678 - val_loss: 2.7719\n",
      "Epoch 180/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.5640 - val_loss: 2.7773\n",
      "Epoch 181/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.5603 - val_loss: 2.7864\n",
      "Epoch 182/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.5569 - val_loss: 2.7570\n",
      "Epoch 183/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 2.5534 - val_loss: 2.7757\n",
      "Epoch 184/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 2.5496 - val_loss: 2.7648\n",
      "Epoch 185/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 2.5460 - val_loss: 2.7506\n",
      "Epoch 186/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.5425 - val_loss: 2.7684\n",
      "Epoch 187/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 2.5390 - val_loss: 2.7453\n",
      "Epoch 188/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.5353 - val_loss: 2.7497\n",
      "Epoch 189/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 2.5317 - val_loss: 2.7528\n",
      "Epoch 190/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.5282 - val_loss: 2.7330\n",
      "Epoch 191/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.5247 - val_loss: 2.7472\n",
      "Epoch 192/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 2.5211 - val_loss: 2.7333\n",
      "Epoch 193/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 2.5175 - val_loss: 2.7294\n",
      "Epoch 194/2500\n",
      "64/64 [==============================] - 0s 416us/step - loss: 2.5139 - val_loss: 2.7367\n",
      "Epoch 195/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 2.5104 - val_loss: 2.7184\n",
      "Epoch 196/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 2.5069 - val_loss: 2.7282\n",
      "Epoch 197/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.5033 - val_loss: 2.7187\n",
      "Epoch 198/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 2.4997 - val_loss: 2.7130\n",
      "Epoch 199/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 2.4962 - val_loss: 2.7190\n",
      "Epoch 200/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.4926 - val_loss: 2.7033\n",
      "Epoch 201/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.4891 - val_loss: 2.7109\n",
      "Epoch 202/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 2.4855 - val_loss: 2.7010\n",
      "Epoch 203/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 2.4819 - val_loss: 2.6979\n",
      "Epoch 204/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.4784 - val_loss: 2.6999\n",
      "Epoch 205/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 2.4749 - val_loss: 2.6874\n",
      "Epoch 206/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.4713 - val_loss: 2.6941\n",
      "Epoch 207/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 2.4678 - val_loss: 2.6818\n",
      "Epoch 208/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 2.4642 - val_loss: 2.6839\n",
      "Epoch 209/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.4607 - val_loss: 2.6787\n",
      "Epoch 210/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 2.4571 - val_loss: 2.6729\n",
      "Epoch 211/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 2.4536 - val_loss: 2.6749\n",
      "Epoch 212/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.4500 - val_loss: 2.6638\n",
      "Epoch 213/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 2.4465 - val_loss: 2.6688\n",
      "Epoch 214/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 2.4429 - val_loss: 2.6571\n",
      "Epoch 215/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.4394 - val_loss: 2.6609\n",
      "Epoch 216/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 2.4358 - val_loss: 2.6516\n",
      "Epoch 217/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 2.4322 - val_loss: 2.6525\n",
      "Epoch 218/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.4287 - val_loss: 2.6463\n",
      "Epoch 219/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.4251 - val_loss: 2.6442\n",
      "Epoch 220/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.4216 - val_loss: 2.6409\n",
      "Epoch 221/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 2.4180 - val_loss: 2.6363\n",
      "Epoch 222/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 2.4145 - val_loss: 2.6353\n",
      "Epoch 223/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.4109 - val_loss: 2.6284\n",
      "Epoch 224/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.4074 - val_loss: 2.6301\n",
      "Epoch 225/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.4038 - val_loss: 2.6199\n",
      "Epoch 226/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.3997 - val_loss: 2.6262\n",
      "Epoch 227/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.3967 - val_loss: 2.6093\n",
      "Epoch 228/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.3932 - val_loss: 2.6260\n",
      "Epoch 229/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 2.3898 - val_loss: 2.5932\n",
      "Epoch 230/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 2.3865 - val_loss: 2.6362\n",
      "Epoch 231/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.3836 - val_loss: 2.5630\n",
      "Epoch 232/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 2.3818 - val_loss: 2.6785\n",
      "Epoch 233/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 2.3828 - val_loss: 2.5045\n",
      "Epoch 234/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.3910 - val_loss: 2.8149\n",
      "Epoch 235/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.4141 - val_loss: 2.4382\n",
      "Epoch 236/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 2.4702 - val_loss: 3.1261\n",
      "Epoch 237/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.5495 - val_loss: 2.4556\n",
      "Epoch 238/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.6579 - val_loss: 3.2174\n",
      "Epoch 239/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.6085 - val_loss: 2.3989\n",
      "Epoch 240/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.4725 - val_loss: 2.5635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 2.3545 - val_loss: 2.7644\n",
      "Epoch 242/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.4106 - val_loss: 2.3656\n",
      "Epoch 243/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.4922 - val_loss: 2.7510\n",
      "Epoch 244/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.4097 - val_loss: 2.5004\n",
      "Epoch 245/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 2.3448 - val_loss: 2.3639\n",
      "Epoch 246/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.4002 - val_loss: 2.7731\n",
      "Epoch 247/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 2.4135 - val_loss: 2.4049\n",
      "Epoch 248/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.3516 - val_loss: 2.4348\n",
      "Epoch 249/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 2.3367 - val_loss: 2.7260\n",
      "Epoch 250/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.3773 - val_loss: 2.3863\n",
      "Epoch 251/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.3740 - val_loss: 2.5892\n",
      "Epoch 252/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 2.3249 - val_loss: 2.5934\n",
      "Epoch 253/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.3204 - val_loss: 2.4161\n",
      "Epoch 254/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.3514 - val_loss: 2.7422\n",
      "Epoch 255/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 2.3506 - val_loss: 2.4571\n",
      "Epoch 256/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.3208 - val_loss: 2.5469\n",
      "Epoch 257/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 2.3006 - val_loss: 2.6462\n",
      "Epoch 258/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.3106 - val_loss: 2.4443\n",
      "Epoch 259/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 2.3278 - val_loss: 2.7131\n",
      "Epoch 260/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 2.3229 - val_loss: 2.4702\n",
      "Epoch 261/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 2.3026 - val_loss: 2.5558\n",
      "Epoch 262/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.2867 - val_loss: 2.5937\n",
      "Epoch 263/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 2.2884 - val_loss: 2.4473\n",
      "Epoch 264/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 2.2975 - val_loss: 2.6419\n",
      "Epoch 265/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.2957 - val_loss: 2.4524\n",
      "Epoch 266/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.2832 - val_loss: 2.5207\n",
      "Epoch 267/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.2720 - val_loss: 2.5422\n",
      "Epoch 268/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 2.2717 - val_loss: 2.4296\n",
      "Epoch 269/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.2761 - val_loss: 2.5725\n",
      "Epoch 270/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.2735 - val_loss: 2.4413\n",
      "Epoch 271/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.2647 - val_loss: 2.4825\n",
      "Epoch 272/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.2580 - val_loss: 2.5176\n",
      "Epoch 273/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 2.2579 - val_loss: 2.4232\n",
      "Epoch 274/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 2.2593 - val_loss: 2.5382\n",
      "Epoch 275/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.2560 - val_loss: 2.4415\n",
      "Epoch 276/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 2.2495 - val_loss: 2.4778\n",
      "Epoch 277/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.2444 - val_loss: 2.5025\n",
      "Epoch 278/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 2.2430 - val_loss: 2.4344\n",
      "Epoch 279/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 2.2430 - val_loss: 2.5312\n",
      "Epoch 280/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.2412 - val_loss: 2.4389\n",
      "Epoch 281/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 2.2371 - val_loss: 2.5023\n",
      "Epoch 282/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.2323 - val_loss: 2.4739\n",
      "Epoch 283/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 2.2287 - val_loss: 2.4603\n",
      "Epoch 284/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 2.2267 - val_loss: 2.5080\n",
      "Epoch 285/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.2255 - val_loss: 2.4374\n",
      "Epoch 286/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.2242 - val_loss: 2.5141\n",
      "Epoch 287/2500\n",
      "64/64 [==============================] - 0s 494us/step - loss: 2.2218 - val_loss: 2.4357\n",
      "Epoch 288/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 2.2186 - val_loss: 2.4922\n",
      "Epoch 289/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.2150 - val_loss: 2.4482\n",
      "Epoch 290/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 2.2117 - val_loss: 2.4604\n",
      "Epoch 291/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 2.2089 - val_loss: 2.4648\n",
      "Epoch 292/2500\n",
      "64/64 [==============================] - 0s 343us/step - loss: 2.2066 - val_loss: 2.4344\n",
      "Epoch 293/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.2047 - val_loss: 2.4748\n",
      "Epoch 294/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 2.2029 - val_loss: 2.4201\n",
      "Epoch 295/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 2.2009 - val_loss: 2.4733\n",
      "Epoch 296/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.1986 - val_loss: 2.4166\n",
      "Epoch 297/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 2.1961 - val_loss: 2.4628\n",
      "Epoch 298/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 2.1934 - val_loss: 2.4203\n",
      "Epoch 299/2500\n",
      "64/64 [==============================] - 0s 409us/step - loss: 2.1907 - val_loss: 2.4492\n",
      "Epoch 300/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 2.1881 - val_loss: 2.4273\n",
      "Epoch 301/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 2.1856 - val_loss: 2.4367\n",
      "Epoch 302/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.1832 - val_loss: 2.4343\n",
      "Epoch 303/2500\n",
      "64/64 [==============================] - 0s 388us/step - loss: 2.1809 - val_loss: 2.4266\n",
      "Epoch 304/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 2.1787 - val_loss: 2.4401\n",
      "Epoch 305/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 2.1766 - val_loss: 2.4177\n",
      "Epoch 306/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 2.1745 - val_loss: 2.4454\n",
      "Epoch 307/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 2.1725 - val_loss: 2.4079\n",
      "Epoch 308/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.1706 - val_loss: 2.4522\n",
      "Epoch 309/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 2.1689 - val_loss: 2.3947\n",
      "Epoch 310/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 2.1675 - val_loss: 2.4647\n",
      "Epoch 311/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.1665 - val_loss: 2.3752\n",
      "Epoch 312/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 2.1660 - val_loss: 2.4905\n",
      "Epoch 313/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 2.1676 - val_loss: 2.3472\n",
      "Epoch 314/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 2.1717 - val_loss: 2.5442\n",
      "Epoch 315/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 2.1791 - val_loss: 2.3136\n",
      "Epoch 316/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.1950 - val_loss: 2.6484\n",
      "Epoch 317/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.2163 - val_loss: 2.2921\n",
      "Epoch 318/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 2.2555 - val_loss: 2.7875\n",
      "Epoch 319/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.2837 - val_loss: 2.2876\n",
      "Epoch 320/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 135us/step - loss: 2.3162 - val_loss: 2.7458\n",
      "Epoch 321/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.2716 - val_loss: 2.2574\n",
      "Epoch 322/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 2.2095 - val_loss: 2.4159\n",
      "Epoch 323/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 2.1491 - val_loss: 2.4100\n",
      "Epoch 324/2500\n",
      "64/64 [==============================] - 0s 712us/step - loss: 2.1476 - val_loss: 2.2465\n",
      "Epoch 325/2500\n",
      "64/64 [==============================] - 0s 514us/step - loss: 2.1866 - val_loss: 2.5761\n",
      "Epoch 326/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 2.1992 - val_loss: 2.2510\n",
      "Epoch 327/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 2.1743 - val_loss: 2.4019\n",
      "Epoch 328/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 2.1361 - val_loss: 2.3952\n",
      "Epoch 329/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 2.1313 - val_loss: 2.2736\n",
      "Epoch 330/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.1536 - val_loss: 2.5507\n",
      "Epoch 331/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 2.1661 - val_loss: 2.2804\n",
      "Epoch 332/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 2.1576 - val_loss: 2.4714\n",
      "Epoch 333/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.1323 - val_loss: 2.3633\n",
      "Epoch 334/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 2.1165 - val_loss: 2.3432\n",
      "Epoch 335/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 2.1184 - val_loss: 2.4948\n",
      "Epoch 336/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 2.1301 - val_loss: 2.3021\n",
      "Epoch 337/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.1391 - val_loss: 2.5190\n",
      "Epoch 338/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.1340 - val_loss: 2.3136\n",
      "Epoch 339/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 2.1211 - val_loss: 2.4151\n",
      "Epoch 340/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.1075 - val_loss: 2.3801\n",
      "Epoch 341/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 2.1027 - val_loss: 2.3185\n",
      "Epoch 342/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 2.1063 - val_loss: 2.4436\n",
      "Epoch 343/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.1104 - val_loss: 2.2922\n",
      "Epoch 344/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 2.1086 - val_loss: 2.4032\n",
      "Epoch 345/2500\n",
      "64/64 [==============================] - 0s 339us/step - loss: 2.1004 - val_loss: 2.3286\n",
      "Epoch 346/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.0935 - val_loss: 2.3179\n",
      "Epoch 347/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0923 - val_loss: 2.3889\n",
      "Epoch 348/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 2.0945 - val_loss: 2.2858\n",
      "Epoch 349/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 2.0945 - val_loss: 2.3812\n",
      "Epoch 350/2500\n",
      "64/64 [==============================] - 0s 306us/step - loss: 2.0900 - val_loss: 2.3134\n",
      "Epoch 351/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 2.0846 - val_loss: 2.3241\n",
      "Epoch 352/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 2.0820 - val_loss: 2.3667\n",
      "Epoch 353/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 2.0822 - val_loss: 2.2956\n",
      "Epoch 354/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 2.0822 - val_loss: 2.3793\n",
      "Epoch 355/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0800 - val_loss: 2.3095\n",
      "Epoch 356/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 2.0762 - val_loss: 2.3442\n",
      "Epoch 357/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 2.0728 - val_loss: 2.3467\n",
      "Epoch 358/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0711 - val_loss: 2.3104\n",
      "Epoch 359/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.0705 - val_loss: 2.3691\n",
      "Epoch 360/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 2.0696 - val_loss: 2.3028\n",
      "Epoch 361/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 2.0677 - val_loss: 2.3540\n",
      "Epoch 362/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 2.0648 - val_loss: 2.3182\n",
      "Epoch 363/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.0620 - val_loss: 2.3207\n",
      "Epoch 364/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 2.0601 - val_loss: 2.3388\n",
      "Epoch 365/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.0588 - val_loss: 2.2978\n",
      "Epoch 366/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 2.0576 - val_loss: 2.3413\n",
      "Epoch 367/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 2.0559 - val_loss: 2.2956\n",
      "Epoch 368/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 2.0537 - val_loss: 2.3212\n",
      "Epoch 369/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.0514 - val_loss: 2.3085\n",
      "Epoch 370/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 2.0494 - val_loss: 2.2973\n",
      "Epoch 371/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 2.0478 - val_loss: 2.3203\n",
      "Epoch 372/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.0464 - val_loss: 2.2863\n",
      "Epoch 373/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.0448 - val_loss: 2.3175\n",
      "Epoch 374/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 2.0429 - val_loss: 2.2906\n",
      "Epoch 375/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 2.0405 - val_loss: 2.3028\n",
      "Epoch 376/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 2.0389 - val_loss: 2.3022\n",
      "Epoch 377/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0372 - val_loss: 2.2889\n",
      "Epoch 378/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.0356 - val_loss: 2.3093\n",
      "Epoch 379/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.0340 - val_loss: 2.2834\n",
      "Epoch 380/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 2.0323 - val_loss: 2.3058\n",
      "Epoch 381/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.0305 - val_loss: 2.2861\n",
      "Epoch 382/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.0286 - val_loss: 2.2947\n",
      "Epoch 383/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.0268 - val_loss: 2.2921\n",
      "Epoch 384/2500\n",
      "64/64 [==============================] - 0s 439us/step - loss: 2.0251 - val_loss: 2.2833\n",
      "Epoch 385/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 2.0234 - val_loss: 2.2951\n",
      "Epoch 386/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 2.0218 - val_loss: 2.2762\n",
      "Epoch 387/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0202 - val_loss: 2.2917\n",
      "Epoch 388/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 2.0184 - val_loss: 2.2745\n",
      "Epoch 389/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 2.0167 - val_loss: 2.2831\n",
      "Epoch 390/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0149 - val_loss: 2.2760\n",
      "Epoch 391/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.0128 - val_loss: 2.2734\n",
      "Epoch 392/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.0115 - val_loss: 2.2775\n",
      "Epoch 393/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 2.0099 - val_loss: 2.2661\n",
      "Epoch 394/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.0082 - val_loss: 2.2762\n",
      "Epoch 395/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.0066 - val_loss: 2.2627\n",
      "Epoch 396/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.0049 - val_loss: 2.2717\n",
      "Epoch 397/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 2.0032 - val_loss: 2.2624\n",
      "Epoch 398/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.0015 - val_loss: 2.2654\n",
      "Epoch 399/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.9999 - val_loss: 2.2633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9982 - val_loss: 2.2593\n",
      "Epoch 401/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.9966 - val_loss: 2.2634\n",
      "Epoch 402/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.9949 - val_loss: 2.2547\n",
      "Epoch 403/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.9933 - val_loss: 2.2615\n",
      "Epoch 404/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.9917 - val_loss: 2.2520\n",
      "Epoch 405/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9900 - val_loss: 2.2577\n",
      "Epoch 406/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.9884 - val_loss: 2.2504\n",
      "Epoch 407/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.9868 - val_loss: 2.2527\n",
      "Epoch 408/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.9851 - val_loss: 2.2493\n",
      "Epoch 409/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.9835 - val_loss: 2.2474\n",
      "Epoch 410/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.9819 - val_loss: 2.2478\n",
      "Epoch 411/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.9803 - val_loss: 2.2426\n",
      "Epoch 412/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.9787 - val_loss: 2.2455\n",
      "Epoch 413/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.9771 - val_loss: 2.2388\n",
      "Epoch 414/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.9755 - val_loss: 2.2424\n",
      "Epoch 415/2500\n",
      "64/64 [==============================] - 0s 509us/step - loss: 1.9739 - val_loss: 2.2359\n",
      "Epoch 416/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.9723 - val_loss: 2.2387\n",
      "Epoch 417/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 1.9707 - val_loss: 2.2336\n",
      "Epoch 418/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.9691 - val_loss: 2.2347\n",
      "Epoch 419/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.9675 - val_loss: 2.2317\n",
      "Epoch 420/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.9659 - val_loss: 2.2307\n",
      "Epoch 421/2500\n",
      "64/64 [==============================] - 0s 473us/step - loss: 1.9643 - val_loss: 2.2297\n",
      "Epoch 422/2500\n",
      "64/64 [==============================] - 0s 395us/step - loss: 1.9627 - val_loss: 2.2270\n",
      "Epoch 423/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.9612 - val_loss: 2.2276\n",
      "Epoch 424/2500\n",
      "64/64 [==============================] - 0s 718us/step - loss: 1.9596 - val_loss: 2.2236\n",
      "Epoch 425/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.9580 - val_loss: 2.2251\n",
      "Epoch 426/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9565 - val_loss: 2.2206\n",
      "Epoch 427/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.9549 - val_loss: 2.2223\n",
      "Epoch 428/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 1.9533 - val_loss: 2.2177\n",
      "Epoch 429/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.9518 - val_loss: 2.2192\n",
      "Epoch 430/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.9502 - val_loss: 2.2149\n",
      "Epoch 431/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.9483 - val_loss: 2.2160\n",
      "Epoch 432/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.9472 - val_loss: 2.2122\n",
      "Epoch 433/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.9456 - val_loss: 2.2127\n",
      "Epoch 434/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.9441 - val_loss: 2.2095\n",
      "Epoch 435/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.9425 - val_loss: 2.2094\n",
      "Epoch 436/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9410 - val_loss: 2.2069\n",
      "Epoch 437/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.9395 - val_loss: 2.2062\n",
      "Epoch 438/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.9380 - val_loss: 2.2042\n",
      "Epoch 439/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.9364 - val_loss: 2.2031\n",
      "Epoch 440/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.9349 - val_loss: 2.2015\n",
      "Epoch 441/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9334 - val_loss: 2.2000\n",
      "Epoch 442/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9319 - val_loss: 2.1988\n",
      "Epoch 443/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.9304 - val_loss: 2.1970\n",
      "Epoch 444/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.9289 - val_loss: 2.1962\n",
      "Epoch 445/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 1.9274 - val_loss: 2.1941\n",
      "Epoch 446/2500\n",
      "64/64 [==============================] - 0s 502us/step - loss: 1.9259 - val_loss: 2.1935\n",
      "Epoch 447/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.9244 - val_loss: 2.1912\n",
      "Epoch 448/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 1.9229 - val_loss: 2.1909\n",
      "Epoch 449/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.9214 - val_loss: 2.1883\n",
      "Epoch 450/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.9199 - val_loss: 2.1882\n",
      "Epoch 451/2500\n",
      "64/64 [==============================] - 0s 325us/step - loss: 1.9184 - val_loss: 2.1853\n",
      "Epoch 452/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.9170 - val_loss: 2.1857\n",
      "Epoch 453/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.9155 - val_loss: 2.1823\n",
      "Epoch 454/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.9140 - val_loss: 2.1831\n",
      "Epoch 455/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.9125 - val_loss: 2.1791\n",
      "Epoch 456/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.9111 - val_loss: 2.1808\n",
      "Epoch 457/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.9096 - val_loss: 2.1759\n",
      "Epoch 458/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.9082 - val_loss: 2.1786\n",
      "Epoch 459/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.9067 - val_loss: 2.1724\n",
      "Epoch 460/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.9053 - val_loss: 2.1767\n",
      "Epoch 461/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.9038 - val_loss: 2.1686\n",
      "Epoch 462/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.9024 - val_loss: 2.1754\n",
      "Epoch 463/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.9009 - val_loss: 2.1642\n",
      "Epoch 464/2500\n",
      "64/64 [==============================] - 0s 382us/step - loss: 1.8995 - val_loss: 2.1747\n",
      "Epoch 465/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.8981 - val_loss: 2.1591\n",
      "Epoch 466/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.8967 - val_loss: 2.1753\n",
      "Epoch 467/2500\n",
      "64/64 [==============================] - 0s 324us/step - loss: 1.8954 - val_loss: 2.1526\n",
      "Epoch 468/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.8940 - val_loss: 2.1780\n",
      "Epoch 469/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.8928 - val_loss: 2.1439\n",
      "Epoch 470/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.8916 - val_loss: 2.1840\n",
      "Epoch 471/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8906 - val_loss: 2.1322\n",
      "Epoch 472/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.8898 - val_loss: 2.1957\n",
      "Epoch 473/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.8894 - val_loss: 2.1158\n",
      "Epoch 474/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.8897 - val_loss: 2.2178\n",
      "Epoch 475/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.8908 - val_loss: 2.0936\n",
      "Epoch 476/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.8937 - val_loss: 2.2574\n",
      "Epoch 477/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.8983 - val_loss: 2.0670\n",
      "Epoch 478/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.9072 - val_loss: 2.3232\n",
      "Epoch 479/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9184 - val_loss: 2.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.9374 - val_loss: 2.4056\n",
      "Epoch 481/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.9524 - val_loss: 2.0285\n",
      "Epoch 482/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.9718 - val_loss: 2.4197\n",
      "Epoch 483/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.9628 - val_loss: 2.0152\n",
      "Epoch 484/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.9427 - val_loss: 2.2547\n",
      "Epoch 485/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.9011 - val_loss: 2.0661\n",
      "Epoch 486/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.8738 - val_loss: 2.0636\n",
      "Epoch 487/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.8724 - val_loss: 2.2207\n",
      "Epoch 488/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.8895 - val_loss: 2.0123\n",
      "Epoch 489/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.9042 - val_loss: 2.2602\n",
      "Epoch 490/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 1.8969 - val_loss: 2.0406\n",
      "Epoch 491/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.8791 - val_loss: 2.1483\n",
      "Epoch 492/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.8630 - val_loss: 2.1461\n",
      "Epoch 493/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.8605 - val_loss: 2.0685\n",
      "Epoch 494/2500\n",
      "64/64 [==============================] - 0s 327us/step - loss: 1.8688 - val_loss: 2.2528\n",
      "Epoch 495/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8775 - val_loss: 2.0565\n",
      "Epoch 496/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8808 - val_loss: 2.2541\n",
      "Epoch 497/2500\n",
      "64/64 [==============================] - 0s 347us/step - loss: 1.8735 - val_loss: 2.0788\n",
      "Epoch 498/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.8634 - val_loss: 2.1716\n",
      "Epoch 499/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.8538 - val_loss: 2.1361\n",
      "Epoch 500/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.8499 - val_loss: 2.0944\n",
      "Epoch 501/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.8517 - val_loss: 2.1929\n",
      "Epoch 502/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.8551 - val_loss: 2.0637\n",
      "Epoch 503/2500\n",
      "64/64 [==============================] - 0s 376us/step - loss: 1.8562 - val_loss: 2.1845\n",
      "Epoch 504/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.8525 - val_loss: 2.0774\n",
      "Epoch 505/2500\n",
      "64/64 [==============================] - 0s 343us/step - loss: 1.8466 - val_loss: 2.1191\n",
      "Epoch 506/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.8423 - val_loss: 2.1245\n",
      "Epoch 507/2500\n",
      "64/64 [==============================] - 0s 286us/step - loss: 1.8415 - val_loss: 2.0682\n",
      "Epoch 508/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.8429 - val_loss: 2.1531\n",
      "Epoch 509/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.8431 - val_loss: 2.0628\n",
      "Epoch 510/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 1.8409 - val_loss: 2.1267\n",
      "Epoch 511/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.8372 - val_loss: 2.0954\n",
      "Epoch 512/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.8345 - val_loss: 2.0853\n",
      "Epoch 513/2500\n",
      "64/64 [==============================] - 0s 409us/step - loss: 1.8337 - val_loss: 2.1336\n",
      "Epoch 514/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.8339 - val_loss: 2.0704\n",
      "Epoch 515/2500\n",
      "64/64 [==============================] - 0s 346us/step - loss: 1.8334 - val_loss: 2.1375\n",
      "Epoch 516/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8315 - val_loss: 2.0848\n",
      "Epoch 517/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.8291 - val_loss: 2.1107\n",
      "Epoch 518/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.8269 - val_loss: 2.1129\n",
      "Epoch 519/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.8258 - val_loss: 2.0848\n",
      "Epoch 520/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.8253 - val_loss: 2.1291\n",
      "Epoch 521/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.8246 - val_loss: 2.0771\n",
      "Epoch 522/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.8233 - val_loss: 2.1186\n",
      "Epoch 523/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.8215 - val_loss: 2.0874\n",
      "Epoch 524/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.8197 - val_loss: 2.0933\n",
      "Epoch 525/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.8182 - val_loss: 2.1033\n",
      "Epoch 526/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.8173 - val_loss: 2.0745\n",
      "Epoch 527/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.8164 - val_loss: 2.1074\n",
      "Epoch 528/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.8153 - val_loss: 2.0720\n",
      "Epoch 529/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8139 - val_loss: 2.0944\n",
      "Epoch 530/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 1.8123 - val_loss: 2.0822\n",
      "Epoch 531/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.8110 - val_loss: 2.0768\n",
      "Epoch 532/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8098 - val_loss: 2.0928\n",
      "Epoch 533/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.8088 - val_loss: 2.0682\n",
      "Epoch 534/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.8077 - val_loss: 2.0928\n",
      "Epoch 535/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.8065 - val_loss: 2.0717\n",
      "Epoch 536/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.8051 - val_loss: 2.0828\n",
      "Epoch 537/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8038 - val_loss: 2.0813\n",
      "Epoch 538/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.8026 - val_loss: 2.0723\n",
      "Epoch 539/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.8015 - val_loss: 2.0873\n",
      "Epoch 540/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.8004 - val_loss: 2.0680\n",
      "Epoch 541/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7992 - val_loss: 2.0843\n",
      "Epoch 542/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.7980 - val_loss: 2.0704\n",
      "Epoch 543/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.7967 - val_loss: 2.0750\n",
      "Epoch 544/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7955 - val_loss: 2.0752\n",
      "Epoch 545/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.7943 - val_loss: 2.0661\n",
      "Epoch 546/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.7932 - val_loss: 2.0766\n",
      "Epoch 547/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.7921 - val_loss: 2.0621\n",
      "Epoch 548/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7909 - val_loss: 2.0723\n",
      "Epoch 549/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.7897 - val_loss: 2.0631\n",
      "Epoch 550/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.7885 - val_loss: 2.0646\n",
      "Epoch 551/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.7873 - val_loss: 2.0656\n",
      "Epoch 552/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.7862 - val_loss: 2.0582\n",
      "Epoch 553/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.7850 - val_loss: 2.0658\n",
      "Epoch 554/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.7839 - val_loss: 2.0557\n",
      "Epoch 555/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.7827 - val_loss: 2.0625\n",
      "Epoch 556/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.7816 - val_loss: 2.0567\n",
      "Epoch 557/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.7801 - val_loss: 2.0573\n",
      "Epoch 558/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.7793 - val_loss: 2.0585\n",
      "Epoch 559/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.7781 - val_loss: 2.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.7770 - val_loss: 2.0584\n",
      "Epoch 561/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7759 - val_loss: 2.0510\n",
      "Epoch 562/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.7747 - val_loss: 2.0555\n",
      "Epoch 563/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.7736 - val_loss: 2.0510\n",
      "Epoch 564/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7725 - val_loss: 2.0511\n",
      "Epoch 565/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.7713 - val_loss: 2.0512\n",
      "Epoch 566/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.7702 - val_loss: 2.0470\n",
      "Epoch 567/2500\n",
      "64/64 [==============================] - 0s 378us/step - loss: 1.7691 - val_loss: 2.0502\n",
      "Epoch 568/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.7680 - val_loss: 2.0445\n",
      "Epoch 569/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.7669 - val_loss: 2.0473\n",
      "Epoch 570/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 1.7657 - val_loss: 2.0435\n",
      "Epoch 571/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.7646 - val_loss: 2.0435\n",
      "Epoch 572/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7635 - val_loss: 2.0430\n",
      "Epoch 573/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 1.7624 - val_loss: 2.0400\n",
      "Epoch 574/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.7613 - val_loss: 2.0418\n",
      "Epoch 575/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.7602 - val_loss: 2.0377\n",
      "Epoch 576/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.7591 - val_loss: 2.0396\n",
      "Epoch 577/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7580 - val_loss: 2.0365\n",
      "Epoch 578/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.7569 - val_loss: 2.0366\n",
      "Epoch 579/2500\n",
      "64/64 [==============================] - 0s 441us/step - loss: 1.7558 - val_loss: 2.0357\n",
      "Epoch 580/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.7545 - val_loss: 2.0338\n",
      "Epoch 581/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.7536 - val_loss: 2.0346\n",
      "Epoch 582/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 1.7525 - val_loss: 2.0316\n",
      "Epoch 583/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.7514 - val_loss: 2.0328\n",
      "Epoch 584/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.7504 - val_loss: 2.0301\n",
      "Epoch 585/2500\n",
      "64/64 [==============================] - 0s 341us/step - loss: 1.7493 - val_loss: 2.0302\n",
      "Epoch 586/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.7482 - val_loss: 2.0289\n",
      "Epoch 587/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.7471 - val_loss: 2.0275\n",
      "Epoch 588/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.7460 - val_loss: 2.0275\n",
      "Epoch 589/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.7450 - val_loss: 2.0251\n",
      "Epoch 590/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.7439 - val_loss: 2.0256\n",
      "Epoch 591/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.7428 - val_loss: 2.0232\n",
      "Epoch 592/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.7418 - val_loss: 2.0233\n",
      "Epoch 593/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.7407 - val_loss: 2.0217\n",
      "Epoch 594/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.7396 - val_loss: 2.0208\n",
      "Epoch 595/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 1.7386 - val_loss: 2.0202\n",
      "Epoch 596/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.7375 - val_loss: 2.0185\n",
      "Epoch 597/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.7365 - val_loss: 2.0185\n",
      "Epoch 598/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.7354 - val_loss: 2.0166\n",
      "Epoch 599/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.7343 - val_loss: 2.0166\n",
      "Epoch 600/2500\n",
      "64/64 [==============================] - 0s 324us/step - loss: 1.7330 - val_loss: 2.0150\n",
      "Epoch 601/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7322 - val_loss: 2.0144\n",
      "Epoch 602/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.7312 - val_loss: 2.0135\n",
      "Epoch 603/2500\n",
      "64/64 [==============================] - 0s 345us/step - loss: 1.7302 - val_loss: 2.0123\n",
      "Epoch 604/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.7291 - val_loss: 2.0119\n",
      "Epoch 605/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.7281 - val_loss: 2.0103\n",
      "Epoch 606/2500\n",
      "64/64 [==============================] - 0s 382us/step - loss: 1.7268 - val_loss: 2.0101\n",
      "Epoch 607/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.7260 - val_loss: 2.0086\n",
      "Epoch 608/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.7250 - val_loss: 2.0080\n",
      "Epoch 609/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.7239 - val_loss: 2.0069\n",
      "Epoch 610/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.7229 - val_loss: 2.0060\n",
      "Epoch 611/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.7219 - val_loss: 2.0053\n",
      "Epoch 612/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7208 - val_loss: 2.0040\n",
      "Epoch 613/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.7198 - val_loss: 2.0035\n",
      "Epoch 614/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.7188 - val_loss: 2.0021\n",
      "Epoch 615/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.7178 - val_loss: 2.0016\n",
      "Epoch 616/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.7168 - val_loss: 2.0004\n",
      "Epoch 617/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.7157 - val_loss: 1.9996\n",
      "Epoch 618/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.7147 - val_loss: 1.9987\n",
      "Epoch 619/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 1.7137 - val_loss: 1.9977\n",
      "Epoch 620/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.7127 - val_loss: 1.9970\n",
      "Epoch 621/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.7117 - val_loss: 1.9959\n",
      "Epoch 622/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.7107 - val_loss: 1.9953\n",
      "Epoch 623/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.7097 - val_loss: 1.9941\n",
      "Epoch 624/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.7087 - val_loss: 1.9934\n",
      "Epoch 625/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7077 - val_loss: 1.9924\n",
      "Epoch 626/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.7067 - val_loss: 1.9916\n",
      "Epoch 627/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.7057 - val_loss: 1.9908\n",
      "Epoch 628/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.7047 - val_loss: 1.9898\n",
      "Epoch 629/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.7037 - val_loss: 1.9890\n",
      "Epoch 630/2500\n",
      "64/64 [==============================] - 0s 286us/step - loss: 1.7027 - val_loss: 1.9880\n",
      "Epoch 631/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7017 - val_loss: 1.9873\n",
      "Epoch 632/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.7007 - val_loss: 1.9863\n",
      "Epoch 633/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.6998 - val_loss: 1.9855\n",
      "Epoch 634/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6988 - val_loss: 1.9846\n",
      "Epoch 635/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.6978 - val_loss: 1.9837\n",
      "Epoch 636/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.6968 - val_loss: 1.9829\n",
      "Epoch 637/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.6958 - val_loss: 1.9819\n",
      "Epoch 638/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6949 - val_loss: 1.9812\n",
      "Epoch 639/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6939 - val_loss: 1.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 640/2500\n",
      "64/64 [==============================] - 0s 375us/step - loss: 1.6929 - val_loss: 1.9794\n",
      "Epoch 641/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6919 - val_loss: 1.9785\n",
      "Epoch 642/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.6910 - val_loss: 1.9777\n",
      "Epoch 643/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.6900 - val_loss: 1.9768\n",
      "Epoch 644/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.6890 - val_loss: 1.9760\n",
      "Epoch 645/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6881 - val_loss: 1.9752\n",
      "Epoch 646/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6871 - val_loss: 1.9743\n",
      "Epoch 647/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 1.6862 - val_loss: 1.9735\n",
      "Epoch 648/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.6852 - val_loss: 1.9726\n",
      "Epoch 649/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.6843 - val_loss: 1.9718\n",
      "Epoch 650/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.6833 - val_loss: 1.9709\n",
      "Epoch 651/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.6824 - val_loss: 1.9701\n",
      "Epoch 652/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.6814 - val_loss: 1.9693\n",
      "Epoch 653/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.6805 - val_loss: 1.9684\n",
      "Epoch 654/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.6795 - val_loss: 1.9676\n",
      "Epoch 655/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6786 - val_loss: 1.9668\n",
      "Epoch 656/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.6776 - val_loss: 1.9660\n",
      "Epoch 657/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.6767 - val_loss: 1.9651\n",
      "Epoch 658/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.6757 - val_loss: 1.9643\n",
      "Epoch 659/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6748 - val_loss: 1.9635\n",
      "Epoch 660/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.6739 - val_loss: 1.9627\n",
      "Epoch 661/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.6729 - val_loss: 1.9619\n",
      "Epoch 662/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6720 - val_loss: 1.9610\n",
      "Epoch 663/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.6711 - val_loss: 1.9603\n",
      "Epoch 664/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.6702 - val_loss: 1.9594\n",
      "Epoch 665/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.6692 - val_loss: 1.9586\n",
      "Epoch 666/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.6683 - val_loss: 1.9578\n",
      "Epoch 667/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.6674 - val_loss: 1.9570\n",
      "Epoch 668/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.6665 - val_loss: 1.9562\n",
      "Epoch 669/2500\n",
      "64/64 [==============================] - 0s 286us/step - loss: 1.6655 - val_loss: 1.9554\n",
      "Epoch 670/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.6646 - val_loss: 1.9546\n",
      "Epoch 671/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.6637 - val_loss: 1.9538\n",
      "Epoch 672/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.6628 - val_loss: 1.9530\n",
      "Epoch 673/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.6619 - val_loss: 1.9522\n",
      "Epoch 674/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.6610 - val_loss: 1.9514\n",
      "Epoch 675/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.6601 - val_loss: 1.9506\n",
      "Epoch 676/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.6592 - val_loss: 1.9499\n",
      "Epoch 677/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.6583 - val_loss: 1.9491\n",
      "Epoch 678/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.6574 - val_loss: 1.9483\n",
      "Epoch 679/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.6565 - val_loss: 1.9475\n",
      "Epoch 680/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6556 - val_loss: 1.9467\n",
      "Epoch 681/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.6547 - val_loss: 1.9459\n",
      "Epoch 682/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 1.6538 - val_loss: 1.9452\n",
      "Epoch 683/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.6529 - val_loss: 1.9444\n",
      "Epoch 684/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.6520 - val_loss: 1.9436\n",
      "Epoch 685/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.6511 - val_loss: 1.9428\n",
      "Epoch 686/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6502 - val_loss: 1.9421\n",
      "Epoch 687/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.6493 - val_loss: 1.9413\n",
      "Epoch 688/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.6484 - val_loss: 1.9405\n",
      "Epoch 689/2500\n",
      "64/64 [==============================] - 0s 352us/step - loss: 1.6475 - val_loss: 1.9398\n",
      "Epoch 690/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6467 - val_loss: 1.9390\n",
      "Epoch 691/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.6458 - val_loss: 1.9383\n",
      "Epoch 692/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.6449 - val_loss: 1.9375\n",
      "Epoch 693/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.6440 - val_loss: 1.9367\n",
      "Epoch 694/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.6432 - val_loss: 1.9360\n",
      "Epoch 695/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.6423 - val_loss: 1.9352\n",
      "Epoch 696/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 1.6412 - val_loss: 1.9345\n",
      "Epoch 697/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.6405 - val_loss: 1.9337\n",
      "Epoch 698/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.6397 - val_loss: 1.9330\n",
      "Epoch 699/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 1.6388 - val_loss: 1.9322\n",
      "Epoch 700/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6379 - val_loss: 1.9315\n",
      "Epoch 701/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.6371 - val_loss: 1.9308\n",
      "Epoch 702/2500\n",
      "64/64 [==============================] - 0s 284us/step - loss: 1.6362 - val_loss: 1.9300\n",
      "Epoch 703/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.6353 - val_loss: 1.9293\n",
      "Epoch 704/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.6345 - val_loss: 1.9285\n",
      "Epoch 705/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.6336 - val_loss: 1.9278\n",
      "Epoch 706/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6328 - val_loss: 1.9271\n",
      "Epoch 707/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.6319 - val_loss: 1.9263\n",
      "Epoch 708/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.6311 - val_loss: 1.9256\n",
      "Epoch 709/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.6302 - val_loss: 1.9249\n",
      "Epoch 710/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.6294 - val_loss: 1.9242\n",
      "Epoch 711/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.6285 - val_loss: 1.9234\n",
      "Epoch 712/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.6277 - val_loss: 1.9227\n",
      "Epoch 713/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.6268 - val_loss: 1.9220\n",
      "Epoch 714/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 1.6258 - val_loss: 1.9213\n",
      "Epoch 715/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.6252 - val_loss: 1.9205\n",
      "Epoch 716/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.6243 - val_loss: 1.9198\n",
      "Epoch 717/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6235 - val_loss: 1.9191\n",
      "Epoch 718/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.6226 - val_loss: 1.9184\n",
      "Epoch 719/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.6218 - val_loss: 1.9177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6210 - val_loss: 1.9170\n",
      "Epoch 721/2500\n",
      "64/64 [==============================] - 0s 246us/step - loss: 1.6201 - val_loss: 1.9163\n",
      "Epoch 722/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6193 - val_loss: 1.9155\n",
      "Epoch 723/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.6185 - val_loss: 1.9148\n",
      "Epoch 724/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 1.6177 - val_loss: 1.9141\n",
      "Epoch 725/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.6168 - val_loss: 1.9134\n",
      "Epoch 726/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.6160 - val_loss: 1.9127\n",
      "Epoch 727/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.6152 - val_loss: 1.9120\n",
      "Epoch 728/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.6144 - val_loss: 1.9113\n",
      "Epoch 729/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6135 - val_loss: 1.9106\n",
      "Epoch 730/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 1.6127 - val_loss: 1.9099\n",
      "Epoch 731/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6119 - val_loss: 1.9092\n",
      "Epoch 732/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.6111 - val_loss: 1.9086\n",
      "Epoch 733/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.6103 - val_loss: 1.9079\n",
      "Epoch 734/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 1.6095 - val_loss: 1.9072\n",
      "Epoch 735/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.6087 - val_loss: 1.9065\n",
      "Epoch 736/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.6079 - val_loss: 1.9058\n",
      "Epoch 737/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.6071 - val_loss: 1.9051\n",
      "Epoch 738/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.6062 - val_loss: 1.9044\n",
      "Epoch 739/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.6052 - val_loss: 1.9038\n",
      "Epoch 740/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.6046 - val_loss: 1.9031\n",
      "Epoch 741/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6038 - val_loss: 1.9024\n",
      "Epoch 742/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.6030 - val_loss: 1.9017\n",
      "Epoch 743/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.6022 - val_loss: 1.9011\n",
      "Epoch 744/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.6014 - val_loss: 1.9004\n",
      "Epoch 745/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6007 - val_loss: 1.8997\n",
      "Epoch 746/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.5999 - val_loss: 1.8990\n",
      "Epoch 747/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.5991 - val_loss: 1.8984\n",
      "Epoch 748/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.5983 - val_loss: 1.8977\n",
      "Epoch 749/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.5975 - val_loss: 1.8970\n",
      "Epoch 750/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5967 - val_loss: 1.8964\n",
      "Epoch 751/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5959 - val_loss: 1.8957\n",
      "Epoch 752/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.5951 - val_loss: 1.8951\n",
      "Epoch 753/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.5943 - val_loss: 1.8944\n",
      "Epoch 754/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.5936 - val_loss: 1.8937\n",
      "Epoch 755/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.5928 - val_loss: 1.8931\n",
      "Epoch 756/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.5920 - val_loss: 1.8924\n",
      "Epoch 757/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.5912 - val_loss: 1.8918\n",
      "Epoch 758/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5905 - val_loss: 1.8911\n",
      "Epoch 759/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5897 - val_loss: 1.8905\n",
      "Epoch 760/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.5889 - val_loss: 1.8898\n",
      "Epoch 761/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.5881 - val_loss: 1.8892\n",
      "Epoch 762/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.5874 - val_loss: 1.8885\n",
      "Epoch 763/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.5866 - val_loss: 1.8879\n",
      "Epoch 764/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.5858 - val_loss: 1.8872\n",
      "Epoch 765/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.5851 - val_loss: 1.8866\n",
      "Epoch 766/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5843 - val_loss: 1.8860\n",
      "Epoch 767/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.5835 - val_loss: 1.8853\n",
      "Epoch 768/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.5828 - val_loss: 1.8847\n",
      "Epoch 769/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.5820 - val_loss: 1.8840\n",
      "Epoch 770/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.5813 - val_loss: 1.8834\n",
      "Epoch 771/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5805 - val_loss: 1.8828\n",
      "Epoch 772/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5798 - val_loss: 1.8821\n",
      "Epoch 773/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.5790 - val_loss: 1.8815\n",
      "Epoch 774/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.5782 - val_loss: 1.8809\n",
      "Epoch 775/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5775 - val_loss: 1.8803\n",
      "Epoch 776/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5767 - val_loss: 1.8796\n",
      "Epoch 777/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 1.5760 - val_loss: 1.8790\n",
      "Epoch 778/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.5753 - val_loss: 1.8784\n",
      "Epoch 779/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5745 - val_loss: 1.8778\n",
      "Epoch 780/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5738 - val_loss: 1.8772\n",
      "Epoch 781/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5728 - val_loss: 1.8765\n",
      "Epoch 782/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.5723 - val_loss: 1.8759\n",
      "Epoch 783/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5715 - val_loss: 1.8753\n",
      "Epoch 784/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5708 - val_loss: 1.8747\n",
      "Epoch 785/2500\n",
      "64/64 [==============================] - 0s 388us/step - loss: 1.5701 - val_loss: 1.8741\n",
      "Epoch 786/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5693 - val_loss: 1.8735\n",
      "Epoch 787/2500\n",
      "64/64 [==============================] - 0s 545us/step - loss: 1.5686 - val_loss: 1.8728\n",
      "Epoch 788/2500\n",
      "64/64 [==============================] - 0s 478us/step - loss: 1.5677 - val_loss: 1.8722\n",
      "Epoch 789/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 1.5671 - val_loss: 1.8716\n",
      "Epoch 790/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.5664 - val_loss: 1.8710\n",
      "Epoch 791/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5657 - val_loss: 1.8704\n",
      "Epoch 792/2500\n",
      "64/64 [==============================] - 0s 382us/step - loss: 1.5649 - val_loss: 1.8698\n",
      "Epoch 793/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.5642 - val_loss: 1.8692\n",
      "Epoch 794/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5635 - val_loss: 1.8686\n",
      "Epoch 795/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.5628 - val_loss: 1.8680\n",
      "Epoch 796/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.5620 - val_loss: 1.8674\n",
      "Epoch 797/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.5613 - val_loss: 1.8668\n",
      "Epoch 798/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.5606 - val_loss: 1.8662\n",
      "Epoch 799/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5599 - val_loss: 1.8656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.5592 - val_loss: 1.8650\n",
      "Epoch 801/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5584 - val_loss: 1.8644\n",
      "Epoch 802/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 1.5577 - val_loss: 1.8638\n",
      "Epoch 803/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.5570 - val_loss: 1.8632\n",
      "Epoch 804/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5563 - val_loss: 1.8627\n",
      "Epoch 805/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5556 - val_loss: 1.8621\n",
      "Epoch 806/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 1.5549 - val_loss: 1.8615\n",
      "Epoch 807/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.5542 - val_loss: 1.8609\n",
      "Epoch 808/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5535 - val_loss: 1.8603\n",
      "Epoch 809/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5528 - val_loss: 1.8597\n",
      "Epoch 810/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.5521 - val_loss: 1.8591\n",
      "Epoch 811/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5514 - val_loss: 1.8586\n",
      "Epoch 812/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5507 - val_loss: 1.8580\n",
      "Epoch 813/2500\n",
      "64/64 [==============================] - 0s 428us/step - loss: 1.5500 - val_loss: 1.8574\n",
      "Epoch 814/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.5493 - val_loss: 1.8568\n",
      "Epoch 815/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 1.5486 - val_loss: 1.8563\n",
      "Epoch 816/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5479 - val_loss: 1.8557\n",
      "Epoch 817/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5472 - val_loss: 1.8551\n",
      "Epoch 818/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.5465 - val_loss: 1.8545\n",
      "Epoch 819/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5458 - val_loss: 1.8540\n",
      "Epoch 820/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5451 - val_loss: 1.8534\n",
      "Epoch 821/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.5444 - val_loss: 1.8528\n",
      "Epoch 822/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.5437 - val_loss: 1.8523\n",
      "Epoch 823/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.5430 - val_loss: 1.8517\n",
      "Epoch 824/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5423 - val_loss: 1.8511\n",
      "Epoch 825/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.5417 - val_loss: 1.8506\n",
      "Epoch 826/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.5410 - val_loss: 1.8500\n",
      "Epoch 827/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.5403 - val_loss: 1.8495\n",
      "Epoch 828/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5396 - val_loss: 1.8489\n",
      "Epoch 829/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.5389 - val_loss: 1.8483\n",
      "Epoch 830/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5382 - val_loss: 1.8478\n",
      "Epoch 831/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.5376 - val_loss: 1.8472\n",
      "Epoch 832/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5369 - val_loss: 1.8467\n",
      "Epoch 833/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5362 - val_loss: 1.8461\n",
      "Epoch 834/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5355 - val_loss: 1.8456\n",
      "Epoch 835/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.5349 - val_loss: 1.8450\n",
      "Epoch 836/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.5342 - val_loss: 1.8445\n",
      "Epoch 837/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.5335 - val_loss: 1.8439\n",
      "Epoch 838/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5329 - val_loss: 1.8434\n",
      "Epoch 839/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.5322 - val_loss: 1.8428\n",
      "Epoch 840/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5315 - val_loss: 1.8423\n",
      "Epoch 841/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.5309 - val_loss: 1.8417\n",
      "Epoch 842/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.5302 - val_loss: 1.8412\n",
      "Epoch 843/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5295 - val_loss: 1.8406\n",
      "Epoch 844/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5289 - val_loss: 1.8401\n",
      "Epoch 845/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.5282 - val_loss: 1.8396\n",
      "Epoch 846/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.5276 - val_loss: 1.8390\n",
      "Epoch 847/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5269 - val_loss: 1.8385\n",
      "Epoch 848/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.5262 - val_loss: 1.8379\n",
      "Epoch 849/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5256 - val_loss: 1.8374\n",
      "Epoch 850/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5249 - val_loss: 1.8369\n",
      "Epoch 851/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5243 - val_loss: 1.8363\n",
      "Epoch 852/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.5235 - val_loss: 1.8358\n",
      "Epoch 853/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5230 - val_loss: 1.8353\n",
      "Epoch 854/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5223 - val_loss: 1.8347\n",
      "Epoch 855/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.5217 - val_loss: 1.8342\n",
      "Epoch 856/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.5210 - val_loss: 1.8337\n",
      "Epoch 857/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.5204 - val_loss: 1.8332\n",
      "Epoch 858/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.5197 - val_loss: 1.8326\n",
      "Epoch 859/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.5191 - val_loss: 1.8321\n",
      "Epoch 860/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.5184 - val_loss: 1.8316\n",
      "Epoch 861/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.5178 - val_loss: 1.8311\n",
      "Epoch 862/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.5172 - val_loss: 1.8305\n",
      "Epoch 863/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.5165 - val_loss: 1.8300\n",
      "Epoch 864/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5159 - val_loss: 1.8295\n",
      "Epoch 865/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.5152 - val_loss: 1.8290\n",
      "Epoch 866/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.5146 - val_loss: 1.8285\n",
      "Epoch 867/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.5140 - val_loss: 1.8279\n",
      "Epoch 868/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5133 - val_loss: 1.8274\n",
      "Epoch 869/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.5127 - val_loss: 1.8269\n",
      "Epoch 870/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.5121 - val_loss: 1.8264\n",
      "Epoch 871/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.5114 - val_loss: 1.8259\n",
      "Epoch 872/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.5108 - val_loss: 1.8254\n",
      "Epoch 873/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.5102 - val_loss: 1.8249\n",
      "Epoch 874/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5096 - val_loss: 1.8244\n",
      "Epoch 875/2500\n",
      "64/64 [==============================] - 0s 386us/step - loss: 1.5089 - val_loss: 1.8238\n",
      "Epoch 876/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5083 - val_loss: 1.8233\n",
      "Epoch 877/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5077 - val_loss: 1.8228\n",
      "Epoch 878/2500\n",
      "64/64 [==============================] - 0s 341us/step - loss: 1.5071 - val_loss: 1.8223\n",
      "Epoch 879/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5064 - val_loss: 1.8218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/2500\n",
      "64/64 [==============================] - 0s 310us/step - loss: 1.5058 - val_loss: 1.8213\n",
      "Epoch 881/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5052 - val_loss: 1.8208\n",
      "Epoch 882/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5046 - val_loss: 1.8203\n",
      "Epoch 883/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.5040 - val_loss: 1.8198\n",
      "Epoch 884/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.5034 - val_loss: 1.8193\n",
      "Epoch 885/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5027 - val_loss: 1.8188\n",
      "Epoch 886/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.5021 - val_loss: 1.8183\n",
      "Epoch 887/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.5015 - val_loss: 1.8178\n",
      "Epoch 888/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.5009 - val_loss: 1.8173\n",
      "Epoch 889/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5003 - val_loss: 1.8168\n",
      "Epoch 890/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.4997 - val_loss: 1.8163\n",
      "Epoch 891/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.4991 - val_loss: 1.8158\n",
      "Epoch 892/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4985 - val_loss: 1.8153\n",
      "Epoch 893/2500\n",
      "64/64 [==============================] - 0s 299us/step - loss: 1.4979 - val_loss: 1.8148\n",
      "Epoch 894/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4973 - val_loss: 1.8144\n",
      "Epoch 895/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.4966 - val_loss: 1.8139\n",
      "Epoch 896/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.4960 - val_loss: 1.8134\n",
      "Epoch 897/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.4954 - val_loss: 1.8129\n",
      "Epoch 898/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4948 - val_loss: 1.8124\n",
      "Epoch 899/2500\n",
      "64/64 [==============================] - 0s 280us/step - loss: 1.4942 - val_loss: 1.8119\n",
      "Epoch 900/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.4936 - val_loss: 1.8114\n",
      "Epoch 901/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4930 - val_loss: 1.8109\n",
      "Epoch 902/2500\n",
      "64/64 [==============================] - 0s 366us/step - loss: 1.4924 - val_loss: 1.8105\n",
      "Epoch 903/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4919 - val_loss: 1.8100\n",
      "Epoch 904/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.4913 - val_loss: 1.8095\n",
      "Epoch 905/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.4907 - val_loss: 1.8090\n",
      "Epoch 906/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.4901 - val_loss: 1.8085\n",
      "Epoch 907/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.4895 - val_loss: 1.8080\n",
      "Epoch 908/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4889 - val_loss: 1.8076\n",
      "Epoch 909/2500\n",
      "64/64 [==============================] - 0s 316us/step - loss: 1.4883 - val_loss: 1.8071\n",
      "Epoch 910/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4877 - val_loss: 1.8066\n",
      "Epoch 911/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.4871 - val_loss: 1.8061\n",
      "Epoch 912/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.4865 - val_loss: 1.8057\n",
      "Epoch 913/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.4860 - val_loss: 1.8052\n",
      "Epoch 914/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4854 - val_loss: 1.8047\n",
      "Epoch 915/2500\n",
      "64/64 [==============================] - 0s 293us/step - loss: 1.4846 - val_loss: 1.8042\n",
      "Epoch 916/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.4842 - val_loss: 1.8038\n",
      "Epoch 917/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4836 - val_loss: 1.8033\n",
      "Epoch 918/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.4830 - val_loss: 1.8028\n",
      "Epoch 919/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4823 - val_loss: 1.8023\n",
      "Epoch 920/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.4819 - val_loss: 1.8019\n",
      "Epoch 921/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4813 - val_loss: 1.8014\n",
      "Epoch 922/2500\n",
      "64/64 [==============================] - 0s 372us/step - loss: 1.4807 - val_loss: 1.8010\n",
      "Epoch 923/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.4802 - val_loss: 1.8005\n",
      "Epoch 924/2500\n",
      "64/64 [==============================] - 0s 312us/step - loss: 1.4796 - val_loss: 1.8000\n",
      "Epoch 925/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4790 - val_loss: 1.7996\n",
      "Epoch 926/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4784 - val_loss: 1.7991\n",
      "Epoch 927/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.4779 - val_loss: 1.7986\n",
      "Epoch 928/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.4773 - val_loss: 1.7982\n",
      "Epoch 929/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4767 - val_loss: 1.7977\n",
      "Epoch 930/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 1.4762 - val_loss: 1.7972\n",
      "Epoch 931/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.4756 - val_loss: 1.7968\n",
      "Epoch 932/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4750 - val_loss: 1.7963\n",
      "Epoch 933/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.4744 - val_loss: 1.7959\n",
      "Epoch 934/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.4739 - val_loss: 1.7954\n",
      "Epoch 935/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.4733 - val_loss: 1.7949\n",
      "Epoch 936/2500\n",
      "64/64 [==============================] - 0s 405us/step - loss: 1.4728 - val_loss: 1.7945\n",
      "Epoch 937/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.4722 - val_loss: 1.7940\n",
      "Epoch 938/2500\n",
      "64/64 [==============================] - 0s 320us/step - loss: 1.4716 - val_loss: 1.7936\n",
      "Epoch 939/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4711 - val_loss: 1.7931\n",
      "Epoch 940/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.4705 - val_loss: 1.7927\n",
      "Epoch 941/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.4700 - val_loss: 1.7922\n",
      "Epoch 942/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4694 - val_loss: 1.7918\n",
      "Epoch 943/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.4688 - val_loss: 1.7913\n",
      "Epoch 944/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.4683 - val_loss: 1.7909\n",
      "Epoch 945/2500\n",
      "64/64 [==============================] - 0s 389us/step - loss: 1.4677 - val_loss: 1.7904\n",
      "Epoch 946/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.4672 - val_loss: 1.7900\n",
      "Epoch 947/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.4666 - val_loss: 1.7895\n",
      "Epoch 948/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.4661 - val_loss: 1.7891\n",
      "Epoch 949/2500\n",
      "64/64 [==============================] - 0s 320us/step - loss: 1.4655 - val_loss: 1.7886\n",
      "Epoch 950/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.4650 - val_loss: 1.7882\n",
      "Epoch 951/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.4644 - val_loss: 1.7877\n",
      "Epoch 952/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4639 - val_loss: 1.7873\n",
      "Epoch 953/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.4632 - val_loss: 1.7869\n",
      "Epoch 954/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.4628 - val_loss: 1.7864\n",
      "Epoch 955/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.4622 - val_loss: 1.7860\n",
      "Epoch 956/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.4617 - val_loss: 1.7855\n",
      "Epoch 957/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4612 - val_loss: 1.7851\n",
      "Epoch 958/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 1.4606 - val_loss: 1.7846\n",
      "Epoch 959/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 436us/step - loss: 1.4601 - val_loss: 1.7842\n",
      "Epoch 960/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4595 - val_loss: 1.7838\n",
      "Epoch 961/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 1.4590 - val_loss: 1.7833\n",
      "Epoch 962/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4585 - val_loss: 1.7829\n",
      "Epoch 963/2500\n",
      "64/64 [==============================] - 0s 400us/step - loss: 1.4579 - val_loss: 1.7825\n",
      "Epoch 964/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.4574 - val_loss: 1.7820\n",
      "Epoch 965/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 1.4568 - val_loss: 1.7816\n",
      "Epoch 966/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4563 - val_loss: 1.7811\n",
      "Epoch 967/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4558 - val_loss: 1.7807\n",
      "Epoch 968/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4552 - val_loss: 1.7803\n",
      "Epoch 969/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.4547 - val_loss: 1.7798\n",
      "Epoch 970/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.4542 - val_loss: 1.7794\n",
      "Epoch 971/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.4536 - val_loss: 1.7790\n",
      "Epoch 972/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4531 - val_loss: 1.7785\n",
      "Epoch 973/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4526 - val_loss: 1.7781\n",
      "Epoch 974/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4521 - val_loss: 1.7777\n",
      "Epoch 975/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 1.4515 - val_loss: 1.7773\n",
      "Epoch 976/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.4510 - val_loss: 1.7768\n",
      "Epoch 977/2500\n",
      "64/64 [==============================] - 0s 432us/step - loss: 1.4505 - val_loss: 1.7764\n",
      "Epoch 978/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4500 - val_loss: 1.7760\n",
      "Epoch 979/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.4494 - val_loss: 1.7756\n",
      "Epoch 980/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4489 - val_loss: 1.7751\n",
      "Epoch 981/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.4484 - val_loss: 1.7747\n",
      "Epoch 982/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4479 - val_loss: 1.7743\n",
      "Epoch 983/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 1.4474 - val_loss: 1.7739\n",
      "Epoch 984/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.4468 - val_loss: 1.7734\n",
      "Epoch 985/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4463 - val_loss: 1.7730\n",
      "Epoch 986/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.4458 - val_loss: 1.7726\n",
      "Epoch 987/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.4453 - val_loss: 1.7722\n",
      "Epoch 988/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4448 - val_loss: 1.7717\n",
      "Epoch 989/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.4442 - val_loss: 1.7713\n",
      "Epoch 990/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4437 - val_loss: 1.7709\n",
      "Epoch 991/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 1.4432 - val_loss: 1.7705\n",
      "Epoch 992/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.4427 - val_loss: 1.7701\n",
      "Epoch 993/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.4422 - val_loss: 1.7697\n",
      "Epoch 994/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.4417 - val_loss: 1.7692\n",
      "Epoch 995/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.4412 - val_loss: 1.7688\n",
      "Epoch 996/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4407 - val_loss: 1.7684\n",
      "Epoch 997/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.4402 - val_loss: 1.7680\n",
      "Epoch 998/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4397 - val_loss: 1.7676\n",
      "Epoch 999/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4391 - val_loss: 1.7672\n",
      "Epoch 1000/2500\n",
      "64/64 [==============================] - 0s 351us/step - loss: 1.4386 - val_loss: 1.7667\n",
      "Epoch 1001/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4381 - val_loss: 1.7663\n",
      "Epoch 1002/2500\n",
      "64/64 [==============================] - 0s 345us/step - loss: 1.4376 - val_loss: 1.7659\n",
      "Epoch 1003/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4371 - val_loss: 1.7655\n",
      "Epoch 1004/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 1.4366 - val_loss: 1.7651\n",
      "Epoch 1005/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.4361 - val_loss: 1.7647\n",
      "Epoch 1006/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 1.4356 - val_loss: 1.7643\n",
      "Epoch 1007/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4351 - val_loss: 1.7639\n",
      "Epoch 1008/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 1.4346 - val_loss: 1.7635\n",
      "Epoch 1009/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4341 - val_loss: 1.7630\n",
      "Epoch 1010/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.4336 - val_loss: 1.7626\n",
      "Epoch 1011/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.4331 - val_loss: 1.7622\n",
      "Epoch 1012/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.4326 - val_loss: 1.7618\n",
      "Epoch 1013/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.4321 - val_loss: 1.7614\n",
      "Epoch 1014/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.4316 - val_loss: 1.7610\n",
      "Epoch 1015/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4311 - val_loss: 1.7606\n",
      "Epoch 1016/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.4307 - val_loss: 1.7602\n",
      "Epoch 1017/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.4302 - val_loss: 1.7598\n",
      "Epoch 1018/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.4297 - val_loss: 1.7594\n",
      "Epoch 1019/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.4292 - val_loss: 1.7590\n",
      "Epoch 1020/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.4287 - val_loss: 1.7586\n",
      "Epoch 1021/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4282 - val_loss: 1.7582\n",
      "Epoch 1022/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.4277 - val_loss: 1.7578\n",
      "Epoch 1023/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.4272 - val_loss: 1.7574\n",
      "Epoch 1024/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.4267 - val_loss: 1.7570\n",
      "Epoch 1025/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4263 - val_loss: 1.7566\n",
      "Epoch 1026/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.4258 - val_loss: 1.7562\n",
      "Epoch 1027/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4253 - val_loss: 1.7558\n",
      "Epoch 1028/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.4248 - val_loss: 1.7554\n",
      "Epoch 1029/2500\n",
      "64/64 [==============================] - 0s 429us/step - loss: 1.4243 - val_loss: 1.7550\n",
      "Epoch 1030/2500\n",
      "64/64 [==============================] - 0s 375us/step - loss: 1.4238 - val_loss: 1.7546\n",
      "Epoch 1031/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4234 - val_loss: 1.7542\n",
      "Epoch 1032/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4229 - val_loss: 1.7538\n",
      "Epoch 1033/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.4224 - val_loss: 1.7534\n",
      "Epoch 1034/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.4219 - val_loss: 1.7530\n",
      "Epoch 1035/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4214 - val_loss: 1.7526\n",
      "Epoch 1036/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 1.4210 - val_loss: 1.7522\n",
      "Epoch 1037/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.4205 - val_loss: 1.7518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1038/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4200 - val_loss: 1.7514\n",
      "Epoch 1039/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 1.4195 - val_loss: 1.7510\n",
      "Epoch 1040/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.4189 - val_loss: 1.7506\n",
      "Epoch 1041/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4186 - val_loss: 1.7503\n",
      "Epoch 1042/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4181 - val_loss: 1.7499\n",
      "Epoch 1043/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.4176 - val_loss: 1.7495\n",
      "Epoch 1044/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.4172 - val_loss: 1.7491\n",
      "Epoch 1045/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4167 - val_loss: 1.7487\n",
      "Epoch 1046/2500\n",
      "64/64 [==============================] - 0s 299us/step - loss: 1.4162 - val_loss: 1.7483\n",
      "Epoch 1047/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4158 - val_loss: 1.7479\n",
      "Epoch 1048/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.4153 - val_loss: 1.7475\n",
      "Epoch 1049/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.4148 - val_loss: 1.7471\n",
      "Epoch 1050/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4144 - val_loss: 1.7467\n",
      "Epoch 1051/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4139 - val_loss: 1.7464\n",
      "Epoch 1052/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.4134 - val_loss: 1.7460\n",
      "Epoch 1053/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4130 - val_loss: 1.7456\n",
      "Epoch 1054/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.4125 - val_loss: 1.7452\n",
      "Epoch 1055/2500\n",
      "64/64 [==============================] - 0s 450us/step - loss: 1.4120 - val_loss: 1.7448\n",
      "Epoch 1056/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4116 - val_loss: 1.7444\n",
      "Epoch 1057/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.4111 - val_loss: 1.7441\n",
      "Epoch 1058/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4106 - val_loss: 1.7437\n",
      "Epoch 1059/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.4102 - val_loss: 1.7433\n",
      "Epoch 1060/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 1.4097 - val_loss: 1.7429\n",
      "Epoch 1061/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4093 - val_loss: 1.7425\n",
      "Epoch 1062/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.4088 - val_loss: 1.7421\n",
      "Epoch 1063/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4083 - val_loss: 1.7417\n",
      "Epoch 1064/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.4079 - val_loss: 1.7414\n",
      "Epoch 1065/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.4074 - val_loss: 1.7410\n",
      "Epoch 1066/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.4070 - val_loss: 1.7406\n",
      "Epoch 1067/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4065 - val_loss: 1.7402\n",
      "Epoch 1068/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 1.4061 - val_loss: 1.7398\n",
      "Epoch 1069/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.4056 - val_loss: 1.7395\n",
      "Epoch 1070/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.4052 - val_loss: 1.7391\n",
      "Epoch 1071/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.4047 - val_loss: 1.7387\n",
      "Epoch 1072/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4043 - val_loss: 1.7383\n",
      "Epoch 1073/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 1.4038 - val_loss: 1.7380\n",
      "Epoch 1074/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4034 - val_loss: 1.7376\n",
      "Epoch 1075/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4029 - val_loss: 1.7372\n",
      "Epoch 1076/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.4025 - val_loss: 1.7368\n",
      "Epoch 1077/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.4020 - val_loss: 1.7365\n",
      "Epoch 1078/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.4016 - val_loss: 1.7361\n",
      "Epoch 1079/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.4011 - val_loss: 1.7357\n",
      "Epoch 1080/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.4007 - val_loss: 1.7353\n",
      "Epoch 1081/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4002 - val_loss: 1.7349\n",
      "Epoch 1082/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3998 - val_loss: 1.7346\n",
      "Epoch 1083/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.3993 - val_loss: 1.7342\n",
      "Epoch 1084/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.3989 - val_loss: 1.7338\n",
      "Epoch 1085/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3984 - val_loss: 1.7335\n",
      "Epoch 1086/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 1.3980 - val_loss: 1.7331\n",
      "Epoch 1087/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3976 - val_loss: 1.7327\n",
      "Epoch 1088/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.3971 - val_loss: 1.7323\n",
      "Epoch 1089/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.3967 - val_loss: 1.7320\n",
      "Epoch 1090/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3962 - val_loss: 1.7316\n",
      "Epoch 1091/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.3958 - val_loss: 1.7312\n",
      "Epoch 1092/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.3954 - val_loss: 1.7309\n",
      "Epoch 1093/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3949 - val_loss: 1.7305\n",
      "Epoch 1094/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3945 - val_loss: 1.7301\n",
      "Epoch 1095/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.3940 - val_loss: 1.7298\n",
      "Epoch 1096/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3936 - val_loss: 1.7294\n",
      "Epoch 1097/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.3932 - val_loss: 1.7290\n",
      "Epoch 1098/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.3927 - val_loss: 1.7287\n",
      "Epoch 1099/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3923 - val_loss: 1.7283\n",
      "Epoch 1100/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.3919 - val_loss: 1.7279\n",
      "Epoch 1101/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3914 - val_loss: 1.7275\n",
      "Epoch 1102/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3910 - val_loss: 1.7272\n",
      "Epoch 1103/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.3906 - val_loss: 1.7268\n",
      "Epoch 1104/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.3901 - val_loss: 1.7264\n",
      "Epoch 1105/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3897 - val_loss: 1.7261\n",
      "Epoch 1106/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 1.3893 - val_loss: 1.7257\n",
      "Epoch 1107/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3889 - val_loss: 1.7254\n",
      "Epoch 1108/2500\n",
      "64/64 [==============================] - 0s 280us/step - loss: 1.3884 - val_loss: 1.7250\n",
      "Epoch 1109/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.3880 - val_loss: 1.7246\n",
      "Epoch 1110/2500\n",
      "64/64 [==============================] - 0s 430us/step - loss: 1.3876 - val_loss: 1.7243\n",
      "Epoch 1111/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3872 - val_loss: 1.7239\n",
      "Epoch 1112/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.3867 - val_loss: 1.7235\n",
      "Epoch 1113/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3863 - val_loss: 1.7232\n",
      "Epoch 1114/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3859 - val_loss: 1.7228\n",
      "Epoch 1115/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 1.3855 - val_loss: 1.7224\n",
      "Epoch 1116/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3850 - val_loss: 1.7221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1117/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3846 - val_loss: 1.7217\n",
      "Epoch 1118/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.3842 - val_loss: 1.7214\n",
      "Epoch 1119/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3838 - val_loss: 1.7210\n",
      "Epoch 1120/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3833 - val_loss: 1.7206\n",
      "Epoch 1121/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3829 - val_loss: 1.7203\n",
      "Epoch 1122/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.3825 - val_loss: 1.7199\n",
      "Epoch 1123/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3821 - val_loss: 1.7196\n",
      "Epoch 1124/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3817 - val_loss: 1.7192\n",
      "Epoch 1125/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.3812 - val_loss: 1.7189\n",
      "Epoch 1126/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3808 - val_loss: 1.7185\n",
      "Epoch 1127/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3804 - val_loss: 1.7181\n",
      "Epoch 1128/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3800 - val_loss: 1.7178\n",
      "Epoch 1129/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 1.3796 - val_loss: 1.7174\n",
      "Epoch 1130/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.3792 - val_loss: 1.7171\n",
      "Epoch 1131/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3788 - val_loss: 1.7167\n",
      "Epoch 1132/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.3783 - val_loss: 1.7164\n",
      "Epoch 1133/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 1.3779 - val_loss: 1.7160\n",
      "Epoch 1134/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.3775 - val_loss: 1.7156\n",
      "Epoch 1135/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3771 - val_loss: 1.7153\n",
      "Epoch 1136/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3767 - val_loss: 1.7149\n",
      "Epoch 1137/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.3763 - val_loss: 1.7146\n",
      "Epoch 1138/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3759 - val_loss: 1.7142\n",
      "Epoch 1139/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3755 - val_loss: 1.7139\n",
      "Epoch 1140/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.3751 - val_loss: 1.7135\n",
      "Epoch 1141/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.3746 - val_loss: 1.7132\n",
      "Epoch 1142/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.3742 - val_loss: 1.7128\n",
      "Epoch 1143/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.3738 - val_loss: 1.7125\n",
      "Epoch 1144/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.3734 - val_loss: 1.7121\n",
      "Epoch 1145/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.3730 - val_loss: 1.7117\n",
      "Epoch 1146/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3726 - val_loss: 1.7114\n",
      "Epoch 1147/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3722 - val_loss: 1.7110\n",
      "Epoch 1148/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3718 - val_loss: 1.7107\n",
      "Epoch 1149/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.3714 - val_loss: 1.7103\n",
      "Epoch 1150/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.3710 - val_loss: 1.7100\n",
      "Epoch 1151/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.3706 - val_loss: 1.7096\n",
      "Epoch 1152/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.3702 - val_loss: 1.7093\n",
      "Epoch 1153/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.3698 - val_loss: 1.7089\n",
      "Epoch 1154/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3694 - val_loss: 1.7086\n",
      "Epoch 1155/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3690 - val_loss: 1.7082\n",
      "Epoch 1156/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.3686 - val_loss: 1.7079\n",
      "Epoch 1157/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.3682 - val_loss: 1.7076\n",
      "Epoch 1158/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3678 - val_loss: 1.7072\n",
      "Epoch 1159/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.3674 - val_loss: 1.7069\n",
      "Epoch 1160/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.3670 - val_loss: 1.7065\n",
      "Epoch 1161/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3666 - val_loss: 1.7062\n",
      "Epoch 1162/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3662 - val_loss: 1.7058\n",
      "Epoch 1163/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.3658 - val_loss: 1.7055\n",
      "Epoch 1164/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3654 - val_loss: 1.7051\n",
      "Epoch 1165/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3650 - val_loss: 1.7048\n",
      "Epoch 1166/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3646 - val_loss: 1.7044\n",
      "Epoch 1167/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.3642 - val_loss: 1.7041\n",
      "Epoch 1168/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.3638 - val_loss: 1.7037\n",
      "Epoch 1169/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3634 - val_loss: 1.7034\n",
      "Epoch 1170/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.3630 - val_loss: 1.7030\n",
      "Epoch 1171/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3626 - val_loss: 1.7027\n",
      "Epoch 1172/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.3623 - val_loss: 1.7024\n",
      "Epoch 1173/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3619 - val_loss: 1.7020\n",
      "Epoch 1174/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 1.3615 - val_loss: 1.7017\n",
      "Epoch 1175/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3611 - val_loss: 1.7013\n",
      "Epoch 1176/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3607 - val_loss: 1.7010\n",
      "Epoch 1177/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.3603 - val_loss: 1.7006\n",
      "Epoch 1178/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.3599 - val_loss: 1.7003\n",
      "Epoch 1179/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3595 - val_loss: 1.7000\n",
      "Epoch 1180/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.3592 - val_loss: 1.6996\n",
      "Epoch 1181/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3588 - val_loss: 1.6993\n",
      "Epoch 1182/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3584 - val_loss: 1.6989\n",
      "Epoch 1183/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3580 - val_loss: 1.6986\n",
      "Epoch 1184/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3576 - val_loss: 1.6982\n",
      "Epoch 1185/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.3572 - val_loss: 1.6979\n",
      "Epoch 1186/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.3568 - val_loss: 1.6976\n",
      "Epoch 1187/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3565 - val_loss: 1.6972\n",
      "Epoch 1188/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.3561 - val_loss: 1.6969\n",
      "Epoch 1189/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.3557 - val_loss: 1.6965\n",
      "Epoch 1190/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3553 - val_loss: 1.6962\n",
      "Epoch 1191/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.3549 - val_loss: 1.6959\n",
      "Epoch 1192/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 1.3545 - val_loss: 1.6955\n",
      "Epoch 1193/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3542 - val_loss: 1.6952\n",
      "Epoch 1194/2500\n",
      "64/64 [==============================] - 0s 376us/step - loss: 1.3538 - val_loss: 1.6948\n",
      "Epoch 1195/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3534 - val_loss: 1.6945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1196/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3530 - val_loss: 1.6942\n",
      "Epoch 1197/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.3527 - val_loss: 1.6938\n",
      "Epoch 1198/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3523 - val_loss: 1.6935\n",
      "Epoch 1199/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.3519 - val_loss: 1.6932\n",
      "Epoch 1200/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 1.3515 - val_loss: 1.6928\n",
      "Epoch 1201/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.3511 - val_loss: 1.6925\n",
      "Epoch 1202/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3508 - val_loss: 1.6922\n",
      "Epoch 1203/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 1.3504 - val_loss: 1.6918\n",
      "Epoch 1204/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3500 - val_loss: 1.6915\n",
      "Epoch 1205/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3496 - val_loss: 1.6911\n",
      "Epoch 1206/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3493 - val_loss: 1.6908\n",
      "Epoch 1207/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3489 - val_loss: 1.6905\n",
      "Epoch 1208/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3485 - val_loss: 1.6901\n",
      "Epoch 1209/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3482 - val_loss: 1.6898\n",
      "Epoch 1210/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.3478 - val_loss: 1.6895\n",
      "Epoch 1211/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3474 - val_loss: 1.6891\n",
      "Epoch 1212/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.3470 - val_loss: 1.6888\n",
      "Epoch 1213/2500\n",
      "64/64 [==============================] - 0s 503us/step - loss: 1.3467 - val_loss: 1.6885\n",
      "Epoch 1214/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.3463 - val_loss: 1.6881\n",
      "Epoch 1215/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.3459 - val_loss: 1.6878\n",
      "Epoch 1216/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 1.3456 - val_loss: 1.6875\n",
      "Epoch 1217/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3452 - val_loss: 1.6871\n",
      "Epoch 1218/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 1.3448 - val_loss: 1.6868\n",
      "Epoch 1219/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3445 - val_loss: 1.6865\n",
      "Epoch 1220/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3441 - val_loss: 1.6861\n",
      "Epoch 1221/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 1.3437 - val_loss: 1.6858\n",
      "Epoch 1222/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3434 - val_loss: 1.6855\n",
      "Epoch 1223/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3430 - val_loss: 1.6851\n",
      "Epoch 1224/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3426 - val_loss: 1.6848\n",
      "Epoch 1225/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.3423 - val_loss: 1.6845\n",
      "Epoch 1226/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3419 - val_loss: 1.6841\n",
      "Epoch 1227/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3415 - val_loss: 1.6838\n",
      "Epoch 1228/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3412 - val_loss: 1.6835\n",
      "Epoch 1229/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.3408 - val_loss: 1.6832\n",
      "Epoch 1230/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.3404 - val_loss: 1.6828\n",
      "Epoch 1231/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3401 - val_loss: 1.6825\n",
      "Epoch 1232/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.3397 - val_loss: 1.6822\n",
      "Epoch 1233/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.3394 - val_loss: 1.6818\n",
      "Epoch 1234/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.3390 - val_loss: 1.6815\n",
      "Epoch 1235/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3386 - val_loss: 1.6812\n",
      "Epoch 1236/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3383 - val_loss: 1.6808\n",
      "Epoch 1237/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.3379 - val_loss: 1.6805\n",
      "Epoch 1238/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.3376 - val_loss: 1.6802\n",
      "Epoch 1239/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3372 - val_loss: 1.6799\n",
      "Epoch 1240/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3368 - val_loss: 1.6795\n",
      "Epoch 1241/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.3365 - val_loss: 1.6792\n",
      "Epoch 1242/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3361 - val_loss: 1.6789\n",
      "Epoch 1243/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.3358 - val_loss: 1.6786\n",
      "Epoch 1244/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.3354 - val_loss: 1.6782\n",
      "Epoch 1245/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3351 - val_loss: 1.6779\n",
      "Epoch 1246/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3347 - val_loss: 1.6776\n",
      "Epoch 1247/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.3344 - val_loss: 1.6772\n",
      "Epoch 1248/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.3340 - val_loss: 1.6769\n",
      "Epoch 1249/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.3336 - val_loss: 1.6766\n",
      "Epoch 1250/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3333 - val_loss: 1.6763\n",
      "Epoch 1251/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3329 - val_loss: 1.6759\n",
      "Epoch 1252/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.3326 - val_loss: 1.6756\n",
      "Epoch 1253/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.3322 - val_loss: 1.6753\n",
      "Epoch 1254/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3319 - val_loss: 1.6750\n",
      "Epoch 1255/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.3315 - val_loss: 1.6746\n",
      "Epoch 1256/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.3312 - val_loss: 1.6743\n",
      "Epoch 1257/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.3308 - val_loss: 1.6740\n",
      "Epoch 1258/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3305 - val_loss: 1.6737\n",
      "Epoch 1259/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3301 - val_loss: 1.6733\n",
      "Epoch 1260/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.3298 - val_loss: 1.6730\n",
      "Epoch 1261/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3294 - val_loss: 1.6727\n",
      "Epoch 1262/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.3291 - val_loss: 1.6724\n",
      "Epoch 1263/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.3287 - val_loss: 1.6720\n",
      "Epoch 1264/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3284 - val_loss: 1.6717\n",
      "Epoch 1265/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.3281 - val_loss: 1.6714\n",
      "Epoch 1266/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.3277 - val_loss: 1.6711\n",
      "Epoch 1267/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3274 - val_loss: 1.6708\n",
      "Epoch 1268/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 1.3270 - val_loss: 1.6704\n",
      "Epoch 1269/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.3267 - val_loss: 1.6701\n",
      "Epoch 1270/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3263 - val_loss: 1.6698\n",
      "Epoch 1271/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3260 - val_loss: 1.6695\n",
      "Epoch 1272/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.3256 - val_loss: 1.6691\n",
      "Epoch 1273/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3253 - val_loss: 1.6688\n",
      "Epoch 1274/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.3250 - val_loss: 1.6685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3246 - val_loss: 1.6682\n",
      "Epoch 1276/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3243 - val_loss: 1.6679\n",
      "Epoch 1277/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.3239 - val_loss: 1.6675\n",
      "Epoch 1278/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3236 - val_loss: 1.6672\n",
      "Epoch 1279/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3232 - val_loss: 1.6669\n",
      "Epoch 1280/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3229 - val_loss: 1.6666\n",
      "Epoch 1281/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3225 - val_loss: 1.6663\n",
      "Epoch 1282/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.3222 - val_loss: 1.6659\n",
      "Epoch 1283/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3219 - val_loss: 1.6656\n",
      "Epoch 1284/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3215 - val_loss: 1.6653\n",
      "Epoch 1285/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 1.3212 - val_loss: 1.6650\n",
      "Epoch 1286/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3209 - val_loss: 1.6647\n",
      "Epoch 1287/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3205 - val_loss: 1.6643\n",
      "Epoch 1288/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3202 - val_loss: 1.6640\n",
      "Epoch 1289/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3199 - val_loss: 1.6637\n",
      "Epoch 1290/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.3195 - val_loss: 1.6634\n",
      "Epoch 1291/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3191 - val_loss: 1.6631\n",
      "Epoch 1292/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3188 - val_loss: 1.6627\n",
      "Epoch 1293/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.3185 - val_loss: 1.6624\n",
      "Epoch 1294/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3182 - val_loss: 1.6621\n",
      "Epoch 1295/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3178 - val_loss: 1.6618\n",
      "Epoch 1296/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3175 - val_loss: 1.6615\n",
      "Epoch 1297/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3172 - val_loss: 1.6612\n",
      "Epoch 1298/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3168 - val_loss: 1.6608\n",
      "Epoch 1299/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3165 - val_loss: 1.6605\n",
      "Epoch 1300/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.3162 - val_loss: 1.6602\n",
      "Epoch 1301/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3158 - val_loss: 1.6599\n",
      "Epoch 1302/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3155 - val_loss: 1.6596\n",
      "Epoch 1303/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.3152 - val_loss: 1.6593\n",
      "Epoch 1304/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.3149 - val_loss: 1.6589\n",
      "Epoch 1305/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3145 - val_loss: 1.6586\n",
      "Epoch 1306/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.3142 - val_loss: 1.6583\n",
      "Epoch 1307/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.3139 - val_loss: 1.6580\n",
      "Epoch 1308/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.3135 - val_loss: 1.6577\n",
      "Epoch 1309/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3132 - val_loss: 1.6574\n",
      "Epoch 1310/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.3129 - val_loss: 1.6571\n",
      "Epoch 1311/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 1.3126 - val_loss: 1.6567\n",
      "Epoch 1312/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.3122 - val_loss: 1.6564\n",
      "Epoch 1313/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.3119 - val_loss: 1.6561\n",
      "Epoch 1314/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3116 - val_loss: 1.6558\n",
      "Epoch 1315/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3112 - val_loss: 1.6555\n",
      "Epoch 1316/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 1.3109 - val_loss: 1.6552\n",
      "Epoch 1317/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.3106 - val_loss: 1.6548\n",
      "Epoch 1318/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3103 - val_loss: 1.6545\n",
      "Epoch 1319/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.3099 - val_loss: 1.6542\n",
      "Epoch 1320/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 1.3096 - val_loss: 1.6539\n",
      "Epoch 1321/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3093 - val_loss: 1.6536\n",
      "Epoch 1322/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3090 - val_loss: 1.6533\n",
      "Epoch 1323/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.3086 - val_loss: 1.6530\n",
      "Epoch 1324/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.3083 - val_loss: 1.6527\n",
      "Epoch 1325/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3080 - val_loss: 1.6523\n",
      "Epoch 1326/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3077 - val_loss: 1.6520\n",
      "Epoch 1327/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 1.3074 - val_loss: 1.6517\n",
      "Epoch 1328/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3070 - val_loss: 1.6514\n",
      "Epoch 1329/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3067 - val_loss: 1.6511\n",
      "Epoch 1330/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3064 - val_loss: 1.6508\n",
      "Epoch 1331/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 1.3061 - val_loss: 1.6505\n",
      "Epoch 1332/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3058 - val_loss: 1.6502\n",
      "Epoch 1333/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3054 - val_loss: 1.6498\n",
      "Epoch 1334/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.3051 - val_loss: 1.6495\n",
      "Epoch 1335/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.3048 - val_loss: 1.6492\n",
      "Epoch 1336/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3045 - val_loss: 1.6489\n",
      "Epoch 1337/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3042 - val_loss: 1.6486\n",
      "Epoch 1338/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3038 - val_loss: 1.6483\n",
      "Epoch 1339/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.3035 - val_loss: 1.6480\n",
      "Epoch 1340/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3032 - val_loss: 1.6477\n",
      "Epoch 1341/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3029 - val_loss: 1.6474\n",
      "Epoch 1342/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3026 - val_loss: 1.6471\n",
      "Epoch 1343/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.3023 - val_loss: 1.6467\n",
      "Epoch 1344/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.3019 - val_loss: 1.6464\n",
      "Epoch 1345/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3016 - val_loss: 1.6461\n",
      "Epoch 1346/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3013 - val_loss: 1.6458\n",
      "Epoch 1347/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3010 - val_loss: 1.6455\n",
      "Epoch 1348/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.3007 - val_loss: 1.6452\n",
      "Epoch 1349/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3004 - val_loss: 1.6449\n",
      "Epoch 1350/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3001 - val_loss: 1.6446\n",
      "Epoch 1351/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2997 - val_loss: 1.6443\n",
      "Epoch 1352/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.2994 - val_loss: 1.6440\n",
      "Epoch 1353/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2991 - val_loss: 1.6437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1354/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2988 - val_loss: 1.6433\n",
      "Epoch 1355/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2985 - val_loss: 1.6430\n",
      "Epoch 1356/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2982 - val_loss: 1.6427\n",
      "Epoch 1357/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.2979 - val_loss: 1.6424\n",
      "Epoch 1358/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2976 - val_loss: 1.6421\n",
      "Epoch 1359/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2972 - val_loss: 1.6418\n",
      "Epoch 1360/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2969 - val_loss: 1.6415\n",
      "Epoch 1361/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 1.2966 - val_loss: 1.6412\n",
      "Epoch 1362/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2963 - val_loss: 1.6409\n",
      "Epoch 1363/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2960 - val_loss: 1.6406\n",
      "Epoch 1364/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2957 - val_loss: 1.6403\n",
      "Epoch 1365/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 1.2954 - val_loss: 1.6400\n",
      "Epoch 1366/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2951 - val_loss: 1.6397\n",
      "Epoch 1367/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2947 - val_loss: 1.6394\n",
      "Epoch 1368/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2945 - val_loss: 1.6390\n",
      "Epoch 1369/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2942 - val_loss: 1.6387\n",
      "Epoch 1370/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2939 - val_loss: 1.6384\n",
      "Epoch 1371/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2935 - val_loss: 1.6381\n",
      "Epoch 1372/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.2932 - val_loss: 1.6378\n",
      "Epoch 1373/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.2929 - val_loss: 1.6375\n",
      "Epoch 1374/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2926 - val_loss: 1.6372\n",
      "Epoch 1375/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 1.2923 - val_loss: 1.6369\n",
      "Epoch 1376/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2920 - val_loss: 1.6366\n",
      "Epoch 1377/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2917 - val_loss: 1.6363\n",
      "Epoch 1378/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2914 - val_loss: 1.6360\n",
      "Epoch 1379/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2911 - val_loss: 1.6357\n",
      "Epoch 1380/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2908 - val_loss: 1.6354\n",
      "Epoch 1381/2500\n",
      "64/64 [==============================] - 0s 379us/step - loss: 1.2905 - val_loss: 1.6351\n",
      "Epoch 1382/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2902 - val_loss: 1.6348\n",
      "Epoch 1383/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2899 - val_loss: 1.6345\n",
      "Epoch 1384/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.2896 - val_loss: 1.6342\n",
      "Epoch 1385/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2893 - val_loss: 1.6339\n",
      "Epoch 1386/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.2890 - val_loss: 1.6336\n",
      "Epoch 1387/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2887 - val_loss: 1.6333\n",
      "Epoch 1388/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2884 - val_loss: 1.6329\n",
      "Epoch 1389/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.2881 - val_loss: 1.6326\n",
      "Epoch 1390/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2878 - val_loss: 1.6323\n",
      "Epoch 1391/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2875 - val_loss: 1.6320\n",
      "Epoch 1392/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.2872 - val_loss: 1.6317\n",
      "Epoch 1393/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2869 - val_loss: 1.6314\n",
      "Epoch 1394/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.2866 - val_loss: 1.6311\n",
      "Epoch 1395/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2863 - val_loss: 1.6308\n",
      "Epoch 1396/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 1.2860 - val_loss: 1.6305\n",
      "Epoch 1397/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2856 - val_loss: 1.6302\n",
      "Epoch 1398/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2854 - val_loss: 1.6299\n",
      "Epoch 1399/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.2851 - val_loss: 1.6296\n",
      "Epoch 1400/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2848 - val_loss: 1.6293\n",
      "Epoch 1401/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2845 - val_loss: 1.6290\n",
      "Epoch 1402/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2842 - val_loss: 1.6287\n",
      "Epoch 1403/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2839 - val_loss: 1.6284\n",
      "Epoch 1404/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2836 - val_loss: 1.6281\n",
      "Epoch 1405/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.2833 - val_loss: 1.6278\n",
      "Epoch 1406/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2830 - val_loss: 1.6275\n",
      "Epoch 1407/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2827 - val_loss: 1.6272\n",
      "Epoch 1408/2500\n",
      "64/64 [==============================] - 0s 369us/step - loss: 1.2824 - val_loss: 1.6269\n",
      "Epoch 1409/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.2822 - val_loss: 1.6266\n",
      "Epoch 1410/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2819 - val_loss: 1.6263\n",
      "Epoch 1411/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.2816 - val_loss: 1.6260\n",
      "Epoch 1412/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2813 - val_loss: 1.6257\n",
      "Epoch 1413/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.2810 - val_loss: 1.6254\n",
      "Epoch 1414/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.2807 - val_loss: 1.6251\n",
      "Epoch 1415/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2804 - val_loss: 1.6248\n",
      "Epoch 1416/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.2801 - val_loss: 1.6245\n",
      "Epoch 1417/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.2798 - val_loss: 1.6242\n",
      "Epoch 1418/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2795 - val_loss: 1.6239\n",
      "Epoch 1419/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2792 - val_loss: 1.6236\n",
      "Epoch 1420/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2789 - val_loss: 1.6233\n",
      "Epoch 1421/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2787 - val_loss: 1.6230\n",
      "Epoch 1422/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2784 - val_loss: 1.6227\n",
      "Epoch 1423/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.2781 - val_loss: 1.6224\n",
      "Epoch 1424/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2778 - val_loss: 1.6221\n",
      "Epoch 1425/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2775 - val_loss: 1.6218\n",
      "Epoch 1426/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2772 - val_loss: 1.6215\n",
      "Epoch 1427/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2769 - val_loss: 1.6212\n",
      "Epoch 1428/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2766 - val_loss: 1.6209\n",
      "Epoch 1429/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2763 - val_loss: 1.6206\n",
      "Epoch 1430/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2761 - val_loss: 1.6203\n",
      "Epoch 1431/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.2758 - val_loss: 1.6200\n",
      "Epoch 1432/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2755 - val_loss: 1.6197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1433/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2752 - val_loss: 1.6194\n",
      "Epoch 1434/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.2749 - val_loss: 1.6191\n",
      "Epoch 1435/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2746 - val_loss: 1.6188\n",
      "Epoch 1436/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2743 - val_loss: 1.6185\n",
      "Epoch 1437/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2740 - val_loss: 1.6182\n",
      "Epoch 1438/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.2738 - val_loss: 1.6179\n",
      "Epoch 1439/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2735 - val_loss: 1.6176\n",
      "Epoch 1440/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.2732 - val_loss: 1.6173\n",
      "Epoch 1441/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2729 - val_loss: 1.6170\n",
      "Epoch 1442/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2726 - val_loss: 1.6167\n",
      "Epoch 1443/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2723 - val_loss: 1.6164\n",
      "Epoch 1444/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.2721 - val_loss: 1.6161\n",
      "Epoch 1445/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.2718 - val_loss: 1.6158\n",
      "Epoch 1446/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2715 - val_loss: 1.6156\n",
      "Epoch 1447/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2712 - val_loss: 1.6153\n",
      "Epoch 1448/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2709 - val_loss: 1.6150\n",
      "Epoch 1449/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2706 - val_loss: 1.6147\n",
      "Epoch 1450/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2704 - val_loss: 1.6144\n",
      "Epoch 1451/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2701 - val_loss: 1.6141\n",
      "Epoch 1452/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2698 - val_loss: 1.6138\n",
      "Epoch 1453/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2695 - val_loss: 1.6135\n",
      "Epoch 1454/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.2692 - val_loss: 1.6132\n",
      "Epoch 1455/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2690 - val_loss: 1.6129\n",
      "Epoch 1456/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2687 - val_loss: 1.6126\n",
      "Epoch 1457/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2684 - val_loss: 1.6123\n",
      "Epoch 1458/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2681 - val_loss: 1.6120\n",
      "Epoch 1459/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.2678 - val_loss: 1.6117\n",
      "Epoch 1460/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2676 - val_loss: 1.6114\n",
      "Epoch 1461/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2673 - val_loss: 1.6111\n",
      "Epoch 1462/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.2670 - val_loss: 1.6108\n",
      "Epoch 1463/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2667 - val_loss: 1.6105\n",
      "Epoch 1464/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2665 - val_loss: 1.6102\n",
      "Epoch 1465/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2662 - val_loss: 1.6099\n",
      "Epoch 1466/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.2659 - val_loss: 1.6096\n",
      "Epoch 1467/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2656 - val_loss: 1.6093\n",
      "Epoch 1468/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2653 - val_loss: 1.6090\n",
      "Epoch 1469/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.2651 - val_loss: 1.6088\n",
      "Epoch 1470/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2648 - val_loss: 1.6085\n",
      "Epoch 1471/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2645 - val_loss: 1.6082\n",
      "Epoch 1472/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.2642 - val_loss: 1.6079\n",
      "Epoch 1473/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2640 - val_loss: 1.6076\n",
      "Epoch 1474/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2637 - val_loss: 1.6073\n",
      "Epoch 1475/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 1.2634 - val_loss: 1.6070\n",
      "Epoch 1476/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2631 - val_loss: 1.6067\n",
      "Epoch 1477/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.2629 - val_loss: 1.6064\n",
      "Epoch 1478/2500\n",
      "64/64 [==============================] - 0s 305us/step - loss: 1.2626 - val_loss: 1.6061\n",
      "Epoch 1479/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2623 - val_loss: 1.6058\n",
      "Epoch 1480/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2620 - val_loss: 1.6055\n",
      "Epoch 1481/2500\n",
      "64/64 [==============================] - 0s 343us/step - loss: 1.2618 - val_loss: 1.6052\n",
      "Epoch 1482/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2615 - val_loss: 1.6049\n",
      "Epoch 1483/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2612 - val_loss: 1.6046\n",
      "Epoch 1484/2500\n",
      "64/64 [==============================] - 0s 329us/step - loss: 1.2610 - val_loss: 1.6044\n",
      "Epoch 1485/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2607 - val_loss: 1.6041\n",
      "Epoch 1486/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2604 - val_loss: 1.6038\n",
      "Epoch 1487/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.2601 - val_loss: 1.6035\n",
      "Epoch 1488/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2599 - val_loss: 1.6032\n",
      "Epoch 1489/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2596 - val_loss: 1.6029\n",
      "Epoch 1490/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2593 - val_loss: 1.6026\n",
      "Epoch 1491/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.2591 - val_loss: 1.6023\n",
      "Epoch 1492/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.2588 - val_loss: 1.6020\n",
      "Epoch 1493/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.2585 - val_loss: 1.6017\n",
      "Epoch 1494/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2583 - val_loss: 1.6014\n",
      "Epoch 1495/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2580 - val_loss: 1.6011\n",
      "Epoch 1496/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2577 - val_loss: 1.6008\n",
      "Epoch 1497/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2574 - val_loss: 1.6006\n",
      "Epoch 1498/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2572 - val_loss: 1.6003\n",
      "Epoch 1499/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 1.2569 - val_loss: 1.6000\n",
      "Epoch 1500/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2566 - val_loss: 1.5997\n",
      "Epoch 1501/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2564 - val_loss: 1.5994\n",
      "Epoch 1502/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2561 - val_loss: 1.5991\n",
      "Epoch 1503/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2558 - val_loss: 1.5988\n",
      "Epoch 1504/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2556 - val_loss: 1.5985\n",
      "Epoch 1505/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2553 - val_loss: 1.5982\n",
      "Epoch 1506/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.2550 - val_loss: 1.5979\n",
      "Epoch 1507/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2547 - val_loss: 1.5976\n",
      "Epoch 1508/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.2545 - val_loss: 1.5974\n",
      "Epoch 1509/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2542 - val_loss: 1.5971\n",
      "Epoch 1510/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.2540 - val_loss: 1.5968\n",
      "Epoch 1511/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2537 - val_loss: 1.5965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1512/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2534 - val_loss: 1.5962\n",
      "Epoch 1513/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.2532 - val_loss: 1.5959\n",
      "Epoch 1514/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2529 - val_loss: 1.5956\n",
      "Epoch 1515/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2527 - val_loss: 1.5953\n",
      "Epoch 1516/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2524 - val_loss: 1.5950\n",
      "Epoch 1517/2500\n",
      "64/64 [==============================] - 0s 314us/step - loss: 1.2521 - val_loss: 1.5947\n",
      "Epoch 1518/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2519 - val_loss: 1.5944\n",
      "Epoch 1519/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2516 - val_loss: 1.5942\n",
      "Epoch 1520/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.2513 - val_loss: 1.5939\n",
      "Epoch 1521/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2511 - val_loss: 1.5936\n",
      "Epoch 1522/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2508 - val_loss: 1.5933\n",
      "Epoch 1523/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2506 - val_loss: 1.5930\n",
      "Epoch 1524/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2503 - val_loss: 1.5927\n",
      "Epoch 1525/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2500 - val_loss: 1.5924\n",
      "Epoch 1526/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2498 - val_loss: 1.5921\n",
      "Epoch 1527/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2495 - val_loss: 1.5918\n",
      "Epoch 1528/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2492 - val_loss: 1.5916\n",
      "Epoch 1529/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2490 - val_loss: 1.5913\n",
      "Epoch 1530/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 1.2487 - val_loss: 1.5910\n",
      "Epoch 1531/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2485 - val_loss: 1.5907\n",
      "Epoch 1532/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 1.2482 - val_loss: 1.5904\n",
      "Epoch 1533/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2479 - val_loss: 1.5901\n",
      "Epoch 1534/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2477 - val_loss: 1.5898\n",
      "Epoch 1535/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 1.2474 - val_loss: 1.5895\n",
      "Epoch 1536/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2472 - val_loss: 1.5892\n",
      "Epoch 1537/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2469 - val_loss: 1.5890\n",
      "Epoch 1538/2500\n",
      "64/64 [==============================] - 0s 321us/step - loss: 1.2466 - val_loss: 1.5887\n",
      "Epoch 1539/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2464 - val_loss: 1.5884\n",
      "Epoch 1540/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.2461 - val_loss: 1.5881\n",
      "Epoch 1541/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2459 - val_loss: 1.5878\n",
      "Epoch 1542/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2456 - val_loss: 1.5875\n",
      "Epoch 1543/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2454 - val_loss: 1.5872\n",
      "Epoch 1544/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.2451 - val_loss: 1.5869\n",
      "Epoch 1545/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2448 - val_loss: 1.5867\n",
      "Epoch 1546/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.2446 - val_loss: 1.5864\n",
      "Epoch 1547/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2443 - val_loss: 1.5861\n",
      "Epoch 1548/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2441 - val_loss: 1.5858\n",
      "Epoch 1549/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2438 - val_loss: 1.5855\n",
      "Epoch 1550/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 1.2436 - val_loss: 1.5852\n",
      "Epoch 1551/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2433 - val_loss: 1.5849\n",
      "Epoch 1552/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2430 - val_loss: 1.5847\n",
      "Epoch 1553/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.2428 - val_loss: 1.5844\n",
      "Epoch 1554/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2425 - val_loss: 1.5841\n",
      "Epoch 1555/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.2423 - val_loss: 1.5838\n",
      "Epoch 1556/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2420 - val_loss: 1.5835\n",
      "Epoch 1557/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 1.2418 - val_loss: 1.5832\n",
      "Epoch 1558/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2415 - val_loss: 1.5829\n",
      "Epoch 1559/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2413 - val_loss: 1.5826\n",
      "Epoch 1560/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2410 - val_loss: 1.5824\n",
      "Epoch 1561/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2408 - val_loss: 1.5821\n",
      "Epoch 1562/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2405 - val_loss: 1.5818\n",
      "Epoch 1563/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2403 - val_loss: 1.5815\n",
      "Epoch 1564/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2400 - val_loss: 1.5812\n",
      "Epoch 1565/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2398 - val_loss: 1.5809\n",
      "Epoch 1566/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2395 - val_loss: 1.5806\n",
      "Epoch 1567/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2393 - val_loss: 1.5804\n",
      "Epoch 1568/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2390 - val_loss: 1.5801\n",
      "Epoch 1569/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2388 - val_loss: 1.5798\n",
      "Epoch 1570/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2385 - val_loss: 1.5795\n",
      "Epoch 1571/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2383 - val_loss: 1.5792\n",
      "Epoch 1572/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2380 - val_loss: 1.5789\n",
      "Epoch 1573/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2378 - val_loss: 1.5786\n",
      "Epoch 1574/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2375 - val_loss: 1.5784\n",
      "Epoch 1575/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.2373 - val_loss: 1.5781\n",
      "Epoch 1576/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2370 - val_loss: 1.5778\n",
      "Epoch 1577/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2367 - val_loss: 1.5775\n",
      "Epoch 1578/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2365 - val_loss: 1.5772\n",
      "Epoch 1579/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2363 - val_loss: 1.5769\n",
      "Epoch 1580/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2360 - val_loss: 1.5766\n",
      "Epoch 1581/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2358 - val_loss: 1.5764\n",
      "Epoch 1582/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2355 - val_loss: 1.5761\n",
      "Epoch 1583/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2353 - val_loss: 1.5758\n",
      "Epoch 1584/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.2350 - val_loss: 1.5755\n",
      "Epoch 1585/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2348 - val_loss: 1.5752\n",
      "Epoch 1586/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2345 - val_loss: 1.5749\n",
      "Epoch 1587/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2343 - val_loss: 1.5746\n",
      "Epoch 1588/2500\n",
      "64/64 [==============================] - 0s 353us/step - loss: 1.2340 - val_loss: 1.5744\n",
      "Epoch 1589/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.2338 - val_loss: 1.5741\n",
      "Epoch 1590/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2335 - val_loss: 1.5738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1591/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 1.2333 - val_loss: 1.5735\n",
      "Epoch 1592/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.2330 - val_loss: 1.5732\n",
      "Epoch 1593/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 1.2328 - val_loss: 1.5729\n",
      "Epoch 1594/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2326 - val_loss: 1.5727\n",
      "Epoch 1595/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 1.2323 - val_loss: 1.5724\n",
      "Epoch 1596/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.2321 - val_loss: 1.5721\n",
      "Epoch 1597/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 1.2318 - val_loss: 1.5718\n",
      "Epoch 1598/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2316 - val_loss: 1.5715\n",
      "Epoch 1599/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2313 - val_loss: 1.5712\n",
      "Epoch 1600/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.2311 - val_loss: 1.5710\n",
      "Epoch 1601/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2308 - val_loss: 1.5707\n",
      "Epoch 1602/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 1.2306 - val_loss: 1.5704\n",
      "Epoch 1603/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2304 - val_loss: 1.5701\n",
      "Epoch 1604/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2301 - val_loss: 1.5698\n",
      "Epoch 1605/2500\n",
      "64/64 [==============================] - 0s 320us/step - loss: 1.2299 - val_loss: 1.5695\n",
      "Epoch 1606/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2296 - val_loss: 1.5693\n",
      "Epoch 1607/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2294 - val_loss: 1.5690\n",
      "Epoch 1608/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.2291 - val_loss: 1.5687\n",
      "Epoch 1609/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.2289 - val_loss: 1.5684\n",
      "Epoch 1610/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2287 - val_loss: 1.5681\n",
      "Epoch 1611/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2284 - val_loss: 1.5678\n",
      "Epoch 1612/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2282 - val_loss: 1.5676\n",
      "Epoch 1613/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2279 - val_loss: 1.5673\n",
      "Epoch 1614/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2277 - val_loss: 1.5670\n",
      "Epoch 1615/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2275 - val_loss: 1.5667\n",
      "Epoch 1616/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2272 - val_loss: 1.5664\n",
      "Epoch 1617/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2270 - val_loss: 1.5661\n",
      "Epoch 1618/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2267 - val_loss: 1.5659\n",
      "Epoch 1619/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2265 - val_loss: 1.5656\n",
      "Epoch 1620/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.2263 - val_loss: 1.5653\n",
      "Epoch 1621/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2260 - val_loss: 1.5650\n",
      "Epoch 1622/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2258 - val_loss: 1.5647\n",
      "Epoch 1623/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2255 - val_loss: 1.5644\n",
      "Epoch 1624/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2253 - val_loss: 1.5642\n",
      "Epoch 1625/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.2251 - val_loss: 1.5639\n",
      "Epoch 1626/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2248 - val_loss: 1.5636\n",
      "Epoch 1627/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2246 - val_loss: 1.5633\n",
      "Epoch 1628/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2243 - val_loss: 1.5630\n",
      "Epoch 1629/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2241 - val_loss: 1.5627\n",
      "Epoch 1630/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.2238 - val_loss: 1.5625\n",
      "Epoch 1631/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2236 - val_loss: 1.5622\n",
      "Epoch 1632/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2234 - val_loss: 1.5619\n",
      "Epoch 1633/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2232 - val_loss: 1.5616\n",
      "Epoch 1634/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2229 - val_loss: 1.5613\n",
      "Epoch 1635/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2227 - val_loss: 1.5611\n",
      "Epoch 1636/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2224 - val_loss: 1.5608\n",
      "Epoch 1637/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2222 - val_loss: 1.5605\n",
      "Epoch 1638/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2220 - val_loss: 1.5602\n",
      "Epoch 1639/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.2217 - val_loss: 1.5599\n",
      "Epoch 1640/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2215 - val_loss: 1.5596\n",
      "Epoch 1641/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2213 - val_loss: 1.5594\n",
      "Epoch 1642/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2210 - val_loss: 1.5591\n",
      "Epoch 1643/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.2208 - val_loss: 1.5588\n",
      "Epoch 1644/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2206 - val_loss: 1.5585\n",
      "Epoch 1645/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2203 - val_loss: 1.5582\n",
      "Epoch 1646/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2201 - val_loss: 1.5580\n",
      "Epoch 1647/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.2198 - val_loss: 1.5577\n",
      "Epoch 1648/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2196 - val_loss: 1.5574\n",
      "Epoch 1649/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2194 - val_loss: 1.5571\n",
      "Epoch 1650/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2192 - val_loss: 1.5568\n",
      "Epoch 1651/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2189 - val_loss: 1.5565\n",
      "Epoch 1652/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2187 - val_loss: 1.5563\n",
      "Epoch 1653/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2184 - val_loss: 1.5560\n",
      "Epoch 1654/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2182 - val_loss: 1.5557\n",
      "Epoch 1655/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2180 - val_loss: 1.5554\n",
      "Epoch 1656/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2178 - val_loss: 1.5551\n",
      "Epoch 1657/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2175 - val_loss: 1.5549\n",
      "Epoch 1658/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.2173 - val_loss: 1.5546\n",
      "Epoch 1659/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2171 - val_loss: 1.5543\n",
      "Epoch 1660/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2168 - val_loss: 1.5540\n",
      "Epoch 1661/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2166 - val_loss: 1.5537\n",
      "Epoch 1662/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.2164 - val_loss: 1.5535\n",
      "Epoch 1663/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2161 - val_loss: 1.5532\n",
      "Epoch 1664/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.2159 - val_loss: 1.5529\n",
      "Epoch 1665/2500\n",
      "64/64 [==============================] - 0s 298us/step - loss: 1.2157 - val_loss: 1.5526\n",
      "Epoch 1666/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.2154 - val_loss: 1.5523\n",
      "Epoch 1667/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.2152 - val_loss: 1.5521\n",
      "Epoch 1668/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.2150 - val_loss: 1.5518\n",
      "Epoch 1669/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2148 - val_loss: 1.5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1670/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.2145 - val_loss: 1.5512\n",
      "Epoch 1671/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2143 - val_loss: 1.5509\n",
      "Epoch 1672/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2141 - val_loss: 1.5507\n",
      "Epoch 1673/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 1.2138 - val_loss: 1.5504\n",
      "Epoch 1674/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2136 - val_loss: 1.5501\n",
      "Epoch 1675/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.2134 - val_loss: 1.5498\n",
      "Epoch 1676/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 1.2132 - val_loss: 1.5495\n",
      "Epoch 1677/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2129 - val_loss: 1.5493\n",
      "Epoch 1678/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2127 - val_loss: 1.5490\n",
      "Epoch 1679/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2125 - val_loss: 1.5487\n",
      "Epoch 1680/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.2122 - val_loss: 1.5484\n",
      "Epoch 1681/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2120 - val_loss: 1.5481\n",
      "Epoch 1682/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2118 - val_loss: 1.5479\n",
      "Epoch 1683/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.2116 - val_loss: 1.5476\n",
      "Epoch 1684/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2113 - val_loss: 1.5473\n",
      "Epoch 1685/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2111 - val_loss: 1.5470\n",
      "Epoch 1686/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2109 - val_loss: 1.5467\n",
      "Epoch 1687/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 1.2107 - val_loss: 1.5465\n",
      "Epoch 1688/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2104 - val_loss: 1.5462\n",
      "Epoch 1689/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2102 - val_loss: 1.5459\n",
      "Epoch 1690/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2100 - val_loss: 1.5456\n",
      "Epoch 1691/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2097 - val_loss: 1.5454\n",
      "Epoch 1692/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.2095 - val_loss: 1.5451\n",
      "Epoch 1693/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2093 - val_loss: 1.5448\n",
      "Epoch 1694/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2091 - val_loss: 1.5445\n",
      "Epoch 1695/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2088 - val_loss: 1.5442\n",
      "Epoch 1696/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2086 - val_loss: 1.5440\n",
      "Epoch 1697/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2084 - val_loss: 1.5437\n",
      "Epoch 1698/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.2082 - val_loss: 1.5434\n",
      "Epoch 1699/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2079 - val_loss: 1.5431\n",
      "Epoch 1700/2500\n",
      "64/64 [==============================] - 0s 277us/step - loss: 1.2077 - val_loss: 1.5428\n",
      "Epoch 1701/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2075 - val_loss: 1.5426\n",
      "Epoch 1702/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2073 - val_loss: 1.5423\n",
      "Epoch 1703/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.2071 - val_loss: 1.5420\n",
      "Epoch 1704/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2068 - val_loss: 1.5417\n",
      "Epoch 1705/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2066 - val_loss: 1.5414\n",
      "Epoch 1706/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2064 - val_loss: 1.5412\n",
      "Epoch 1707/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2062 - val_loss: 1.5409\n",
      "Epoch 1708/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2059 - val_loss: 1.5406\n",
      "Epoch 1709/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2057 - val_loss: 1.5403\n",
      "Epoch 1710/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2055 - val_loss: 1.5401\n",
      "Epoch 1711/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2053 - val_loss: 1.5398\n",
      "Epoch 1712/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2051 - val_loss: 1.5395\n",
      "Epoch 1713/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2048 - val_loss: 1.5392\n",
      "Epoch 1714/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2046 - val_loss: 1.5389\n",
      "Epoch 1715/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.2043 - val_loss: 1.5387\n",
      "Epoch 1716/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.2042 - val_loss: 1.5384\n",
      "Epoch 1717/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2039 - val_loss: 1.5381\n",
      "Epoch 1718/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.2037 - val_loss: 1.5378\n",
      "Epoch 1719/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2035 - val_loss: 1.5375\n",
      "Epoch 1720/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.2033 - val_loss: 1.5373\n",
      "Epoch 1721/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 1.2031 - val_loss: 1.5370\n",
      "Epoch 1722/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.2028 - val_loss: 1.5367\n",
      "Epoch 1723/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2026 - val_loss: 1.5364\n",
      "Epoch 1724/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.2024 - val_loss: 1.5361\n",
      "Epoch 1725/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2022 - val_loss: 1.5359\n",
      "Epoch 1726/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2020 - val_loss: 1.5356\n",
      "Epoch 1727/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2017 - val_loss: 1.5353\n",
      "Epoch 1728/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2015 - val_loss: 1.5350\n",
      "Epoch 1729/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2013 - val_loss: 1.5348\n",
      "Epoch 1730/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2011 - val_loss: 1.5345\n",
      "Epoch 1731/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2009 - val_loss: 1.5342\n",
      "Epoch 1732/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2007 - val_loss: 1.5339\n",
      "Epoch 1733/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2004 - val_loss: 1.5337\n",
      "Epoch 1734/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.2002 - val_loss: 1.5334\n",
      "Epoch 1735/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2000 - val_loss: 1.5331\n",
      "Epoch 1736/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1998 - val_loss: 1.5328\n",
      "Epoch 1737/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1996 - val_loss: 1.5325\n",
      "Epoch 1738/2500\n",
      "64/64 [==============================] - 0s 339us/step - loss: 1.1993 - val_loss: 1.5323\n",
      "Epoch 1739/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1991 - val_loss: 1.5320\n",
      "Epoch 1740/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1989 - val_loss: 1.5317\n",
      "Epoch 1741/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1987 - val_loss: 1.5314\n",
      "Epoch 1742/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1985 - val_loss: 1.5312\n",
      "Epoch 1743/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1983 - val_loss: 1.5309\n",
      "Epoch 1744/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1980 - val_loss: 1.5306\n",
      "Epoch 1745/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1978 - val_loss: 1.5303\n",
      "Epoch 1746/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.1976 - val_loss: 1.5300\n",
      "Epoch 1747/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1974 - val_loss: 1.5298\n",
      "Epoch 1748/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1972 - val_loss: 1.5295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1749/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.1969 - val_loss: 1.5292\n",
      "Epoch 1750/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1968 - val_loss: 1.5289\n",
      "Epoch 1751/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1965 - val_loss: 1.5287\n",
      "Epoch 1752/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1963 - val_loss: 1.5284\n",
      "Epoch 1753/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1961 - val_loss: 1.5281\n",
      "Epoch 1754/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1959 - val_loss: 1.5278\n",
      "Epoch 1755/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1957 - val_loss: 1.5275\n",
      "Epoch 1756/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1955 - val_loss: 1.5273\n",
      "Epoch 1757/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1953 - val_loss: 1.5270\n",
      "Epoch 1758/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1950 - val_loss: 1.5267\n",
      "Epoch 1759/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.1948 - val_loss: 1.5264\n",
      "Epoch 1760/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1946 - val_loss: 1.5262\n",
      "Epoch 1761/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1944 - val_loss: 1.5259\n",
      "Epoch 1762/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1942 - val_loss: 1.5256\n",
      "Epoch 1763/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1940 - val_loss: 1.5253\n",
      "Epoch 1764/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1938 - val_loss: 1.5251\n",
      "Epoch 1765/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1935 - val_loss: 1.5248\n",
      "Epoch 1766/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1933 - val_loss: 1.5245\n",
      "Epoch 1767/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1931 - val_loss: 1.5242\n",
      "Epoch 1768/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1929 - val_loss: 1.5240\n",
      "Epoch 1769/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1927 - val_loss: 1.5237\n",
      "Epoch 1770/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1925 - val_loss: 1.5234\n",
      "Epoch 1771/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1923 - val_loss: 1.5231\n",
      "Epoch 1772/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 1.1921 - val_loss: 1.5228\n",
      "Epoch 1773/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1919 - val_loss: 1.5226\n",
      "Epoch 1774/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1916 - val_loss: 1.5223\n",
      "Epoch 1775/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1914 - val_loss: 1.5220\n",
      "Epoch 1776/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 1.1912 - val_loss: 1.5217\n",
      "Epoch 1777/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1910 - val_loss: 1.5215\n",
      "Epoch 1778/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1908 - val_loss: 1.5212\n",
      "Epoch 1779/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1906 - val_loss: 1.5209\n",
      "Epoch 1780/2500\n",
      "64/64 [==============================] - 0s 379us/step - loss: 1.1904 - val_loss: 1.5206\n",
      "Epoch 1781/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1902 - val_loss: 1.5204\n",
      "Epoch 1782/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1900 - val_loss: 1.5201\n",
      "Epoch 1783/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.1898 - val_loss: 1.5198\n",
      "Epoch 1784/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1895 - val_loss: 1.5195\n",
      "Epoch 1785/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1893 - val_loss: 1.5192\n",
      "Epoch 1786/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.1891 - val_loss: 1.5190\n",
      "Epoch 1787/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1889 - val_loss: 1.5187\n",
      "Epoch 1788/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1887 - val_loss: 1.5184\n",
      "Epoch 1789/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1885 - val_loss: 1.5181\n",
      "Epoch 1790/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1883 - val_loss: 1.5179\n",
      "Epoch 1791/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1881 - val_loss: 1.5176\n",
      "Epoch 1792/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1879 - val_loss: 1.5173\n",
      "Epoch 1793/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1877 - val_loss: 1.5170\n",
      "Epoch 1794/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1875 - val_loss: 1.5168\n",
      "Epoch 1795/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1872 - val_loss: 1.5165\n",
      "Epoch 1796/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1870 - val_loss: 1.5162\n",
      "Epoch 1797/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1868 - val_loss: 1.5159\n",
      "Epoch 1798/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1866 - val_loss: 1.5157\n",
      "Epoch 1799/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1864 - val_loss: 1.5154\n",
      "Epoch 1800/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1862 - val_loss: 1.5151\n",
      "Epoch 1801/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1860 - val_loss: 1.5148\n",
      "Epoch 1802/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1858 - val_loss: 1.5145\n",
      "Epoch 1803/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1856 - val_loss: 1.5143\n",
      "Epoch 1804/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1854 - val_loss: 1.5140\n",
      "Epoch 1805/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1852 - val_loss: 1.5137\n",
      "Epoch 1806/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1850 - val_loss: 1.5134\n",
      "Epoch 1807/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1848 - val_loss: 1.5132\n",
      "Epoch 1808/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 1.1846 - val_loss: 1.5129\n",
      "Epoch 1809/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1844 - val_loss: 1.5126\n",
      "Epoch 1810/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1842 - val_loss: 1.5123\n",
      "Epoch 1811/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.1839 - val_loss: 1.5121\n",
      "Epoch 1812/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1837 - val_loss: 1.5118\n",
      "Epoch 1813/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1835 - val_loss: 1.5115\n",
      "Epoch 1814/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1833 - val_loss: 1.5112\n",
      "Epoch 1815/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1831 - val_loss: 1.5110\n",
      "Epoch 1816/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1829 - val_loss: 1.5107\n",
      "Epoch 1817/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1827 - val_loss: 1.5104\n",
      "Epoch 1818/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1825 - val_loss: 1.5101\n",
      "Epoch 1819/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.1823 - val_loss: 1.5099\n",
      "Epoch 1820/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1821 - val_loss: 1.5096\n",
      "Epoch 1821/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1819 - val_loss: 1.5093\n",
      "Epoch 1822/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1817 - val_loss: 1.5090\n",
      "Epoch 1823/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1815 - val_loss: 1.5088\n",
      "Epoch 1824/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1813 - val_loss: 1.5085\n",
      "Epoch 1825/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1811 - val_loss: 1.5082\n",
      "Epoch 1826/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1809 - val_loss: 1.5079\n",
      "Epoch 1827/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1807 - val_loss: 1.5077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1828/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1805 - val_loss: 1.5074\n",
      "Epoch 1829/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1803 - val_loss: 1.5071\n",
      "Epoch 1830/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1801 - val_loss: 1.5068\n",
      "Epoch 1831/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1799 - val_loss: 1.5066\n",
      "Epoch 1832/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1797 - val_loss: 1.5063\n",
      "Epoch 1833/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1795 - val_loss: 1.5060\n",
      "Epoch 1834/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1793 - val_loss: 1.5057\n",
      "Epoch 1835/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1791 - val_loss: 1.5055\n",
      "Epoch 1836/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1789 - val_loss: 1.5052\n",
      "Epoch 1837/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.1787 - val_loss: 1.5049\n",
      "Epoch 1838/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1785 - val_loss: 1.5046\n",
      "Epoch 1839/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1783 - val_loss: 1.5044\n",
      "Epoch 1840/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1781 - val_loss: 1.5041\n",
      "Epoch 1841/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1779 - val_loss: 1.5038\n",
      "Epoch 1842/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1777 - val_loss: 1.5035\n",
      "Epoch 1843/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1775 - val_loss: 1.5033\n",
      "Epoch 1844/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1773 - val_loss: 1.5030\n",
      "Epoch 1845/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.1771 - val_loss: 1.5027\n",
      "Epoch 1846/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1769 - val_loss: 1.5024\n",
      "Epoch 1847/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1767 - val_loss: 1.5022\n",
      "Epoch 1848/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1765 - val_loss: 1.5019\n",
      "Epoch 1849/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1763 - val_loss: 1.5016\n",
      "Epoch 1850/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1761 - val_loss: 1.5013\n",
      "Epoch 1851/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1759 - val_loss: 1.5011\n",
      "Epoch 1852/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1757 - val_loss: 1.5008\n",
      "Epoch 1853/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.1755 - val_loss: 1.5005\n",
      "Epoch 1854/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1753 - val_loss: 1.5002\n",
      "Epoch 1855/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1751 - val_loss: 1.5000\n",
      "Epoch 1856/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1749 - val_loss: 1.4997\n",
      "Epoch 1857/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 1.1747 - val_loss: 1.4994\n",
      "Epoch 1858/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1745 - val_loss: 1.4991\n",
      "Epoch 1859/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.1743 - val_loss: 1.4989\n",
      "Epoch 1860/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1741 - val_loss: 1.4986\n",
      "Epoch 1861/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1739 - val_loss: 1.4983\n",
      "Epoch 1862/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1737 - val_loss: 1.4980\n",
      "Epoch 1863/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.1735 - val_loss: 1.4978\n",
      "Epoch 1864/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1733 - val_loss: 1.4975\n",
      "Epoch 1865/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1731 - val_loss: 1.4972\n",
      "Epoch 1866/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1729 - val_loss: 1.4969\n",
      "Epoch 1867/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1727 - val_loss: 1.4967\n",
      "Epoch 1868/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.1725 - val_loss: 1.4964\n",
      "Epoch 1869/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1723 - val_loss: 1.4961\n",
      "Epoch 1870/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.1721 - val_loss: 1.4959\n",
      "Epoch 1871/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1719 - val_loss: 1.4956\n",
      "Epoch 1872/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1717 - val_loss: 1.4953\n",
      "Epoch 1873/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1715 - val_loss: 1.4950\n",
      "Epoch 1874/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.1713 - val_loss: 1.4948\n",
      "Epoch 1875/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1711 - val_loss: 1.4945\n",
      "Epoch 1876/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1710 - val_loss: 1.4942\n",
      "Epoch 1877/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1708 - val_loss: 1.4939\n",
      "Epoch 1878/2500\n",
      "64/64 [==============================] - 0s 430us/step - loss: 1.1706 - val_loss: 1.4937\n",
      "Epoch 1879/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1704 - val_loss: 1.4934\n",
      "Epoch 1880/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1702 - val_loss: 1.4931\n",
      "Epoch 1881/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1700 - val_loss: 1.4928\n",
      "Epoch 1882/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1698 - val_loss: 1.4926\n",
      "Epoch 1883/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1696 - val_loss: 1.4923\n",
      "Epoch 1884/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1694 - val_loss: 1.4920\n",
      "Epoch 1885/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1692 - val_loss: 1.4918\n",
      "Epoch 1886/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1690 - val_loss: 1.4915\n",
      "Epoch 1887/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1688 - val_loss: 1.4912\n",
      "Epoch 1888/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.1686 - val_loss: 1.4909\n",
      "Epoch 1889/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1684 - val_loss: 1.4907\n",
      "Epoch 1890/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1682 - val_loss: 1.4904\n",
      "Epoch 1891/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1680 - val_loss: 1.4901\n",
      "Epoch 1892/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1679 - val_loss: 1.4898\n",
      "Epoch 1893/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.1677 - val_loss: 1.4896\n",
      "Epoch 1894/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1675 - val_loss: 1.4893\n",
      "Epoch 1895/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1673 - val_loss: 1.4890\n",
      "Epoch 1896/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1671 - val_loss: 1.4887\n",
      "Epoch 1897/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1669 - val_loss: 1.4885\n",
      "Epoch 1898/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.1667 - val_loss: 1.4882\n",
      "Epoch 1899/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1665 - val_loss: 1.4879\n",
      "Epoch 1900/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1663 - val_loss: 1.4876\n",
      "Epoch 1901/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1661 - val_loss: 1.4874\n",
      "Epoch 1902/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 1.1659 - val_loss: 1.4871\n",
      "Epoch 1903/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1657 - val_loss: 1.4868\n",
      "Epoch 1904/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1656 - val_loss: 1.4866\n",
      "Epoch 1905/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1654 - val_loss: 1.4863\n",
      "Epoch 1906/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.1652 - val_loss: 1.4860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1907/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1650 - val_loss: 1.4857\n",
      "Epoch 1908/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1648 - val_loss: 1.4855\n",
      "Epoch 1909/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1646 - val_loss: 1.4852\n",
      "Epoch 1910/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1644 - val_loss: 1.4849\n",
      "Epoch 1911/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1642 - val_loss: 1.4846\n",
      "Epoch 1912/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1640 - val_loss: 1.4844\n",
      "Epoch 1913/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1638 - val_loss: 1.4841\n",
      "Epoch 1914/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1636 - val_loss: 1.4838\n",
      "Epoch 1915/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.1635 - val_loss: 1.4836\n",
      "Epoch 1916/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1633 - val_loss: 1.4833\n",
      "Epoch 1917/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1631 - val_loss: 1.4830\n",
      "Epoch 1918/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1629 - val_loss: 1.4827\n",
      "Epoch 1919/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.1627 - val_loss: 1.4825\n",
      "Epoch 1920/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1625 - val_loss: 1.4822\n",
      "Epoch 1921/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1623 - val_loss: 1.4819\n",
      "Epoch 1922/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1621 - val_loss: 1.4816\n",
      "Epoch 1923/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 1.1620 - val_loss: 1.4814\n",
      "Epoch 1924/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1618 - val_loss: 1.4811\n",
      "Epoch 1925/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1616 - val_loss: 1.4808\n",
      "Epoch 1926/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1614 - val_loss: 1.4806\n",
      "Epoch 1927/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.1612 - val_loss: 1.4803\n",
      "Epoch 1928/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1610 - val_loss: 1.4800\n",
      "Epoch 1929/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1608 - val_loss: 1.4797\n",
      "Epoch 1930/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 1.1606 - val_loss: 1.4795\n",
      "Epoch 1931/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1604 - val_loss: 1.4792\n",
      "Epoch 1932/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1603 - val_loss: 1.4789\n",
      "Epoch 1933/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1601 - val_loss: 1.4787\n",
      "Epoch 1934/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1599 - val_loss: 1.4784\n",
      "Epoch 1935/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1597 - val_loss: 1.4781\n",
      "Epoch 1936/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.1595 - val_loss: 1.4778\n",
      "Epoch 1937/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1593 - val_loss: 1.4776\n",
      "Epoch 1938/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.1591 - val_loss: 1.4773\n",
      "Epoch 1939/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 1.1590 - val_loss: 1.4770\n",
      "Epoch 1940/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1588 - val_loss: 1.4768\n",
      "Epoch 1941/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.1586 - val_loss: 1.4765\n",
      "Epoch 1942/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1584 - val_loss: 1.4762\n",
      "Epoch 1943/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.1582 - val_loss: 1.4759\n",
      "Epoch 1944/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1580 - val_loss: 1.4757\n",
      "Epoch 1945/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1578 - val_loss: 1.4754\n",
      "Epoch 1946/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 1.1577 - val_loss: 1.4751\n",
      "Epoch 1947/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1575 - val_loss: 1.4749\n",
      "Epoch 1948/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1573 - val_loss: 1.4746\n",
      "Epoch 1949/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 1.1571 - val_loss: 1.4743\n",
      "Epoch 1950/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1569 - val_loss: 1.4741\n",
      "Epoch 1951/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1567 - val_loss: 1.4738\n",
      "Epoch 1952/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.1566 - val_loss: 1.4735\n",
      "Epoch 1953/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1564 - val_loss: 1.4732\n",
      "Epoch 1954/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1562 - val_loss: 1.4730\n",
      "Epoch 1955/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1560 - val_loss: 1.4727\n",
      "Epoch 1956/2500\n",
      "64/64 [==============================] - 0s 267us/step - loss: 1.1558 - val_loss: 1.4724\n",
      "Epoch 1957/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1556 - val_loss: 1.4722\n",
      "Epoch 1958/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.1555 - val_loss: 1.4719\n",
      "Epoch 1959/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1553 - val_loss: 1.4716\n",
      "Epoch 1960/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1551 - val_loss: 1.4713\n",
      "Epoch 1961/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.1549 - val_loss: 1.4711\n",
      "Epoch 1962/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1547 - val_loss: 1.4708\n",
      "Epoch 1963/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1545 - val_loss: 1.4705\n",
      "Epoch 1964/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.1544 - val_loss: 1.4703\n",
      "Epoch 1965/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1542 - val_loss: 1.4700\n",
      "Epoch 1966/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.1540 - val_loss: 1.4697\n",
      "Epoch 1967/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1538 - val_loss: 1.4695\n",
      "Epoch 1968/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1536 - val_loss: 1.4692\n",
      "Epoch 1969/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1534 - val_loss: 1.4689\n",
      "Epoch 1970/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.1533 - val_loss: 1.4687\n",
      "Epoch 1971/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1531 - val_loss: 1.4684\n",
      "Epoch 1972/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1529 - val_loss: 1.4681\n",
      "Epoch 1973/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1527 - val_loss: 1.4678\n",
      "Epoch 1974/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1525 - val_loss: 1.4676\n",
      "Epoch 1975/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1524 - val_loss: 1.4673\n",
      "Epoch 1976/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1522 - val_loss: 1.4670\n",
      "Epoch 1977/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1520 - val_loss: 1.4668\n",
      "Epoch 1978/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1518 - val_loss: 1.4665\n",
      "Epoch 1979/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1516 - val_loss: 1.4662\n",
      "Epoch 1980/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1515 - val_loss: 1.4660\n",
      "Epoch 1981/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.1513 - val_loss: 1.4657\n",
      "Epoch 1982/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1511 - val_loss: 1.4654\n",
      "Epoch 1983/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1509 - val_loss: 1.4652\n",
      "Epoch 1984/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1507 - val_loss: 1.4649\n",
      "Epoch 1985/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1506 - val_loss: 1.4646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1986/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1504 - val_loss: 1.4644\n",
      "Epoch 1987/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 1.1502 - val_loss: 1.4641\n",
      "Epoch 1988/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.1500 - val_loss: 1.4638\n",
      "Epoch 1989/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1498 - val_loss: 1.4635\n",
      "Epoch 1990/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1497 - val_loss: 1.4633\n",
      "Epoch 1991/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.1495 - val_loss: 1.4630\n",
      "Epoch 1992/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1493 - val_loss: 1.4627\n",
      "Epoch 1993/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1491 - val_loss: 1.4625\n",
      "Epoch 1994/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.1489 - val_loss: 1.4622\n",
      "Epoch 1995/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1488 - val_loss: 1.4619\n",
      "Epoch 1996/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1486 - val_loss: 1.4617\n",
      "Epoch 1997/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1484 - val_loss: 1.4614\n",
      "Epoch 1998/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 1.1482 - val_loss: 1.4611\n",
      "Epoch 1999/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1481 - val_loss: 1.4609\n",
      "Epoch 2000/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1479 - val_loss: 1.4606\n",
      "Epoch 2001/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1477 - val_loss: 1.4603\n",
      "Epoch 2002/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1475 - val_loss: 1.4601\n",
      "Epoch 2003/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1473 - val_loss: 1.4598\n",
      "Epoch 2004/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1472 - val_loss: 1.4595\n",
      "Epoch 2005/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1470 - val_loss: 1.4593\n",
      "Epoch 2006/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1468 - val_loss: 1.4590\n",
      "Epoch 2007/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1466 - val_loss: 1.4587\n",
      "Epoch 2008/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1465 - val_loss: 1.4585\n",
      "Epoch 2009/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1463 - val_loss: 1.4582\n",
      "Epoch 2010/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1461 - val_loss: 1.4579\n",
      "Epoch 2011/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1459 - val_loss: 1.4577\n",
      "Epoch 2012/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1458 - val_loss: 1.4574\n",
      "Epoch 2013/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.1456 - val_loss: 1.4571\n",
      "Epoch 2014/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1454 - val_loss: 1.4569\n",
      "Epoch 2015/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1452 - val_loss: 1.4566\n",
      "Epoch 2016/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.1451 - val_loss: 1.4563\n",
      "Epoch 2017/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1449 - val_loss: 1.4561\n",
      "Epoch 2018/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.1447 - val_loss: 1.4558\n",
      "Epoch 2019/2500\n",
      "64/64 [==============================] - 0s 421us/step - loss: 1.1445 - val_loss: 1.4555\n",
      "Epoch 2020/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1444 - val_loss: 1.4553\n",
      "Epoch 2021/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 1.1442 - val_loss: 1.4550\n",
      "Epoch 2022/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1440 - val_loss: 1.4547\n",
      "Epoch 2023/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1438 - val_loss: 1.4545\n",
      "Epoch 2024/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1437 - val_loss: 1.4542\n",
      "Epoch 2025/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1435 - val_loss: 1.4540\n",
      "Epoch 2026/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1433 - val_loss: 1.4537\n",
      "Epoch 2027/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 1.1431 - val_loss: 1.4534\n",
      "Epoch 2028/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1430 - val_loss: 1.4531\n",
      "Epoch 2029/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1428 - val_loss: 1.4529\n",
      "Epoch 2030/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.1426 - val_loss: 1.4526\n",
      "Epoch 2031/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1424 - val_loss: 1.4524\n",
      "Epoch 2032/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1423 - val_loss: 1.4521\n",
      "Epoch 2033/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1421 - val_loss: 1.4519\n",
      "Epoch 2034/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1419 - val_loss: 1.4516\n",
      "Epoch 2035/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1417 - val_loss: 1.4513\n",
      "Epoch 2036/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1416 - val_loss: 1.4510\n",
      "Epoch 2037/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.1414 - val_loss: 1.4508\n",
      "Epoch 2038/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1412 - val_loss: 1.4505\n",
      "Epoch 2039/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1411 - val_loss: 1.4503\n",
      "Epoch 2040/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.1409 - val_loss: 1.4500\n",
      "Epoch 2041/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1407 - val_loss: 1.4497\n",
      "Epoch 2042/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1405 - val_loss: 1.4495\n",
      "Epoch 2043/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1404 - val_loss: 1.4492\n",
      "Epoch 2044/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.1402 - val_loss: 1.4489\n",
      "Epoch 2045/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1400 - val_loss: 1.4487\n",
      "Epoch 2046/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1399 - val_loss: 1.4484\n",
      "Epoch 2047/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1397 - val_loss: 1.4481\n",
      "Epoch 2048/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.1395 - val_loss: 1.4479\n",
      "Epoch 2049/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1393 - val_loss: 1.4476\n",
      "Epoch 2050/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1392 - val_loss: 1.4474\n",
      "Epoch 2051/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1390 - val_loss: 1.4471\n",
      "Epoch 2052/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1388 - val_loss: 1.4468\n",
      "Epoch 2053/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1387 - val_loss: 1.4466\n",
      "Epoch 2054/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1385 - val_loss: 1.4463\n",
      "Epoch 2055/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1383 - val_loss: 1.4460\n",
      "Epoch 2056/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1382 - val_loss: 1.4458\n",
      "Epoch 2057/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1380 - val_loss: 1.4455\n",
      "Epoch 2058/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1378 - val_loss: 1.4453\n",
      "Epoch 2059/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.1376 - val_loss: 1.4450\n",
      "Epoch 2060/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1375 - val_loss: 1.4448\n",
      "Epoch 2061/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1373 - val_loss: 1.4445\n",
      "Epoch 2062/2500\n",
      "64/64 [==============================] - 0s 286us/step - loss: 1.1371 - val_loss: 1.4442\n",
      "Epoch 2063/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1370 - val_loss: 1.4440\n",
      "Epoch 2064/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1368 - val_loss: 1.4437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2065/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1366 - val_loss: 1.4434\n",
      "Epoch 2066/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.1365 - val_loss: 1.4432\n",
      "Epoch 2067/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1363 - val_loss: 1.4429\n",
      "Epoch 2068/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1361 - val_loss: 1.4427\n",
      "Epoch 2069/2500\n",
      "64/64 [==============================] - 0s 287us/step - loss: 1.1360 - val_loss: 1.4424\n",
      "Epoch 2070/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1358 - val_loss: 1.4421\n",
      "Epoch 2071/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1356 - val_loss: 1.4419\n",
      "Epoch 2072/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1355 - val_loss: 1.4416\n",
      "Epoch 2073/2500\n",
      "64/64 [==============================] - 0s 393us/step - loss: 1.1353 - val_loss: 1.4414\n",
      "Epoch 2074/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1351 - val_loss: 1.4411\n",
      "Epoch 2075/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 1.1349 - val_loss: 1.4408\n",
      "Epoch 2076/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1348 - val_loss: 1.4406\n",
      "Epoch 2077/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1346 - val_loss: 1.4403\n",
      "Epoch 2078/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.1344 - val_loss: 1.4401\n",
      "Epoch 2079/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1343 - val_loss: 1.4398\n",
      "Epoch 2080/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.1341 - val_loss: 1.4395\n",
      "Epoch 2081/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1339 - val_loss: 1.4393\n",
      "Epoch 2082/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1338 - val_loss: 1.4390\n",
      "Epoch 2083/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1336 - val_loss: 1.4388\n",
      "Epoch 2084/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.1334 - val_loss: 1.4385\n",
      "Epoch 2085/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1333 - val_loss: 1.4383\n",
      "Epoch 2086/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1331 - val_loss: 1.4380\n",
      "Epoch 2087/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.1329 - val_loss: 1.4377\n",
      "Epoch 2088/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1328 - val_loss: 1.4375\n",
      "Epoch 2089/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1326 - val_loss: 1.4372\n",
      "Epoch 2090/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1325 - val_loss: 1.4370\n",
      "Epoch 2091/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1323 - val_loss: 1.4367\n",
      "Epoch 2092/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.1321 - val_loss: 1.4365\n",
      "Epoch 2093/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1320 - val_loss: 1.4362\n",
      "Epoch 2094/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1318 - val_loss: 1.4359\n",
      "Epoch 2095/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1316 - val_loss: 1.4357\n",
      "Epoch 2096/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1315 - val_loss: 1.4354\n",
      "Epoch 2097/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1313 - val_loss: 1.4352\n",
      "Epoch 2098/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1311 - val_loss: 1.4349\n",
      "Epoch 2099/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1310 - val_loss: 1.4347\n",
      "Epoch 2100/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.1308 - val_loss: 1.4344\n",
      "Epoch 2101/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1306 - val_loss: 1.4342\n",
      "Epoch 2102/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1305 - val_loss: 1.4339\n",
      "Epoch 2103/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.1303 - val_loss: 1.4336\n",
      "Epoch 2104/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1301 - val_loss: 1.4334\n",
      "Epoch 2105/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1300 - val_loss: 1.4331\n",
      "Epoch 2106/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1298 - val_loss: 1.4329\n",
      "Epoch 2107/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1297 - val_loss: 1.4326\n",
      "Epoch 2108/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1295 - val_loss: 1.4324\n",
      "Epoch 2109/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1293 - val_loss: 1.4321\n",
      "Epoch 2110/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1292 - val_loss: 1.4318\n",
      "Epoch 2111/2500\n",
      "64/64 [==============================] - 0s 305us/step - loss: 1.1290 - val_loss: 1.4316\n",
      "Epoch 2112/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1288 - val_loss: 1.4313\n",
      "Epoch 2113/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.1287 - val_loss: 1.4311\n",
      "Epoch 2114/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1285 - val_loss: 1.4308\n",
      "Epoch 2115/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.1284 - val_loss: 1.4306\n",
      "Epoch 2116/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.1282 - val_loss: 1.4303\n",
      "Epoch 2117/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1280 - val_loss: 1.4301\n",
      "Epoch 2118/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1279 - val_loss: 1.4298\n",
      "Epoch 2119/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1277 - val_loss: 1.4296\n",
      "Epoch 2120/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1276 - val_loss: 1.4293\n",
      "Epoch 2121/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1274 - val_loss: 1.4291\n",
      "Epoch 2122/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1272 - val_loss: 1.4288\n",
      "Epoch 2123/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.1271 - val_loss: 1.4286\n",
      "Epoch 2124/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1269 - val_loss: 1.4283\n",
      "Epoch 2125/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1267 - val_loss: 1.4281\n",
      "Epoch 2126/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1266 - val_loss: 1.4278\n",
      "Epoch 2127/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1264 - val_loss: 1.4276\n",
      "Epoch 2128/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1263 - val_loss: 1.4273\n",
      "Epoch 2129/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1261 - val_loss: 1.4271\n",
      "Epoch 2130/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.1259 - val_loss: 1.4268\n",
      "Epoch 2131/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1258 - val_loss: 1.4266\n",
      "Epoch 2132/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1256 - val_loss: 1.4263\n",
      "Epoch 2133/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1255 - val_loss: 1.4261\n",
      "Epoch 2134/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1253 - val_loss: 1.4258\n",
      "Epoch 2135/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1251 - val_loss: 1.4256\n",
      "Epoch 2136/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1250 - val_loss: 1.4253\n",
      "Epoch 2137/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.1248 - val_loss: 1.4251\n",
      "Epoch 2138/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 1.1247 - val_loss: 1.4248\n",
      "Epoch 2139/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.1245 - val_loss: 1.4246\n",
      "Epoch 2140/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1243 - val_loss: 1.4243\n",
      "Epoch 2141/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1242 - val_loss: 1.4241\n",
      "Epoch 2142/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.1240 - val_loss: 1.4238\n",
      "Epoch 2143/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1239 - val_loss: 1.4236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2144/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1237 - val_loss: 1.4233\n",
      "Epoch 2145/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1236 - val_loss: 1.4231\n",
      "Epoch 2146/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1234 - val_loss: 1.4228\n",
      "Epoch 2147/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1232 - val_loss: 1.4226\n",
      "Epoch 2148/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1231 - val_loss: 1.4223\n",
      "Epoch 2149/2500\n",
      "64/64 [==============================] - 0s 298us/step - loss: 1.1229 - val_loss: 1.4221\n",
      "Epoch 2150/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1228 - val_loss: 1.4218\n",
      "Epoch 2151/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1226 - val_loss: 1.4216\n",
      "Epoch 2152/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.1225 - val_loss: 1.4213\n",
      "Epoch 2153/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1223 - val_loss: 1.4211\n",
      "Epoch 2154/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1221 - val_loss: 1.4208\n",
      "Epoch 2155/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1220 - val_loss: 1.4206\n",
      "Epoch 2156/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1218 - val_loss: 1.4204\n",
      "Epoch 2157/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1217 - val_loss: 1.4201\n",
      "Epoch 2158/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1215 - val_loss: 1.4199\n",
      "Epoch 2159/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1214 - val_loss: 1.4196\n",
      "Epoch 2160/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1212 - val_loss: 1.4194\n",
      "Epoch 2161/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1210 - val_loss: 1.4191\n",
      "Epoch 2162/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1209 - val_loss: 1.4189\n",
      "Epoch 2163/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1207 - val_loss: 1.4186\n",
      "Epoch 2164/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1206 - val_loss: 1.4184\n",
      "Epoch 2165/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1204 - val_loss: 1.4181\n",
      "Epoch 2166/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1203 - val_loss: 1.4179\n",
      "Epoch 2167/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1201 - val_loss: 1.4177\n",
      "Epoch 2168/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.1200 - val_loss: 1.4174\n",
      "Epoch 2169/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1198 - val_loss: 1.4172\n",
      "Epoch 2170/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1196 - val_loss: 1.4169\n",
      "Epoch 2171/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.1195 - val_loss: 1.4167\n",
      "Epoch 2172/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1193 - val_loss: 1.4164\n",
      "Epoch 2173/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1192 - val_loss: 1.4162\n",
      "Epoch 2174/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1190 - val_loss: 1.4160\n",
      "Epoch 2175/2500\n",
      "64/64 [==============================] - 0s 279us/step - loss: 1.1189 - val_loss: 1.4157\n",
      "Epoch 2176/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1187 - val_loss: 1.4155\n",
      "Epoch 2177/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.1186 - val_loss: 1.4152\n",
      "Epoch 2178/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1184 - val_loss: 1.4150\n",
      "Epoch 2179/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1183 - val_loss: 1.4147\n",
      "Epoch 2180/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1181 - val_loss: 1.4145\n",
      "Epoch 2181/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1179 - val_loss: 1.4143\n",
      "Epoch 2182/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1178 - val_loss: 1.4140\n",
      "Epoch 2183/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1176 - val_loss: 1.4138\n",
      "Epoch 2184/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.1175 - val_loss: 1.4135\n",
      "Epoch 2185/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1173 - val_loss: 1.4133\n",
      "Epoch 2186/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1172 - val_loss: 1.4131\n",
      "Epoch 2187/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1170 - val_loss: 1.4128\n",
      "Epoch 2188/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1169 - val_loss: 1.4126\n",
      "Epoch 2189/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1167 - val_loss: 1.4123\n",
      "Epoch 2190/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1166 - val_loss: 1.4121\n",
      "Epoch 2191/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1164 - val_loss: 1.4119\n",
      "Epoch 2192/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1163 - val_loss: 1.4116\n",
      "Epoch 2193/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1161 - val_loss: 1.4114\n",
      "Epoch 2194/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1160 - val_loss: 1.4112\n",
      "Epoch 2195/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1158 - val_loss: 1.4109\n",
      "Epoch 2196/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1157 - val_loss: 1.4107\n",
      "Epoch 2197/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1155 - val_loss: 1.4104\n",
      "Epoch 2198/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1154 - val_loss: 1.4102\n",
      "Epoch 2199/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1152 - val_loss: 1.4099\n",
      "Epoch 2200/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1151 - val_loss: 1.4097\n",
      "Epoch 2201/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.1149 - val_loss: 1.4095\n",
      "Epoch 2202/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1148 - val_loss: 1.4093\n",
      "Epoch 2203/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1146 - val_loss: 1.4090\n",
      "Epoch 2204/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1145 - val_loss: 1.4088\n",
      "Epoch 2205/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1143 - val_loss: 1.4085\n",
      "Epoch 2206/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1142 - val_loss: 1.4083\n",
      "Epoch 2207/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1140 - val_loss: 1.4080\n",
      "Epoch 2208/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1139 - val_loss: 1.4079\n",
      "Epoch 2209/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1137 - val_loss: 1.4076\n",
      "Epoch 2210/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1136 - val_loss: 1.4074\n",
      "Epoch 2211/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1134 - val_loss: 1.4071\n",
      "Epoch 2212/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1133 - val_loss: 1.4070\n",
      "Epoch 2213/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1131 - val_loss: 1.4066\n",
      "Epoch 2214/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1130 - val_loss: 1.4065\n",
      "Epoch 2215/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1128 - val_loss: 1.4061\n",
      "Epoch 2216/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1127 - val_loss: 1.4060\n",
      "Epoch 2217/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1125 - val_loss: 1.4057\n",
      "Epoch 2218/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.1124 - val_loss: 1.4056\n",
      "Epoch 2219/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1122 - val_loss: 1.4052\n",
      "Epoch 2220/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1121 - val_loss: 1.4051\n",
      "Epoch 2221/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1119 - val_loss: 1.4047\n",
      "Epoch 2222/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1118 - val_loss: 1.4047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2223/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1116 - val_loss: 1.4042\n",
      "Epoch 2224/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1115 - val_loss: 1.4042\n",
      "Epoch 2225/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1113 - val_loss: 1.4037\n",
      "Epoch 2226/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.1112 - val_loss: 1.4038\n",
      "Epoch 2227/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1110 - val_loss: 1.4033\n",
      "Epoch 2228/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1109 - val_loss: 1.4033\n",
      "Epoch 2229/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1107 - val_loss: 1.4028\n",
      "Epoch 2230/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1106 - val_loss: 1.4029\n",
      "Epoch 2231/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1104 - val_loss: 1.4023\n",
      "Epoch 2232/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1103 - val_loss: 1.4025\n",
      "Epoch 2233/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1101 - val_loss: 1.4018\n",
      "Epoch 2234/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.1100 - val_loss: 1.4021\n",
      "Epoch 2235/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1099 - val_loss: 1.4013\n",
      "Epoch 2236/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1097 - val_loss: 1.4017\n",
      "Epoch 2237/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1096 - val_loss: 1.4008\n",
      "Epoch 2238/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1094 - val_loss: 1.4013\n",
      "Epoch 2239/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1093 - val_loss: 1.4002\n",
      "Epoch 2240/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1091 - val_loss: 1.4009\n",
      "Epoch 2241/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 1.1090 - val_loss: 1.3997\n",
      "Epoch 2242/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1088 - val_loss: 1.4005\n",
      "Epoch 2243/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1087 - val_loss: 1.3991\n",
      "Epoch 2244/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.1085 - val_loss: 1.4002\n",
      "Epoch 2245/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1084 - val_loss: 1.3985\n",
      "Epoch 2246/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1082 - val_loss: 1.3999\n",
      "Epoch 2247/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 1.1081 - val_loss: 1.3979\n",
      "Epoch 2248/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1080 - val_loss: 1.3997\n",
      "Epoch 2249/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1078 - val_loss: 1.3972\n",
      "Epoch 2250/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 1.1077 - val_loss: 1.3994\n",
      "Epoch 2251/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1075 - val_loss: 1.3965\n",
      "Epoch 2252/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1074 - val_loss: 1.3993\n",
      "Epoch 2253/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.1072 - val_loss: 1.3957\n",
      "Epoch 2254/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.1071 - val_loss: 1.3992\n",
      "Epoch 2255/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1070 - val_loss: 1.3949\n",
      "Epoch 2256/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1068 - val_loss: 1.3993\n",
      "Epoch 2257/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1067 - val_loss: 1.3939\n",
      "Epoch 2258/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1065 - val_loss: 1.3994\n",
      "Epoch 2259/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1064 - val_loss: 1.3929\n",
      "Epoch 2260/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.1062 - val_loss: 1.3996\n",
      "Epoch 2261/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1061 - val_loss: 1.3917\n",
      "Epoch 2262/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1060 - val_loss: 1.4000\n",
      "Epoch 2263/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1058 - val_loss: 1.3904\n",
      "Epoch 2264/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1057 - val_loss: 1.4003\n",
      "Epoch 2265/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1056 - val_loss: 1.3892\n",
      "Epoch 2266/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1054 - val_loss: 1.4007\n",
      "Epoch 2267/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1053 - val_loss: 1.3881\n",
      "Epoch 2268/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1051 - val_loss: 1.4008\n",
      "Epoch 2269/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1050 - val_loss: 1.3873\n",
      "Epoch 2270/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1049 - val_loss: 1.4004\n",
      "Epoch 2271/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1047 - val_loss: 1.3870\n",
      "Epoch 2272/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.1046 - val_loss: 1.3995\n",
      "Epoch 2273/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1044 - val_loss: 1.3874\n",
      "Epoch 2274/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1043 - val_loss: 1.3979\n",
      "Epoch 2275/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 1.1041 - val_loss: 1.3883\n",
      "Epoch 2276/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1040 - val_loss: 1.3959\n",
      "Epoch 2277/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1038 - val_loss: 1.3896\n",
      "Epoch 2278/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1037 - val_loss: 1.3936\n",
      "Epoch 2279/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.1035 - val_loss: 1.3910\n",
      "Epoch 2280/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1034 - val_loss: 1.3914\n",
      "Epoch 2281/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1032 - val_loss: 1.3922\n",
      "Epoch 2282/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.1031 - val_loss: 1.3896\n",
      "Epoch 2283/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1030 - val_loss: 1.3929\n",
      "Epoch 2284/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1028 - val_loss: 1.3883\n",
      "Epoch 2285/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1027 - val_loss: 1.3931\n",
      "Epoch 2286/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 1.1026 - val_loss: 1.3875\n",
      "Epoch 2287/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1024 - val_loss: 1.3928\n",
      "Epoch 2288/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1023 - val_loss: 1.3872\n",
      "Epoch 2289/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.1021 - val_loss: 1.3920\n",
      "Epoch 2290/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1020 - val_loss: 1.3873\n",
      "Epoch 2291/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1019 - val_loss: 1.3909\n",
      "Epoch 2292/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1017 - val_loss: 1.3877\n",
      "Epoch 2293/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.1016 - val_loss: 1.3896\n",
      "Epoch 2294/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1014 - val_loss: 1.3881\n",
      "Epoch 2295/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1013 - val_loss: 1.3884\n",
      "Epoch 2296/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1012 - val_loss: 1.3884\n",
      "Epoch 2297/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1010 - val_loss: 1.3873\n",
      "Epoch 2298/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1009 - val_loss: 1.3885\n",
      "Epoch 2299/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1007 - val_loss: 1.3864\n",
      "Epoch 2300/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1006 - val_loss: 1.3884\n",
      "Epoch 2301/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1004 - val_loss: 1.3858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2302/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1003 - val_loss: 1.3881\n",
      "Epoch 2303/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1002 - val_loss: 1.3854\n",
      "Epoch 2304/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1000 - val_loss: 1.3875\n",
      "Epoch 2305/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 1.0999 - val_loss: 1.3851\n",
      "Epoch 2306/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0998 - val_loss: 1.3868\n",
      "Epoch 2307/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.0996 - val_loss: 1.3850\n",
      "Epoch 2308/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.0995 - val_loss: 1.3861\n",
      "Epoch 2309/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.0994 - val_loss: 1.3850\n",
      "Epoch 2310/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.0992 - val_loss: 1.3853\n",
      "Epoch 2311/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.0991 - val_loss: 1.3849\n",
      "Epoch 2312/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 1.0989 - val_loss: 1.3846\n",
      "Epoch 2313/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.0988 - val_loss: 1.3847\n",
      "Epoch 2314/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.0987 - val_loss: 1.3839\n",
      "Epoch 2315/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.0985 - val_loss: 1.3845\n",
      "Epoch 2316/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.0984 - val_loss: 1.3834\n",
      "Epoch 2317/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.0983 - val_loss: 1.3842\n",
      "Epoch 2318/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0981 - val_loss: 1.3829\n",
      "Epoch 2319/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 1.0980 - val_loss: 1.3838\n",
      "Epoch 2320/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.0979 - val_loss: 1.3825\n",
      "Epoch 2321/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0977 - val_loss: 1.3833\n",
      "Epoch 2322/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.0976 - val_loss: 1.3822\n",
      "Epoch 2323/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0974 - val_loss: 1.3828\n",
      "Epoch 2324/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.0973 - val_loss: 1.3819\n",
      "Epoch 2325/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.0972 - val_loss: 1.3823\n",
      "Epoch 2326/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.0970 - val_loss: 1.3816\n",
      "Epoch 2327/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.0969 - val_loss: 1.3817\n",
      "Epoch 2328/2500\n",
      "64/64 [==============================] - 0s 286us/step - loss: 1.0968 - val_loss: 1.3813\n",
      "Epoch 2329/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0966 - val_loss: 1.3812\n",
      "Epoch 2330/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0965 - val_loss: 1.3810\n",
      "Epoch 2331/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.0964 - val_loss: 1.3807\n",
      "Epoch 2332/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.0962 - val_loss: 1.3807\n",
      "Epoch 2333/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.0961 - val_loss: 1.3802\n",
      "Epoch 2334/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0960 - val_loss: 1.3803\n",
      "Epoch 2335/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.0958 - val_loss: 1.3798\n",
      "Epoch 2336/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.0957 - val_loss: 1.3800\n",
      "Epoch 2337/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.0956 - val_loss: 1.3793\n",
      "Epoch 2338/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0954 - val_loss: 1.3796\n",
      "Epoch 2339/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.0953 - val_loss: 1.3789\n",
      "Epoch 2340/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.0952 - val_loss: 1.3792\n",
      "Epoch 2341/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.0950 - val_loss: 1.3786\n",
      "Epoch 2342/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0949 - val_loss: 1.3787\n",
      "Epoch 2343/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.0948 - val_loss: 1.3782\n",
      "Epoch 2344/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0946 - val_loss: 1.3783\n",
      "Epoch 2345/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0945 - val_loss: 1.3778\n",
      "Epoch 2346/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.0944 - val_loss: 1.3779\n",
      "Epoch 2347/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.0942 - val_loss: 1.3775\n",
      "Epoch 2348/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.0941 - val_loss: 1.3774\n",
      "Epoch 2349/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.0940 - val_loss: 1.3771\n",
      "Epoch 2350/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.0938 - val_loss: 1.3770\n",
      "Epoch 2351/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0937 - val_loss: 1.3767\n",
      "Epoch 2352/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.0936 - val_loss: 1.3766\n",
      "Epoch 2353/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.0934 - val_loss: 1.3764\n",
      "Epoch 2354/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.0933 - val_loss: 1.3762\n",
      "Epoch 2355/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.0932 - val_loss: 1.3760\n",
      "Epoch 2356/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.0930 - val_loss: 1.3757\n",
      "Epoch 2357/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.0929 - val_loss: 1.3756\n",
      "Epoch 2358/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.0928 - val_loss: 1.3753\n",
      "Epoch 2359/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.0926 - val_loss: 1.3752\n",
      "Epoch 2360/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.0925 - val_loss: 1.3749\n",
      "Epoch 2361/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0924 - val_loss: 1.3748\n",
      "Epoch 2362/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.0922 - val_loss: 1.3745\n",
      "Epoch 2363/2500\n",
      "64/64 [==============================] - 0s 306us/step - loss: 1.0921 - val_loss: 1.3745\n",
      "Epoch 2364/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.0920 - val_loss: 1.3741\n",
      "Epoch 2365/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.0919 - val_loss: 1.3741\n",
      "Epoch 2366/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.0917 - val_loss: 1.3738\n",
      "Epoch 2367/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.0916 - val_loss: 1.3737\n",
      "Epoch 2368/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.0915 - val_loss: 1.3734\n",
      "Epoch 2369/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.0913 - val_loss: 1.3733\n",
      "Epoch 2370/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.0912 - val_loss: 1.3730\n",
      "Epoch 2371/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.0911 - val_loss: 1.3729\n",
      "Epoch 2372/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.0909 - val_loss: 1.3726\n",
      "Epoch 2373/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0908 - val_loss: 1.3725\n",
      "Epoch 2374/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.0907 - val_loss: 1.3722\n",
      "Epoch 2375/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.0906 - val_loss: 1.3721\n",
      "Epoch 2376/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.0904 - val_loss: 1.3718\n",
      "Epoch 2377/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0903 - val_loss: 1.3717\n",
      "Epoch 2378/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0902 - val_loss: 1.3714\n",
      "Epoch 2379/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.0900 - val_loss: 1.3714\n",
      "Epoch 2380/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.0899 - val_loss: 1.3711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2381/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.0898 - val_loss: 1.3710\n",
      "Epoch 2382/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.0897 - val_loss: 1.3707\n",
      "Epoch 2383/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0895 - val_loss: 1.3706\n",
      "Epoch 2384/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.0894 - val_loss: 1.3703\n",
      "Epoch 2385/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.0893 - val_loss: 1.3702\n",
      "Epoch 2386/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.0891 - val_loss: 1.3699\n",
      "Epoch 2387/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0890 - val_loss: 1.3699\n",
      "Epoch 2388/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 1.0889 - val_loss: 1.3695\n",
      "Epoch 2389/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.0888 - val_loss: 1.3695\n",
      "Epoch 2390/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0886 - val_loss: 1.3692\n",
      "Epoch 2391/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.0885 - val_loss: 1.3691\n",
      "Epoch 2392/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.0884 - val_loss: 1.3688\n",
      "Epoch 2393/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.0882 - val_loss: 1.3687\n",
      "Epoch 2394/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.0881 - val_loss: 1.3684\n",
      "Epoch 2395/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 1.0880 - val_loss: 1.3684\n",
      "Epoch 2396/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.0879 - val_loss: 1.3680\n",
      "Epoch 2397/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.0877 - val_loss: 1.3680\n",
      "Epoch 2398/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 1.0876 - val_loss: 1.3676\n",
      "Epoch 2399/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.0875 - val_loss: 1.3677\n",
      "Epoch 2400/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.0874 - val_loss: 1.3672\n",
      "Epoch 2401/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.0872 - val_loss: 1.3673\n",
      "Epoch 2402/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.0871 - val_loss: 1.3668\n",
      "Epoch 2403/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.0870 - val_loss: 1.3670\n",
      "Epoch 2404/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.0869 - val_loss: 1.3664\n",
      "Epoch 2405/2500\n",
      "64/64 [==============================] - 0s 431us/step - loss: 1.0867 - val_loss: 1.3667\n",
      "Epoch 2406/2500\n",
      "64/64 [==============================] - 0s 284us/step - loss: 1.0866 - val_loss: 1.3660\n",
      "Epoch 2407/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.0865 - val_loss: 1.3664\n",
      "Epoch 2408/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.0863 - val_loss: 1.3656\n",
      "Epoch 2409/2500\n",
      "64/64 [==============================] - 0s 395us/step - loss: 1.0862 - val_loss: 1.3661\n",
      "Epoch 2410/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 1.0861 - val_loss: 1.3651\n",
      "Epoch 2411/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.0860 - val_loss: 1.3658\n",
      "Epoch 2412/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.0858 - val_loss: 1.3646\n",
      "Epoch 2413/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.0857 - val_loss: 1.3656\n",
      "Epoch 2414/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.0856 - val_loss: 1.3641\n",
      "Epoch 2415/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.0855 - val_loss: 1.3654\n",
      "Epoch 2416/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0853 - val_loss: 1.3636\n",
      "Epoch 2417/2500\n",
      "64/64 [==============================] - 0s 417us/step - loss: 1.0852 - val_loss: 1.3653\n",
      "Epoch 2418/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0851 - val_loss: 1.3629\n",
      "Epoch 2419/2500\n",
      "64/64 [==============================] - 0s 279us/step - loss: 1.0850 - val_loss: 1.3652\n",
      "Epoch 2420/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.0848 - val_loss: 1.3622\n",
      "Epoch 2421/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.0847 - val_loss: 1.3653\n",
      "Epoch 2422/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 1.0846 - val_loss: 1.3613\n",
      "Epoch 2423/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.0845 - val_loss: 1.3656\n",
      "Epoch 2424/2500\n",
      "64/64 [==============================] - 0s 384us/step - loss: 1.0844 - val_loss: 1.3603\n",
      "Epoch 2425/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0842 - val_loss: 1.3660\n",
      "Epoch 2426/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.0841 - val_loss: 1.3590\n",
      "Epoch 2427/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 1.0840 - val_loss: 1.3668\n",
      "Epoch 2428/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.0839 - val_loss: 1.3574\n",
      "Epoch 2429/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0838 - val_loss: 1.3679\n",
      "Epoch 2430/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.0837 - val_loss: 1.3554\n",
      "Epoch 2431/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.0836 - val_loss: 1.3695\n",
      "Epoch 2432/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.0835 - val_loss: 1.3529\n",
      "Epoch 2433/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 1.0834 - val_loss: 1.3714\n",
      "Epoch 2434/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.0833 - val_loss: 1.3503\n",
      "Epoch 2435/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.0832 - val_loss: 1.3735\n",
      "Epoch 2436/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.0831 - val_loss: 1.3479\n",
      "Epoch 2437/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 1.0830 - val_loss: 1.3749\n",
      "Epoch 2438/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.0829 - val_loss: 1.3464\n",
      "Epoch 2439/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0828 - val_loss: 1.3747\n",
      "Epoch 2440/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 1.0827 - val_loss: 1.3470\n",
      "Epoch 2441/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.0825 - val_loss: 1.3720\n",
      "Epoch 2442/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0824 - val_loss: 1.3500\n",
      "Epoch 2443/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.0822 - val_loss: 1.3671\n",
      "Epoch 2444/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.0820 - val_loss: 1.3549\n",
      "Epoch 2445/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.0818 - val_loss: 1.3611\n",
      "Epoch 2446/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.0817 - val_loss: 1.3601\n",
      "Epoch 2447/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.0815 - val_loss: 1.3559\n",
      "Epoch 2448/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.0814 - val_loss: 1.3641\n",
      "Epoch 2449/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0813 - val_loss: 1.3524\n",
      "Epoch 2450/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.0812 - val_loss: 1.3658\n",
      "Epoch 2451/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.0811 - val_loss: 1.3512\n",
      "Epoch 2452/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.0810 - val_loss: 1.3650\n",
      "Epoch 2453/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0809 - val_loss: 1.3521\n",
      "Epoch 2454/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.0807 - val_loss: 1.3623\n",
      "Epoch 2455/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.0806 - val_loss: 1.3545\n",
      "Epoch 2456/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.0805 - val_loss: 1.3588\n",
      "Epoch 2457/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0803 - val_loss: 1.3575\n",
      "Epoch 2458/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 1.0802 - val_loss: 1.3556\n",
      "Epoch 2459/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.0801 - val_loss: 1.3597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2460/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.0800 - val_loss: 1.3534\n",
      "Epoch 2461/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.0799 - val_loss: 1.3607\n",
      "Epoch 2462/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0797 - val_loss: 1.3524\n",
      "Epoch 2463/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.0796 - val_loss: 1.3602\n",
      "Epoch 2464/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0795 - val_loss: 1.3527\n",
      "Epoch 2465/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.0794 - val_loss: 1.3586\n",
      "Epoch 2466/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.0792 - val_loss: 1.3539\n",
      "Epoch 2467/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.0791 - val_loss: 1.3565\n",
      "Epoch 2468/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.0790 - val_loss: 1.3553\n",
      "Epoch 2469/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.0789 - val_loss: 1.3546\n",
      "Epoch 2470/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.0788 - val_loss: 1.3565\n",
      "Epoch 2471/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.0786 - val_loss: 1.3531\n",
      "Epoch 2472/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.0785 - val_loss: 1.3570\n",
      "Epoch 2473/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.0784 - val_loss: 1.3524\n",
      "Epoch 2474/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 1.0783 - val_loss: 1.3568\n",
      "Epoch 2475/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.0782 - val_loss: 1.3522\n",
      "Epoch 2476/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0781 - val_loss: 1.3559\n",
      "Epoch 2477/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.0779 - val_loss: 1.3526\n",
      "Epoch 2478/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.0778 - val_loss: 1.3547\n",
      "Epoch 2479/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.0777 - val_loss: 1.3531\n",
      "Epoch 2480/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.0776 - val_loss: 1.3535\n",
      "Epoch 2481/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0775 - val_loss: 1.3537\n",
      "Epoch 2482/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0773 - val_loss: 1.3524\n",
      "Epoch 2483/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0772 - val_loss: 1.3540\n",
      "Epoch 2484/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.0771 - val_loss: 1.3517\n",
      "Epoch 2485/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.0770 - val_loss: 1.3539\n",
      "Epoch 2486/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.0769 - val_loss: 1.3512\n",
      "Epoch 2487/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.0768 - val_loss: 1.3535\n",
      "Epoch 2488/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.0766 - val_loss: 1.3511\n",
      "Epoch 2489/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.0765 - val_loss: 1.3529\n",
      "Epoch 2490/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.0764 - val_loss: 1.3511\n",
      "Epoch 2491/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.0763 - val_loss: 1.3522\n",
      "Epoch 2492/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.0762 - val_loss: 1.3512\n",
      "Epoch 2493/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.0760 - val_loss: 1.3514\n",
      "Epoch 2494/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.0759 - val_loss: 1.3514\n",
      "Epoch 2495/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.0758 - val_loss: 1.3507\n",
      "Epoch 2496/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.0757 - val_loss: 1.3514\n",
      "Epoch 2497/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.0756 - val_loss: 1.3502\n",
      "Epoch 2498/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.0755 - val_loss: 1.3512\n",
      "Epoch 2499/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.0753 - val_loss: 1.3498\n",
      "Epoch 2500/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0752 - val_loss: 1.3509\n"
     ]
    }
   ],
   "source": [
    "L2_reg = model_L2.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "X_val_L2 = L2_reg.validation_data[0]\n",
    "Y_val_L2 = L2_reg.validation_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $L_{1}$ Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.005\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model_L1 = models.Sequential()\n",
    "\n",
    "model_L1.add(layers.Dense(N, input_dim=input_dim, kernel_initializer='normal', activation='tanh', \n",
    "                          kernel_regularizer=regularizers.l1(alpha)))\n",
    "\n",
    "for h in range(num_layers):\n",
    "    model_L1.add(layers.Dense(N, activation='tanh', kernel_regularizer=regularizers.l1(alpha)))\n",
    "    \n",
    "model_L1.add(layers.Dense(1, activation='linear', kernel_regularizer=regularizers.l1(alpha)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 27.3567 - val_loss: 25.3241\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 26.5550 - val_loss: 24.9764\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 26.2976 - val_loss: 24.8225\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 26.2051 - val_loss: 24.6045\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 25.9926 - val_loss: 24.3516\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 25.7114 - val_loss: 24.1467\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 25.4698 - val_loss: 23.9941\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 374us/step - loss: 25.2892 - val_loss: 23.8400\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 25.1222 - val_loss: 23.6401\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 24.9243 - val_loss: 23.3876\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6873 - val_loss: 23.1021\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 24.4302 - val_loss: 22.8144\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 24.1822 - val_loss: 22.5487\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 23.9625 - val_loss: 22.3056\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 23.7598 - val_loss: 22.0666\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 23.5430 - val_loss: 21.8286\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 23.3041 - val_loss: 21.6154\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 23.0732 - val_loss: 21.4441\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 22.8810 - val_loss: 21.2885\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 22.7164 - val_loss: 21.1012\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 22.5434 - val_loss: 20.8830\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 22.3651 - val_loss: 20.6843\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 22.2211 - val_loss: 20.5295\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 22.1073 - val_loss: 20.3917\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 21.9721 - val_loss: 20.2686\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 21.8183 - val_loss: 20.1636\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 21.6765 - val_loss: 20.0350\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 320us/step - loss: 21.5295 - val_loss: 19.8579\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 21.3579 - val_loss: 19.6613\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 21.1810 - val_loss: 19.4794\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 21.0169 - val_loss: 19.3180\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 20.8583 - val_loss: 19.1713\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 20.6972 - val_loss: 19.0376\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 20.5395 - val_loss: 18.9125\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 20.3910 - val_loss: 18.7839\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 20.2471 - val_loss: 18.6425\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 20.1009 - val_loss: 18.4872\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 19.9500 - val_loss: 18.3289\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 19.8012 - val_loss: 18.1709\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 19.6528 - val_loss: 18.0183\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 19.5050 - val_loss: 17.8690\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 19.3538 - val_loss: 17.7217\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 19.1992 - val_loss: 17.5788\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 19.0478 - val_loss: 17.4348\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 314us/step - loss: 18.8983 - val_loss: 17.2852\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 18.7491 - val_loss: 17.1287\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 18.5995 - val_loss: 16.9696\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 18.4511 - val_loss: 16.8134\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 18.3051 - val_loss: 16.6630\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 18.1602 - val_loss: 16.5187\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 18.0148 - val_loss: 16.3794\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 17.8695 - val_loss: 16.2417\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 17.7254 - val_loss: 16.1010\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 17.5815 - val_loss: 15.9550\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 17.4369 - val_loss: 15.8061\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 17.2924 - val_loss: 15.6584\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 17.1488 - val_loss: 15.5150\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 17.0060 - val_loss: 15.3763\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 16.8636 - val_loss: 15.2411\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 16.7221 - val_loss: 15.1067\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 16.5814 - val_loss: 14.9703\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 16.4415 - val_loss: 14.8308\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 16.3018 - val_loss: 14.6894\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 16.1625 - val_loss: 14.5483\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 16.0237 - val_loss: 14.4096\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.8855 - val_loss: 14.2737\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 15.7479 - val_loss: 14.1400\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 15.6110 - val_loss: 14.0065\n",
      "Epoch 69/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 15.4748 - val_loss: 13.8717\n",
      "Epoch 70/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 15.3392 - val_loss: 13.7354\n",
      "Epoch 71/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 15.2040 - val_loss: 13.5984\n",
      "Epoch 72/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 15.0693 - val_loss: 13.4629\n",
      "Epoch 73/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 14.9357 - val_loss: 13.3296\n",
      "Epoch 74/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 14.8027 - val_loss: 13.1987\n",
      "Epoch 75/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 14.6704 - val_loss: 13.0693\n",
      "Epoch 76/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 14.5389 - val_loss: 12.9402\n",
      "Epoch 77/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 14.4081 - val_loss: 12.8101\n",
      "Epoch 78/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 14.2776 - val_loss: 12.6798\n",
      "Epoch 79/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 14.1479 - val_loss: 12.5501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.0189 - val_loss: 12.4220\n",
      "Epoch 81/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 13.8906 - val_loss: 12.2957\n",
      "Epoch 82/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 13.7629 - val_loss: 12.1707\n",
      "Epoch 83/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 13.6358 - val_loss: 12.0465\n",
      "Epoch 84/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 13.5095 - val_loss: 11.9223\n",
      "Epoch 85/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 13.3840 - val_loss: 11.7980\n",
      "Epoch 86/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 13.2591 - val_loss: 11.6740\n",
      "Epoch 87/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 13.1349 - val_loss: 11.5508\n",
      "Epoch 88/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 13.0111 - val_loss: 11.4290\n",
      "Epoch 89/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 12.8879 - val_loss: 11.3085\n",
      "Epoch 90/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 12.7656 - val_loss: 11.1888\n",
      "Epoch 91/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 12.6441 - val_loss: 11.0693\n",
      "Epoch 92/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 12.5231 - val_loss: 10.9499\n",
      "Epoch 93/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 12.4030 - val_loss: 10.8310\n",
      "Epoch 94/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 12.2836 - val_loss: 10.7129\n",
      "Epoch 95/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 12.1646 - val_loss: 10.5959\n",
      "Epoch 96/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 12.0463 - val_loss: 10.4800\n",
      "Epoch 97/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 11.9286 - val_loss: 10.3650\n",
      "Epoch 98/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 11.8116 - val_loss: 10.2505\n",
      "Epoch 99/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 11.6953 - val_loss: 10.1365\n",
      "Epoch 100/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 11.5796 - val_loss: 10.0229\n",
      "Epoch 101/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 11.4645 - val_loss: 9.9101\n",
      "Epoch 102/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 11.3499 - val_loss: 9.7985\n",
      "Epoch 103/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 11.2361 - val_loss: 9.6879\n",
      "Epoch 104/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 11.1229 - val_loss: 9.5780\n",
      "Epoch 105/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 11.0104 - val_loss: 9.4685\n",
      "Epoch 106/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 10.8984 - val_loss: 9.3595\n",
      "Epoch 107/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 10.7868 - val_loss: 9.2514\n",
      "Epoch 108/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 10.6762 - val_loss: 9.1444\n",
      "Epoch 109/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 10.5663 - val_loss: 9.0384\n",
      "Epoch 110/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 10.4570 - val_loss: 8.9327\n",
      "Epoch 111/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 10.3479 - val_loss: 8.8280\n",
      "Epoch 112/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 10.2397 - val_loss: 8.7237\n",
      "Epoch 113/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 10.1320 - val_loss: 8.6199\n",
      "Epoch 114/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 10.0246 - val_loss: 8.5173\n",
      "Epoch 115/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 9.9181 - val_loss: 8.4155\n",
      "Epoch 116/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 9.8117 - val_loss: 8.3144\n",
      "Epoch 117/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 9.7059 - val_loss: 8.2138\n",
      "Epoch 118/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 9.6006 - val_loss: 8.1135\n",
      "Epoch 119/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 9.4957 - val_loss: 8.0138\n",
      "Epoch 120/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 9.3911 - val_loss: 7.9151\n",
      "Epoch 121/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 9.2866 - val_loss: 7.8171\n",
      "Epoch 122/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 9.1823 - val_loss: 7.7194\n",
      "Epoch 123/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 9.0782 - val_loss: 7.6220\n",
      "Epoch 124/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 8.9743 - val_loss: 7.5248\n",
      "Epoch 125/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 8.8705 - val_loss: 7.4285\n",
      "Epoch 126/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 8.7668 - val_loss: 7.3335\n",
      "Epoch 127/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 8.6635 - val_loss: 7.2389\n",
      "Epoch 128/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 8.5602 - val_loss: 7.1447\n",
      "Epoch 129/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 8.4568 - val_loss: 7.0508\n",
      "Epoch 130/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 8.3533 - val_loss: 6.9576\n",
      "Epoch 131/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 8.2495 - val_loss: 6.8653\n",
      "Epoch 132/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 8.1455 - val_loss: 6.7735\n",
      "Epoch 133/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 8.0411 - val_loss: 6.6815\n",
      "Epoch 134/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 7.9355 - val_loss: 6.5895\n",
      "Epoch 135/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 7.8289 - val_loss: 6.4981\n",
      "Epoch 136/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 7.7215 - val_loss: 6.4069\n",
      "Epoch 137/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 7.6126 - val_loss: 6.3155\n",
      "Epoch 138/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 7.5019 - val_loss: 6.2239\n",
      "Epoch 139/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 7.3892 - val_loss: 6.1325\n",
      "Epoch 140/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 7.2739 - val_loss: 6.0406\n",
      "Epoch 141/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 7.1556 - val_loss: 5.9486\n",
      "Epoch 142/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 7.0340 - val_loss: 5.8567\n",
      "Epoch 143/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 6.9081 - val_loss: 5.7640\n",
      "Epoch 144/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 6.7773 - val_loss: 5.6715\n",
      "Epoch 145/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 6.6409 - val_loss: 5.5798\n",
      "Epoch 146/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 6.4982 - val_loss: 5.4880\n",
      "Epoch 147/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 6.3487 - val_loss: 5.4016\n",
      "Epoch 148/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 6.1920 - val_loss: 5.3098\n",
      "Epoch 149/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 6.0283 - val_loss: 5.2657\n",
      "Epoch 150/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 5.8606 - val_loss: 5.0906\n",
      "Epoch 151/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 5.7552 - val_loss: 6.2794\n",
      "Epoch 152/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 6.2697 - val_loss: 5.0693\n",
      "Epoch 153/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 5.8357 - val_loss: 4.9439\n",
      "Epoch 154/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 5.6258 - val_loss: 5.6462\n",
      "Epoch 155/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 5.6094 - val_loss: 5.3650\n",
      "Epoch 156/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 5.3575 - val_loss: 4.8314\n",
      "Epoch 157/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 5.3488 - val_loss: 4.7914\n",
      "Epoch 158/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 5.1981 - val_loss: 5.2880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 5.1086 - val_loss: 5.3163\n",
      "Epoch 160/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 5.0651 - val_loss: 4.7407\n",
      "Epoch 161/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 4.9154 - val_loss: 4.7303\n",
      "Epoch 162/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 4.9454 - val_loss: 5.0125\n",
      "Epoch 163/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 4.7594 - val_loss: 5.2146\n",
      "Epoch 164/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 4.8237 - val_loss: 4.6426\n",
      "Epoch 165/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 4.6419 - val_loss: 4.6068\n",
      "Epoch 166/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 4.7073 - val_loss: 4.8465\n",
      "Epoch 167/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 4.5414 - val_loss: 5.0507\n",
      "Epoch 168/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 4.5968 - val_loss: 4.5861\n",
      "Epoch 169/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 4.4533 - val_loss: 4.5389\n",
      "Epoch 170/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 4.4962 - val_loss: 4.7332\n",
      "Epoch 171/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 4.3683 - val_loss: 4.8993\n",
      "Epoch 172/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 4.4057 - val_loss: 4.5229\n",
      "Epoch 173/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 4.2895 - val_loss: 4.4316\n",
      "Epoch 174/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 4.3200 - val_loss: 4.5413\n",
      "Epoch 175/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 4.2131 - val_loss: 4.6920\n",
      "Epoch 176/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 4.2395 - val_loss: 4.4044\n",
      "Epoch 177/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 4.1434 - val_loss: 4.2781\n",
      "Epoch 178/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 4.1621 - val_loss: 4.3287\n",
      "Epoch 179/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 4.0791 - val_loss: 4.4788\n",
      "Epoch 180/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 4.0880 - val_loss: 4.3117\n",
      "Epoch 181/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 4.0211 - val_loss: 4.1569\n",
      "Epoch 182/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 4.0163 - val_loss: 4.1555\n",
      "Epoch 183/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 3.9677 - val_loss: 4.2721\n",
      "Epoch 184/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 3.9476 - val_loss: 4.2238\n",
      "Epoch 185/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 3.9156 - val_loss: 4.0585\n",
      "Epoch 186/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 3.8831 - val_loss: 4.0106\n",
      "Epoch 187/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 3.8640 - val_loss: 4.0745\n",
      "Epoch 188/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 3.8248 - val_loss: 4.1117\n",
      "Epoch 189/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 3.8117 - val_loss: 3.9917\n",
      "Epoch 190/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 3.7722 - val_loss: 3.9112\n",
      "Epoch 191/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 3.7591 - val_loss: 3.9296\n",
      "Epoch 192/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 3.7239 - val_loss: 3.9917\n",
      "Epoch 193/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 3.7074 - val_loss: 3.9407\n",
      "Epoch 194/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 3.6790 - val_loss: 3.8462\n",
      "Epoch 195/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 3.6581 - val_loss: 3.8262\n",
      "Epoch 196/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 3.6358 - val_loss: 3.8721\n",
      "Epoch 197/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 3.6116 - val_loss: 3.8740\n",
      "Epoch 198/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 3.5932 - val_loss: 3.7941\n",
      "Epoch 199/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 3.5674 - val_loss: 3.7483\n",
      "Epoch 200/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 3.5504 - val_loss: 3.7683\n",
      "Epoch 201/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 3.5254 - val_loss: 3.7940\n",
      "Epoch 202/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 3.5088 - val_loss: 3.7460\n",
      "Epoch 203/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 3.4859 - val_loss: 3.6892\n",
      "Epoch 204/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 3.4686 - val_loss: 3.6852\n",
      "Epoch 205/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 3.4480 - val_loss: 3.7104\n",
      "Epoch 206/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 3.4299 - val_loss: 3.6905\n",
      "Epoch 207/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 3.4113 - val_loss: 3.6361\n",
      "Epoch 208/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 3.3931 - val_loss: 3.6139\n",
      "Epoch 209/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 3.3758 - val_loss: 3.6289\n",
      "Epoch 210/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 3.3574 - val_loss: 3.6264\n",
      "Epoch 211/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 3.3413 - val_loss: 3.5833\n",
      "Epoch 212/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 3.3233 - val_loss: 3.5512\n",
      "Epoch 213/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 3.3076 - val_loss: 3.5534\n",
      "Epoch 214/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 3.2901 - val_loss: 3.5580\n",
      "Epoch 215/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 3.2748 - val_loss: 3.5289\n",
      "Epoch 216/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 3.2583 - val_loss: 3.4939\n",
      "Epoch 217/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 3.2432 - val_loss: 3.4852\n",
      "Epoch 218/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 3.2274 - val_loss: 3.4899\n",
      "Epoch 219/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 3.2125 - val_loss: 3.4722\n",
      "Epoch 220/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 3.1974 - val_loss: 3.4394\n",
      "Epoch 221/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 3.1827 - val_loss: 3.4236\n",
      "Epoch 222/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 3.1684 - val_loss: 3.4248\n",
      "Epoch 223/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 3.1515 - val_loss: 3.4150\n",
      "Epoch 224/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 3.1400 - val_loss: 3.3875\n",
      "Epoch 225/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 3.1256 - val_loss: 3.3677\n",
      "Epoch 226/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 3.1122 - val_loss: 3.3645\n",
      "Epoch 227/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 3.0984 - val_loss: 3.3591\n",
      "Epoch 228/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 3.0852 - val_loss: 3.3381\n",
      "Epoch 229/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 3.0718 - val_loss: 3.3174\n",
      "Epoch 230/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 3.0589 - val_loss: 3.3103\n",
      "Epoch 231/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 3.0460 - val_loss: 3.3060\n",
      "Epoch 232/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 3.0334 - val_loss: 3.2903\n",
      "Epoch 233/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 3.0209 - val_loss: 3.2707\n",
      "Epoch 234/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 3.0088 - val_loss: 3.2605\n",
      "Epoch 235/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 2.9968 - val_loss: 3.2558\n",
      "Epoch 236/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 2.9847 - val_loss: 3.2445\n",
      "Epoch 237/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.9729 - val_loss: 3.2274\n",
      "Epoch 238/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 2.9613 - val_loss: 3.2158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 2.9498 - val_loss: 3.2105\n",
      "Epoch 240/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.9383 - val_loss: 3.2012\n",
      "Epoch 241/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.9269 - val_loss: 3.1862\n",
      "Epoch 242/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.9158 - val_loss: 3.1744\n",
      "Epoch 243/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.9050 - val_loss: 3.1683\n",
      "Epoch 244/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 2.8943 - val_loss: 3.1603\n",
      "Epoch 245/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.8835 - val_loss: 3.1471\n",
      "Epoch 246/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.8729 - val_loss: 3.1350\n",
      "Epoch 247/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.8624 - val_loss: 3.1282\n",
      "Epoch 248/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 2.8520 - val_loss: 3.1212\n",
      "Epoch 249/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 2.8416 - val_loss: 3.1099\n",
      "Epoch 250/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 2.8316 - val_loss: 3.0980\n",
      "Epoch 251/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.8216 - val_loss: 3.0898\n",
      "Epoch 252/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 2.8117 - val_loss: 3.0824\n",
      "Epoch 253/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.8018 - val_loss: 3.0720\n",
      "Epoch 254/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.7920 - val_loss: 3.0607\n",
      "Epoch 255/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 2.7824 - val_loss: 3.0522\n",
      "Epoch 256/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 2.7728 - val_loss: 3.0454\n",
      "Epoch 257/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.7634 - val_loss: 3.0364\n",
      "Epoch 258/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.7540 - val_loss: 3.0263\n",
      "Epoch 259/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.7448 - val_loss: 3.0179\n",
      "Epoch 260/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 2.7358 - val_loss: 3.0109\n",
      "Epoch 261/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.7269 - val_loss: 3.0026\n",
      "Epoch 262/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.7181 - val_loss: 2.9931\n",
      "Epoch 263/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.7093 - val_loss: 2.9846\n",
      "Epoch 264/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 2.7007 - val_loss: 2.9774\n",
      "Epoch 265/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.6920 - val_loss: 2.9697\n",
      "Epoch 266/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.6835 - val_loss: 2.9607\n",
      "Epoch 267/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 2.6750 - val_loss: 2.9527\n",
      "Epoch 268/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.6667 - val_loss: 2.9458\n",
      "Epoch 269/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.6585 - val_loss: 2.9383\n",
      "Epoch 270/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.6504 - val_loss: 2.9299\n",
      "Epoch 271/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.6422 - val_loss: 2.9223\n",
      "Epoch 272/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 2.6342 - val_loss: 2.9154\n",
      "Epoch 273/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.6262 - val_loss: 2.9083\n",
      "Epoch 274/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.6183 - val_loss: 2.9004\n",
      "Epoch 275/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 2.6105 - val_loss: 2.8928\n",
      "Epoch 276/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.6026 - val_loss: 2.8861\n",
      "Epoch 277/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 2.5949 - val_loss: 2.8797\n",
      "Epoch 278/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.5875 - val_loss: 2.8726\n",
      "Epoch 279/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 2.5801 - val_loss: 2.8649\n",
      "Epoch 280/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 2.5725 - val_loss: 2.8580\n",
      "Epoch 281/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.5651 - val_loss: 2.8515\n",
      "Epoch 282/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.5578 - val_loss: 2.8445\n",
      "Epoch 283/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.5505 - val_loss: 2.8371\n",
      "Epoch 284/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 2.5433 - val_loss: 2.8300\n",
      "Epoch 285/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.5361 - val_loss: 2.8234\n",
      "Epoch 286/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.5290 - val_loss: 2.8169\n",
      "Epoch 287/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.5221 - val_loss: 2.8103\n",
      "Epoch 288/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 2.5153 - val_loss: 2.8038\n",
      "Epoch 289/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.5084 - val_loss: 2.7976\n",
      "Epoch 290/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.5016 - val_loss: 2.7913\n",
      "Epoch 291/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.4949 - val_loss: 2.7853\n",
      "Epoch 292/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 2.4883 - val_loss: 2.7794\n",
      "Epoch 293/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.4818 - val_loss: 2.7736\n",
      "Epoch 294/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.4753 - val_loss: 2.7678\n",
      "Epoch 295/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.4690 - val_loss: 2.7620\n",
      "Epoch 296/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 2.4626 - val_loss: 2.7561\n",
      "Epoch 297/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.4563 - val_loss: 2.7502\n",
      "Epoch 298/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.4500 - val_loss: 2.7442\n",
      "Epoch 299/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.4437 - val_loss: 2.7383\n",
      "Epoch 300/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 2.4374 - val_loss: 2.7331\n",
      "Epoch 301/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.4313 - val_loss: 2.7277\n",
      "Epoch 302/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.4254 - val_loss: 2.7218\n",
      "Epoch 303/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 2.4195 - val_loss: 2.7162\n",
      "Epoch 304/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 2.4134 - val_loss: 2.7109\n",
      "Epoch 305/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 2.4074 - val_loss: 2.7053\n",
      "Epoch 306/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.4015 - val_loss: 2.6993\n",
      "Epoch 307/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.3957 - val_loss: 2.6941\n",
      "Epoch 308/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 2.3902 - val_loss: 2.6892\n",
      "Epoch 309/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.3845 - val_loss: 2.6845\n",
      "Epoch 310/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.3787 - val_loss: 2.6788\n",
      "Epoch 311/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.3730 - val_loss: 2.6734\n",
      "Epoch 312/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 2.3675 - val_loss: 2.6688\n",
      "Epoch 313/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.3621 - val_loss: 2.6640\n",
      "Epoch 314/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.3565 - val_loss: 2.6586\n",
      "Epoch 315/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 2.3512 - val_loss: 2.6535\n",
      "Epoch 316/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.3458 - val_loss: 2.6490\n",
      "Epoch 317/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.3405 - val_loss: 2.6444\n",
      "Epoch 318/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.3352 - val_loss: 2.6392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.3300 - val_loss: 2.6343\n",
      "Epoch 320/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 2.3248 - val_loss: 2.6297\n",
      "Epoch 321/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.3196 - val_loss: 2.6249\n",
      "Epoch 322/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.3144 - val_loss: 2.6198\n",
      "Epoch 323/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.3094 - val_loss: 2.6151\n",
      "Epoch 324/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.3045 - val_loss: 2.6107\n",
      "Epoch 325/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.2996 - val_loss: 2.6058\n",
      "Epoch 326/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.2945 - val_loss: 2.6006\n",
      "Epoch 327/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.2895 - val_loss: 2.5959\n",
      "Epoch 328/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.2847 - val_loss: 2.5916\n",
      "Epoch 329/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.2799 - val_loss: 2.5870\n",
      "Epoch 330/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 2.2750 - val_loss: 2.5822\n",
      "Epoch 331/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 2.2701 - val_loss: 2.5773\n",
      "Epoch 332/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 2.2654 - val_loss: 2.5728\n",
      "Epoch 333/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.2607 - val_loss: 2.5686\n",
      "Epoch 334/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 2.2560 - val_loss: 2.5644\n",
      "Epoch 335/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.2513 - val_loss: 2.5601\n",
      "Epoch 336/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 2.2467 - val_loss: 2.5558\n",
      "Epoch 337/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.2421 - val_loss: 2.5516\n",
      "Epoch 338/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.2377 - val_loss: 2.5473\n",
      "Epoch 339/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 2.2331 - val_loss: 2.5431\n",
      "Epoch 340/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.2286 - val_loss: 2.5390\n",
      "Epoch 341/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.2241 - val_loss: 2.5350\n",
      "Epoch 342/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 2.2196 - val_loss: 2.5316\n",
      "Epoch 343/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 2.2152 - val_loss: 2.5277\n",
      "Epoch 344/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 2.2108 - val_loss: 2.5238\n",
      "Epoch 345/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.2065 - val_loss: 2.5202\n",
      "Epoch 346/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.2022 - val_loss: 2.5167\n",
      "Epoch 347/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 2.1980 - val_loss: 2.5128\n",
      "Epoch 348/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 2.1937 - val_loss: 2.5089\n",
      "Epoch 349/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.1894 - val_loss: 2.5055\n",
      "Epoch 350/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.1852 - val_loss: 2.5016\n",
      "Epoch 351/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 2.1809 - val_loss: 2.4977\n",
      "Epoch 352/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.1768 - val_loss: 2.4939\n",
      "Epoch 353/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.1728 - val_loss: 2.4898\n",
      "Epoch 354/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 2.1687 - val_loss: 2.4855\n",
      "Epoch 355/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.1647 - val_loss: 2.4816\n",
      "Epoch 356/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.1607 - val_loss: 2.4779\n",
      "Epoch 357/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.1568 - val_loss: 2.4741\n",
      "Epoch 358/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 2.1528 - val_loss: 2.4702\n",
      "Epoch 359/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.1488 - val_loss: 2.4664\n",
      "Epoch 360/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.1449 - val_loss: 2.4628\n",
      "Epoch 361/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.1410 - val_loss: 2.4592\n",
      "Epoch 362/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.1371 - val_loss: 2.4557\n",
      "Epoch 363/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 2.1333 - val_loss: 2.4521\n",
      "Epoch 364/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.1295 - val_loss: 2.4488\n",
      "Epoch 365/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.1256 - val_loss: 2.4453\n",
      "Epoch 366/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.1219 - val_loss: 2.4417\n",
      "Epoch 367/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.1181 - val_loss: 2.4382\n",
      "Epoch 368/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 2.1145 - val_loss: 2.4349\n",
      "Epoch 369/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.1108 - val_loss: 2.4317\n",
      "Epoch 370/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.1071 - val_loss: 2.4284\n",
      "Epoch 371/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 2.1034 - val_loss: 2.4251\n",
      "Epoch 372/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 2.0999 - val_loss: 2.4214\n",
      "Epoch 373/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.0963 - val_loss: 2.4182\n",
      "Epoch 374/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.0927 - val_loss: 2.4152\n",
      "Epoch 375/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 2.0891 - val_loss: 2.4116\n",
      "Epoch 376/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0854 - val_loss: 2.4078\n",
      "Epoch 377/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.0819 - val_loss: 2.4046\n",
      "Epoch 378/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.0785 - val_loss: 2.4019\n",
      "Epoch 379/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 2.0751 - val_loss: 2.3992\n",
      "Epoch 380/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 2.0717 - val_loss: 2.3960\n",
      "Epoch 381/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 2.0683 - val_loss: 2.3930\n",
      "Epoch 382/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0649 - val_loss: 2.3907\n",
      "Epoch 383/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0616 - val_loss: 2.3876\n",
      "Epoch 384/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 2.0582 - val_loss: 2.3839\n",
      "Epoch 385/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.0548 - val_loss: 2.3807\n",
      "Epoch 386/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.0514 - val_loss: 2.3780\n",
      "Epoch 387/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.0481 - val_loss: 2.3752\n",
      "Epoch 388/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.0450 - val_loss: 2.3718\n",
      "Epoch 389/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0417 - val_loss: 2.3691\n",
      "Epoch 390/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 2.0385 - val_loss: 2.3662\n",
      "Epoch 391/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.0352 - val_loss: 2.3633\n",
      "Epoch 392/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0320 - val_loss: 2.3602\n",
      "Epoch 393/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.0289 - val_loss: 2.3573\n",
      "Epoch 394/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.0258 - val_loss: 2.3543\n",
      "Epoch 395/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 2.0225 - val_loss: 2.3511\n",
      "Epoch 396/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.0194 - val_loss: 2.3480\n",
      "Epoch 397/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.0164 - val_loss: 2.3450\n",
      "Epoch 398/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.0131 - val_loss: 2.3423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.0101 - val_loss: 2.3393\n",
      "Epoch 400/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 2.0070 - val_loss: 2.3360\n",
      "Epoch 401/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 2.0041 - val_loss: 2.3333\n",
      "Epoch 402/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.0011 - val_loss: 2.3310\n",
      "Epoch 403/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.9981 - val_loss: 2.3282\n",
      "Epoch 404/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.9951 - val_loss: 2.3250\n",
      "Epoch 405/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.9922 - val_loss: 2.3224\n",
      "Epoch 406/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.9893 - val_loss: 2.3201\n",
      "Epoch 407/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.9864 - val_loss: 2.3174\n",
      "Epoch 408/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.9834 - val_loss: 2.3145\n",
      "Epoch 409/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.9805 - val_loss: 2.3123\n",
      "Epoch 410/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.9776 - val_loss: 2.3107\n",
      "Epoch 411/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.9750 - val_loss: 2.3083\n",
      "Epoch 412/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.9721 - val_loss: 2.3055\n",
      "Epoch 413/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9693 - val_loss: 2.3030\n",
      "Epoch 414/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.9666 - val_loss: 2.3008\n",
      "Epoch 415/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.9638 - val_loss: 2.2984\n",
      "Epoch 416/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.9609 - val_loss: 2.2956\n",
      "Epoch 417/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.9582 - val_loss: 2.2929\n",
      "Epoch 418/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.9555 - val_loss: 2.2897\n",
      "Epoch 419/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.9525 - val_loss: 2.2868\n",
      "Epoch 420/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.9497 - val_loss: 2.2838\n",
      "Epoch 421/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9471 - val_loss: 2.2809\n",
      "Epoch 422/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.9445 - val_loss: 2.2784\n",
      "Epoch 423/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.9419 - val_loss: 2.2762\n",
      "Epoch 424/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.9392 - val_loss: 2.2736\n",
      "Epoch 425/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.9364 - val_loss: 2.2710\n",
      "Epoch 426/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.9337 - val_loss: 2.2686\n",
      "Epoch 427/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.9311 - val_loss: 2.2666\n",
      "Epoch 428/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9285 - val_loss: 2.2645\n",
      "Epoch 429/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.9260 - val_loss: 2.2617\n",
      "Epoch 430/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9233 - val_loss: 2.2590\n",
      "Epoch 431/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.9207 - val_loss: 2.2571\n",
      "Epoch 432/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9183 - val_loss: 2.2553\n",
      "Epoch 433/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 1.9158 - val_loss: 2.2527\n",
      "Epoch 434/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.9133 - val_loss: 2.2503\n",
      "Epoch 435/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9108 - val_loss: 2.2482\n",
      "Epoch 436/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.9083 - val_loss: 2.2464\n",
      "Epoch 437/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.9059 - val_loss: 2.2442\n",
      "Epoch 438/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.9034 - val_loss: 2.2415\n",
      "Epoch 439/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.9009 - val_loss: 2.2388\n",
      "Epoch 440/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.8984 - val_loss: 2.2366\n",
      "Epoch 441/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.8961 - val_loss: 2.2343\n",
      "Epoch 442/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.8936 - val_loss: 2.2318\n",
      "Epoch 443/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.8911 - val_loss: 2.2300\n",
      "Epoch 444/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.8888 - val_loss: 2.2280\n",
      "Epoch 445/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.8864 - val_loss: 2.2259\n",
      "Epoch 446/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.8840 - val_loss: 2.2235\n",
      "Epoch 447/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.8816 - val_loss: 2.2211\n",
      "Epoch 448/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.8791 - val_loss: 2.2188\n",
      "Epoch 449/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.8766 - val_loss: 2.2167\n",
      "Epoch 450/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.8743 - val_loss: 2.2140\n",
      "Epoch 451/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.8718 - val_loss: 2.2119\n",
      "Epoch 452/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.8697 - val_loss: 2.2098\n",
      "Epoch 453/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.8674 - val_loss: 2.2075\n",
      "Epoch 454/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.8651 - val_loss: 2.2056\n",
      "Epoch 455/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.8630 - val_loss: 2.2040\n",
      "Epoch 456/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8608 - val_loss: 2.2021\n",
      "Epoch 457/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.8586 - val_loss: 2.1999\n",
      "Epoch 458/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.8563 - val_loss: 2.1978\n",
      "Epoch 459/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.8539 - val_loss: 2.1962\n",
      "Epoch 460/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8517 - val_loss: 2.1939\n",
      "Epoch 461/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.8496 - val_loss: 2.1914\n",
      "Epoch 462/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.8474 - val_loss: 2.1893\n",
      "Epoch 463/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.8452 - val_loss: 2.1876\n",
      "Epoch 464/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.8429 - val_loss: 2.1856\n",
      "Epoch 465/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.8408 - val_loss: 2.1832\n",
      "Epoch 466/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.8387 - val_loss: 2.1816\n",
      "Epoch 467/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.8366 - val_loss: 2.1801\n",
      "Epoch 468/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.8346 - val_loss: 2.1779\n",
      "Epoch 469/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.8324 - val_loss: 2.1755\n",
      "Epoch 470/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.8304 - val_loss: 2.1733\n",
      "Epoch 471/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.8281 - val_loss: 2.1711\n",
      "Epoch 472/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.8260 - val_loss: 2.1688\n",
      "Epoch 473/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.8240 - val_loss: 2.1672\n",
      "Epoch 474/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.8219 - val_loss: 2.1655\n",
      "Epoch 475/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.8198 - val_loss: 2.1634\n",
      "Epoch 476/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.8177 - val_loss: 2.1614\n",
      "Epoch 477/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.8155 - val_loss: 2.1597\n",
      "Epoch 478/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.8136 - val_loss: 2.1571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.8116 - val_loss: 2.1548\n",
      "Epoch 480/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.8096 - val_loss: 2.1531\n",
      "Epoch 481/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.8075 - val_loss: 2.1512\n",
      "Epoch 482/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8055 - val_loss: 2.1491\n",
      "Epoch 483/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.8035 - val_loss: 2.1471\n",
      "Epoch 484/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.8014 - val_loss: 2.1455\n",
      "Epoch 485/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.7994 - val_loss: 2.1434\n",
      "Epoch 486/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.7975 - val_loss: 2.1412\n",
      "Epoch 487/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.7954 - val_loss: 2.1400\n",
      "Epoch 488/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.7935 - val_loss: 2.1385\n",
      "Epoch 489/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7915 - val_loss: 2.1365\n",
      "Epoch 490/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.7896 - val_loss: 2.1347\n",
      "Epoch 491/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.7877 - val_loss: 2.1333\n",
      "Epoch 492/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.7859 - val_loss: 2.1317\n",
      "Epoch 493/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.7840 - val_loss: 2.1298\n",
      "Epoch 494/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.7820 - val_loss: 2.1286\n",
      "Epoch 495/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7802 - val_loss: 2.1275\n",
      "Epoch 496/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.7783 - val_loss: 2.1252\n",
      "Epoch 497/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.7764 - val_loss: 2.1225\n",
      "Epoch 498/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.7744 - val_loss: 2.1211\n",
      "Epoch 499/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.7725 - val_loss: 2.1197\n",
      "Epoch 500/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7708 - val_loss: 2.1174\n",
      "Epoch 501/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.7690 - val_loss: 2.1155\n",
      "Epoch 502/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7671 - val_loss: 2.1143\n",
      "Epoch 503/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.7652 - val_loss: 2.1123\n",
      "Epoch 504/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.7633 - val_loss: 2.1101\n",
      "Epoch 505/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7616 - val_loss: 2.1084\n",
      "Epoch 506/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.7597 - val_loss: 2.1066\n",
      "Epoch 507/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.7580 - val_loss: 2.1047\n",
      "Epoch 508/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.7562 - val_loss: 2.1028\n",
      "Epoch 509/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.7544 - val_loss: 2.1007\n",
      "Epoch 510/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.7525 - val_loss: 2.0992\n",
      "Epoch 511/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.7506 - val_loss: 2.0979\n",
      "Epoch 512/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 1.7489 - val_loss: 2.0960\n",
      "Epoch 513/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.7473 - val_loss: 2.0944\n",
      "Epoch 514/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.7456 - val_loss: 2.0929\n",
      "Epoch 515/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.7437 - val_loss: 2.0912\n",
      "Epoch 516/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.7420 - val_loss: 2.0896\n",
      "Epoch 517/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.7402 - val_loss: 2.0885\n",
      "Epoch 518/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.7386 - val_loss: 2.0872\n",
      "Epoch 519/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7369 - val_loss: 2.0855\n",
      "Epoch 520/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.7351 - val_loss: 2.0836\n",
      "Epoch 521/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.7333 - val_loss: 2.0821\n",
      "Epoch 522/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.7316 - val_loss: 2.0807\n",
      "Epoch 523/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7300 - val_loss: 2.0787\n",
      "Epoch 524/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.7283 - val_loss: 2.0768\n",
      "Epoch 525/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7265 - val_loss: 2.0755\n",
      "Epoch 526/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.7248 - val_loss: 2.0738\n",
      "Epoch 527/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.7231 - val_loss: 2.0718\n",
      "Epoch 528/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.7216 - val_loss: 2.0703\n",
      "Epoch 529/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.7199 - val_loss: 2.0692\n",
      "Epoch 530/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.7183 - val_loss: 2.0674\n",
      "Epoch 531/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.7165 - val_loss: 2.0661\n",
      "Epoch 532/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.7150 - val_loss: 2.0650\n",
      "Epoch 533/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7134 - val_loss: 2.0635\n",
      "Epoch 534/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.7118 - val_loss: 2.0614\n",
      "Epoch 535/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.7101 - val_loss: 2.0598\n",
      "Epoch 536/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7084 - val_loss: 2.0588\n",
      "Epoch 537/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7069 - val_loss: 2.0572\n",
      "Epoch 538/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7052 - val_loss: 2.0553\n",
      "Epoch 539/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.7036 - val_loss: 2.0536\n",
      "Epoch 540/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.7021 - val_loss: 2.0524\n",
      "Epoch 541/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.7006 - val_loss: 2.0509\n",
      "Epoch 542/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6990 - val_loss: 2.0494\n",
      "Epoch 543/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6976 - val_loss: 2.0478\n",
      "Epoch 544/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6960 - val_loss: 2.0461\n",
      "Epoch 545/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.6943 - val_loss: 2.0444\n",
      "Epoch 546/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6928 - val_loss: 2.0429\n",
      "Epoch 547/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6913 - val_loss: 2.0418\n",
      "Epoch 548/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.6897 - val_loss: 2.0402\n",
      "Epoch 549/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.6881 - val_loss: 2.0381\n",
      "Epoch 550/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.6866 - val_loss: 2.0370\n",
      "Epoch 551/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6849 - val_loss: 2.0360\n",
      "Epoch 552/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.6834 - val_loss: 2.0339\n",
      "Epoch 553/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6819 - val_loss: 2.0325\n",
      "Epoch 554/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.6804 - val_loss: 2.0316\n",
      "Epoch 555/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.6789 - val_loss: 2.0298\n",
      "Epoch 556/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.6775 - val_loss: 2.0277\n",
      "Epoch 557/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.6761 - val_loss: 2.0274\n",
      "Epoch 558/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6746 - val_loss: 2.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.6731 - val_loss: 2.0248\n",
      "Epoch 560/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.6717 - val_loss: 2.0234\n",
      "Epoch 561/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.6703 - val_loss: 2.0226\n",
      "Epoch 562/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.6689 - val_loss: 2.0204\n",
      "Epoch 563/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.6674 - val_loss: 2.0187\n",
      "Epoch 564/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.6660 - val_loss: 2.0183\n",
      "Epoch 565/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6646 - val_loss: 2.0177\n",
      "Epoch 566/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.6632 - val_loss: 2.0158\n",
      "Epoch 567/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.6619 - val_loss: 2.0142\n",
      "Epoch 568/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.6605 - val_loss: 2.0134\n",
      "Epoch 569/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6591 - val_loss: 2.0110\n",
      "Epoch 570/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.6576 - val_loss: 2.0090\n",
      "Epoch 571/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6561 - val_loss: 2.0086\n",
      "Epoch 572/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.6549 - val_loss: 2.0073\n",
      "Epoch 573/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.6536 - val_loss: 2.0055\n",
      "Epoch 574/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.6521 - val_loss: 2.0045\n",
      "Epoch 575/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.6506 - val_loss: 2.0033\n",
      "Epoch 576/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6493 - val_loss: 2.0018\n",
      "Epoch 577/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.6481 - val_loss: 2.0008\n",
      "Epoch 578/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.6467 - val_loss: 1.9996\n",
      "Epoch 579/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6453 - val_loss: 1.9981\n",
      "Epoch 580/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.6441 - val_loss: 1.9966\n",
      "Epoch 581/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6429 - val_loss: 1.9956\n",
      "Epoch 582/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6416 - val_loss: 1.9942\n",
      "Epoch 583/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.6403 - val_loss: 1.9936\n",
      "Epoch 584/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.6390 - val_loss: 1.9926\n",
      "Epoch 585/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.6377 - val_loss: 1.9908\n",
      "Epoch 586/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.6364 - val_loss: 1.9891\n",
      "Epoch 587/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.6351 - val_loss: 1.9879\n",
      "Epoch 588/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6338 - val_loss: 1.9868\n",
      "Epoch 589/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6324 - val_loss: 1.9859\n",
      "Epoch 590/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6313 - val_loss: 1.9849\n",
      "Epoch 591/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.6300 - val_loss: 1.9837\n",
      "Epoch 592/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.6287 - val_loss: 1.9823\n",
      "Epoch 593/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.6274 - val_loss: 1.9811\n",
      "Epoch 594/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.6261 - val_loss: 1.9802\n",
      "Epoch 595/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.6248 - val_loss: 1.9791\n",
      "Epoch 596/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.6238 - val_loss: 1.9774\n",
      "Epoch 597/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.6224 - val_loss: 1.9760\n",
      "Epoch 598/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.6212 - val_loss: 1.9751\n",
      "Epoch 599/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.6200 - val_loss: 1.9743\n",
      "Epoch 600/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.6188 - val_loss: 1.9726\n",
      "Epoch 601/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6175 - val_loss: 1.9718\n",
      "Epoch 602/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.6162 - val_loss: 1.9707\n",
      "Epoch 603/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6151 - val_loss: 1.9694\n",
      "Epoch 604/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.6139 - val_loss: 1.9681\n",
      "Epoch 605/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6128 - val_loss: 1.9673\n",
      "Epoch 606/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.6116 - val_loss: 1.9657\n",
      "Epoch 607/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6102 - val_loss: 1.9648\n",
      "Epoch 608/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.6090 - val_loss: 1.9640\n",
      "Epoch 609/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6079 - val_loss: 1.9623\n",
      "Epoch 610/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.6067 - val_loss: 1.9605\n",
      "Epoch 611/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.6055 - val_loss: 1.9595\n",
      "Epoch 612/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.6043 - val_loss: 1.9585\n",
      "Epoch 613/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6032 - val_loss: 1.9579\n",
      "Epoch 614/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.6022 - val_loss: 1.9574\n",
      "Epoch 615/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.6010 - val_loss: 1.9561\n",
      "Epoch 616/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.5997 - val_loss: 1.9549\n",
      "Epoch 617/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5987 - val_loss: 1.9544\n",
      "Epoch 618/2500\n",
      "64/64 [==============================] - 0s 322us/step - loss: 1.5976 - val_loss: 1.9533\n",
      "Epoch 619/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5962 - val_loss: 1.9517\n",
      "Epoch 620/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.5952 - val_loss: 1.9504\n",
      "Epoch 621/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5942 - val_loss: 1.9495\n",
      "Epoch 622/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.5931 - val_loss: 1.9484\n",
      "Epoch 623/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.5919 - val_loss: 1.9472\n",
      "Epoch 624/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5907 - val_loss: 1.9462\n",
      "Epoch 625/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5897 - val_loss: 1.9453\n",
      "Epoch 626/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5886 - val_loss: 1.9443\n",
      "Epoch 627/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 1.5875 - val_loss: 1.9429\n",
      "Epoch 628/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.5865 - val_loss: 1.9421\n",
      "Epoch 629/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.5853 - val_loss: 1.9412\n",
      "Epoch 630/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5844 - val_loss: 1.9404\n",
      "Epoch 631/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.5833 - val_loss: 1.9397\n",
      "Epoch 632/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5822 - val_loss: 1.9388\n",
      "Epoch 633/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5812 - val_loss: 1.9373\n",
      "Epoch 634/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5801 - val_loss: 1.9360\n",
      "Epoch 635/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.5791 - val_loss: 1.9350\n",
      "Epoch 636/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.5779 - val_loss: 1.9340\n",
      "Epoch 637/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.5768 - val_loss: 1.9329\n",
      "Epoch 638/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5758 - val_loss: 1.9321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.5748 - val_loss: 1.9311\n",
      "Epoch 640/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.5737 - val_loss: 1.9299\n",
      "Epoch 641/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5726 - val_loss: 1.9291\n",
      "Epoch 642/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.5715 - val_loss: 1.9276\n",
      "Epoch 643/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.5704 - val_loss: 1.9266\n",
      "Epoch 644/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5695 - val_loss: 1.9254\n",
      "Epoch 645/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.5685 - val_loss: 1.9242\n",
      "Epoch 646/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.5675 - val_loss: 1.9231\n",
      "Epoch 647/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.5663 - val_loss: 1.9221\n",
      "Epoch 648/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5653 - val_loss: 1.9215\n",
      "Epoch 649/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.5643 - val_loss: 1.9204\n",
      "Epoch 650/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5634 - val_loss: 1.9193\n",
      "Epoch 651/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.5624 - val_loss: 1.9188\n",
      "Epoch 652/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5613 - val_loss: 1.9173\n",
      "Epoch 653/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5603 - val_loss: 1.9160\n",
      "Epoch 654/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.5593 - val_loss: 1.9153\n",
      "Epoch 655/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.5584 - val_loss: 1.9142\n",
      "Epoch 656/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5574 - val_loss: 1.9136\n",
      "Epoch 657/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5564 - val_loss: 1.9130\n",
      "Epoch 658/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.5554 - val_loss: 1.9118\n",
      "Epoch 659/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.5545 - val_loss: 1.9114\n",
      "Epoch 660/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.5534 - val_loss: 1.9104\n",
      "Epoch 661/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5524 - val_loss: 1.9090\n",
      "Epoch 662/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5515 - val_loss: 1.9086\n",
      "Epoch 663/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.5507 - val_loss: 1.9079\n",
      "Epoch 664/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.5495 - val_loss: 1.9066\n",
      "Epoch 665/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5486 - val_loss: 1.9058\n",
      "Epoch 666/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5477 - val_loss: 1.9047\n",
      "Epoch 667/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.5467 - val_loss: 1.9033\n",
      "Epoch 668/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.5459 - val_loss: 1.9023\n",
      "Epoch 669/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5449 - val_loss: 1.9017\n",
      "Epoch 670/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5439 - val_loss: 1.9010\n",
      "Epoch 671/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.5429 - val_loss: 1.9006\n",
      "Epoch 672/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5420 - val_loss: 1.8994\n",
      "Epoch 673/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.5411 - val_loss: 1.8983\n",
      "Epoch 674/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5402 - val_loss: 1.8972\n",
      "Epoch 675/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.5392 - val_loss: 1.8961\n",
      "Epoch 676/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.5383 - val_loss: 1.8950\n",
      "Epoch 677/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5373 - val_loss: 1.8944\n",
      "Epoch 678/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.5363 - val_loss: 1.8933\n",
      "Epoch 679/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.5353 - val_loss: 1.8922\n",
      "Epoch 680/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.5345 - val_loss: 1.8918\n",
      "Epoch 681/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5336 - val_loss: 1.8907\n",
      "Epoch 682/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.5326 - val_loss: 1.8888\n",
      "Epoch 683/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.5317 - val_loss: 1.8884\n",
      "Epoch 684/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5309 - val_loss: 1.8877\n",
      "Epoch 685/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.5300 - val_loss: 1.8866\n",
      "Epoch 686/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.5291 - val_loss: 1.8860\n",
      "Epoch 687/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5282 - val_loss: 1.8854\n",
      "Epoch 688/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.5273 - val_loss: 1.8844\n",
      "Epoch 689/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.5265 - val_loss: 1.8834\n",
      "Epoch 690/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.5256 - val_loss: 1.8822\n",
      "Epoch 691/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.5245 - val_loss: 1.8810\n",
      "Epoch 692/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.5237 - val_loss: 1.8806\n",
      "Epoch 693/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5228 - val_loss: 1.8798\n",
      "Epoch 694/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.5219 - val_loss: 1.8791\n",
      "Epoch 695/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.5210 - val_loss: 1.8783\n",
      "Epoch 696/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.5201 - val_loss: 1.8770\n",
      "Epoch 697/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5193 - val_loss: 1.8760\n",
      "Epoch 698/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.5185 - val_loss: 1.8758\n",
      "Epoch 699/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 1.5176 - val_loss: 1.8744\n",
      "Epoch 700/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5167 - val_loss: 1.8739\n",
      "Epoch 701/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5159 - val_loss: 1.8740\n",
      "Epoch 702/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.5151 - val_loss: 1.8733\n",
      "Epoch 703/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.5142 - val_loss: 1.8719\n",
      "Epoch 704/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5132 - val_loss: 1.8715\n",
      "Epoch 705/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5124 - val_loss: 1.8705\n",
      "Epoch 706/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5115 - val_loss: 1.8693\n",
      "Epoch 707/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5107 - val_loss: 1.8691\n",
      "Epoch 708/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.5099 - val_loss: 1.8681\n",
      "Epoch 709/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5091 - val_loss: 1.8673\n",
      "Epoch 710/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.5082 - val_loss: 1.8666\n",
      "Epoch 711/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5073 - val_loss: 1.8656\n",
      "Epoch 712/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5067 - val_loss: 1.8645\n",
      "Epoch 713/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.5058 - val_loss: 1.8635\n",
      "Epoch 714/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5048 - val_loss: 1.8622\n",
      "Epoch 715/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.5040 - val_loss: 1.8617\n",
      "Epoch 716/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.5033 - val_loss: 1.8605\n",
      "Epoch 717/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.5024 - val_loss: 1.8600\n",
      "Epoch 718/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5016 - val_loss: 1.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5008 - val_loss: 1.8579\n",
      "Epoch 720/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.5000 - val_loss: 1.8575\n",
      "Epoch 721/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4992 - val_loss: 1.8566\n",
      "Epoch 722/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.4983 - val_loss: 1.8560\n",
      "Epoch 723/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.4976 - val_loss: 1.8555\n",
      "Epoch 724/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4969 - val_loss: 1.8543\n",
      "Epoch 725/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4961 - val_loss: 1.8531\n",
      "Epoch 726/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4952 - val_loss: 1.8534\n",
      "Epoch 727/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.4944 - val_loss: 1.8524\n",
      "Epoch 728/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.4936 - val_loss: 1.8516\n",
      "Epoch 729/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4928 - val_loss: 1.8512\n",
      "Epoch 730/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4920 - val_loss: 1.8498\n",
      "Epoch 731/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4910 - val_loss: 1.8486\n",
      "Epoch 732/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.4904 - val_loss: 1.8481\n",
      "Epoch 733/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4896 - val_loss: 1.8473\n",
      "Epoch 734/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4888 - val_loss: 1.8469\n",
      "Epoch 735/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.4881 - val_loss: 1.8464\n",
      "Epoch 736/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.4872 - val_loss: 1.8453\n",
      "Epoch 737/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.4865 - val_loss: 1.8446\n",
      "Epoch 738/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4857 - val_loss: 1.8439\n",
      "Epoch 739/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4849 - val_loss: 1.8429\n",
      "Epoch 740/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4842 - val_loss: 1.8423\n",
      "Epoch 741/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.4834 - val_loss: 1.8416\n",
      "Epoch 742/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.4826 - val_loss: 1.8407\n",
      "Epoch 743/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.4819 - val_loss: 1.8398\n",
      "Epoch 744/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.4812 - val_loss: 1.8389\n",
      "Epoch 745/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.4804 - val_loss: 1.8381\n",
      "Epoch 746/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4796 - val_loss: 1.8376\n",
      "Epoch 747/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4789 - val_loss: 1.8366\n",
      "Epoch 748/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4783 - val_loss: 1.8363\n",
      "Epoch 749/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.4775 - val_loss: 1.8353\n",
      "Epoch 750/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4767 - val_loss: 1.8342\n",
      "Epoch 751/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4758 - val_loss: 1.8333\n",
      "Epoch 752/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.4752 - val_loss: 1.8328\n",
      "Epoch 753/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4746 - val_loss: 1.8320\n",
      "Epoch 754/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.4738 - val_loss: 1.8315\n",
      "Epoch 755/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4729 - val_loss: 1.8312\n",
      "Epoch 756/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4721 - val_loss: 1.8297\n",
      "Epoch 757/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.4715 - val_loss: 1.8297\n",
      "Epoch 758/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4708 - val_loss: 1.8293\n",
      "Epoch 759/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.4700 - val_loss: 1.8272\n",
      "Epoch 760/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4692 - val_loss: 1.8277\n",
      "Epoch 761/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.4685 - val_loss: 1.8260\n",
      "Epoch 762/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4678 - val_loss: 1.8251\n",
      "Epoch 763/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.4671 - val_loss: 1.8258\n",
      "Epoch 764/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.4665 - val_loss: 1.8242\n",
      "Epoch 765/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4657 - val_loss: 1.8235\n",
      "Epoch 766/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4649 - val_loss: 1.8235\n",
      "Epoch 767/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4640 - val_loss: 1.8215\n",
      "Epoch 768/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.4634 - val_loss: 1.8208\n",
      "Epoch 769/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.4627 - val_loss: 1.8204\n",
      "Epoch 770/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4621 - val_loss: 1.8186\n",
      "Epoch 771/2500\n",
      "64/64 [==============================] - 0s 287us/step - loss: 1.4612 - val_loss: 1.8186\n",
      "Epoch 772/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.4605 - val_loss: 1.8182\n",
      "Epoch 773/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4599 - val_loss: 1.8180\n",
      "Epoch 774/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.4593 - val_loss: 1.8177\n",
      "Epoch 775/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4585 - val_loss: 1.8172\n",
      "Epoch 776/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4578 - val_loss: 1.8164\n",
      "Epoch 777/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.4572 - val_loss: 1.8154\n",
      "Epoch 778/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.4565 - val_loss: 1.8143\n",
      "Epoch 779/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.4557 - val_loss: 1.8133\n",
      "Epoch 780/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4551 - val_loss: 1.8128\n",
      "Epoch 781/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4544 - val_loss: 1.8122\n",
      "Epoch 782/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4538 - val_loss: 1.8119\n",
      "Epoch 783/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 1.4531 - val_loss: 1.8120\n",
      "Epoch 784/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.4524 - val_loss: 1.8103\n",
      "Epoch 785/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.4517 - val_loss: 1.8095\n",
      "Epoch 786/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4510 - val_loss: 1.8089\n",
      "Epoch 787/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.4502 - val_loss: 1.8073\n",
      "Epoch 788/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.4497 - val_loss: 1.8076\n",
      "Epoch 789/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4491 - val_loss: 1.8068\n",
      "Epoch 790/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4483 - val_loss: 1.8058\n",
      "Epoch 791/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4476 - val_loss: 1.8067\n",
      "Epoch 792/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.4470 - val_loss: 1.8051\n",
      "Epoch 793/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4464 - val_loss: 1.8041\n",
      "Epoch 794/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4457 - val_loss: 1.8039\n",
      "Epoch 795/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4450 - val_loss: 1.8033\n",
      "Epoch 796/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.4443 - val_loss: 1.8030\n",
      "Epoch 797/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4437 - val_loss: 1.8020\n",
      "Epoch 798/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4431 - val_loss: 1.8017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4422 - val_loss: 1.8008\n",
      "Epoch 800/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.4416 - val_loss: 1.7998\n",
      "Epoch 801/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4411 - val_loss: 1.7995\n",
      "Epoch 802/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4404 - val_loss: 1.7981\n",
      "Epoch 803/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.4398 - val_loss: 1.7981\n",
      "Epoch 804/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4392 - val_loss: 1.7971\n",
      "Epoch 805/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4385 - val_loss: 1.7967\n",
      "Epoch 806/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.4380 - val_loss: 1.7965\n",
      "Epoch 807/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4374 - val_loss: 1.7955\n",
      "Epoch 808/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4367 - val_loss: 1.7948\n",
      "Epoch 809/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4361 - val_loss: 1.7946\n",
      "Epoch 810/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.4355 - val_loss: 1.7934\n",
      "Epoch 811/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4347 - val_loss: 1.7930\n",
      "Epoch 812/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4342 - val_loss: 1.7921\n",
      "Epoch 813/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4337 - val_loss: 1.7913\n",
      "Epoch 814/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.4331 - val_loss: 1.7911\n",
      "Epoch 815/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.4324 - val_loss: 1.7901\n",
      "Epoch 816/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4318 - val_loss: 1.7901\n",
      "Epoch 817/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4311 - val_loss: 1.7897\n",
      "Epoch 818/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.4304 - val_loss: 1.7888\n",
      "Epoch 819/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.4299 - val_loss: 1.7891\n",
      "Epoch 820/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.4293 - val_loss: 1.7881\n",
      "Epoch 821/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4286 - val_loss: 1.7874\n",
      "Epoch 822/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4280 - val_loss: 1.7874\n",
      "Epoch 823/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.4274 - val_loss: 1.7860\n",
      "Epoch 824/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4269 - val_loss: 1.7851\n",
      "Epoch 825/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.4263 - val_loss: 1.7841\n",
      "Epoch 826/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4256 - val_loss: 1.7830\n",
      "Epoch 827/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4249 - val_loss: 1.7831\n",
      "Epoch 828/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.4244 - val_loss: 1.7817\n",
      "Epoch 829/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.4238 - val_loss: 1.7814\n",
      "Epoch 830/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4232 - val_loss: 1.7810\n",
      "Epoch 831/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4228 - val_loss: 1.7801\n",
      "Epoch 832/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4222 - val_loss: 1.7798\n",
      "Epoch 833/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.4215 - val_loss: 1.7791\n",
      "Epoch 834/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4209 - val_loss: 1.7780\n",
      "Epoch 835/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4203 - val_loss: 1.7775\n",
      "Epoch 836/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4197 - val_loss: 1.7777\n",
      "Epoch 837/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.4193 - val_loss: 1.7778\n",
      "Epoch 838/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.4186 - val_loss: 1.7771\n",
      "Epoch 839/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.4179 - val_loss: 1.7766\n",
      "Epoch 840/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4173 - val_loss: 1.7760\n",
      "Epoch 841/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.4168 - val_loss: 1.7752\n",
      "Epoch 842/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4162 - val_loss: 1.7750\n",
      "Epoch 843/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.4157 - val_loss: 1.7745\n",
      "Epoch 844/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.4151 - val_loss: 1.7735\n",
      "Epoch 845/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4145 - val_loss: 1.7728\n",
      "Epoch 846/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4139 - val_loss: 1.7713\n",
      "Epoch 847/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4133 - val_loss: 1.7711\n",
      "Epoch 848/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4128 - val_loss: 1.7701\n",
      "Epoch 849/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.4122 - val_loss: 1.7701\n",
      "Epoch 850/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4117 - val_loss: 1.7694\n",
      "Epoch 851/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4110 - val_loss: 1.7694\n",
      "Epoch 852/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4106 - val_loss: 1.7685\n",
      "Epoch 853/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4100 - val_loss: 1.7677\n",
      "Epoch 854/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4094 - val_loss: 1.7673\n",
      "Epoch 855/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.4089 - val_loss: 1.7670\n",
      "Epoch 856/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.4084 - val_loss: 1.7663\n",
      "Epoch 857/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4078 - val_loss: 1.7658\n",
      "Epoch 858/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4071 - val_loss: 1.7652\n",
      "Epoch 859/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.4065 - val_loss: 1.7653\n",
      "Epoch 860/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4061 - val_loss: 1.7644\n",
      "Epoch 861/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.4055 - val_loss: 1.7635\n",
      "Epoch 862/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.4049 - val_loss: 1.7631\n",
      "Epoch 863/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.4043 - val_loss: 1.7618\n",
      "Epoch 864/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4038 - val_loss: 1.7624\n",
      "Epoch 865/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.4034 - val_loss: 1.7610\n",
      "Epoch 866/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.4028 - val_loss: 1.7613\n",
      "Epoch 867/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.4023 - val_loss: 1.7603\n",
      "Epoch 868/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.4017 - val_loss: 1.7597\n",
      "Epoch 869/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4013 - val_loss: 1.7595\n",
      "Epoch 870/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4008 - val_loss: 1.7577\n",
      "Epoch 871/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.4001 - val_loss: 1.7574\n",
      "Epoch 872/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3996 - val_loss: 1.7575\n",
      "Epoch 873/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3991 - val_loss: 1.7560\n",
      "Epoch 874/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.3986 - val_loss: 1.7568\n",
      "Epoch 875/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3980 - val_loss: 1.7551\n",
      "Epoch 876/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3974 - val_loss: 1.7558\n",
      "Epoch 877/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3969 - val_loss: 1.7545\n",
      "Epoch 878/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3964 - val_loss: 1.7543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.3959 - val_loss: 1.7540\n",
      "Epoch 880/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3952 - val_loss: 1.7529\n",
      "Epoch 881/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3947 - val_loss: 1.7532\n",
      "Epoch 882/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3943 - val_loss: 1.7525\n",
      "Epoch 883/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.3938 - val_loss: 1.7515\n",
      "Epoch 884/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.3932 - val_loss: 1.7506\n",
      "Epoch 885/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3927 - val_loss: 1.7498\n",
      "Epoch 886/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3922 - val_loss: 1.7498\n",
      "Epoch 887/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3918 - val_loss: 1.7494\n",
      "Epoch 888/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.3912 - val_loss: 1.7489\n",
      "Epoch 889/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3907 - val_loss: 1.7492\n",
      "Epoch 890/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3901 - val_loss: 1.7480\n",
      "Epoch 891/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3896 - val_loss: 1.7483\n",
      "Epoch 892/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.3891 - val_loss: 1.7473\n",
      "Epoch 893/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.3886 - val_loss: 1.7471\n",
      "Epoch 894/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3882 - val_loss: 1.7469\n",
      "Epoch 895/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3876 - val_loss: 1.7461\n",
      "Epoch 896/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.3871 - val_loss: 1.7459\n",
      "Epoch 897/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3867 - val_loss: 1.7450\n",
      "Epoch 898/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3863 - val_loss: 1.7442\n",
      "Epoch 899/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.3855 - val_loss: 1.7437\n",
      "Epoch 900/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.3851 - val_loss: 1.7437\n",
      "Epoch 901/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3848 - val_loss: 1.7432\n",
      "Epoch 902/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3843 - val_loss: 1.7414\n",
      "Epoch 903/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3838 - val_loss: 1.7418\n",
      "Epoch 904/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.3832 - val_loss: 1.7400\n",
      "Epoch 905/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.3827 - val_loss: 1.7407\n",
      "Epoch 906/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3822 - val_loss: 1.7396\n",
      "Epoch 907/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.3817 - val_loss: 1.7400\n",
      "Epoch 908/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3813 - val_loss: 1.7397\n",
      "Epoch 909/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.3807 - val_loss: 1.7379\n",
      "Epoch 910/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3802 - val_loss: 1.7382\n",
      "Epoch 911/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3796 - val_loss: 1.7359\n",
      "Epoch 912/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3792 - val_loss: 1.7371\n",
      "Epoch 913/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3786 - val_loss: 1.7348\n",
      "Epoch 914/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3781 - val_loss: 1.7364\n",
      "Epoch 915/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3776 - val_loss: 1.7349\n",
      "Epoch 916/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.3772 - val_loss: 1.7351\n",
      "Epoch 917/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3767 - val_loss: 1.7353\n",
      "Epoch 918/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3762 - val_loss: 1.7334\n",
      "Epoch 919/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3757 - val_loss: 1.7350\n",
      "Epoch 920/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.3753 - val_loss: 1.7315\n",
      "Epoch 921/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3749 - val_loss: 1.7340\n",
      "Epoch 922/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3745 - val_loss: 1.7312\n",
      "Epoch 923/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3740 - val_loss: 1.7332\n",
      "Epoch 924/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.3735 - val_loss: 1.7316\n",
      "Epoch 925/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.3730 - val_loss: 1.7317\n",
      "Epoch 926/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3725 - val_loss: 1.7319\n",
      "Epoch 927/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3720 - val_loss: 1.7297\n",
      "Epoch 928/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3716 - val_loss: 1.7304\n",
      "Epoch 929/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.3710 - val_loss: 1.7277\n",
      "Epoch 930/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3704 - val_loss: 1.7289\n",
      "Epoch 931/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3698 - val_loss: 1.7268\n",
      "Epoch 932/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.3695 - val_loss: 1.7268\n",
      "Epoch 933/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3690 - val_loss: 1.7258\n",
      "Epoch 934/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3684 - val_loss: 1.7252\n",
      "Epoch 935/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3679 - val_loss: 1.7254\n",
      "Epoch 936/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3674 - val_loss: 1.7242\n",
      "Epoch 937/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3670 - val_loss: 1.7240\n",
      "Epoch 938/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.3665 - val_loss: 1.7235\n",
      "Epoch 939/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3661 - val_loss: 1.7229\n",
      "Epoch 940/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.3656 - val_loss: 1.7231\n",
      "Epoch 941/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.3652 - val_loss: 1.7221\n",
      "Epoch 942/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3648 - val_loss: 1.7227\n",
      "Epoch 943/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3643 - val_loss: 1.7217\n",
      "Epoch 944/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3638 - val_loss: 1.7220\n",
      "Epoch 945/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3634 - val_loss: 1.7202\n",
      "Epoch 946/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3628 - val_loss: 1.7207\n",
      "Epoch 947/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.3621 - val_loss: 1.7189\n",
      "Epoch 948/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3618 - val_loss: 1.7206\n",
      "Epoch 949/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3613 - val_loss: 1.7182\n",
      "Epoch 950/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3610 - val_loss: 1.7195\n",
      "Epoch 951/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.3604 - val_loss: 1.7171\n",
      "Epoch 952/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3599 - val_loss: 1.7181\n",
      "Epoch 953/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3594 - val_loss: 1.7159\n",
      "Epoch 954/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3591 - val_loss: 1.7178\n",
      "Epoch 955/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3586 - val_loss: 1.7145\n",
      "Epoch 956/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.3580 - val_loss: 1.7184\n",
      "Epoch 957/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.3576 - val_loss: 1.7124\n",
      "Epoch 958/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3572 - val_loss: 1.7179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3568 - val_loss: 1.7104\n",
      "Epoch 960/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.3564 - val_loss: 1.7174\n",
      "Epoch 961/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3560 - val_loss: 1.7089\n",
      "Epoch 962/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3555 - val_loss: 1.7182\n",
      "Epoch 963/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3552 - val_loss: 1.7066\n",
      "Epoch 964/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3548 - val_loss: 1.7182\n",
      "Epoch 965/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.3543 - val_loss: 1.7039\n",
      "Epoch 966/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3538 - val_loss: 1.7189\n",
      "Epoch 967/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3533 - val_loss: 1.7020\n",
      "Epoch 968/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3529 - val_loss: 1.7192\n",
      "Epoch 969/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3526 - val_loss: 1.7007\n",
      "Epoch 970/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.3521 - val_loss: 1.7187\n",
      "Epoch 971/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3515 - val_loss: 1.6988\n",
      "Epoch 972/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3512 - val_loss: 1.7183\n",
      "Epoch 973/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.3509 - val_loss: 1.6985\n",
      "Epoch 974/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3504 - val_loss: 1.7166\n",
      "Epoch 975/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3498 - val_loss: 1.6986\n",
      "Epoch 976/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.3494 - val_loss: 1.7147\n",
      "Epoch 977/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3488 - val_loss: 1.6984\n",
      "Epoch 978/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3484 - val_loss: 1.7132\n",
      "Epoch 979/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3479 - val_loss: 1.6985\n",
      "Epoch 980/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.3475 - val_loss: 1.7125\n",
      "Epoch 981/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.3470 - val_loss: 1.6972\n",
      "Epoch 982/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3466 - val_loss: 1.7120\n",
      "Epoch 983/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3462 - val_loss: 1.6948\n",
      "Epoch 984/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.3458 - val_loss: 1.7128\n",
      "Epoch 985/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.3455 - val_loss: 1.6920\n",
      "Epoch 986/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3451 - val_loss: 1.7154\n",
      "Epoch 987/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3448 - val_loss: 1.6885\n",
      "Epoch 988/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3446 - val_loss: 1.7184\n",
      "Epoch 989/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3443 - val_loss: 1.6846\n",
      "Epoch 990/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3439 - val_loss: 1.7202\n",
      "Epoch 991/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3436 - val_loss: 1.6820\n",
      "Epoch 992/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3433 - val_loss: 1.7194\n",
      "Epoch 993/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.3429 - val_loss: 1.6814\n",
      "Epoch 994/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3424 - val_loss: 1.7162\n",
      "Epoch 995/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3418 - val_loss: 1.6830\n",
      "Epoch 996/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3413 - val_loss: 1.7105\n",
      "Epoch 997/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3407 - val_loss: 1.6860\n",
      "Epoch 998/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.3400 - val_loss: 1.7039\n",
      "Epoch 999/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3395 - val_loss: 1.6895\n",
      "Epoch 1000/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.3389 - val_loss: 1.6988\n",
      "Epoch 1001/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3384 - val_loss: 1.6934\n",
      "Epoch 1002/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 1.3380 - val_loss: 1.6962\n",
      "Epoch 1003/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3376 - val_loss: 1.6962\n",
      "Epoch 1004/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3373 - val_loss: 1.6932\n",
      "Epoch 1005/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3368 - val_loss: 1.6970\n",
      "Epoch 1006/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.3364 - val_loss: 1.6899\n",
      "Epoch 1007/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3360 - val_loss: 1.6990\n",
      "Epoch 1008/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.3358 - val_loss: 1.6880\n",
      "Epoch 1009/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3354 - val_loss: 1.7013\n",
      "Epoch 1010/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3350 - val_loss: 1.6843\n",
      "Epoch 1011/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.3346 - val_loss: 1.7032\n",
      "Epoch 1012/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3344 - val_loss: 1.6790\n",
      "Epoch 1013/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3343 - val_loss: 1.7060\n",
      "Epoch 1014/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3340 - val_loss: 1.6730\n",
      "Epoch 1015/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.3336 - val_loss: 1.7105\n",
      "Epoch 1016/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3336 - val_loss: 1.6681\n",
      "Epoch 1017/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3337 - val_loss: 1.7150\n",
      "Epoch 1018/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3336 - val_loss: 1.6641\n",
      "Epoch 1019/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.3332 - val_loss: 1.7150\n",
      "Epoch 1020/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.3328 - val_loss: 1.6643\n",
      "Epoch 1021/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3323 - val_loss: 1.7104\n",
      "Epoch 1022/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3317 - val_loss: 1.6691\n",
      "Epoch 1023/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3309 - val_loss: 1.7010\n",
      "Epoch 1024/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.3298 - val_loss: 1.6760\n",
      "Epoch 1025/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3290 - val_loss: 1.6907\n",
      "Epoch 1026/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3286 - val_loss: 1.6826\n",
      "Epoch 1027/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3282 - val_loss: 1.6829\n",
      "Epoch 1028/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3277 - val_loss: 1.6885\n",
      "Epoch 1029/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.3274 - val_loss: 1.6778\n",
      "Epoch 1030/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3270 - val_loss: 1.6936\n",
      "Epoch 1031/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3269 - val_loss: 1.6730\n",
      "Epoch 1032/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3266 - val_loss: 1.6972\n",
      "Epoch 1033/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3263 - val_loss: 1.6689\n",
      "Epoch 1034/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3260 - val_loss: 1.6999\n",
      "Epoch 1035/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3258 - val_loss: 1.6658\n",
      "Epoch 1036/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3256 - val_loss: 1.7022\n",
      "Epoch 1037/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.3253 - val_loss: 1.6638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1038/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3250 - val_loss: 1.7017\n",
      "Epoch 1039/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.3246 - val_loss: 1.6625\n",
      "Epoch 1040/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3242 - val_loss: 1.6989\n",
      "Epoch 1041/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3238 - val_loss: 1.6634\n",
      "Epoch 1042/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3232 - val_loss: 1.6940\n",
      "Epoch 1043/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3226 - val_loss: 1.6659\n",
      "Epoch 1044/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.3220 - val_loss: 1.6882\n",
      "Epoch 1045/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3214 - val_loss: 1.6689\n",
      "Epoch 1046/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.3210 - val_loss: 1.6836\n",
      "Epoch 1047/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3205 - val_loss: 1.6713\n",
      "Epoch 1048/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.3202 - val_loss: 1.6808\n",
      "Epoch 1049/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3197 - val_loss: 1.6734\n",
      "Epoch 1050/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3193 - val_loss: 1.6793\n",
      "Epoch 1051/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.3189 - val_loss: 1.6737\n",
      "Epoch 1052/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3186 - val_loss: 1.6782\n",
      "Epoch 1053/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3183 - val_loss: 1.6727\n",
      "Epoch 1054/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3179 - val_loss: 1.6789\n",
      "Epoch 1055/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3176 - val_loss: 1.6704\n",
      "Epoch 1056/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3172 - val_loss: 1.6808\n",
      "Epoch 1057/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3168 - val_loss: 1.6666\n",
      "Epoch 1058/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3165 - val_loss: 1.6841\n",
      "Epoch 1059/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3162 - val_loss: 1.6604\n",
      "Epoch 1060/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3161 - val_loss: 1.6903\n",
      "Epoch 1061/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3162 - val_loss: 1.6522\n",
      "Epoch 1062/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3164 - val_loss: 1.6988\n",
      "Epoch 1063/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.3167 - val_loss: 1.6429\n",
      "Epoch 1064/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.3173 - val_loss: 1.7093\n",
      "Epoch 1065/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3178 - val_loss: 1.6363\n",
      "Epoch 1066/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3184 - val_loss: 1.7139\n",
      "Epoch 1067/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.3182 - val_loss: 1.6354\n",
      "Epoch 1068/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3175 - val_loss: 1.7039\n",
      "Epoch 1069/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3159 - val_loss: 1.6447\n",
      "Epoch 1070/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3142 - val_loss: 1.6826\n",
      "Epoch 1071/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3126 - val_loss: 1.6626\n",
      "Epoch 1072/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.3116 - val_loss: 1.6614\n",
      "Epoch 1073/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3111 - val_loss: 1.6801\n",
      "Epoch 1074/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3112 - val_loss: 1.6468\n",
      "Epoch 1075/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.3117 - val_loss: 1.6913\n",
      "Epoch 1076/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.3122 - val_loss: 1.6407\n",
      "Epoch 1077/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3121 - val_loss: 1.6923\n",
      "Epoch 1078/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3116 - val_loss: 1.6441\n",
      "Epoch 1079/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3109 - val_loss: 1.6849\n",
      "Epoch 1080/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3100 - val_loss: 1.6546\n",
      "Epoch 1081/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3090 - val_loss: 1.6716\n",
      "Epoch 1082/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3082 - val_loss: 1.6655\n",
      "Epoch 1083/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3078 - val_loss: 1.6597\n",
      "Epoch 1084/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3077 - val_loss: 1.6746\n",
      "Epoch 1085/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3076 - val_loss: 1.6515\n",
      "Epoch 1086/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.3074 - val_loss: 1.6797\n",
      "Epoch 1087/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3071 - val_loss: 1.6478\n",
      "Epoch 1088/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3069 - val_loss: 1.6805\n",
      "Epoch 1089/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.3067 - val_loss: 1.6472\n",
      "Epoch 1090/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3063 - val_loss: 1.6768\n",
      "Epoch 1091/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3057 - val_loss: 1.6497\n",
      "Epoch 1092/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3051 - val_loss: 1.6710\n",
      "Epoch 1093/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3047 - val_loss: 1.6542\n",
      "Epoch 1094/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.3043 - val_loss: 1.6645\n",
      "Epoch 1095/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3037 - val_loss: 1.6579\n",
      "Epoch 1096/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3032 - val_loss: 1.6588\n",
      "Epoch 1097/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3029 - val_loss: 1.6614\n",
      "Epoch 1098/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3026 - val_loss: 1.6538\n",
      "Epoch 1099/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3022 - val_loss: 1.6639\n",
      "Epoch 1100/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.3019 - val_loss: 1.6496\n",
      "Epoch 1101/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3017 - val_loss: 1.6664\n",
      "Epoch 1102/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3013 - val_loss: 1.6466\n",
      "Epoch 1103/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3012 - val_loss: 1.6693\n",
      "Epoch 1104/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3009 - val_loss: 1.6439\n",
      "Epoch 1105/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.3007 - val_loss: 1.6710\n",
      "Epoch 1106/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3006 - val_loss: 1.6406\n",
      "Epoch 1107/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.3003 - val_loss: 1.6724\n",
      "Epoch 1108/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3001 - val_loss: 1.6387\n",
      "Epoch 1109/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2998 - val_loss: 1.6737\n",
      "Epoch 1110/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2995 - val_loss: 1.6374\n",
      "Epoch 1111/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2992 - val_loss: 1.6733\n",
      "Epoch 1112/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2989 - val_loss: 1.6365\n",
      "Epoch 1113/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2986 - val_loss: 1.6722\n",
      "Epoch 1114/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2981 - val_loss: 1.6368\n",
      "Epoch 1115/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2977 - val_loss: 1.6695\n",
      "Epoch 1116/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.2973 - val_loss: 1.6376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1117/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2970 - val_loss: 1.6664\n",
      "Epoch 1118/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2965 - val_loss: 1.6394\n",
      "Epoch 1119/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2960 - val_loss: 1.6633\n",
      "Epoch 1120/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2955 - val_loss: 1.6411\n",
      "Epoch 1121/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.2952 - val_loss: 1.6604\n",
      "Epoch 1122/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2948 - val_loss: 1.6406\n",
      "Epoch 1123/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2944 - val_loss: 1.6581\n",
      "Epoch 1124/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2941 - val_loss: 1.6391\n",
      "Epoch 1125/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.2939 - val_loss: 1.6580\n",
      "Epoch 1126/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.2936 - val_loss: 1.6388\n",
      "Epoch 1127/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2932 - val_loss: 1.6608\n",
      "Epoch 1128/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2929 - val_loss: 1.6374\n",
      "Epoch 1129/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.2927 - val_loss: 1.6637\n",
      "Epoch 1130/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2925 - val_loss: 1.6332\n",
      "Epoch 1131/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2925 - val_loss: 1.6675\n",
      "Epoch 1132/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2925 - val_loss: 1.6273\n",
      "Epoch 1133/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.2924 - val_loss: 1.6716\n",
      "Epoch 1134/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2925 - val_loss: 1.6211\n",
      "Epoch 1135/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2927 - val_loss: 1.6760\n",
      "Epoch 1136/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2926 - val_loss: 1.6179\n",
      "Epoch 1137/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2926 - val_loss: 1.6776\n",
      "Epoch 1138/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.2924 - val_loss: 1.6188\n",
      "Epoch 1139/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2919 - val_loss: 1.6735\n",
      "Epoch 1140/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2912 - val_loss: 1.6229\n",
      "Epoch 1141/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2904 - val_loss: 1.6634\n",
      "Epoch 1142/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2895 - val_loss: 1.6294\n",
      "Epoch 1143/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.2888 - val_loss: 1.6509\n",
      "Epoch 1144/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2880 - val_loss: 1.6366\n",
      "Epoch 1145/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2874 - val_loss: 1.6416\n",
      "Epoch 1146/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2871 - val_loss: 1.6441\n",
      "Epoch 1147/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 1.2867 - val_loss: 1.6356\n",
      "Epoch 1148/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2864 - val_loss: 1.6511\n",
      "Epoch 1149/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.2864 - val_loss: 1.6306\n",
      "Epoch 1150/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2862 - val_loss: 1.6559\n",
      "Epoch 1151/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2860 - val_loss: 1.6257\n",
      "Epoch 1152/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2860 - val_loss: 1.6594\n",
      "Epoch 1153/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2861 - val_loss: 1.6223\n",
      "Epoch 1154/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2859 - val_loss: 1.6616\n",
      "Epoch 1155/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2857 - val_loss: 1.6210\n",
      "Epoch 1156/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2855 - val_loss: 1.6626\n",
      "Epoch 1157/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2852 - val_loss: 1.6205\n",
      "Epoch 1158/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2848 - val_loss: 1.6602\n",
      "Epoch 1159/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.2843 - val_loss: 1.6206\n",
      "Epoch 1160/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2839 - val_loss: 1.6562\n",
      "Epoch 1161/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2835 - val_loss: 1.6219\n",
      "Epoch 1162/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2831 - val_loss: 1.6510\n",
      "Epoch 1163/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.2825 - val_loss: 1.6248\n",
      "Epoch 1164/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2821 - val_loss: 1.6466\n",
      "Epoch 1165/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2817 - val_loss: 1.6279\n",
      "Epoch 1166/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.2813 - val_loss: 1.6428\n",
      "Epoch 1167/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2809 - val_loss: 1.6296\n",
      "Epoch 1168/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2806 - val_loss: 1.6402\n",
      "Epoch 1169/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2803 - val_loss: 1.6303\n",
      "Epoch 1170/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2799 - val_loss: 1.6387\n",
      "Epoch 1171/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2796 - val_loss: 1.6299\n",
      "Epoch 1172/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2793 - val_loss: 1.6390\n",
      "Epoch 1173/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2792 - val_loss: 1.6287\n",
      "Epoch 1174/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2790 - val_loss: 1.6404\n",
      "Epoch 1175/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.2787 - val_loss: 1.6262\n",
      "Epoch 1176/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2783 - val_loss: 1.6433\n",
      "Epoch 1177/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2781 - val_loss: 1.6222\n",
      "Epoch 1178/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2781 - val_loss: 1.6484\n",
      "Epoch 1179/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2782 - val_loss: 1.6152\n",
      "Epoch 1180/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2783 - val_loss: 1.6555\n",
      "Epoch 1181/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2784 - val_loss: 1.6074\n",
      "Epoch 1182/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2787 - val_loss: 1.6649\n",
      "Epoch 1183/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2793 - val_loss: 1.5997\n",
      "Epoch 1184/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.2799 - val_loss: 1.6724\n",
      "Epoch 1185/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2802 - val_loss: 1.5948\n",
      "Epoch 1186/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2805 - val_loss: 1.6727\n",
      "Epoch 1187/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2800 - val_loss: 1.5963\n",
      "Epoch 1188/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2790 - val_loss: 1.6600\n",
      "Epoch 1189/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2775 - val_loss: 1.6069\n",
      "Epoch 1190/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2759 - val_loss: 1.6396\n",
      "Epoch 1191/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2746 - val_loss: 1.6237\n",
      "Epoch 1192/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2738 - val_loss: 1.6215\n",
      "Epoch 1193/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2737 - val_loss: 1.6399\n",
      "Epoch 1194/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2738 - val_loss: 1.6091\n",
      "Epoch 1195/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2741 - val_loss: 1.6503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1196/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2744 - val_loss: 1.6026\n",
      "Epoch 1197/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.2747 - val_loss: 1.6535\n",
      "Epoch 1198/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2746 - val_loss: 1.6032\n",
      "Epoch 1199/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2740 - val_loss: 1.6497\n",
      "Epoch 1200/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2732 - val_loss: 1.6100\n",
      "Epoch 1201/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2725 - val_loss: 1.6411\n",
      "Epoch 1202/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2720 - val_loss: 1.6195\n",
      "Epoch 1203/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2714 - val_loss: 1.6301\n",
      "Epoch 1204/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2709 - val_loss: 1.6270\n",
      "Epoch 1205/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2706 - val_loss: 1.6200\n",
      "Epoch 1206/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.2704 - val_loss: 1.6329\n",
      "Epoch 1207/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.2702 - val_loss: 1.6140\n",
      "Epoch 1208/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2701 - val_loss: 1.6380\n",
      "Epoch 1209/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2701 - val_loss: 1.6100\n",
      "Epoch 1210/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.2700 - val_loss: 1.6407\n",
      "Epoch 1211/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.2698 - val_loss: 1.6068\n",
      "Epoch 1212/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2697 - val_loss: 1.6401\n",
      "Epoch 1213/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2694 - val_loss: 1.6055\n",
      "Epoch 1214/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.2690 - val_loss: 1.6378\n",
      "Epoch 1215/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2686 - val_loss: 1.6073\n",
      "Epoch 1216/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2682 - val_loss: 1.6348\n",
      "Epoch 1217/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2678 - val_loss: 1.6110\n",
      "Epoch 1218/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2674 - val_loss: 1.6298\n",
      "Epoch 1219/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.2669 - val_loss: 1.6139\n",
      "Epoch 1220/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2666 - val_loss: 1.6244\n",
      "Epoch 1221/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2662 - val_loss: 1.6163\n",
      "Epoch 1222/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2659 - val_loss: 1.6206\n",
      "Epoch 1223/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.2656 - val_loss: 1.6182\n",
      "Epoch 1224/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2654 - val_loss: 1.6187\n",
      "Epoch 1225/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2652 - val_loss: 1.6197\n",
      "Epoch 1226/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2650 - val_loss: 1.6167\n",
      "Epoch 1227/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2648 - val_loss: 1.6216\n",
      "Epoch 1228/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.2646 - val_loss: 1.6146\n",
      "Epoch 1229/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2644 - val_loss: 1.6233\n",
      "Epoch 1230/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2642 - val_loss: 1.6116\n",
      "Epoch 1231/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2640 - val_loss: 1.6255\n",
      "Epoch 1232/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2637 - val_loss: 1.6082\n",
      "Epoch 1233/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2636 - val_loss: 1.6295\n",
      "Epoch 1234/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2635 - val_loss: 1.6031\n",
      "Epoch 1235/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2634 - val_loss: 1.6349\n",
      "Epoch 1236/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2635 - val_loss: 1.5961\n",
      "Epoch 1237/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.2638 - val_loss: 1.6422\n",
      "Epoch 1238/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2640 - val_loss: 1.5884\n",
      "Epoch 1239/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2645 - val_loss: 1.6501\n",
      "Epoch 1240/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2648 - val_loss: 1.5825\n",
      "Epoch 1241/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2653 - val_loss: 1.6556\n",
      "Epoch 1242/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.2654 - val_loss: 1.5808\n",
      "Epoch 1243/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2653 - val_loss: 1.6522\n",
      "Epoch 1244/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2645 - val_loss: 1.5842\n",
      "Epoch 1245/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2633 - val_loss: 1.6383\n",
      "Epoch 1246/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2621 - val_loss: 1.5952\n",
      "Epoch 1247/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2608 - val_loss: 1.6207\n",
      "Epoch 1248/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2599 - val_loss: 1.6107\n",
      "Epoch 1249/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.2595 - val_loss: 1.6058\n",
      "Epoch 1250/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2592 - val_loss: 1.6229\n",
      "Epoch 1251/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2593 - val_loss: 1.5950\n",
      "Epoch 1252/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2597 - val_loss: 1.6322\n",
      "Epoch 1253/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2600 - val_loss: 1.5891\n",
      "Epoch 1254/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2599 - val_loss: 1.6374\n",
      "Epoch 1255/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2598 - val_loss: 1.5879\n",
      "Epoch 1256/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2597 - val_loss: 1.6367\n",
      "Epoch 1257/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2594 - val_loss: 1.5905\n",
      "Epoch 1258/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.2590 - val_loss: 1.6298\n",
      "Epoch 1259/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2582 - val_loss: 1.5972\n",
      "Epoch 1260/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2576 - val_loss: 1.6210\n",
      "Epoch 1261/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2570 - val_loss: 1.6047\n",
      "Epoch 1262/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.2565 - val_loss: 1.6119\n",
      "Epoch 1263/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.2560 - val_loss: 1.6104\n",
      "Epoch 1264/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2558 - val_loss: 1.6042\n",
      "Epoch 1265/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2556 - val_loss: 1.6150\n",
      "Epoch 1266/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2555 - val_loss: 1.5984\n",
      "Epoch 1267/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.2553 - val_loss: 1.6194\n",
      "Epoch 1268/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2551 - val_loss: 1.5942\n",
      "Epoch 1269/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.2551 - val_loss: 1.6231\n",
      "Epoch 1270/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2550 - val_loss: 1.5910\n",
      "Epoch 1271/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2550 - val_loss: 1.6250\n",
      "Epoch 1272/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2547 - val_loss: 1.5882\n",
      "Epoch 1273/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2546 - val_loss: 1.6248\n",
      "Epoch 1274/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2544 - val_loss: 1.5866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2541 - val_loss: 1.6234\n",
      "Epoch 1276/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2537 - val_loss: 1.5881\n",
      "Epoch 1277/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2535 - val_loss: 1.6211\n",
      "Epoch 1278/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2532 - val_loss: 1.5913\n",
      "Epoch 1279/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2528 - val_loss: 1.6177\n",
      "Epoch 1280/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2523 - val_loss: 1.5938\n",
      "Epoch 1281/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.2520 - val_loss: 1.6130\n",
      "Epoch 1282/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2516 - val_loss: 1.5956\n",
      "Epoch 1283/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2513 - val_loss: 1.6099\n",
      "Epoch 1284/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2511 - val_loss: 1.5977\n",
      "Epoch 1285/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2508 - val_loss: 1.6081\n",
      "Epoch 1286/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.2506 - val_loss: 1.5984\n",
      "Epoch 1287/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2502 - val_loss: 1.6067\n",
      "Epoch 1288/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2500 - val_loss: 1.5970\n",
      "Epoch 1289/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2498 - val_loss: 1.6067\n",
      "Epoch 1290/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2496 - val_loss: 1.5952\n",
      "Epoch 1291/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.2492 - val_loss: 1.6089\n",
      "Epoch 1292/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2492 - val_loss: 1.5929\n",
      "Epoch 1293/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2491 - val_loss: 1.6128\n",
      "Epoch 1294/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2489 - val_loss: 1.5875\n",
      "Epoch 1295/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.2489 - val_loss: 1.6177\n",
      "Epoch 1296/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2489 - val_loss: 1.5800\n",
      "Epoch 1297/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2492 - val_loss: 1.6250\n",
      "Epoch 1298/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2495 - val_loss: 1.5733\n",
      "Epoch 1299/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2499 - val_loss: 1.6335\n",
      "Epoch 1300/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2503 - val_loss: 1.5676\n",
      "Epoch 1301/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2507 - val_loss: 1.6384\n",
      "Epoch 1302/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2509 - val_loss: 1.5641\n",
      "Epoch 1303/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2509 - val_loss: 1.6363\n",
      "Epoch 1304/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.2503 - val_loss: 1.5661\n",
      "Epoch 1305/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2495 - val_loss: 1.6259\n",
      "Epoch 1306/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2484 - val_loss: 1.5752\n",
      "Epoch 1307/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2472 - val_loss: 1.6096\n",
      "Epoch 1308/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2461 - val_loss: 1.5894\n",
      "Epoch 1309/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 1.2454 - val_loss: 1.5952\n",
      "Epoch 1310/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2450 - val_loss: 1.6029\n",
      "Epoch 1311/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2449 - val_loss: 1.5839\n",
      "Epoch 1312/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2450 - val_loss: 1.6129\n",
      "Epoch 1313/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2452 - val_loss: 1.5750\n",
      "Epoch 1314/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.2456 - val_loss: 1.6193\n",
      "Epoch 1315/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2458 - val_loss: 1.5715\n",
      "Epoch 1316/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2458 - val_loss: 1.6221\n",
      "Epoch 1317/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2455 - val_loss: 1.5737\n",
      "Epoch 1318/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2452 - val_loss: 1.6196\n",
      "Epoch 1319/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2447 - val_loss: 1.5782\n",
      "Epoch 1320/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2440 - val_loss: 1.6107\n",
      "Epoch 1321/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2433 - val_loss: 1.5836\n",
      "Epoch 1322/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2428 - val_loss: 1.6002\n",
      "Epoch 1323/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2423 - val_loss: 1.5888\n",
      "Epoch 1324/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.2420 - val_loss: 1.5926\n",
      "Epoch 1325/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2417 - val_loss: 1.5942\n",
      "Epoch 1326/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2414 - val_loss: 1.5877\n",
      "Epoch 1327/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.2411 - val_loss: 1.5985\n",
      "Epoch 1328/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2410 - val_loss: 1.5835\n",
      "Epoch 1329/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2409 - val_loss: 1.6014\n",
      "Epoch 1330/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2407 - val_loss: 1.5795\n",
      "Epoch 1331/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2406 - val_loss: 1.6047\n",
      "Epoch 1332/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2406 - val_loss: 1.5763\n",
      "Epoch 1333/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2406 - val_loss: 1.6078\n",
      "Epoch 1334/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2405 - val_loss: 1.5735\n",
      "Epoch 1335/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2403 - val_loss: 1.6103\n",
      "Epoch 1336/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2402 - val_loss: 1.5707\n",
      "Epoch 1337/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2403 - val_loss: 1.6122\n",
      "Epoch 1338/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2402 - val_loss: 1.5683\n",
      "Epoch 1339/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2399 - val_loss: 1.6125\n",
      "Epoch 1340/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2398 - val_loss: 1.5683\n",
      "Epoch 1341/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2396 - val_loss: 1.6106\n",
      "Epoch 1342/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2393 - val_loss: 1.5698\n",
      "Epoch 1343/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2388 - val_loss: 1.6061\n",
      "Epoch 1344/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2384 - val_loss: 1.5727\n",
      "Epoch 1345/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2379 - val_loss: 1.6009\n",
      "Epoch 1346/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2376 - val_loss: 1.5772\n",
      "Epoch 1347/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.2371 - val_loss: 1.5962\n",
      "Epoch 1348/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2368 - val_loss: 1.5798\n",
      "Epoch 1349/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2366 - val_loss: 1.5922\n",
      "Epoch 1350/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2363 - val_loss: 1.5811\n",
      "Epoch 1351/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2360 - val_loss: 1.5902\n",
      "Epoch 1352/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2357 - val_loss: 1.5822\n",
      "Epoch 1353/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2355 - val_loss: 1.5902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1354/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2353 - val_loss: 1.5817\n",
      "Epoch 1355/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2351 - val_loss: 1.5902\n",
      "Epoch 1356/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2349 - val_loss: 1.5804\n",
      "Epoch 1357/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2347 - val_loss: 1.5909\n",
      "Epoch 1358/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2345 - val_loss: 1.5779\n",
      "Epoch 1359/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2344 - val_loss: 1.5931\n",
      "Epoch 1360/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2342 - val_loss: 1.5734\n",
      "Epoch 1361/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2341 - val_loss: 1.5969\n",
      "Epoch 1362/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.2341 - val_loss: 1.5681\n",
      "Epoch 1363/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2342 - val_loss: 1.6037\n",
      "Epoch 1364/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2343 - val_loss: 1.5621\n",
      "Epoch 1365/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.2345 - val_loss: 1.6117\n",
      "Epoch 1366/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2349 - val_loss: 1.5539\n",
      "Epoch 1367/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2355 - val_loss: 1.6191\n",
      "Epoch 1368/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2360 - val_loss: 1.5472\n",
      "Epoch 1369/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.2367 - val_loss: 1.6242\n",
      "Epoch 1370/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2368 - val_loss: 1.5455\n",
      "Epoch 1371/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2366 - val_loss: 1.6218\n",
      "Epoch 1372/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2359 - val_loss: 1.5520\n",
      "Epoch 1373/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2348 - val_loss: 1.6078\n",
      "Epoch 1374/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 1.2332 - val_loss: 1.5641\n",
      "Epoch 1375/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.2319 - val_loss: 1.5874\n",
      "Epoch 1376/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2309 - val_loss: 1.5789\n",
      "Epoch 1377/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2307 - val_loss: 1.5710\n",
      "Epoch 1378/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 1.2308 - val_loss: 1.5924\n",
      "Epoch 1379/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2309 - val_loss: 1.5598\n",
      "Epoch 1380/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2312 - val_loss: 1.6021\n",
      "Epoch 1381/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2316 - val_loss: 1.5549\n",
      "Epoch 1382/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.2317 - val_loss: 1.6058\n",
      "Epoch 1383/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2316 - val_loss: 1.5558\n",
      "Epoch 1384/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2313 - val_loss: 1.6025\n",
      "Epoch 1385/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2306 - val_loss: 1.5614\n",
      "Epoch 1386/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.2300 - val_loss: 1.5942\n",
      "Epoch 1387/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2293 - val_loss: 1.5697\n",
      "Epoch 1388/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2287 - val_loss: 1.5842\n",
      "Epoch 1389/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2282 - val_loss: 1.5771\n",
      "Epoch 1390/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2280 - val_loss: 1.5751\n",
      "Epoch 1391/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2278 - val_loss: 1.5826\n",
      "Epoch 1392/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2277 - val_loss: 1.5687\n",
      "Epoch 1393/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2275 - val_loss: 1.5875\n",
      "Epoch 1394/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2274 - val_loss: 1.5644\n",
      "Epoch 1395/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2274 - val_loss: 1.5915\n",
      "Epoch 1396/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.2275 - val_loss: 1.5609\n",
      "Epoch 1397/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.2275 - val_loss: 1.5929\n",
      "Epoch 1398/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2273 - val_loss: 1.5585\n",
      "Epoch 1399/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.2271 - val_loss: 1.5924\n",
      "Epoch 1400/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2270 - val_loss: 1.5583\n",
      "Epoch 1401/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2267 - val_loss: 1.5909\n",
      "Epoch 1402/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2264 - val_loss: 1.5604\n",
      "Epoch 1403/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2261 - val_loss: 1.5884\n",
      "Epoch 1404/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2259 - val_loss: 1.5626\n",
      "Epoch 1405/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.2255 - val_loss: 1.5840\n",
      "Epoch 1406/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2252 - val_loss: 1.5646\n",
      "Epoch 1407/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2249 - val_loss: 1.5794\n",
      "Epoch 1408/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2247 - val_loss: 1.5661\n",
      "Epoch 1409/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2244 - val_loss: 1.5766\n",
      "Epoch 1410/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.2241 - val_loss: 1.5684\n",
      "Epoch 1411/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2238 - val_loss: 1.5756\n",
      "Epoch 1412/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2237 - val_loss: 1.5706\n",
      "Epoch 1413/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2235 - val_loss: 1.5746\n",
      "Epoch 1414/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2234 - val_loss: 1.5712\n",
      "Epoch 1415/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2232 - val_loss: 1.5728\n",
      "Epoch 1416/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2228 - val_loss: 1.5702\n",
      "Epoch 1417/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2227 - val_loss: 1.5718\n",
      "Epoch 1418/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2226 - val_loss: 1.5701\n",
      "Epoch 1419/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2224 - val_loss: 1.5719\n",
      "Epoch 1420/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2221 - val_loss: 1.5694\n",
      "Epoch 1421/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2219 - val_loss: 1.5719\n",
      "Epoch 1422/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2216 - val_loss: 1.5680\n",
      "Epoch 1423/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2214 - val_loss: 1.5719\n",
      "Epoch 1424/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2212 - val_loss: 1.5653\n",
      "Epoch 1425/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2211 - val_loss: 1.5734\n",
      "Epoch 1426/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2210 - val_loss: 1.5623\n",
      "Epoch 1427/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2208 - val_loss: 1.5774\n",
      "Epoch 1428/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.2208 - val_loss: 1.5582\n",
      "Epoch 1429/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2207 - val_loss: 1.5829\n",
      "Epoch 1430/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2207 - val_loss: 1.5504\n",
      "Epoch 1431/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2208 - val_loss: 1.5915\n",
      "Epoch 1432/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2214 - val_loss: 1.5408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1433/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2221 - val_loss: 1.6043\n",
      "Epoch 1434/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2229 - val_loss: 1.5310\n",
      "Epoch 1435/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2242 - val_loss: 1.6185\n",
      "Epoch 1436/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2255 - val_loss: 1.5239\n",
      "Epoch 1437/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2266 - val_loss: 1.6236\n",
      "Epoch 1438/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2267 - val_loss: 1.5232\n",
      "Epoch 1439/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2258 - val_loss: 1.6089\n",
      "Epoch 1440/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2235 - val_loss: 1.5354\n",
      "Epoch 1441/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2209 - val_loss: 1.5788\n",
      "Epoch 1442/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2188 - val_loss: 1.5604\n",
      "Epoch 1443/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.2179 - val_loss: 1.5530\n",
      "Epoch 1444/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2181 - val_loss: 1.5858\n",
      "Epoch 1445/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2189 - val_loss: 1.5385\n",
      "Epoch 1446/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2198 - val_loss: 1.5976\n",
      "Epoch 1447/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.2202 - val_loss: 1.5350\n",
      "Epoch 1448/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.2201 - val_loss: 1.5910\n",
      "Epoch 1449/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2193 - val_loss: 1.5425\n",
      "Epoch 1450/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2181 - val_loss: 1.5746\n",
      "Epoch 1451/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2169 - val_loss: 1.5595\n",
      "Epoch 1452/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2163 - val_loss: 1.5610\n",
      "Epoch 1453/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.2162 - val_loss: 1.5760\n",
      "Epoch 1454/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2163 - val_loss: 1.5507\n",
      "Epoch 1455/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2164 - val_loss: 1.5848\n",
      "Epoch 1456/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.2165 - val_loss: 1.5455\n",
      "Epoch 1457/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2165 - val_loss: 1.5845\n",
      "Epoch 1458/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2164 - val_loss: 1.5464\n",
      "Epoch 1459/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2159 - val_loss: 1.5770\n",
      "Epoch 1460/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2154 - val_loss: 1.5528\n",
      "Epoch 1461/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.2149 - val_loss: 1.5670\n",
      "Epoch 1462/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2145 - val_loss: 1.5611\n",
      "Epoch 1463/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2142 - val_loss: 1.5580\n",
      "Epoch 1464/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2141 - val_loss: 1.5674\n",
      "Epoch 1465/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2140 - val_loss: 1.5508\n",
      "Epoch 1466/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.2139 - val_loss: 1.5707\n",
      "Epoch 1467/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2138 - val_loss: 1.5474\n",
      "Epoch 1468/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2139 - val_loss: 1.5717\n",
      "Epoch 1469/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2136 - val_loss: 1.5476\n",
      "Epoch 1470/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2133 - val_loss: 1.5701\n",
      "Epoch 1471/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2131 - val_loss: 1.5498\n",
      "Epoch 1472/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2128 - val_loss: 1.5668\n",
      "Epoch 1473/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2125 - val_loss: 1.5523\n",
      "Epoch 1474/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.2123 - val_loss: 1.5632\n",
      "Epoch 1475/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2120 - val_loss: 1.5551\n",
      "Epoch 1476/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2119 - val_loss: 1.5603\n",
      "Epoch 1477/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2118 - val_loss: 1.5573\n",
      "Epoch 1478/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2115 - val_loss: 1.5582\n",
      "Epoch 1479/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2112 - val_loss: 1.5595\n",
      "Epoch 1480/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2111 - val_loss: 1.5562\n",
      "Epoch 1481/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2111 - val_loss: 1.5610\n",
      "Epoch 1482/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2110 - val_loss: 1.5534\n",
      "Epoch 1483/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2107 - val_loss: 1.5621\n",
      "Epoch 1484/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2105 - val_loss: 1.5500\n",
      "Epoch 1485/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.2103 - val_loss: 1.5639\n",
      "Epoch 1486/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2103 - val_loss: 1.5470\n",
      "Epoch 1487/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2101 - val_loss: 1.5663\n",
      "Epoch 1488/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2100 - val_loss: 1.5435\n",
      "Epoch 1489/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.2099 - val_loss: 1.5690\n",
      "Epoch 1490/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2098 - val_loss: 1.5408\n",
      "Epoch 1491/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2098 - val_loss: 1.5722\n",
      "Epoch 1492/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2098 - val_loss: 1.5374\n",
      "Epoch 1493/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2097 - val_loss: 1.5750\n",
      "Epoch 1494/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2097 - val_loss: 1.5346\n",
      "Epoch 1495/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2097 - val_loss: 1.5763\n",
      "Epoch 1496/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2096 - val_loss: 1.5327\n",
      "Epoch 1497/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2095 - val_loss: 1.5763\n",
      "Epoch 1498/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2093 - val_loss: 1.5332\n",
      "Epoch 1499/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2092 - val_loss: 1.5742\n",
      "Epoch 1500/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2088 - val_loss: 1.5346\n",
      "Epoch 1501/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2084 - val_loss: 1.5703\n",
      "Epoch 1502/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2081 - val_loss: 1.5368\n",
      "Epoch 1503/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2077 - val_loss: 1.5658\n",
      "Epoch 1504/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.2074 - val_loss: 1.5396\n",
      "Epoch 1505/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2071 - val_loss: 1.5622\n",
      "Epoch 1506/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2068 - val_loss: 1.5421\n",
      "Epoch 1507/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2066 - val_loss: 1.5597\n",
      "Epoch 1508/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2064 - val_loss: 1.5443\n",
      "Epoch 1509/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.2062 - val_loss: 1.5584\n",
      "Epoch 1510/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2060 - val_loss: 1.5447\n",
      "Epoch 1511/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2057 - val_loss: 1.5579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1512/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2055 - val_loss: 1.5432\n",
      "Epoch 1513/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.2055 - val_loss: 1.5586\n",
      "Epoch 1514/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2052 - val_loss: 1.5403\n",
      "Epoch 1515/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2051 - val_loss: 1.5615\n",
      "Epoch 1516/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2052 - val_loss: 1.5379\n",
      "Epoch 1517/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.2053 - val_loss: 1.5655\n",
      "Epoch 1518/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.2051 - val_loss: 1.5330\n",
      "Epoch 1519/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2051 - val_loss: 1.5703\n",
      "Epoch 1520/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2053 - val_loss: 1.5271\n",
      "Epoch 1521/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2056 - val_loss: 1.5758\n",
      "Epoch 1522/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2058 - val_loss: 1.5220\n",
      "Epoch 1523/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.2060 - val_loss: 1.5815\n",
      "Epoch 1524/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2063 - val_loss: 1.5181\n",
      "Epoch 1525/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2064 - val_loss: 1.5834\n",
      "Epoch 1526/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2064 - val_loss: 1.5164\n",
      "Epoch 1527/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2062 - val_loss: 1.5789\n",
      "Epoch 1528/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2055 - val_loss: 1.5203\n",
      "Epoch 1529/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2048 - val_loss: 1.5692\n",
      "Epoch 1530/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2039 - val_loss: 1.5302\n",
      "Epoch 1531/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2031 - val_loss: 1.5564\n",
      "Epoch 1532/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2024 - val_loss: 1.5406\n",
      "Epoch 1533/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2020 - val_loss: 1.5449\n",
      "Epoch 1534/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2018 - val_loss: 1.5495\n",
      "Epoch 1535/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2018 - val_loss: 1.5371\n",
      "Epoch 1536/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2018 - val_loss: 1.5568\n",
      "Epoch 1537/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2019 - val_loss: 1.5313\n",
      "Epoch 1538/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2019 - val_loss: 1.5631\n",
      "Epoch 1539/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2020 - val_loss: 1.5277\n",
      "Epoch 1540/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.2022 - val_loss: 1.5673\n",
      "Epoch 1541/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2021 - val_loss: 1.5252\n",
      "Epoch 1542/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2020 - val_loss: 1.5680\n",
      "Epoch 1543/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2017 - val_loss: 1.5246\n",
      "Epoch 1544/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2016 - val_loss: 1.5661\n",
      "Epoch 1545/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2013 - val_loss: 1.5268\n",
      "Epoch 1546/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2010 - val_loss: 1.5616\n",
      "Epoch 1547/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2005 - val_loss: 1.5301\n",
      "Epoch 1548/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2002 - val_loss: 1.5554\n",
      "Epoch 1549/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1998 - val_loss: 1.5337\n",
      "Epoch 1550/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1994 - val_loss: 1.5487\n",
      "Epoch 1551/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1991 - val_loss: 1.5381\n",
      "Epoch 1552/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1989 - val_loss: 1.5434\n",
      "Epoch 1553/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.1986 - val_loss: 1.5419\n",
      "Epoch 1554/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1984 - val_loss: 1.5390\n",
      "Epoch 1555/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1982 - val_loss: 1.5445\n",
      "Epoch 1556/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1981 - val_loss: 1.5349\n",
      "Epoch 1557/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.1980 - val_loss: 1.5473\n",
      "Epoch 1558/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1980 - val_loss: 1.5317\n",
      "Epoch 1559/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1979 - val_loss: 1.5520\n",
      "Epoch 1560/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1978 - val_loss: 1.5294\n",
      "Epoch 1561/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1979 - val_loss: 1.5570\n",
      "Epoch 1562/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1978 - val_loss: 1.5246\n",
      "Epoch 1563/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1979 - val_loss: 1.5613\n",
      "Epoch 1564/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1981 - val_loss: 1.5185\n",
      "Epoch 1565/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.1983 - val_loss: 1.5661\n",
      "Epoch 1566/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1985 - val_loss: 1.5144\n",
      "Epoch 1567/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1985 - val_loss: 1.5700\n",
      "Epoch 1568/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1986 - val_loss: 1.5128\n",
      "Epoch 1569/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1987 - val_loss: 1.5705\n",
      "Epoch 1570/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.1985 - val_loss: 1.5128\n",
      "Epoch 1571/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1982 - val_loss: 1.5654\n",
      "Epoch 1572/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1977 - val_loss: 1.5162\n",
      "Epoch 1573/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1970 - val_loss: 1.5571\n",
      "Epoch 1574/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.1963 - val_loss: 1.5227\n",
      "Epoch 1575/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1959 - val_loss: 1.5484\n",
      "Epoch 1576/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1953 - val_loss: 1.5298\n",
      "Epoch 1577/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1948 - val_loss: 1.5407\n",
      "Epoch 1578/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.1945 - val_loss: 1.5352\n",
      "Epoch 1579/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1944 - val_loss: 1.5344\n",
      "Epoch 1580/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1944 - val_loss: 1.5390\n",
      "Epoch 1581/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1942 - val_loss: 1.5293\n",
      "Epoch 1582/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 1.1941 - val_loss: 1.5438\n",
      "Epoch 1583/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1941 - val_loss: 1.5262\n",
      "Epoch 1584/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1941 - val_loss: 1.5499\n",
      "Epoch 1585/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 1.1941 - val_loss: 1.5232\n",
      "Epoch 1586/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1940 - val_loss: 1.5542\n",
      "Epoch 1587/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1941 - val_loss: 1.5191\n",
      "Epoch 1588/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1941 - val_loss: 1.5572\n",
      "Epoch 1589/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1943 - val_loss: 1.5151\n",
      "Epoch 1590/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1944 - val_loss: 1.5590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1591/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1942 - val_loss: 1.5128\n",
      "Epoch 1592/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1941 - val_loss: 1.5587\n",
      "Epoch 1593/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1939 - val_loss: 1.5133\n",
      "Epoch 1594/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 1.1937 - val_loss: 1.5562\n",
      "Epoch 1595/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1933 - val_loss: 1.5154\n",
      "Epoch 1596/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1929 - val_loss: 1.5516\n",
      "Epoch 1597/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 1.1926 - val_loss: 1.5190\n",
      "Epoch 1598/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1922 - val_loss: 1.5455\n",
      "Epoch 1599/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.1917 - val_loss: 1.5221\n",
      "Epoch 1600/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1914 - val_loss: 1.5395\n",
      "Epoch 1601/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1912 - val_loss: 1.5252\n",
      "Epoch 1602/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1909 - val_loss: 1.5356\n",
      "Epoch 1603/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1907 - val_loss: 1.5284\n",
      "Epoch 1604/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1905 - val_loss: 1.5332\n",
      "Epoch 1605/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1904 - val_loss: 1.5309\n",
      "Epoch 1606/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1903 - val_loss: 1.5317\n",
      "Epoch 1607/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1901 - val_loss: 1.5321\n",
      "Epoch 1608/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1899 - val_loss: 1.5308\n",
      "Epoch 1609/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1897 - val_loss: 1.5326\n",
      "Epoch 1610/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1895 - val_loss: 1.5294\n",
      "Epoch 1611/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1894 - val_loss: 1.5330\n",
      "Epoch 1612/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1893 - val_loss: 1.5283\n",
      "Epoch 1613/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1890 - val_loss: 1.5346\n",
      "Epoch 1614/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1890 - val_loss: 1.5268\n",
      "Epoch 1615/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1888 - val_loss: 1.5364\n",
      "Epoch 1616/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1887 - val_loss: 1.5228\n",
      "Epoch 1617/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1887 - val_loss: 1.5387\n",
      "Epoch 1618/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1885 - val_loss: 1.5167\n",
      "Epoch 1619/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1886 - val_loss: 1.5444\n",
      "Epoch 1620/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1889 - val_loss: 1.5107\n",
      "Epoch 1621/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1891 - val_loss: 1.5533\n",
      "Epoch 1622/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1893 - val_loss: 1.5031\n",
      "Epoch 1623/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1899 - val_loss: 1.5634\n",
      "Epoch 1624/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1905 - val_loss: 1.4948\n",
      "Epoch 1625/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1914 - val_loss: 1.5727\n",
      "Epoch 1626/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1922 - val_loss: 1.4884\n",
      "Epoch 1627/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1927 - val_loss: 1.5752\n",
      "Epoch 1628/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1926 - val_loss: 1.4894\n",
      "Epoch 1629/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1919 - val_loss: 1.5647\n",
      "Epoch 1630/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1905 - val_loss: 1.5000\n",
      "Epoch 1631/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1887 - val_loss: 1.5425\n",
      "Epoch 1632/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.1871 - val_loss: 1.5183\n",
      "Epoch 1633/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1861 - val_loss: 1.5210\n",
      "Epoch 1634/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1860 - val_loss: 1.5375\n",
      "Epoch 1635/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1863 - val_loss: 1.5069\n",
      "Epoch 1636/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1869 - val_loss: 1.5510\n",
      "Epoch 1637/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1874 - val_loss: 1.4996\n",
      "Epoch 1638/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1878 - val_loss: 1.5540\n",
      "Epoch 1639/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1877 - val_loss: 1.4997\n",
      "Epoch 1640/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1872 - val_loss: 1.5472\n",
      "Epoch 1641/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.1866 - val_loss: 1.5084\n",
      "Epoch 1642/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1859 - val_loss: 1.5364\n",
      "Epoch 1643/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1853 - val_loss: 1.5217\n",
      "Epoch 1644/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1848 - val_loss: 1.5260\n",
      "Epoch 1645/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1846 - val_loss: 1.5327\n",
      "Epoch 1646/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.1844 - val_loss: 1.5163\n",
      "Epoch 1647/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1845 - val_loss: 1.5380\n",
      "Epoch 1648/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1846 - val_loss: 1.5093\n",
      "Epoch 1649/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1846 - val_loss: 1.5402\n",
      "Epoch 1650/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.1846 - val_loss: 1.5078\n",
      "Epoch 1651/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1844 - val_loss: 1.5409\n",
      "Epoch 1652/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1842 - val_loss: 1.5097\n",
      "Epoch 1653/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1839 - val_loss: 1.5371\n",
      "Epoch 1654/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1838 - val_loss: 1.5120\n",
      "Epoch 1655/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1834 - val_loss: 1.5303\n",
      "Epoch 1656/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1831 - val_loss: 1.5155\n",
      "Epoch 1657/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1830 - val_loss: 1.5245\n",
      "Epoch 1658/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1826 - val_loss: 1.5204\n",
      "Epoch 1659/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1825 - val_loss: 1.5210\n",
      "Epoch 1660/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1824 - val_loss: 1.5244\n",
      "Epoch 1661/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1822 - val_loss: 1.5178\n",
      "Epoch 1662/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1822 - val_loss: 1.5266\n",
      "Epoch 1663/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1821 - val_loss: 1.5145\n",
      "Epoch 1664/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1818 - val_loss: 1.5277\n",
      "Epoch 1665/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1817 - val_loss: 1.5124\n",
      "Epoch 1666/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1817 - val_loss: 1.5288\n",
      "Epoch 1667/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1815 - val_loss: 1.5114\n",
      "Epoch 1668/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1815 - val_loss: 1.5302\n",
      "Epoch 1669/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1812 - val_loss: 1.5107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1670/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1812 - val_loss: 1.5316\n",
      "Epoch 1671/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1812 - val_loss: 1.5089\n",
      "Epoch 1672/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1810 - val_loss: 1.5317\n",
      "Epoch 1673/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1808 - val_loss: 1.5067\n",
      "Epoch 1674/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1807 - val_loss: 1.5320\n",
      "Epoch 1675/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1807 - val_loss: 1.5059\n",
      "Epoch 1676/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1803 - val_loss: 1.5327\n",
      "Epoch 1677/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1803 - val_loss: 1.5059\n",
      "Epoch 1678/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1804 - val_loss: 1.5329\n",
      "Epoch 1679/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1802 - val_loss: 1.5042\n",
      "Epoch 1680/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1800 - val_loss: 1.5317\n",
      "Epoch 1681/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1799 - val_loss: 1.5028\n",
      "Epoch 1682/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1798 - val_loss: 1.5322\n",
      "Epoch 1683/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.1797 - val_loss: 1.5029\n",
      "Epoch 1684/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1797 - val_loss: 1.5333\n",
      "Epoch 1685/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1795 - val_loss: 1.5025\n",
      "Epoch 1686/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1794 - val_loss: 1.5329\n",
      "Epoch 1687/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1792 - val_loss: 1.5014\n",
      "Epoch 1688/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.1790 - val_loss: 1.5319\n",
      "Epoch 1689/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1791 - val_loss: 1.5006\n",
      "Epoch 1690/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1790 - val_loss: 1.5317\n",
      "Epoch 1691/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1787 - val_loss: 1.5008\n",
      "Epoch 1692/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1785 - val_loss: 1.5321\n",
      "Epoch 1693/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.1784 - val_loss: 1.5007\n",
      "Epoch 1694/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1783 - val_loss: 1.5321\n",
      "Epoch 1695/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1781 - val_loss: 1.4994\n",
      "Epoch 1696/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1780 - val_loss: 1.5320\n",
      "Epoch 1697/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1780 - val_loss: 1.4983\n",
      "Epoch 1698/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1780 - val_loss: 1.5329\n",
      "Epoch 1699/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1778 - val_loss: 1.4976\n",
      "Epoch 1700/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1777 - val_loss: 1.5337\n",
      "Epoch 1701/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1777 - val_loss: 1.4967\n",
      "Epoch 1702/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1776 - val_loss: 1.5336\n",
      "Epoch 1703/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1774 - val_loss: 1.4953\n",
      "Epoch 1704/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1774 - val_loss: 1.5331\n",
      "Epoch 1705/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1772 - val_loss: 1.4944\n",
      "Epoch 1706/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.1771 - val_loss: 1.5330\n",
      "Epoch 1707/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1769 - val_loss: 1.4947\n",
      "Epoch 1708/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1768 - val_loss: 1.5321\n",
      "Epoch 1709/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1765 - val_loss: 1.4957\n",
      "Epoch 1710/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.1764 - val_loss: 1.5303\n",
      "Epoch 1711/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1763 - val_loss: 1.4966\n",
      "Epoch 1712/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1760 - val_loss: 1.5282\n",
      "Epoch 1713/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1757 - val_loss: 1.4975\n",
      "Epoch 1714/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1755 - val_loss: 1.5264\n",
      "Epoch 1715/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1754 - val_loss: 1.4993\n",
      "Epoch 1716/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1752 - val_loss: 1.5252\n",
      "Epoch 1717/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1749 - val_loss: 1.5002\n",
      "Epoch 1718/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1749 - val_loss: 1.5243\n",
      "Epoch 1719/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1747 - val_loss: 1.4994\n",
      "Epoch 1720/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.1745 - val_loss: 1.5235\n",
      "Epoch 1721/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1743 - val_loss: 1.4978\n",
      "Epoch 1722/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1743 - val_loss: 1.5250\n",
      "Epoch 1723/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1743 - val_loss: 1.4962\n",
      "Epoch 1724/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1742 - val_loss: 1.5274\n",
      "Epoch 1725/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1741 - val_loss: 1.4940\n",
      "Epoch 1726/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1742 - val_loss: 1.5301\n",
      "Epoch 1727/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1742 - val_loss: 1.4906\n",
      "Epoch 1728/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1743 - val_loss: 1.5318\n",
      "Epoch 1729/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1743 - val_loss: 1.4877\n",
      "Epoch 1730/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1742 - val_loss: 1.5332\n",
      "Epoch 1731/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1742 - val_loss: 1.4871\n",
      "Epoch 1732/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1741 - val_loss: 1.5330\n",
      "Epoch 1733/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.1740 - val_loss: 1.4876\n",
      "Epoch 1734/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1739 - val_loss: 1.5307\n",
      "Epoch 1735/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1735 - val_loss: 1.4889\n",
      "Epoch 1736/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1732 - val_loss: 1.5270\n",
      "Epoch 1737/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1729 - val_loss: 1.4920\n",
      "Epoch 1738/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1728 - val_loss: 1.5234\n",
      "Epoch 1739/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1722 - val_loss: 1.4956\n",
      "Epoch 1740/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1721 - val_loss: 1.5199\n",
      "Epoch 1741/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 1.1719 - val_loss: 1.4985\n",
      "Epoch 1742/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1716 - val_loss: 1.5159\n",
      "Epoch 1743/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1713 - val_loss: 1.4994\n",
      "Epoch 1744/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1712 - val_loss: 1.5130\n",
      "Epoch 1745/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1711 - val_loss: 1.5001\n",
      "Epoch 1746/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1710 - val_loss: 1.5127\n",
      "Epoch 1747/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1708 - val_loss: 1.5001\n",
      "Epoch 1748/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1706 - val_loss: 1.5139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1749/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1705 - val_loss: 1.4993\n",
      "Epoch 1750/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1705 - val_loss: 1.5159\n",
      "Epoch 1751/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1705 - val_loss: 1.4963\n",
      "Epoch 1752/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1705 - val_loss: 1.5180\n",
      "Epoch 1753/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1703 - val_loss: 1.4919\n",
      "Epoch 1754/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1703 - val_loss: 1.5215\n",
      "Epoch 1755/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1703 - val_loss: 1.4871\n",
      "Epoch 1756/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.1706 - val_loss: 1.5271\n",
      "Epoch 1757/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1709 - val_loss: 1.4829\n",
      "Epoch 1758/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1711 - val_loss: 1.5328\n",
      "Epoch 1759/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1711 - val_loss: 1.4785\n",
      "Epoch 1760/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1714 - val_loss: 1.5370\n",
      "Epoch 1761/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1716 - val_loss: 1.4758\n",
      "Epoch 1762/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1718 - val_loss: 1.5369\n",
      "Epoch 1763/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1715 - val_loss: 1.4753\n",
      "Epoch 1764/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1712 - val_loss: 1.5311\n",
      "Epoch 1765/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1707 - val_loss: 1.4802\n",
      "Epoch 1766/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1701 - val_loss: 1.5217\n",
      "Epoch 1767/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1693 - val_loss: 1.4897\n",
      "Epoch 1768/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1687 - val_loss: 1.5114\n",
      "Epoch 1769/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1682 - val_loss: 1.4988\n",
      "Epoch 1770/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1679 - val_loss: 1.5020\n",
      "Epoch 1771/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1678 - val_loss: 1.5053\n",
      "Epoch 1772/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1677 - val_loss: 1.4942\n",
      "Epoch 1773/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1675 - val_loss: 1.5117\n",
      "Epoch 1774/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1677 - val_loss: 1.4896\n",
      "Epoch 1775/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1678 - val_loss: 1.5185\n",
      "Epoch 1776/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1678 - val_loss: 1.4859\n",
      "Epoch 1777/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1679 - val_loss: 1.5231\n",
      "Epoch 1778/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1679 - val_loss: 1.4823\n",
      "Epoch 1779/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1680 - val_loss: 1.5249\n",
      "Epoch 1780/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.1681 - val_loss: 1.4800\n",
      "Epoch 1781/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1681 - val_loss: 1.5247\n",
      "Epoch 1782/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1679 - val_loss: 1.4804\n",
      "Epoch 1783/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1676 - val_loss: 1.5222\n",
      "Epoch 1784/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1672 - val_loss: 1.4834\n",
      "Epoch 1785/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1669 - val_loss: 1.5172\n",
      "Epoch 1786/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1666 - val_loss: 1.4872\n",
      "Epoch 1787/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1661 - val_loss: 1.5104\n",
      "Epoch 1788/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 1.1659 - val_loss: 1.4913\n",
      "Epoch 1789/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1656 - val_loss: 1.5052\n",
      "Epoch 1790/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1655 - val_loss: 1.4947\n",
      "Epoch 1791/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.1653 - val_loss: 1.5010\n",
      "Epoch 1792/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1651 - val_loss: 1.4968\n",
      "Epoch 1793/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1648 - val_loss: 1.4982\n",
      "Epoch 1794/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1647 - val_loss: 1.4991\n",
      "Epoch 1795/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1647 - val_loss: 1.4965\n",
      "Epoch 1796/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1645 - val_loss: 1.5007\n",
      "Epoch 1797/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1644 - val_loss: 1.4949\n",
      "Epoch 1798/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1643 - val_loss: 1.5029\n",
      "Epoch 1799/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1643 - val_loss: 1.4932\n",
      "Epoch 1800/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1642 - val_loss: 1.5051\n",
      "Epoch 1801/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1641 - val_loss: 1.4898\n",
      "Epoch 1802/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1638 - val_loss: 1.5077\n",
      "Epoch 1803/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1639 - val_loss: 1.4856\n",
      "Epoch 1804/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1639 - val_loss: 1.5117\n",
      "Epoch 1805/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1641 - val_loss: 1.4812\n",
      "Epoch 1806/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1642 - val_loss: 1.5180\n",
      "Epoch 1807/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1643 - val_loss: 1.4751\n",
      "Epoch 1808/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1646 - val_loss: 1.5244\n",
      "Epoch 1809/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1649 - val_loss: 1.4693\n",
      "Epoch 1810/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1654 - val_loss: 1.5294\n",
      "Epoch 1811/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1656 - val_loss: 1.4659\n",
      "Epoch 1812/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1658 - val_loss: 1.5309\n",
      "Epoch 1813/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1656 - val_loss: 1.4661\n",
      "Epoch 1814/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1654 - val_loss: 1.5261\n",
      "Epoch 1815/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1648 - val_loss: 1.4705\n",
      "Epoch 1816/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1640 - val_loss: 1.5154\n",
      "Epoch 1817/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1632 - val_loss: 1.4787\n",
      "Epoch 1818/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1626 - val_loss: 1.5034\n",
      "Epoch 1819/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1620 - val_loss: 1.4885\n",
      "Epoch 1820/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1616 - val_loss: 1.4937\n",
      "Epoch 1821/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1615 - val_loss: 1.4975\n",
      "Epoch 1822/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1615 - val_loss: 1.4865\n",
      "Epoch 1823/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1615 - val_loss: 1.5050\n",
      "Epoch 1824/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1617 - val_loss: 1.4808\n",
      "Epoch 1825/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1617 - val_loss: 1.5105\n",
      "Epoch 1826/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1617 - val_loss: 1.4769\n",
      "Epoch 1827/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1618 - val_loss: 1.5145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1828/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1620 - val_loss: 1.4749\n",
      "Epoch 1829/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1619 - val_loss: 1.5154\n",
      "Epoch 1830/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.1617 - val_loss: 1.4751\n",
      "Epoch 1831/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1615 - val_loss: 1.5137\n",
      "Epoch 1832/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1613 - val_loss: 1.4765\n",
      "Epoch 1833/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1611 - val_loss: 1.5096\n",
      "Epoch 1834/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1608 - val_loss: 1.4791\n",
      "Epoch 1835/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1604 - val_loss: 1.5036\n",
      "Epoch 1836/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1600 - val_loss: 1.4828\n",
      "Epoch 1837/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1598 - val_loss: 1.4989\n",
      "Epoch 1838/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1596 - val_loss: 1.4864\n",
      "Epoch 1839/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1595 - val_loss: 1.4950\n",
      "Epoch 1840/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1594 - val_loss: 1.4890\n",
      "Epoch 1841/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1592 - val_loss: 1.4912\n",
      "Epoch 1842/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.1590 - val_loss: 1.4907\n",
      "Epoch 1843/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1589 - val_loss: 1.4888\n",
      "Epoch 1844/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1588 - val_loss: 1.4929\n",
      "Epoch 1845/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1587 - val_loss: 1.4878\n",
      "Epoch 1846/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.1587 - val_loss: 1.4949\n",
      "Epoch 1847/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1585 - val_loss: 1.4857\n",
      "Epoch 1848/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1584 - val_loss: 1.4961\n",
      "Epoch 1849/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1582 - val_loss: 1.4832\n",
      "Epoch 1850/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1583 - val_loss: 1.4982\n",
      "Epoch 1851/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1582 - val_loss: 1.4804\n",
      "Epoch 1852/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1581 - val_loss: 1.5011\n",
      "Epoch 1853/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1581 - val_loss: 1.4770\n",
      "Epoch 1854/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1582 - val_loss: 1.5048\n",
      "Epoch 1855/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1583 - val_loss: 1.4727\n",
      "Epoch 1856/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1583 - val_loss: 1.5095\n",
      "Epoch 1857/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1585 - val_loss: 1.4681\n",
      "Epoch 1858/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1588 - val_loss: 1.5144\n",
      "Epoch 1859/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1589 - val_loss: 1.4637\n",
      "Epoch 1860/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1591 - val_loss: 1.5185\n",
      "Epoch 1861/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1592 - val_loss: 1.4604\n",
      "Epoch 1862/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1594 - val_loss: 1.5201\n",
      "Epoch 1863/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1594 - val_loss: 1.4599\n",
      "Epoch 1864/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.1592 - val_loss: 1.5167\n",
      "Epoch 1865/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1586 - val_loss: 1.4634\n",
      "Epoch 1866/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1582 - val_loss: 1.5089\n",
      "Epoch 1867/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1575 - val_loss: 1.4706\n",
      "Epoch 1868/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.1570 - val_loss: 1.4988\n",
      "Epoch 1869/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1565 - val_loss: 1.4788\n",
      "Epoch 1870/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1561 - val_loss: 1.4895\n",
      "Epoch 1871/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1558 - val_loss: 1.4858\n",
      "Epoch 1872/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.1558 - val_loss: 1.4825\n",
      "Epoch 1873/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1557 - val_loss: 1.4918\n",
      "Epoch 1874/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1556 - val_loss: 1.4779\n",
      "Epoch 1875/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1556 - val_loss: 1.4975\n",
      "Epoch 1876/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1556 - val_loss: 1.4739\n",
      "Epoch 1877/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1557 - val_loss: 1.5018\n",
      "Epoch 1878/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1559 - val_loss: 1.4705\n",
      "Epoch 1879/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1559 - val_loss: 1.5043\n",
      "Epoch 1880/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1558 - val_loss: 1.4687\n",
      "Epoch 1881/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1558 - val_loss: 1.5050\n",
      "Epoch 1882/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1557 - val_loss: 1.4679\n",
      "Epoch 1883/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1555 - val_loss: 1.5033\n",
      "Epoch 1884/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1553 - val_loss: 1.4686\n",
      "Epoch 1885/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1550 - val_loss: 1.5006\n",
      "Epoch 1886/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.1549 - val_loss: 1.4710\n",
      "Epoch 1887/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1547 - val_loss: 1.4981\n",
      "Epoch 1888/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1544 - val_loss: 1.4729\n",
      "Epoch 1889/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1541 - val_loss: 1.4939\n",
      "Epoch 1890/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1540 - val_loss: 1.4744\n",
      "Epoch 1891/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.1539 - val_loss: 1.4899\n",
      "Epoch 1892/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1536 - val_loss: 1.4759\n",
      "Epoch 1893/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1535 - val_loss: 1.4881\n",
      "Epoch 1894/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1533 - val_loss: 1.4782\n",
      "Epoch 1895/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.1533 - val_loss: 1.4878\n",
      "Epoch 1896/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1531 - val_loss: 1.4784\n",
      "Epoch 1897/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1530 - val_loss: 1.4874\n",
      "Epoch 1898/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1528 - val_loss: 1.4769\n",
      "Epoch 1899/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1527 - val_loss: 1.4883\n",
      "Epoch 1900/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1527 - val_loss: 1.4751\n",
      "Epoch 1901/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1527 - val_loss: 1.4904\n",
      "Epoch 1902/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1526 - val_loss: 1.4731\n",
      "Epoch 1903/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1525 - val_loss: 1.4933\n",
      "Epoch 1904/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1523 - val_loss: 1.4699\n",
      "Epoch 1905/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 1.1523 - val_loss: 1.4974\n",
      "Epoch 1906/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1525 - val_loss: 1.4647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1907/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1525 - val_loss: 1.5011\n",
      "Epoch 1908/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1528 - val_loss: 1.4596\n",
      "Epoch 1909/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1531 - val_loss: 1.5064\n",
      "Epoch 1910/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.1532 - val_loss: 1.4557\n",
      "Epoch 1911/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1535 - val_loss: 1.5112\n",
      "Epoch 1912/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1538 - val_loss: 1.4533\n",
      "Epoch 1913/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1538 - val_loss: 1.5121\n",
      "Epoch 1914/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1536 - val_loss: 1.4528\n",
      "Epoch 1915/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.1535 - val_loss: 1.5084\n",
      "Epoch 1916/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1531 - val_loss: 1.4563\n",
      "Epoch 1917/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1524 - val_loss: 1.5003\n",
      "Epoch 1918/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1518 - val_loss: 1.4629\n",
      "Epoch 1919/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1512 - val_loss: 1.4900\n",
      "Epoch 1920/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1507 - val_loss: 1.4710\n",
      "Epoch 1921/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1504 - val_loss: 1.4813\n",
      "Epoch 1922/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1501 - val_loss: 1.4784\n",
      "Epoch 1923/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1500 - val_loss: 1.4749\n",
      "Epoch 1924/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1500 - val_loss: 1.4835\n",
      "Epoch 1925/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1500 - val_loss: 1.4698\n",
      "Epoch 1926/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1501 - val_loss: 1.4885\n",
      "Epoch 1927/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1500 - val_loss: 1.4661\n",
      "Epoch 1928/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.1500 - val_loss: 1.4928\n",
      "Epoch 1929/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1501 - val_loss: 1.4632\n",
      "Epoch 1930/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1502 - val_loss: 1.4963\n",
      "Epoch 1931/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1501 - val_loss: 1.4611\n",
      "Epoch 1932/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.1501 - val_loss: 1.4976\n",
      "Epoch 1933/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1500 - val_loss: 1.4599\n",
      "Epoch 1934/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1501 - val_loss: 1.4974\n",
      "Epoch 1935/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1500 - val_loss: 1.4595\n",
      "Epoch 1936/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1496 - val_loss: 1.4953\n",
      "Epoch 1937/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1494 - val_loss: 1.4610\n",
      "Epoch 1938/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1493 - val_loss: 1.4925\n",
      "Epoch 1939/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1490 - val_loss: 1.4627\n",
      "Epoch 1940/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.1488 - val_loss: 1.4880\n",
      "Epoch 1941/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1485 - val_loss: 1.4646\n",
      "Epoch 1942/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1483 - val_loss: 1.4840\n",
      "Epoch 1943/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1481 - val_loss: 1.4673\n",
      "Epoch 1944/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1480 - val_loss: 1.4815\n",
      "Epoch 1945/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1478 - val_loss: 1.4698\n",
      "Epoch 1946/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1476 - val_loss: 1.4788\n",
      "Epoch 1947/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1475 - val_loss: 1.4710\n",
      "Epoch 1948/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.1473 - val_loss: 1.4776\n",
      "Epoch 1949/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1472 - val_loss: 1.4717\n",
      "Epoch 1950/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1472 - val_loss: 1.4778\n",
      "Epoch 1951/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1470 - val_loss: 1.4712\n",
      "Epoch 1952/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1469 - val_loss: 1.4783\n",
      "Epoch 1953/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1467 - val_loss: 1.4697\n",
      "Epoch 1954/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1467 - val_loss: 1.4797\n",
      "Epoch 1955/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1466 - val_loss: 1.4675\n",
      "Epoch 1956/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1466 - val_loss: 1.4821\n",
      "Epoch 1957/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1465 - val_loss: 1.4645\n",
      "Epoch 1958/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1466 - val_loss: 1.4860\n",
      "Epoch 1959/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1466 - val_loss: 1.4596\n",
      "Epoch 1960/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1466 - val_loss: 1.4908\n",
      "Epoch 1961/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1467 - val_loss: 1.4541\n",
      "Epoch 1962/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1470 - val_loss: 1.4968\n",
      "Epoch 1963/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1472 - val_loss: 1.4483\n",
      "Epoch 1964/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1475 - val_loss: 1.5027\n",
      "Epoch 1965/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1479 - val_loss: 1.4438\n",
      "Epoch 1966/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.1483 - val_loss: 1.5068\n",
      "Epoch 1967/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1484 - val_loss: 1.4421\n",
      "Epoch 1968/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1484 - val_loss: 1.5057\n",
      "Epoch 1969/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1480 - val_loss: 1.4440\n",
      "Epoch 1970/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1476 - val_loss: 1.4978\n",
      "Epoch 1971/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1469 - val_loss: 1.4500\n",
      "Epoch 1972/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1463 - val_loss: 1.4858\n",
      "Epoch 1973/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1454 - val_loss: 1.4601\n",
      "Epoch 1974/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1449 - val_loss: 1.4751\n",
      "Epoch 1975/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1446 - val_loss: 1.4709\n",
      "Epoch 1976/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.1444 - val_loss: 1.4655\n",
      "Epoch 1977/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1443 - val_loss: 1.4790\n",
      "Epoch 1978/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1445 - val_loss: 1.4578\n",
      "Epoch 1979/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1446 - val_loss: 1.4860\n",
      "Epoch 1980/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1449 - val_loss: 1.4533\n",
      "Epoch 1981/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1451 - val_loss: 1.4912\n",
      "Epoch 1982/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1450 - val_loss: 1.4514\n",
      "Epoch 1983/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1451 - val_loss: 1.4931\n",
      "Epoch 1984/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1451 - val_loss: 1.4519\n",
      "Epoch 1985/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1450 - val_loss: 1.4913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1986/2500\n",
      "64/64 [==============================] - 0s 280us/step - loss: 1.1447 - val_loss: 1.4533\n",
      "Epoch 1987/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1443 - val_loss: 1.4860\n",
      "Epoch 1988/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1440 - val_loss: 1.4564\n",
      "Epoch 1989/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1437 - val_loss: 1.4800\n",
      "Epoch 1990/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1435 - val_loss: 1.4608\n",
      "Epoch 1991/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1431 - val_loss: 1.4748\n",
      "Epoch 1992/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.1429 - val_loss: 1.4645\n",
      "Epoch 1993/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.1426 - val_loss: 1.4699\n",
      "Epoch 1994/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1425 - val_loss: 1.4664\n",
      "Epoch 1995/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1424 - val_loss: 1.4661\n",
      "Epoch 1996/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.1423 - val_loss: 1.4683\n",
      "Epoch 1997/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1422 - val_loss: 1.4641\n",
      "Epoch 1998/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1421 - val_loss: 1.4712\n",
      "Epoch 1999/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1420 - val_loss: 1.4630\n",
      "Epoch 2000/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1419 - val_loss: 1.4741\n",
      "Epoch 2001/2500\n",
      "64/64 [==============================] - 0s 325us/step - loss: 1.1419 - val_loss: 1.4597\n",
      "Epoch 2002/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1418 - val_loss: 1.4761\n",
      "Epoch 2003/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1418 - val_loss: 1.4554\n",
      "Epoch 2004/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1417 - val_loss: 1.4799\n",
      "Epoch 2005/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1419 - val_loss: 1.4525\n",
      "Epoch 2006/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1419 - val_loss: 1.4843\n",
      "Epoch 2007/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1419 - val_loss: 1.4494\n",
      "Epoch 2008/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1422 - val_loss: 1.4882\n",
      "Epoch 2009/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1422 - val_loss: 1.4455\n",
      "Epoch 2010/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1423 - val_loss: 1.4897\n",
      "Epoch 2011/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1423 - val_loss: 1.4432\n",
      "Epoch 2012/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1423 - val_loss: 1.4898\n",
      "Epoch 2013/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1422 - val_loss: 1.4439\n",
      "Epoch 2014/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1421 - val_loss: 1.4881\n",
      "Epoch 2015/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1418 - val_loss: 1.4462\n",
      "Epoch 2016/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1415 - val_loss: 1.4833\n",
      "Epoch 2017/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1411 - val_loss: 1.4498\n",
      "Epoch 2018/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1408 - val_loss: 1.4765\n",
      "Epoch 2019/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1406 - val_loss: 1.4543\n",
      "Epoch 2020/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1402 - val_loss: 1.4706\n",
      "Epoch 2021/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1401 - val_loss: 1.4590\n",
      "Epoch 2022/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1399 - val_loss: 1.4671\n",
      "Epoch 2023/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1397 - val_loss: 1.4623\n",
      "Epoch 2024/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1396 - val_loss: 1.4641\n",
      "Epoch 2025/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1394 - val_loss: 1.4640\n",
      "Epoch 2026/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.1393 - val_loss: 1.4619\n",
      "Epoch 2027/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1391 - val_loss: 1.4661\n",
      "Epoch 2028/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1391 - val_loss: 1.4608\n",
      "Epoch 2029/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.1390 - val_loss: 1.4681\n",
      "Epoch 2030/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1390 - val_loss: 1.4589\n",
      "Epoch 2031/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1389 - val_loss: 1.4692\n",
      "Epoch 2032/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1388 - val_loss: 1.4552\n",
      "Epoch 2033/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1386 - val_loss: 1.4715\n",
      "Epoch 2034/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1386 - val_loss: 1.4523\n",
      "Epoch 2035/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1387 - val_loss: 1.4758\n",
      "Epoch 2036/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1387 - val_loss: 1.4485\n",
      "Epoch 2037/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1388 - val_loss: 1.4800\n",
      "Epoch 2038/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1389 - val_loss: 1.4435\n",
      "Epoch 2039/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1390 - val_loss: 1.4841\n",
      "Epoch 2040/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1392 - val_loss: 1.4387\n",
      "Epoch 2041/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1394 - val_loss: 1.4886\n",
      "Epoch 2042/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1396 - val_loss: 1.4351\n",
      "Epoch 2043/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1399 - val_loss: 1.4912\n",
      "Epoch 2044/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.1399 - val_loss: 1.4343\n",
      "Epoch 2045/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1397 - val_loss: 1.4892\n",
      "Epoch 2046/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1395 - val_loss: 1.4371\n",
      "Epoch 2047/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1390 - val_loss: 1.4823\n",
      "Epoch 2048/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1384 - val_loss: 1.4430\n",
      "Epoch 2049/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1379 - val_loss: 1.4728\n",
      "Epoch 2050/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1373 - val_loss: 1.4506\n",
      "Epoch 2051/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1369 - val_loss: 1.4644\n",
      "Epoch 2052/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1369 - val_loss: 1.4577\n",
      "Epoch 2053/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1367 - val_loss: 1.4572\n",
      "Epoch 2054/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 1.1365 - val_loss: 1.4634\n",
      "Epoch 2055/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1365 - val_loss: 1.4523\n",
      "Epoch 2056/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1364 - val_loss: 1.4686\n",
      "Epoch 2057/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1364 - val_loss: 1.4489\n",
      "Epoch 2058/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1365 - val_loss: 1.4732\n",
      "Epoch 2059/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1365 - val_loss: 1.4460\n",
      "Epoch 2060/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1365 - val_loss: 1.4764\n",
      "Epoch 2061/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1366 - val_loss: 1.4431\n",
      "Epoch 2062/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1367 - val_loss: 1.4780\n",
      "Epoch 2063/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1366 - val_loss: 1.4415\n",
      "Epoch 2064/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1365 - val_loss: 1.4777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2065/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1365 - val_loss: 1.4412\n",
      "Epoch 2066/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1363 - val_loss: 1.4755\n",
      "Epoch 2067/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.1360 - val_loss: 1.4424\n",
      "Epoch 2068/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1359 - val_loss: 1.4728\n",
      "Epoch 2069/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1357 - val_loss: 1.4450\n",
      "Epoch 2070/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1356 - val_loss: 1.4692\n",
      "Epoch 2071/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1352 - val_loss: 1.4467\n",
      "Epoch 2072/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1348 - val_loss: 1.4652\n",
      "Epoch 2073/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1347 - val_loss: 1.4487\n",
      "Epoch 2074/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1347 - val_loss: 1.4621\n",
      "Epoch 2075/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1346 - val_loss: 1.4501\n",
      "Epoch 2076/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1344 - val_loss: 1.4607\n",
      "Epoch 2077/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1342 - val_loss: 1.4520\n",
      "Epoch 2078/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1342 - val_loss: 1.4612\n",
      "Epoch 2079/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1342 - val_loss: 1.4527\n",
      "Epoch 2080/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1341 - val_loss: 1.4612\n",
      "Epoch 2081/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1338 - val_loss: 1.4503\n",
      "Epoch 2082/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.1337 - val_loss: 1.4616\n",
      "Epoch 2083/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1337 - val_loss: 1.4481\n",
      "Epoch 2084/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1337 - val_loss: 1.4639\n",
      "Epoch 2085/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1337 - val_loss: 1.4460\n",
      "Epoch 2086/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1336 - val_loss: 1.4677\n",
      "Epoch 2087/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1335 - val_loss: 1.4429\n",
      "Epoch 2088/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1336 - val_loss: 1.4712\n",
      "Epoch 2089/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1336 - val_loss: 1.4384\n",
      "Epoch 2090/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1336 - val_loss: 1.4742\n",
      "Epoch 2091/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1338 - val_loss: 1.4348\n",
      "Epoch 2092/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1340 - val_loss: 1.4767\n",
      "Epoch 2093/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1340 - val_loss: 1.4324\n",
      "Epoch 2094/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1341 - val_loss: 1.4787\n",
      "Epoch 2095/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1341 - val_loss: 1.4318\n",
      "Epoch 2096/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1339 - val_loss: 1.4777\n",
      "Epoch 2097/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1338 - val_loss: 1.4323\n",
      "Epoch 2098/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1336 - val_loss: 1.4737\n",
      "Epoch 2099/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1332 - val_loss: 1.4352\n",
      "Epoch 2100/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1328 - val_loss: 1.4686\n",
      "Epoch 2101/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1324 - val_loss: 1.4406\n",
      "Epoch 2102/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1322 - val_loss: 1.4630\n",
      "Epoch 2103/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1319 - val_loss: 1.4442\n",
      "Epoch 2104/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1316 - val_loss: 1.4573\n",
      "Epoch 2105/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1314 - val_loss: 1.4473\n",
      "Epoch 2106/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1313 - val_loss: 1.4544\n",
      "Epoch 2107/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1312 - val_loss: 1.4507\n",
      "Epoch 2108/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1311 - val_loss: 1.4527\n",
      "Epoch 2109/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1309 - val_loss: 1.4528\n",
      "Epoch 2110/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1309 - val_loss: 1.4507\n",
      "Epoch 2111/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1308 - val_loss: 1.4539\n",
      "Epoch 2112/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1307 - val_loss: 1.4495\n",
      "Epoch 2113/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1305 - val_loss: 1.4552\n",
      "Epoch 2114/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1304 - val_loss: 1.4481\n",
      "Epoch 2115/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1303 - val_loss: 1.4563\n",
      "Epoch 2116/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.1302 - val_loss: 1.4454\n",
      "Epoch 2117/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1302 - val_loss: 1.4579\n",
      "Epoch 2118/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1301 - val_loss: 1.4425\n",
      "Epoch 2119/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.1301 - val_loss: 1.4602\n",
      "Epoch 2120/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1301 - val_loss: 1.4386\n",
      "Epoch 2121/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1300 - val_loss: 1.4630\n",
      "Epoch 2122/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1300 - val_loss: 1.4355\n",
      "Epoch 2123/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.1301 - val_loss: 1.4673\n",
      "Epoch 2124/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1303 - val_loss: 1.4323\n",
      "Epoch 2125/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1305 - val_loss: 1.4720\n",
      "Epoch 2126/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1306 - val_loss: 1.4280\n",
      "Epoch 2127/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1307 - val_loss: 1.4747\n",
      "Epoch 2128/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1308 - val_loss: 1.4244\n",
      "Epoch 2129/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1309 - val_loss: 1.4762\n",
      "Epoch 2130/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1309 - val_loss: 1.4237\n",
      "Epoch 2131/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1308 - val_loss: 1.4756\n",
      "Epoch 2132/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1306 - val_loss: 1.4254\n",
      "Epoch 2133/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1303 - val_loss: 1.4709\n",
      "Epoch 2134/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1299 - val_loss: 1.4297\n",
      "Epoch 2135/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1294 - val_loss: 1.4636\n",
      "Epoch 2136/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1290 - val_loss: 1.4359\n",
      "Epoch 2137/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1286 - val_loss: 1.4561\n",
      "Epoch 2138/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1283 - val_loss: 1.4425\n",
      "Epoch 2139/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.1281 - val_loss: 1.4498\n",
      "Epoch 2140/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1278 - val_loss: 1.4479\n",
      "Epoch 2141/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1278 - val_loss: 1.4446\n",
      "Epoch 2142/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1277 - val_loss: 1.4519\n",
      "Epoch 2143/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.1277 - val_loss: 1.4401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2144/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.1273 - val_loss: 1.4562\n",
      "Epoch 2145/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1274 - val_loss: 1.4372\n",
      "Epoch 2146/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1275 - val_loss: 1.4606\n",
      "Epoch 2147/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1276 - val_loss: 1.4337\n",
      "Epoch 2148/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1276 - val_loss: 1.4639\n",
      "Epoch 2149/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1277 - val_loss: 1.4299\n",
      "Epoch 2150/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1278 - val_loss: 1.4664\n",
      "Epoch 2151/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1278 - val_loss: 1.4273\n",
      "Epoch 2152/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1279 - val_loss: 1.4671\n",
      "Epoch 2153/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1277 - val_loss: 1.4261\n",
      "Epoch 2154/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1278 - val_loss: 1.4665\n",
      "Epoch 2155/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1277 - val_loss: 1.4267\n",
      "Epoch 2156/2500\n",
      "64/64 [==============================] - 0s 276us/step - loss: 1.1273 - val_loss: 1.4634\n",
      "Epoch 2157/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1270 - val_loss: 1.4293\n",
      "Epoch 2158/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1270 - val_loss: 1.4591\n",
      "Epoch 2159/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.1266 - val_loss: 1.4322\n",
      "Epoch 2160/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1263 - val_loss: 1.4545\n",
      "Epoch 2161/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1261 - val_loss: 1.4363\n",
      "Epoch 2162/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1257 - val_loss: 1.4505\n",
      "Epoch 2163/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1257 - val_loss: 1.4400\n",
      "Epoch 2164/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1256 - val_loss: 1.4471\n",
      "Epoch 2165/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1255 - val_loss: 1.4423\n",
      "Epoch 2166/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1254 - val_loss: 1.4444\n",
      "Epoch 2167/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1252 - val_loss: 1.4439\n",
      "Epoch 2168/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.1251 - val_loss: 1.4429\n",
      "Epoch 2169/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1250 - val_loss: 1.4454\n",
      "Epoch 2170/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1249 - val_loss: 1.4420\n",
      "Epoch 2171/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1247 - val_loss: 1.4460\n",
      "Epoch 2172/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1248 - val_loss: 1.4409\n",
      "Epoch 2173/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.1246 - val_loss: 1.4466\n",
      "Epoch 2174/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1245 - val_loss: 1.4393\n",
      "Epoch 2175/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1244 - val_loss: 1.4477\n",
      "Epoch 2176/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1243 - val_loss: 1.4378\n",
      "Epoch 2177/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1242 - val_loss: 1.4489\n",
      "Epoch 2178/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.1242 - val_loss: 1.4350\n",
      "Epoch 2179/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1241 - val_loss: 1.4502\n",
      "Epoch 2180/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1240 - val_loss: 1.4318\n",
      "Epoch 2181/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1240 - val_loss: 1.4542\n",
      "Epoch 2182/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1241 - val_loss: 1.4283\n",
      "Epoch 2183/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1242 - val_loss: 1.4587\n",
      "Epoch 2184/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1242 - val_loss: 1.4235\n",
      "Epoch 2185/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.1243 - val_loss: 1.4637\n",
      "Epoch 2186/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1246 - val_loss: 1.4186\n",
      "Epoch 2187/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1249 - val_loss: 1.4678\n",
      "Epoch 2188/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1251 - val_loss: 1.4150\n",
      "Epoch 2189/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.1252 - val_loss: 1.4700\n",
      "Epoch 2190/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1252 - val_loss: 1.4146\n",
      "Epoch 2191/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1251 - val_loss: 1.4678\n",
      "Epoch 2192/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1248 - val_loss: 1.4173\n",
      "Epoch 2193/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1243 - val_loss: 1.4616\n",
      "Epoch 2194/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.1239 - val_loss: 1.4228\n",
      "Epoch 2195/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1235 - val_loss: 1.4545\n",
      "Epoch 2196/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1231 - val_loss: 1.4298\n",
      "Epoch 2197/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1227 - val_loss: 1.4470\n",
      "Epoch 2198/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1225 - val_loss: 1.4358\n",
      "Epoch 2199/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1223 - val_loss: 1.4399\n",
      "Epoch 2200/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1221 - val_loss: 1.4401\n",
      "Epoch 2201/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1220 - val_loss: 1.4344\n",
      "Epoch 2202/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.1219 - val_loss: 1.4452\n",
      "Epoch 2203/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1219 - val_loss: 1.4320\n",
      "Epoch 2204/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1219 - val_loss: 1.4503\n",
      "Epoch 2205/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1220 - val_loss: 1.4294\n",
      "Epoch 2206/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1221 - val_loss: 1.4533\n",
      "Epoch 2207/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 1.1219 - val_loss: 1.4253\n",
      "Epoch 2208/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1220 - val_loss: 1.4550\n",
      "Epoch 2209/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1219 - val_loss: 1.4222\n",
      "Epoch 2210/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1221 - val_loss: 1.4569\n",
      "Epoch 2211/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.1220 - val_loss: 1.4210\n",
      "Epoch 2212/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1219 - val_loss: 1.4578\n",
      "Epoch 2213/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1218 - val_loss: 1.4211\n",
      "Epoch 2214/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1219 - val_loss: 1.4566\n",
      "Epoch 2215/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.1216 - val_loss: 1.4214\n",
      "Epoch 2216/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1212 - val_loss: 1.4532\n",
      "Epoch 2217/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1211 - val_loss: 1.4228\n",
      "Epoch 2218/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1210 - val_loss: 1.4493\n",
      "Epoch 2219/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.1208 - val_loss: 1.4257\n",
      "Epoch 2220/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.1206 - val_loss: 1.4465\n",
      "Epoch 2221/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1204 - val_loss: 1.4283\n",
      "Epoch 2222/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1202 - val_loss: 1.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2223/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.1200 - val_loss: 1.4294\n",
      "Epoch 2224/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1200 - val_loss: 1.4407\n",
      "Epoch 2225/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1197 - val_loss: 1.4302\n",
      "Epoch 2226/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1196 - val_loss: 1.4401\n",
      "Epoch 2227/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.1196 - val_loss: 1.4313\n",
      "Epoch 2228/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1195 - val_loss: 1.4411\n",
      "Epoch 2229/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1194 - val_loss: 1.4315\n",
      "Epoch 2230/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1194 - val_loss: 1.4426\n",
      "Epoch 2231/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1192 - val_loss: 1.4295\n",
      "Epoch 2232/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.1192 - val_loss: 1.4444\n",
      "Epoch 2233/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1193 - val_loss: 1.4265\n",
      "Epoch 2234/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1192 - val_loss: 1.4468\n",
      "Epoch 2235/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1192 - val_loss: 1.4229\n",
      "Epoch 2236/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1193 - val_loss: 1.4505\n",
      "Epoch 2237/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1194 - val_loss: 1.4192\n",
      "Epoch 2238/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1195 - val_loss: 1.4544\n",
      "Epoch 2239/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1196 - val_loss: 1.4148\n",
      "Epoch 2240/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1197 - val_loss: 1.4576\n",
      "Epoch 2241/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 1.1198 - val_loss: 1.4114\n",
      "Epoch 2242/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1200 - val_loss: 1.4597\n",
      "Epoch 2243/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1199 - val_loss: 1.4105\n",
      "Epoch 2244/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1199 - val_loss: 1.4591\n",
      "Epoch 2245/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.1197 - val_loss: 1.4120\n",
      "Epoch 2246/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 1.1195 - val_loss: 1.4538\n",
      "Epoch 2247/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1191 - val_loss: 1.4159\n",
      "Epoch 2248/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.1187 - val_loss: 1.4462\n",
      "Epoch 2249/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1182 - val_loss: 1.4228\n",
      "Epoch 2250/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1180 - val_loss: 1.4394\n",
      "Epoch 2251/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1176 - val_loss: 1.4294\n",
      "Epoch 2252/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 1.1174 - val_loss: 1.4331\n",
      "Epoch 2253/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1172 - val_loss: 1.4344\n",
      "Epoch 2254/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1172 - val_loss: 1.4289\n",
      "Epoch 2255/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1172 - val_loss: 1.4384\n",
      "Epoch 2256/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 1.1171 - val_loss: 1.4250\n",
      "Epoch 2257/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1170 - val_loss: 1.4418\n",
      "Epoch 2258/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1171 - val_loss: 1.4218\n",
      "Epoch 2259/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1172 - val_loss: 1.4459\n",
      "Epoch 2260/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1172 - val_loss: 1.4194\n",
      "Epoch 2261/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1172 - val_loss: 1.4498\n",
      "Epoch 2262/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1173 - val_loss: 1.4165\n",
      "Epoch 2263/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1174 - val_loss: 1.4511\n",
      "Epoch 2264/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1173 - val_loss: 1.4131\n",
      "Epoch 2265/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1173 - val_loss: 1.4506\n",
      "Epoch 2266/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1174 - val_loss: 1.4124\n",
      "Epoch 2267/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1173 - val_loss: 1.4493\n",
      "Epoch 2268/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1171 - val_loss: 1.4147\n",
      "Epoch 2269/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1168 - val_loss: 1.4463\n",
      "Epoch 2270/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1166 - val_loss: 1.4182\n",
      "Epoch 2271/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1163 - val_loss: 1.4409\n",
      "Epoch 2272/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1160 - val_loss: 1.4212\n",
      "Epoch 2273/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1158 - val_loss: 1.4364\n",
      "Epoch 2274/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1156 - val_loss: 1.4239\n",
      "Epoch 2275/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1154 - val_loss: 1.4331\n",
      "Epoch 2276/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1153 - val_loss: 1.4263\n",
      "Epoch 2277/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1152 - val_loss: 1.4316\n",
      "Epoch 2278/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1152 - val_loss: 1.4284\n",
      "Epoch 2279/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1150 - val_loss: 1.4309\n",
      "Epoch 2280/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1149 - val_loss: 1.4291\n",
      "Epoch 2281/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1148 - val_loss: 1.4302\n",
      "Epoch 2282/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1148 - val_loss: 1.4289\n",
      "Epoch 2283/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 1.1148 - val_loss: 1.4295\n",
      "Epoch 2284/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1145 - val_loss: 1.4285\n",
      "Epoch 2285/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1144 - val_loss: 1.4299\n",
      "Epoch 2286/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1145 - val_loss: 1.4281\n",
      "Epoch 2287/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1144 - val_loss: 1.4299\n",
      "Epoch 2288/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1141 - val_loss: 1.4266\n",
      "Epoch 2289/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1140 - val_loss: 1.4307\n",
      "Epoch 2290/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1140 - val_loss: 1.4246\n",
      "Epoch 2291/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.1139 - val_loss: 1.4323\n",
      "Epoch 2292/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1138 - val_loss: 1.4219\n",
      "Epoch 2293/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1138 - val_loss: 1.4353\n",
      "Epoch 2294/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1138 - val_loss: 1.4179\n",
      "Epoch 2295/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1138 - val_loss: 1.4387\n",
      "Epoch 2296/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1138 - val_loss: 1.4128\n",
      "Epoch 2297/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1138 - val_loss: 1.4435\n",
      "Epoch 2298/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1140 - val_loss: 1.4083\n",
      "Epoch 2299/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.1143 - val_loss: 1.4500\n",
      "Epoch 2300/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1145 - val_loss: 1.4036\n",
      "Epoch 2301/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1148 - val_loss: 1.4552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2302/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1152 - val_loss: 1.3993\n",
      "Epoch 2303/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1154 - val_loss: 1.4582\n",
      "Epoch 2304/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.1155 - val_loss: 1.3981\n",
      "Epoch 2305/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1155 - val_loss: 1.4569\n",
      "Epoch 2306/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1151 - val_loss: 1.4008\n",
      "Epoch 2307/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.1147 - val_loss: 1.4506\n",
      "Epoch 2308/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1142 - val_loss: 1.4070\n",
      "Epoch 2309/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1136 - val_loss: 1.4400\n",
      "Epoch 2310/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1130 - val_loss: 1.4154\n",
      "Epoch 2311/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1125 - val_loss: 1.4300\n",
      "Epoch 2312/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1122 - val_loss: 1.4240\n",
      "Epoch 2313/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.1121 - val_loss: 1.4220\n",
      "Epoch 2314/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1120 - val_loss: 1.4299\n",
      "Epoch 2315/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1119 - val_loss: 1.4159\n",
      "Epoch 2316/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1120 - val_loss: 1.4358\n",
      "Epoch 2317/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1121 - val_loss: 1.4121\n",
      "Epoch 2318/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1123 - val_loss: 1.4405\n",
      "Epoch 2319/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1123 - val_loss: 1.4090\n",
      "Epoch 2320/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1122 - val_loss: 1.4427\n",
      "Epoch 2321/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.1122 - val_loss: 1.4078\n",
      "Epoch 2322/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1124 - val_loss: 1.4429\n",
      "Epoch 2323/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1123 - val_loss: 1.4080\n",
      "Epoch 2324/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1120 - val_loss: 1.4402\n",
      "Epoch 2325/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.1117 - val_loss: 1.4104\n",
      "Epoch 2326/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1115 - val_loss: 1.4358\n",
      "Epoch 2327/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1113 - val_loss: 1.4138\n",
      "Epoch 2328/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 1.1111 - val_loss: 1.4310\n",
      "Epoch 2329/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1108 - val_loss: 1.4177\n",
      "Epoch 2330/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1107 - val_loss: 1.4267\n",
      "Epoch 2331/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1106 - val_loss: 1.4209\n",
      "Epoch 2332/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.1104 - val_loss: 1.4229\n",
      "Epoch 2333/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1103 - val_loss: 1.4230\n",
      "Epoch 2334/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1102 - val_loss: 1.4196\n",
      "Epoch 2335/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1101 - val_loss: 1.4249\n",
      "Epoch 2336/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1100 - val_loss: 1.4181\n",
      "Epoch 2337/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.1100 - val_loss: 1.4272\n",
      "Epoch 2338/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1099 - val_loss: 1.4159\n",
      "Epoch 2339/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1099 - val_loss: 1.4294\n",
      "Epoch 2340/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1099 - val_loss: 1.4131\n",
      "Epoch 2341/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1099 - val_loss: 1.4319\n",
      "Epoch 2342/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1099 - val_loss: 1.4100\n",
      "Epoch 2343/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1100 - val_loss: 1.4353\n",
      "Epoch 2344/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1100 - val_loss: 1.4077\n",
      "Epoch 2345/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1101 - val_loss: 1.4387\n",
      "Epoch 2346/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.1102 - val_loss: 1.4046\n",
      "Epoch 2347/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1101 - val_loss: 1.4400\n",
      "Epoch 2348/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1100 - val_loss: 1.4021\n",
      "Epoch 2349/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1101 - val_loss: 1.4407\n",
      "Epoch 2350/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1102 - val_loss: 1.4017\n",
      "Epoch 2351/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1099 - val_loss: 1.4399\n",
      "Epoch 2352/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1098 - val_loss: 1.4032\n",
      "Epoch 2353/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1096 - val_loss: 1.4370\n",
      "Epoch 2354/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1094 - val_loss: 1.4059\n",
      "Epoch 2355/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1091 - val_loss: 1.4333\n",
      "Epoch 2356/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1087 - val_loss: 1.4090\n",
      "Epoch 2357/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1086 - val_loss: 1.4287\n",
      "Epoch 2358/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1085 - val_loss: 1.4116\n",
      "Epoch 2359/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.1082 - val_loss: 1.4240\n",
      "Epoch 2360/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1079 - val_loss: 1.4135\n",
      "Epoch 2361/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1080 - val_loss: 1.4223\n",
      "Epoch 2362/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1080 - val_loss: 1.4161\n",
      "Epoch 2363/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 1.1078 - val_loss: 1.4215\n",
      "Epoch 2364/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1078 - val_loss: 1.4176\n",
      "Epoch 2365/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1076 - val_loss: 1.4207\n",
      "Epoch 2366/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1076 - val_loss: 1.4177\n",
      "Epoch 2367/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1076 - val_loss: 1.4198\n",
      "Epoch 2368/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1076 - val_loss: 1.4173\n",
      "Epoch 2369/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1074 - val_loss: 1.4204\n",
      "Epoch 2370/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.1074 - val_loss: 1.4164\n",
      "Epoch 2371/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1073 - val_loss: 1.4207\n",
      "Epoch 2372/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1073 - val_loss: 1.4149\n",
      "Epoch 2373/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1072 - val_loss: 1.4209\n",
      "Epoch 2374/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1071 - val_loss: 1.4136\n",
      "Epoch 2375/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1070 - val_loss: 1.4225\n",
      "Epoch 2376/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1069 - val_loss: 1.4116\n",
      "Epoch 2377/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1070 - val_loss: 1.4257\n",
      "Epoch 2378/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 1.1069 - val_loss: 1.4082\n",
      "Epoch 2379/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1070 - val_loss: 1.4292\n",
      "Epoch 2380/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1070 - val_loss: 1.4031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2381/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1070 - val_loss: 1.4337\n",
      "Epoch 2382/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1072 - val_loss: 1.3982\n",
      "Epoch 2383/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1075 - val_loss: 1.4394\n",
      "Epoch 2384/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1077 - val_loss: 1.3937\n",
      "Epoch 2385/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1080 - val_loss: 1.4447\n",
      "Epoch 2386/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1083 - val_loss: 1.3900\n",
      "Epoch 2387/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1084 - val_loss: 1.4468\n",
      "Epoch 2388/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1085 - val_loss: 1.3891\n",
      "Epoch 2389/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1085 - val_loss: 1.4448\n",
      "Epoch 2390/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.1082 - val_loss: 1.3923\n",
      "Epoch 2391/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1077 - val_loss: 1.4381\n",
      "Epoch 2392/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1071 - val_loss: 1.3990\n",
      "Epoch 2393/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1065 - val_loss: 1.4280\n",
      "Epoch 2394/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1060 - val_loss: 1.4067\n",
      "Epoch 2395/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1057 - val_loss: 1.4184\n",
      "Epoch 2396/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1054 - val_loss: 1.4133\n",
      "Epoch 2397/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1053 - val_loss: 1.4113\n",
      "Epoch 2398/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1055 - val_loss: 1.4197\n",
      "Epoch 2399/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1054 - val_loss: 1.4067\n",
      "Epoch 2400/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1053 - val_loss: 1.4258\n",
      "Epoch 2401/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1055 - val_loss: 1.4035\n",
      "Epoch 2402/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 1.1056 - val_loss: 1.4304\n",
      "Epoch 2403/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1057 - val_loss: 1.4000\n",
      "Epoch 2404/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1057 - val_loss: 1.4326\n",
      "Epoch 2405/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1057 - val_loss: 1.3980\n",
      "Epoch 2406/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.1058 - val_loss: 1.4329\n",
      "Epoch 2407/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1056 - val_loss: 1.3975\n",
      "Epoch 2408/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1054 - val_loss: 1.4317\n",
      "Epoch 2409/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1053 - val_loss: 1.3994\n",
      "Epoch 2410/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1052 - val_loss: 1.4291\n",
      "Epoch 2411/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1050 - val_loss: 1.4013\n",
      "Epoch 2412/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1048 - val_loss: 1.4247\n",
      "Epoch 2413/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1046 - val_loss: 1.4033\n",
      "Epoch 2414/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1044 - val_loss: 1.4206\n",
      "Epoch 2415/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1043 - val_loss: 1.4065\n",
      "Epoch 2416/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1041 - val_loss: 1.4173\n",
      "Epoch 2417/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1040 - val_loss: 1.4095\n",
      "Epoch 2418/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1040 - val_loss: 1.4144\n",
      "Epoch 2419/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.1038 - val_loss: 1.4115\n",
      "Epoch 2420/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1037 - val_loss: 1.4124\n",
      "Epoch 2421/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1036 - val_loss: 1.4125\n",
      "Epoch 2422/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1036 - val_loss: 1.4108\n",
      "Epoch 2423/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1035 - val_loss: 1.4135\n",
      "Epoch 2424/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1034 - val_loss: 1.4095\n",
      "Epoch 2425/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1033 - val_loss: 1.4150\n",
      "Epoch 2426/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1033 - val_loss: 1.4091\n",
      "Epoch 2427/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1032 - val_loss: 1.4167\n",
      "Epoch 2428/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.1032 - val_loss: 1.4073\n",
      "Epoch 2429/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1032 - val_loss: 1.4173\n",
      "Epoch 2430/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1032 - val_loss: 1.4045\n",
      "Epoch 2431/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1030 - val_loss: 1.4189\n",
      "Epoch 2432/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1030 - val_loss: 1.4027\n",
      "Epoch 2433/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1030 - val_loss: 1.4223\n",
      "Epoch 2434/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1030 - val_loss: 1.3995\n",
      "Epoch 2435/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1030 - val_loss: 1.4250\n",
      "Epoch 2436/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1030 - val_loss: 1.3953\n",
      "Epoch 2437/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1032 - val_loss: 1.4276\n",
      "Epoch 2438/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 1.1033 - val_loss: 1.3924\n",
      "Epoch 2439/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.1033 - val_loss: 1.4303\n",
      "Epoch 2440/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1034 - val_loss: 1.3915\n",
      "Epoch 2441/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1034 - val_loss: 1.4325\n",
      "Epoch 2442/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1034 - val_loss: 1.3913\n",
      "Epoch 2443/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 1.1033 - val_loss: 1.4313\n",
      "Epoch 2444/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1031 - val_loss: 1.3914\n",
      "Epoch 2445/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1029 - val_loss: 1.4278\n",
      "Epoch 2446/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1027 - val_loss: 1.3934\n",
      "Epoch 2447/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1025 - val_loss: 1.4240\n",
      "Epoch 2448/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1022 - val_loss: 1.3971\n",
      "Epoch 2449/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1021 - val_loss: 1.4204\n",
      "Epoch 2450/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1018 - val_loss: 1.4002\n",
      "Epoch 2451/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1017 - val_loss: 1.4168\n",
      "Epoch 2452/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1016 - val_loss: 1.4023\n",
      "Epoch 2453/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1015 - val_loss: 1.4139\n",
      "Epoch 2454/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1014 - val_loss: 1.4035\n",
      "Epoch 2455/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1012 - val_loss: 1.4123\n",
      "Epoch 2456/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1011 - val_loss: 1.4041\n",
      "Epoch 2457/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1011 - val_loss: 1.4124\n",
      "Epoch 2458/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1012 - val_loss: 1.4041\n",
      "Epoch 2459/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1010 - val_loss: 1.4131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2460/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1009 - val_loss: 1.4040\n",
      "Epoch 2461/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1008 - val_loss: 1.4145\n",
      "Epoch 2462/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1008 - val_loss: 1.4015\n",
      "Epoch 2463/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1008 - val_loss: 1.4160\n",
      "Epoch 2464/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1006 - val_loss: 1.3976\n",
      "Epoch 2465/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1006 - val_loss: 1.4198\n",
      "Epoch 2466/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 1.1009 - val_loss: 1.3944\n",
      "Epoch 2467/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1009 - val_loss: 1.4238\n",
      "Epoch 2468/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1008 - val_loss: 1.3907\n",
      "Epoch 2469/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1011 - val_loss: 1.4281\n",
      "Epoch 2470/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.1013 - val_loss: 1.3864\n",
      "Epoch 2471/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1015 - val_loss: 1.4309\n",
      "Epoch 2472/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1017 - val_loss: 1.3838\n",
      "Epoch 2473/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1016 - val_loss: 1.4317\n",
      "Epoch 2474/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.1016 - val_loss: 1.3838\n",
      "Epoch 2475/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.1016 - val_loss: 1.4292\n",
      "Epoch 2476/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1012 - val_loss: 1.3868\n",
      "Epoch 2477/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1008 - val_loss: 1.4236\n",
      "Epoch 2478/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.1005 - val_loss: 1.3926\n",
      "Epoch 2479/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1001 - val_loss: 1.4167\n",
      "Epoch 2480/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.0996 - val_loss: 1.3983\n",
      "Epoch 2481/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.0994 - val_loss: 1.4100\n",
      "Epoch 2482/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.0993 - val_loss: 1.4034\n",
      "Epoch 2483/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0992 - val_loss: 1.4041\n",
      "Epoch 2484/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.0991 - val_loss: 1.4073\n",
      "Epoch 2485/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.0991 - val_loss: 1.4005\n",
      "Epoch 2486/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.0991 - val_loss: 1.4115\n",
      "Epoch 2487/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.0990 - val_loss: 1.3984\n",
      "Epoch 2488/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.0990 - val_loss: 1.4152\n",
      "Epoch 2489/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.0990 - val_loss: 1.3951\n",
      "Epoch 2490/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.0991 - val_loss: 1.4171\n",
      "Epoch 2491/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.0990 - val_loss: 1.3917\n",
      "Epoch 2492/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.0991 - val_loss: 1.4205\n",
      "Epoch 2493/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0992 - val_loss: 1.3898\n",
      "Epoch 2494/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.0994 - val_loss: 1.4238\n",
      "Epoch 2495/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.0993 - val_loss: 1.3873\n",
      "Epoch 2496/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.0992 - val_loss: 1.4246\n",
      "Epoch 2497/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0993 - val_loss: 1.3853\n",
      "Epoch 2498/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.0993 - val_loss: 1.4237\n",
      "Epoch 2499/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.0993 - val_loss: 1.3860\n",
      "Epoch 2500/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.0991 - val_loss: 1.4220\n"
     ]
    }
   ],
   "source": [
    "model_L1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "L1_reg = model_L1.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_L1 = L1_reg.validation_data[0]\n",
    "Y_val_L1 = L1_reg.validation_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(0.0, 5, 1000)\n",
    "y_pred_L2 = model_L2.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20,14), sharex=True)\n",
    "\n",
    "ax[0].plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax[0].plot(X_train, Y_train, '.', label='Training data')\n",
    "ax[0].plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax[0].plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax[0].plot(X_range, y_pred_L2, lw=4, ls='--', color='g', label=r'$L_{2}$ Prediction')\n",
    "\n",
    "ax[0].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[0].tick_params(labelsize=20)\n",
    "\n",
    "ax[0].legend(loc=1, fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_L1 = model_L1.predict(X_range)\n",
    "\n",
    "ax[1].plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax[1].plot(X_train, Y_train, '.', label='Training data')\n",
    "ax[1].plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax[1].plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax[1].plot(X_range, y_pred_L1, lw=4, ls='--', color='g', label=r'$L_{1}$ Prediction')\n",
    "\n",
    "ax[1].set_xlabel(r'$X$', fontsize=20)\n",
    "ax[1].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[1].tick_params(labelsize=20)\n",
    "\n",
    "ax[1].legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping\n",
    "The results without any regularization do not look right.  $L_{2}$ and $L_{1}$ regularizaton helped somewhat, but the results still aren't convincing.\n",
    "\n",
    "We can gain some more insight by plotting the loss functions from the training and validation set.  Let's use a `log-log` scale to enhance any discrepancies between the two curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a reminder.\n",
    "\n",
    "Remember that the `fit` method can store the history of the model.  For the unregularized model we stored all the history in the name `no_reg`.  Let's see what attributes are in that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'epoch',\n",
       " 'history',\n",
       " 'model',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'params',\n",
       " 'set_model',\n",
       " 'set_params',\n",
       " 'validation_data']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(no_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of stuff; most of it we're not interested in.  However, at the very end of the list, we see some useful keys.  Let's access some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no_reg.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `history` is a dictionary.  Let's take a look at it's keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_reg.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool.  There is a `validation` and `training` loss.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the one we'll want to use right now, but we can look at the other attributes too just to get a feel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no_reg.validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no_reg.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'epochs', 'steps', 'samples', 'verbose', 'do_validation', 'metrics'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_reg.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_reg.params['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was fun and informative.  But what we're really after is the loss data as a function of epoch number.  Here we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = no_reg.history['loss']\n",
    "L_val = no_reg.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "ax.plot(L, label='Training Loss')\n",
    "ax.plot(L_val, label='Validation Loss')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(r'Epochs', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow.  That is striking.\n",
    "\n",
    "We used $2500$ epochs, but the validation loss begins to rise at around $50$ epochs and becomes larger than the training loss at around $70$ epochs.  After that, we're basically overfitting.\n",
    "\n",
    "Notice that the training loss keeps decreasing.  We're fitting the training data better and better all the time.  The validation loss is getting larger and larger meaning that we're losing generalizability.\n",
    "\n",
    "We can use this new information to our advantage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### Part 1\n",
    "Train a network without any penalization, but this time stop after $20$ epochs.\n",
    "\n",
    "### Part 2\n",
    "Train a network without any penalization, but this time stop at the \"optimal\" number of epochs (based on the crossing of the loss curves).\n",
    "\n",
    "**Deliverables**\n",
    "* Plot the following on a single figure:\n",
    "  - The true solution\n",
    "  - The model prediction without any regularization (after $2500$ epochs)\n",
    "  - The model prediction without any regularization using $20$ epochs\n",
    "  - The model prediction without any regularization using the optimal number of epochs\n",
    "* You may also want to include the training and validation data on the same plot.  Be careful that the plot doesn't become too cluttered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/20\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 5.6850 - val_loss: 4.3010\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 0s 93us/step - loss: 5.4600 - val_loss: 4.1267\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 0s 74us/step - loss: 5.2879 - val_loss: 3.9640\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 0s 57us/step - loss: 5.1291 - val_loss: 3.8122\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 0s 54us/step - loss: 4.9815 - val_loss: 3.6669\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 0s 76us/step - loss: 4.8420 - val_loss: 3.5258\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 0s 66us/step - loss: 4.7103 - val_loss: 3.3956\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 0s 162us/step - loss: 4.5926 - val_loss: 3.2867\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 0s 142us/step - loss: 4.5014 - val_loss: 3.2074\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 0s 76us/step - loss: 4.4459 - val_loss: 3.1723\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 0s 93us/step - loss: 4.4390 - val_loss: 3.1780\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 0s 143us/step - loss: 4.4732 - val_loss: 3.1893\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 0s 51us/step - loss: 4.5036 - val_loss: 3.1746\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 0s 82us/step - loss: 4.4937 - val_loss: 3.1367\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 0s 53us/step - loss: 4.4497 - val_loss: 3.0901\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 0s 109us/step - loss: 4.3894 - val_loss: 3.0518\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 0s 70us/step - loss: 4.3342 - val_loss: 3.0304\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 0s 50us/step - loss: 4.2953 - val_loss: 3.0258\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 0s 67us/step - loss: 4.2753 - val_loss: 3.0297\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 0s 43us/step - loss: 4.2668 - val_loss: 3.0334\n"
     ]
    }
   ],
   "source": [
    "no_reg_20 = model.fit(X_train, Y_train, epochs=20, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_range = np.linspace(0.0, 5, 1000)\n",
    "y_pred_20 = model.predict(X_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/75\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 5.5814 - val_loss: 4.2742\n",
      "Epoch 2/75\n",
      "64/64 [==============================] - 0s 68us/step - loss: 5.4333 - val_loss: 4.1437\n",
      "Epoch 3/75\n",
      "64/64 [==============================] - 0s 78us/step - loss: 5.3041 - val_loss: 4.0190\n",
      "Epoch 4/75\n",
      "64/64 [==============================] - 0s 68us/step - loss: 5.1810 - val_loss: 3.8716\n",
      "Epoch 5/75\n",
      "64/64 [==============================] - 0s 48us/step - loss: 5.0383 - val_loss: 3.6972\n",
      "Epoch 6/75\n",
      "64/64 [==============================] - 0s 70us/step - loss: 4.8703 - val_loss: 3.5241\n",
      "Epoch 7/75\n",
      "64/64 [==============================] - 0s 56us/step - loss: 4.7081 - val_loss: 3.3718\n",
      "Epoch 8/75\n",
      "64/64 [==============================] - 0s 84us/step - loss: 4.5720 - val_loss: 3.2516\n",
      "Epoch 9/75\n",
      "64/64 [==============================] - 0s 132us/step - loss: 4.4736 - val_loss: 3.1815\n",
      "Epoch 10/75\n",
      "64/64 [==============================] - 0s 136us/step - loss: 4.4328 - val_loss: 3.1722\n",
      "Epoch 11/75\n",
      "64/64 [==============================] - 0s 82us/step - loss: 4.4562 - val_loss: 3.1913\n",
      "Epoch 12/75\n",
      "64/64 [==============================] - 0s 107us/step - loss: 4.5020 - val_loss: 3.1885\n",
      "Epoch 13/75\n",
      "64/64 [==============================] - 0s 102us/step - loss: 4.5098 - val_loss: 3.1520\n",
      "Epoch 14/75\n",
      "64/64 [==============================] - 0s 61us/step - loss: 4.4675 - val_loss: 3.1000\n",
      "Epoch 15/75\n",
      "64/64 [==============================] - 0s 60us/step - loss: 4.3989 - val_loss: 3.0613\n",
      "Epoch 16/75\n",
      "64/64 [==============================] - 0s 80us/step - loss: 4.3404 - val_loss: 3.0435\n",
      "Epoch 17/75\n",
      "64/64 [==============================] - 0s 134us/step - loss: 4.3033 - val_loss: 3.0416\n",
      "Epoch 18/75\n",
      "64/64 [==============================] - 0s 108us/step - loss: 4.2854 - val_loss: 3.0480\n",
      "Epoch 19/75\n",
      "64/64 [==============================] - 0s 80us/step - loss: 4.2788 - val_loss: 3.0523\n",
      "Epoch 20/75\n",
      "64/64 [==============================] - 0s 51us/step - loss: 4.2743 - val_loss: 3.0474\n",
      "Epoch 21/75\n",
      "64/64 [==============================] - 0s 82us/step - loss: 4.2641 - val_loss: 3.0283\n",
      "Epoch 22/75\n",
      "64/64 [==============================] - 0s 151us/step - loss: 4.2420 - val_loss: 2.9959\n",
      "Epoch 23/75\n",
      "64/64 [==============================] - 0s 58us/step - loss: 4.2102 - val_loss: 2.9539\n",
      "Epoch 24/75\n",
      "64/64 [==============================] - 0s 54us/step - loss: 4.1719 - val_loss: 2.9073\n",
      "Epoch 25/75\n",
      "64/64 [==============================] - 0s 50us/step - loss: 4.1309 - val_loss: 2.8604\n",
      "Epoch 26/75\n",
      "64/64 [==============================] - 0s 53us/step - loss: 4.0910 - val_loss: 2.8190\n",
      "Epoch 27/75\n",
      "64/64 [==============================] - 0s 49us/step - loss: 4.0569 - val_loss: 2.7845\n",
      "Epoch 28/75\n",
      "64/64 [==============================] - 0s 111us/step - loss: 4.0267 - val_loss: 2.7562\n",
      "Epoch 29/75\n",
      "64/64 [==============================] - 0s 146us/step - loss: 3.9990 - val_loss: 2.7306\n",
      "Epoch 30/75\n",
      "64/64 [==============================] - 0s 69us/step - loss: 3.9670 - val_loss: 2.7051\n",
      "Epoch 31/75\n",
      "64/64 [==============================] - 0s 64us/step - loss: 3.9266 - val_loss: 2.6788\n",
      "Epoch 32/75\n",
      "64/64 [==============================] - 0s 88us/step - loss: 3.8770 - val_loss: 2.6569\n",
      "Epoch 33/75\n",
      "64/64 [==============================] - 0s 144us/step - loss: 3.8254 - val_loss: 2.6386\n",
      "Epoch 34/75\n",
      "64/64 [==============================] - 0s 47us/step - loss: 3.7746 - val_loss: 2.6248\n",
      "Epoch 35/75\n",
      "64/64 [==============================] - 0s 56us/step - loss: 3.7269 - val_loss: 2.6083\n",
      "Epoch 36/75\n",
      "64/64 [==============================] - 0s 50us/step - loss: 3.6775 - val_loss: 2.5816\n",
      "Epoch 37/75\n",
      "64/64 [==============================] - 0s 51us/step - loss: 3.6198 - val_loss: 2.5435\n",
      "Epoch 38/75\n",
      "64/64 [==============================] - 0s 47us/step - loss: 3.5524 - val_loss: 2.4985\n",
      "Epoch 39/75\n",
      "64/64 [==============================] - 0s 62us/step - loss: 3.4804 - val_loss: 2.4444\n",
      "Epoch 40/75\n",
      "64/64 [==============================] - 0s 57us/step - loss: 3.4030 - val_loss: 2.3909\n",
      "Epoch 41/75\n",
      "64/64 [==============================] - 0s 65us/step - loss: 3.3285 - val_loss: 2.3391\n",
      "Epoch 42/75\n",
      "64/64 [==============================] - 0s 47us/step - loss: 3.2494 - val_loss: 2.2893\n",
      "Epoch 43/75\n",
      "64/64 [==============================] - 0s 71us/step - loss: 3.1642 - val_loss: 2.2379\n",
      "Epoch 44/75\n",
      "64/64 [==============================] - 0s 89us/step - loss: 3.0751 - val_loss: 2.1881\n",
      "Epoch 45/75\n",
      "64/64 [==============================] - 0s 106us/step - loss: 2.9876 - val_loss: 2.1353\n",
      "Epoch 46/75\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.9017 - val_loss: 2.0667\n",
      "Epoch 47/75\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.8112 - val_loss: 1.9850\n",
      "Epoch 48/75\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.7159 - val_loss: 1.9064\n",
      "Epoch 49/75\n",
      "64/64 [==============================] - 0s 230us/step - loss: 2.6299 - val_loss: 1.8281\n",
      "Epoch 50/75\n",
      "64/64 [==============================] - 0s 83us/step - loss: 2.5344 - val_loss: 1.7651\n",
      "Epoch 51/75\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.4404 - val_loss: 1.7021\n",
      "Epoch 52/75\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.3521 - val_loss: 1.6022\n",
      "Epoch 53/75\n",
      "64/64 [==============================] - 0s 157us/step - loss: 2.2529 - val_loss: 1.5134\n",
      "Epoch 54/75\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.1678 - val_loss: 1.4564\n",
      "Epoch 55/75\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.0761 - val_loss: 1.4036\n",
      "Epoch 56/75\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.9948 - val_loss: 1.3029\n",
      "Epoch 57/75\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.9112 - val_loss: 1.2501\n",
      "Epoch 58/75\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.8337 - val_loss: 1.2565\n",
      "Epoch 59/75\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.7680 - val_loss: 1.1460\n",
      "Epoch 60/75\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.7003 - val_loss: 1.1777\n",
      "Epoch 61/75\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.6331 - val_loss: 1.1580\n",
      "Epoch 62/75\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.5731 - val_loss: 1.1060\n",
      "Epoch 63/75\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.5231 - val_loss: 1.3182\n",
      "Epoch 64/75\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4989 - val_loss: 1.0226\n",
      "Epoch 65/75\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5233 - val_loss: 1.4517\n",
      "Epoch 66/75\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4413 - val_loss: 1.3443\n",
      "Epoch 67/75\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.3630 - val_loss: 1.0809\n",
      "Epoch 68/75\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3962 - val_loss: 1.3833\n",
      "Epoch 69/75\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2865 - val_loss: 1.5812\n",
      "Epoch 70/75\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2947 - val_loss: 1.2049\n",
      "Epoch 71/75\n",
      "64/64 [==============================] - 0s 253us/step - loss: 1.2446 - val_loss: 1.2781\n",
      "Epoch 72/75\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1862 - val_loss: 1.6365\n",
      "Epoch 73/75\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1901 - val_loss: 1.3551\n",
      "Epoch 74/75\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1029 - val_loss: 1.1817\n",
      "Epoch 75/75\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1032 - val_loss: 1.4452\n"
     ]
    }
   ],
   "source": [
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "no_reg_75 = model.fit(X_train, Y_train, epochs=75, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_75 = model.predict(X_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10,8))\n",
    "\n",
    "ax.plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax.plot(X_train, Y_train, '.', label='Training data')\n",
    "ax.plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax.plot(X_range, y_pred_20, lw=4, ls='--', color='g', label=r'$20$ Epochs')\n",
    "ax.plot(X_range, y_pred_75, lw=4, ls=':', color='m', label=r'$75$ Epochs')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=3, ncol=2, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to do things more systematically.\n",
    "\n",
    "How do you think early stopping should be implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do early stopping in `Keras`, you specify the `EarlyStopping` [*callback*](https://keras.io/callbacks/).  From the documentation:\n",
    "> A callback is a set of functions to be applied at given stages of the training procedure.\n",
    "\n",
    "Callbacks can be used to view internal states and statistic of the model during training.\n",
    "\n",
    "Right now, we'll use one to monitor the validation loss function.  When the validation loss starts to go up, the training process will stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Syntax\n",
    "To specify a callback, you just pass a `callbacks` list into the model `fit()` method, like this:\n",
    "```python\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2, \n",
    "          callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Fit the model using the early stopping technique.  Try different values for `patience` to see which one gives you the lowest validation loss.\n",
    "\n",
    "How many epochs are needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 5.5357 - val_loss: 4.1557\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 5.3162 - val_loss: 3.9106\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 5.0770 - val_loss: 3.6994\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 4.8734 - val_loss: 3.5102\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 4.6960 - val_loss: 3.3440\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 4.5474 - val_loss: 3.2187\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 4.4472 - val_loss: 3.1557\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 4.4162 - val_loss: 3.1568\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 4.4521 - val_loss: 3.1769\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 4.4971 - val_loss: 3.1631\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 4.4888 - val_loss: 3.1144\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 4.4297 - val_loss: 3.0601\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 4.3570 - val_loss: 3.0229\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 4.2992 - val_loss: 3.0100\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 4.2668 - val_loss: 3.0143\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 4.2546 - val_loss: 3.0229\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 4.2504 - val_loss: 3.0236\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 4.2423 - val_loss: 3.0096\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 4.2229 - val_loss: 2.9795\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 4.1906 - val_loss: 2.9365\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 4.1487 - val_loss: 2.8854\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 4.1016 - val_loss: 2.8328\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 4.0562 - val_loss: 2.7856\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 4.0164 - val_loss: 2.7463\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 3.9838 - val_loss: 2.7139\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 3.9529 - val_loss: 2.6848\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 3.9181 - val_loss: 2.6547\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 3.8725 - val_loss: 2.6244\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 3.8176 - val_loss: 2.5996\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 3.7624 - val_loss: 2.5812\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 3.7120 - val_loss: 2.5643\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 3.6649 - val_loss: 2.5415\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 3.6145 - val_loss: 2.5051\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 3.5551 - val_loss: 2.4520\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 3.4840 - val_loss: 2.3921\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 3.4097 - val_loss: 2.3355\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 3.3412 - val_loss: 2.2838\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 3.2692 - val_loss: 2.2335\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 3.1885 - val_loss: 2.1853\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 3.1032 - val_loss: 2.1406\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 3.0203 - val_loss: 2.0892\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.9385 - val_loss: 2.0173\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.8441 - val_loss: 1.9396\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.7472 - val_loss: 1.8636\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 2.6581 - val_loss: 1.7889\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 2.5662 - val_loss: 1.7183\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.4701 - val_loss: 1.6618\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.3811 - val_loss: 1.5864\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.2862 - val_loss: 1.4983\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 287us/step - loss: 2.1874 - val_loss: 1.4240\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.0914 - val_loss: 1.3722\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.9977 - val_loss: 1.3016\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.9067 - val_loss: 1.2093\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.8203 - val_loss: 1.1830\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.7307 - val_loss: 1.1246\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6461 - val_loss: 1.0464\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.5686 - val_loss: 1.1228\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.5060 - val_loss: 0.9349\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4571 - val_loss: 1.1941\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.4029 - val_loss: 0.9454\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.3086 - val_loss: 0.9592\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.2539 - val_loss: 1.2732\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2536 - val_loss: 0.9016\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2357 - val_loss: 1.2551\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1466 - val_loss: 1.2184\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.0941 - val_loss: 1.0171\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 1.1208 - val_loss: 1.5134\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.0878 - val_loss: 1.2356\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit model\n",
    "no_reg_ES = model.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2, \n",
    "                     callbacks=[EarlyStopping(monitor='val_loss', patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_ES = model.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,8))\n",
    "\n",
    "ax.plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax.plot(X_train, Y_train, '.', label='Training data')\n",
    "ax.plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax.plot(X_range, y_pred_ES, lw=4, ls=':', color='b', label=r'Early Stopping')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=3, ncol=2, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution should looks pretty good.  Of course, we had to play with the `patience` parameter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
