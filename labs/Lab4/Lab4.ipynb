{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4:  Regularization\n",
    "\n",
    "## Saturday, November 3rd 2018\n",
    "\n",
    "#### David Sondak and Pavlos Protopapas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Lecture 3 introduced several types of regularization.  In today's lab, you will become more familiar with those regularization techniques and actually apply them to a problem.  The types of regularization that you will explore today are:\n",
    "* Penalization\n",
    "* Early stopping\n",
    "* Dropout\n",
    "\n",
    "There are many other types of regularization (as mentioned in lecture).  The three regularization techniques that you will explore today are very popular and used frequently in real applications.\n",
    "\n",
    "We'll begin the story by building a neural network to learn a function from some noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warming Up\n",
    "Today we'll try to fit the function $$f\\left(x\\right) = x\\sin\\left(x\\right).$$\n",
    "\n",
    "Using `keras`, build a fully-connected neural network to fit $f\\left(x\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll generate some synthetic data with some synthetic noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100 # set the number of samples to take for each toy dataset\n",
    "test_size = 0.2 # set the proportion of toy data to hold out for testing\n",
    "random_seed = 1 # set the random seed to make the experiment reproducible \n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# define a function\n",
    "f = lambda x: x * np.sin(x)\n",
    "\n",
    "# Generate the truth function (without any noise)\n",
    "X_true = np.linspace(0.0, 5.0, n_samples)\n",
    "Y_true = f(X_true)\n",
    "\n",
    "# Now sample the true function at some points\n",
    "X = np.random.permutation(X_true) # choose some points from the function - this is our toy dataset \n",
    "Y = f(X)\n",
    "\n",
    "Y = Y + np.random.normal(0.0, 1.0, len(Y)) # Add some noise from a random normal distribution\n",
    "\n",
    "# create training and testing data from this set of points\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build a network.  We choose $5$ hidden layers and $100$ nodes per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for _ in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll fit the model.  \n",
    "\n",
    "Notice that we're specifying a *validation set*.  What this means is that `keras` will further split the training set into a training part and a validation part.  The neural network will only be trained on the *training* set.  Meanwhile, `keras` will report performance metrics on the *validation* set so we can get a sense of how well the model has been trained.  We will be using the validation set quite a bit in this lab.\n",
    "\n",
    "Remember, we don't want to use the test set for anything relating to the training of our models.  By withholding the validation set, we can assess the model performance on the validation set.  Later, we can see how the model performs on data it has never seen before by using in on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 12ms/step - loss: 5.6882 - val_loss: 4.2976\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 5.4559 - val_loss: 4.0915\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 5.2525 - val_loss: 3.9141\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 5.0797 - val_loss: 3.7370\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 4.9095 - val_loss: 3.5784\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 4.7597 - val_loss: 3.4278\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 4.6210 - val_loss: 3.3011\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 557us/step - loss: 4.5127 - val_loss: 3.2093\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 4.4457 - val_loss: 3.1686\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 4.4357 - val_loss: 3.1716\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 4.4678 - val_loss: 3.1814\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 4.4966 - val_loss: 3.1607\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 4.4795 - val_loss: 3.1141\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 4.4232 - val_loss: 3.0658\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 4.3583 - val_loss: 3.0334\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 4.3077 - val_loss: 3.0203\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 4.2774 - val_loss: 3.0212\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 4.2631 - val_loss: 3.0248\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 544us/step - loss: 4.2552 - val_loss: 3.0231\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 414us/step - loss: 4.2452 - val_loss: 3.0103\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 4.2277 - val_loss: 2.9840\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 4.1996 - val_loss: 2.9461\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 4.1625 - val_loss: 2.9006\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 445us/step - loss: 4.1202 - val_loss: 2.8528\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 4.0774 - val_loss: 2.8073\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 4.0381 - val_loss: 2.7682\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 330us/step - loss: 4.0053 - val_loss: 2.7359\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 3.9765 - val_loss: 2.7073\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 3.9448 - val_loss: 2.6795\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 3.9066 - val_loss: 2.6506\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 3.8600 - val_loss: 2.6239\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 3.8081 - val_loss: 2.6025\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 3.7571 - val_loss: 2.5871\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 3.7111 - val_loss: 2.5713\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 3.6660 - val_loss: 2.5487\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 3.6175 - val_loss: 2.5141\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 3.5607 - val_loss: 2.4685\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 3.4957 - val_loss: 2.4155\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 3.4266 - val_loss: 2.3600\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 3.3537 - val_loss: 2.3088\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 3.2844 - val_loss: 2.2590\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 3.2116 - val_loss: 2.2091\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 3.1320 - val_loss: 2.1631\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 3.0506 - val_loss: 2.1166\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 2.9697 - val_loss: 2.0660\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 2.8895 - val_loss: 2.0051\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 2.8065 - val_loss: 1.9349\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 2.7208 - val_loss: 1.8658\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.6365 - val_loss: 1.7989\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.5518 - val_loss: 1.7355\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 334us/step - loss: 2.4674 - val_loss: 1.6754\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.3851 - val_loss: 1.6069\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 2.3005 - val_loss: 1.5321\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 2.2170 - val_loss: 1.4668\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.1366 - val_loss: 1.4184\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.0572 - val_loss: 1.3679\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 298us/step - loss: 1.9808 - val_loss: 1.3009\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.9056 - val_loss: 1.2602\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 1.8336 - val_loss: 1.2355\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.7684 - val_loss: 1.1745\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 471us/step - loss: 1.7073 - val_loss: 1.1890\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6500 - val_loss: 1.1523\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.5951 - val_loss: 1.1552\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.5463 - val_loss: 1.1733\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5019 - val_loss: 1.1406\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4627 - val_loss: 1.3760\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4553 - val_loss: 1.0549\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.5652 - val_loss: 1.4767\n",
      "Epoch 69/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4065 - val_loss: 1.6246\n",
      "Epoch 70/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4239 - val_loss: 1.1535\n",
      "Epoch 71/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 1.3558 - val_loss: 1.1692\n",
      "Epoch 72/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3303 - val_loss: 1.6060\n",
      "Epoch 73/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.3057 - val_loss: 1.5867\n",
      "Epoch 74/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2672 - val_loss: 1.2289\n",
      "Epoch 75/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2423 - val_loss: 1.2760\n",
      "Epoch 76/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2003 - val_loss: 1.6347\n",
      "Epoch 77/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1862 - val_loss: 1.5647\n",
      "Epoch 78/2500\n",
      "64/64 [==============================] - 0s 290us/step - loss: 1.1399 - val_loss: 1.2514\n",
      "Epoch 79/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1263 - val_loss: 1.2980\n",
      "Epoch 80/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.0697 - val_loss: 1.5721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.0734 - val_loss: 1.3866\n",
      "Epoch 82/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.0113 - val_loss: 1.1587\n",
      "Epoch 83/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.0239 - val_loss: 1.3033\n",
      "Epoch 84/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.9624 - val_loss: 1.5021\n",
      "Epoch 85/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.9766 - val_loss: 1.2996\n",
      "Epoch 86/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.9264 - val_loss: 1.2416\n",
      "Epoch 87/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 0.9343 - val_loss: 1.4583\n",
      "Epoch 88/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.9019 - val_loss: 1.4914\n",
      "Epoch 89/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8956 - val_loss: 1.2856\n",
      "Epoch 90/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.8826 - val_loss: 1.3145\n",
      "Epoch 91/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.8640 - val_loss: 1.4967\n",
      "Epoch 92/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.8697 - val_loss: 1.3818\n",
      "Epoch 93/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.8449 - val_loss: 1.2688\n",
      "Epoch 94/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.8593 - val_loss: 1.4190\n",
      "Epoch 95/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.8388 - val_loss: 1.4269\n",
      "Epoch 96/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.8393 - val_loss: 1.2474\n",
      "Epoch 97/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.8383 - val_loss: 1.2761\n",
      "Epoch 98/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.8236 - val_loss: 1.3771\n",
      "Epoch 99/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.8322 - val_loss: 1.2518\n",
      "Epoch 100/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 0.8172 - val_loss: 1.1884\n",
      "Epoch 101/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.8238 - val_loss: 1.2972\n",
      "Epoch 102/2500\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.8167 - val_loss: 1.2904\n",
      "Epoch 103/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.8140 - val_loss: 1.1851\n",
      "Epoch 104/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.8159 - val_loss: 1.2352\n",
      "Epoch 105/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.8062 - val_loss: 1.3081\n",
      "Epoch 106/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.8109 - val_loss: 1.2214\n",
      "Epoch 107/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.8031 - val_loss: 1.2124\n",
      "Epoch 108/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.8032 - val_loss: 1.3112\n",
      "Epoch 109/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.8025 - val_loss: 1.2708\n",
      "Epoch 110/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7967 - val_loss: 1.2162\n",
      "Epoch 111/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.8001 - val_loss: 1.2947\n",
      "Epoch 112/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.7953 - val_loss: 1.2866\n",
      "Epoch 113/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.7936 - val_loss: 1.2098\n",
      "Epoch 114/2500\n",
      "64/64 [==============================] - 0s 619us/step - loss: 0.7943 - val_loss: 1.2551\n",
      "Epoch 115/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.7895 - val_loss: 1.2590\n",
      "Epoch 116/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.7889 - val_loss: 1.1928\n",
      "Epoch 117/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.7878 - val_loss: 1.2155\n",
      "Epoch 118/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 0.7844 - val_loss: 1.2464\n",
      "Epoch 119/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.7846 - val_loss: 1.1945\n",
      "Epoch 120/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7831 - val_loss: 1.2187\n",
      "Epoch 121/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.7810 - val_loss: 1.2494\n",
      "Epoch 122/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.7811 - val_loss: 1.2022\n",
      "Epoch 123/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.7796 - val_loss: 1.2132\n",
      "Epoch 124/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7776 - val_loss: 1.2306\n",
      "Epoch 125/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.7771 - val_loss: 1.1916\n",
      "Epoch 126/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.7755 - val_loss: 1.2226\n",
      "Epoch 127/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7733 - val_loss: 1.2453\n",
      "Epoch 128/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7724 - val_loss: 1.2153\n",
      "Epoch 129/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7718 - val_loss: 1.2370\n",
      "Epoch 130/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7700 - val_loss: 1.2335\n",
      "Epoch 131/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.7689 - val_loss: 1.1955\n",
      "Epoch 132/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7682 - val_loss: 1.2241\n",
      "Epoch 133/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7665 - val_loss: 1.2175\n",
      "Epoch 134/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.7651 - val_loss: 1.2022\n",
      "Epoch 135/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.7642 - val_loss: 1.2426\n",
      "Epoch 136/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.7631 - val_loss: 1.2236\n",
      "Epoch 137/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7616 - val_loss: 1.2032\n",
      "Epoch 138/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.7604 - val_loss: 1.2233\n",
      "Epoch 139/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.7595 - val_loss: 1.1949\n",
      "Epoch 140/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.7584 - val_loss: 1.2097\n",
      "Epoch 141/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.7567 - val_loss: 1.2146\n",
      "Epoch 142/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.7556 - val_loss: 1.1960\n",
      "Epoch 143/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.7547 - val_loss: 1.2266\n",
      "Epoch 144/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.7538 - val_loss: 1.1944\n",
      "Epoch 145/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.7525 - val_loss: 1.2089\n",
      "Epoch 146/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.7511 - val_loss: 1.2263\n",
      "Epoch 147/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.7501 - val_loss: 1.1945\n",
      "Epoch 148/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.7492 - val_loss: 1.2202\n",
      "Epoch 149/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.7482 - val_loss: 1.1998\n",
      "Epoch 150/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.7467 - val_loss: 1.2065\n",
      "Epoch 151/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.7455 - val_loss: 1.2042\n",
      "Epoch 152/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.7443 - val_loss: 1.2035\n",
      "Epoch 153/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.7431 - val_loss: 1.2108\n",
      "Epoch 154/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.7423 - val_loss: 1.1742\n",
      "Epoch 155/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.7411 - val_loss: 1.2028\n",
      "Epoch 156/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.7399 - val_loss: 1.1862\n",
      "Epoch 157/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7384 - val_loss: 1.1785\n",
      "Epoch 158/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.7373 - val_loss: 1.2086\n",
      "Epoch 159/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.7365 - val_loss: 1.1663\n",
      "Epoch 160/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 0.7362 - val_loss: 1.2137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.7348 - val_loss: 1.1656\n",
      "Epoch 162/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7340 - val_loss: 1.2155\n",
      "Epoch 163/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.7330 - val_loss: 1.1542\n",
      "Epoch 164/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.7315 - val_loss: 1.1877\n",
      "Epoch 165/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.7295 - val_loss: 1.1768\n",
      "Epoch 166/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 0.7286 - val_loss: 1.1560\n",
      "Epoch 167/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7281 - val_loss: 1.1996\n",
      "Epoch 168/2500\n",
      "64/64 [==============================] - 0s 293us/step - loss: 0.7274 - val_loss: 1.1519\n",
      "Epoch 169/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.7267 - val_loss: 1.2047\n",
      "Epoch 170/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 0.7256 - val_loss: 1.1464\n",
      "Epoch 171/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.7243 - val_loss: 1.1957\n",
      "Epoch 172/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.7230 - val_loss: 1.1438\n",
      "Epoch 173/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.7219 - val_loss: 1.1860\n",
      "Epoch 174/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.7213 - val_loss: 1.1149\n",
      "Epoch 175/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.7208 - val_loss: 1.1915\n",
      "Epoch 176/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.7204 - val_loss: 1.1238\n",
      "Epoch 177/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.7202 - val_loss: 1.2292\n",
      "Epoch 178/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.7217 - val_loss: 1.0872\n",
      "Epoch 179/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.7240 - val_loss: 1.2518\n",
      "Epoch 180/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7265 - val_loss: 1.0702\n",
      "Epoch 181/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.7266 - val_loss: 1.2308\n",
      "Epoch 182/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.7254 - val_loss: 1.0979\n",
      "Epoch 183/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7161 - val_loss: 1.1807\n",
      "Epoch 184/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.7100 - val_loss: 1.1510\n",
      "Epoch 185/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.7082 - val_loss: 1.1019\n",
      "Epoch 186/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.7105 - val_loss: 1.2246\n",
      "Epoch 187/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.7131 - val_loss: 1.0789\n",
      "Epoch 188/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.7144 - val_loss: 1.2438\n",
      "Epoch 189/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7181 - val_loss: 1.0969\n",
      "Epoch 190/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 0.7103 - val_loss: 1.1580\n",
      "Epoch 191/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.7034 - val_loss: 1.1509\n",
      "Epoch 192/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.7024 - val_loss: 1.0865\n",
      "Epoch 193/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 0.7062 - val_loss: 1.2074\n",
      "Epoch 194/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.7090 - val_loss: 1.0723\n",
      "Epoch 195/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.7070 - val_loss: 1.2048\n",
      "Epoch 196/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.7030 - val_loss: 1.1210\n",
      "Epoch 197/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.6977 - val_loss: 1.1118\n",
      "Epoch 198/2500\n",
      "64/64 [==============================] - 0s 345us/step - loss: 0.6962 - val_loss: 1.1801\n",
      "Epoch 199/2500\n",
      "64/64 [==============================] - 0s 407us/step - loss: 0.6985 - val_loss: 1.0583\n",
      "Epoch 200/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.7015 - val_loss: 1.2085\n",
      "Epoch 201/2500\n",
      "64/64 [==============================] - 0s 360us/step - loss: 0.7016 - val_loss: 1.0650\n",
      "Epoch 202/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.6994 - val_loss: 1.1741\n",
      "Epoch 203/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6955 - val_loss: 1.0880\n",
      "Epoch 204/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 0.6909 - val_loss: 1.1399\n",
      "Epoch 205/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6889 - val_loss: 1.1203\n",
      "Epoch 206/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.6887 - val_loss: 1.0752\n",
      "Epoch 207/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.6888 - val_loss: 1.1768\n",
      "Epoch 208/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.6900 - val_loss: 1.0433\n",
      "Epoch 209/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6892 - val_loss: 1.1464\n",
      "Epoch 210/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.6867 - val_loss: 1.1148\n",
      "Epoch 211/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 0.6848 - val_loss: 1.0778\n",
      "Epoch 212/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.6839 - val_loss: 1.1350\n",
      "Epoch 213/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 0.6844 - val_loss: 1.0710\n",
      "Epoch 214/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.6884 - val_loss: 1.1839\n",
      "Epoch 215/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6938 - val_loss: 1.0337\n",
      "Epoch 216/2500\n",
      "64/64 [==============================] - 0s 546us/step - loss: 0.6900 - val_loss: 1.1623\n",
      "Epoch 217/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.6841 - val_loss: 1.0643\n",
      "Epoch 218/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.6793 - val_loss: 1.0543\n",
      "Epoch 219/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.6787 - val_loss: 1.1447\n",
      "Epoch 220/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.6810 - val_loss: 1.0252\n",
      "Epoch 221/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6841 - val_loss: 1.1724\n",
      "Epoch 222/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.6852 - val_loss: 1.0516\n",
      "Epoch 223/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.6809 - val_loss: 1.1063\n",
      "Epoch 224/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6751 - val_loss: 1.0816\n",
      "Epoch 225/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.6731 - val_loss: 1.0509\n",
      "Epoch 226/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6740 - val_loss: 1.1148\n",
      "Epoch 227/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.6756 - val_loss: 1.0055\n",
      "Epoch 228/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6784 - val_loss: 1.1960\n",
      "Epoch 229/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6863 - val_loss: 1.0000\n",
      "Epoch 230/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6804 - val_loss: 1.1370\n",
      "Epoch 231/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6744 - val_loss: 1.0741\n",
      "Epoch 232/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 0.6690 - val_loss: 1.0228\n",
      "Epoch 233/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 0.6703 - val_loss: 1.1512\n",
      "Epoch 234/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.6798 - val_loss: 0.9839\n",
      "Epoch 235/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6779 - val_loss: 1.1273\n",
      "Epoch 236/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6739 - val_loss: 1.0575\n",
      "Epoch 237/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.6662 - val_loss: 1.0114\n",
      "Epoch 238/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.6712 - val_loss: 1.2164\n",
      "Epoch 239/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6887 - val_loss: 0.9500\n",
      "Epoch 240/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.6786 - val_loss: 1.1343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.6683 - val_loss: 1.0676\n",
      "Epoch 242/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6649 - val_loss: 0.9500\n",
      "Epoch 243/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.6723 - val_loss: 1.1916\n",
      "Epoch 244/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6819 - val_loss: 0.9626\n",
      "Epoch 245/2500\n",
      "64/64 [==============================] - 0s 195us/step - loss: 0.6667 - val_loss: 1.0120\n",
      "Epoch 246/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6609 - val_loss: 1.1062\n",
      "Epoch 247/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6660 - val_loss: 0.9445\n",
      "Epoch 248/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.6681 - val_loss: 1.1242\n",
      "Epoch 249/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.6684 - val_loss: 1.0025\n",
      "Epoch 250/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.6595 - val_loss: 0.9977\n",
      "Epoch 251/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6579 - val_loss: 1.0621\n",
      "Epoch 252/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6608 - val_loss: 0.9477\n",
      "Epoch 253/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.6638 - val_loss: 1.1121\n",
      "Epoch 254/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6645 - val_loss: 0.9692\n",
      "Epoch 255/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6605 - val_loss: 1.0478\n",
      "Epoch 256/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 0.6549 - val_loss: 1.0296\n",
      "Epoch 257/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.6543 - val_loss: 0.9461\n",
      "Epoch 258/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6625 - val_loss: 1.1142\n",
      "Epoch 259/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 0.6655 - val_loss: 0.9187\n",
      "Epoch 260/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.6603 - val_loss: 1.1041\n",
      "Epoch 261/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6575 - val_loss: 0.9799\n",
      "Epoch 262/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.6527 - val_loss: 0.9694\n",
      "Epoch 263/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.6512 - val_loss: 1.0630\n",
      "Epoch 264/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.6542 - val_loss: 0.8977\n",
      "Epoch 265/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6559 - val_loss: 1.0979\n",
      "Epoch 266/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.6562 - val_loss: 0.9920\n",
      "Epoch 267/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 0.6570 - val_loss: 0.9930\n",
      "Epoch 268/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6510 - val_loss: 1.0026\n",
      "Epoch 269/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.6458 - val_loss: 0.9741\n",
      "Epoch 270/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.6529 - val_loss: 1.0455\n",
      "Epoch 271/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.6586 - val_loss: 0.9226\n",
      "Epoch 272/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6566 - val_loss: 1.1337\n",
      "Epoch 273/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.6540 - val_loss: 0.9794\n",
      "Epoch 274/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 0.6464 - val_loss: 0.8956\n",
      "Epoch 275/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 0.6543 - val_loss: 1.1744\n",
      "Epoch 276/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.6645 - val_loss: 0.9314\n",
      "Epoch 277/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.6453 - val_loss: 0.9359\n",
      "Epoch 278/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6456 - val_loss: 1.1158\n",
      "Epoch 279/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.6500 - val_loss: 0.9783\n",
      "Epoch 280/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 0.6432 - val_loss: 0.9353\n",
      "Epoch 281/2500\n",
      "64/64 [==============================] - 0s 418us/step - loss: 0.6413 - val_loss: 1.0766\n",
      "Epoch 282/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.6480 - val_loss: 0.9192\n",
      "Epoch 283/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.6602 - val_loss: 1.1105\n",
      "Epoch 284/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6589 - val_loss: 0.9625\n",
      "Epoch 285/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6407 - val_loss: 0.9596\n",
      "Epoch 286/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.6476 - val_loss: 1.1562\n",
      "Epoch 287/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.6697 - val_loss: 0.8722\n",
      "Epoch 288/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.6519 - val_loss: 1.0102\n",
      "Epoch 289/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6369 - val_loss: 1.0960\n",
      "Epoch 290/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.6482 - val_loss: 0.9039\n",
      "Epoch 291/2500\n",
      "64/64 [==============================] - 0s 341us/step - loss: 0.6452 - val_loss: 1.0480\n",
      "Epoch 292/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.6358 - val_loss: 1.0252\n",
      "Epoch 293/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 0.6362 - val_loss: 0.8893\n",
      "Epoch 294/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6428 - val_loss: 1.0956\n",
      "Epoch 295/2500\n",
      "64/64 [==============================] - 0s 386us/step - loss: 0.6422 - val_loss: 0.9375\n",
      "Epoch 296/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6338 - val_loss: 0.9362\n",
      "Epoch 297/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 0.6334 - val_loss: 1.1144\n",
      "Epoch 298/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6431 - val_loss: 0.8855\n",
      "Epoch 299/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.6415 - val_loss: 1.0593\n",
      "Epoch 300/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.6348 - val_loss: 0.9768\n",
      "Epoch 301/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 0.6290 - val_loss: 0.9293\n",
      "Epoch 302/2500\n",
      "64/64 [==============================] - 0s 428us/step - loss: 0.6311 - val_loss: 1.0625\n",
      "Epoch 303/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.6366 - val_loss: 0.9286\n",
      "Epoch 304/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 0.6309 - val_loss: 1.0564\n",
      "Epoch 305/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.6310 - val_loss: 0.9793\n",
      "Epoch 306/2500\n",
      "64/64 [==============================] - 0s 437us/step - loss: 0.6262 - val_loss: 0.9427\n",
      "Epoch 307/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6312 - val_loss: 1.0939\n",
      "Epoch 308/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 0.6367 - val_loss: 0.8832\n",
      "Epoch 309/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6372 - val_loss: 1.0591\n",
      "Epoch 310/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.6314 - val_loss: 0.9645\n",
      "Epoch 311/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.6248 - val_loss: 0.9141\n",
      "Epoch 312/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6273 - val_loss: 1.1155\n",
      "Epoch 313/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6368 - val_loss: 0.9016\n",
      "Epoch 314/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6327 - val_loss: 1.0698\n",
      "Epoch 315/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6279 - val_loss: 0.9815\n",
      "Epoch 316/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.6215 - val_loss: 0.8966\n",
      "Epoch 317/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.6304 - val_loss: 1.1472\n",
      "Epoch 318/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.6413 - val_loss: 0.8881\n",
      "Epoch 319/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6302 - val_loss: 1.0175\n",
      "Epoch 320/2500\n",
      "64/64 [==============================] - 0s 427us/step - loss: 0.6205 - val_loss: 1.0638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/2500\n",
      "64/64 [==============================] - 0s 383us/step - loss: 0.6232 - val_loss: 0.8677\n",
      "Epoch 322/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.6315 - val_loss: 1.1006\n",
      "Epoch 323/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 0.6263 - val_loss: 0.9467\n",
      "Epoch 324/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6184 - val_loss: 0.9732\n",
      "Epoch 325/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.6164 - val_loss: 1.0477\n",
      "Epoch 326/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6171 - val_loss: 0.9214\n",
      "Epoch 327/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 0.6199 - val_loss: 1.1122\n",
      "Epoch 328/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.6250 - val_loss: 0.9277\n",
      "Epoch 329/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6262 - val_loss: 1.0916\n",
      "Epoch 330/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.6277 - val_loss: 0.9937\n",
      "Epoch 331/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.6168 - val_loss: 0.9628\n",
      "Epoch 332/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6146 - val_loss: 1.0960\n",
      "Epoch 333/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.6213 - val_loss: 0.9397\n",
      "Epoch 334/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 0.6241 - val_loss: 1.0809\n",
      "Epoch 335/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.6235 - val_loss: 0.9787\n",
      "Epoch 336/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.6140 - val_loss: 0.9467\n",
      "Epoch 337/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.6151 - val_loss: 1.1462\n",
      "Epoch 338/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6279 - val_loss: 0.9101\n",
      "Epoch 339/2500\n",
      "64/64 [==============================] - 0s 415us/step - loss: 0.6275 - val_loss: 1.1112\n",
      "Epoch 340/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.6177 - val_loss: 1.0151\n",
      "Epoch 341/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.6104 - val_loss: 0.9297\n",
      "Epoch 342/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.6194 - val_loss: 1.1536\n",
      "Epoch 343/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.6271 - val_loss: 0.9163\n",
      "Epoch 344/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 0.6145 - val_loss: 1.0061\n",
      "Epoch 345/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.6091 - val_loss: 1.0437\n",
      "Epoch 346/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.6122 - val_loss: 0.9357\n",
      "Epoch 347/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.6180 - val_loss: 1.0947\n",
      "Epoch 348/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6133 - val_loss: 0.9555\n",
      "Epoch 349/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.6084 - val_loss: 1.0270\n",
      "Epoch 350/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.6067 - val_loss: 1.0755\n",
      "Epoch 351/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6174 - val_loss: 0.9434\n",
      "Epoch 352/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.6192 - val_loss: 1.1416\n",
      "Epoch 353/2500\n",
      "64/64 [==============================] - 0s 390us/step - loss: 0.6129 - val_loss: 0.9594\n",
      "Epoch 354/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.6072 - val_loss: 1.0909\n",
      "Epoch 355/2500\n",
      "64/64 [==============================] - 0s 503us/step - loss: 0.6076 - val_loss: 0.9730\n",
      "Epoch 356/2500\n",
      "64/64 [==============================] - 0s 284us/step - loss: 0.6056 - val_loss: 0.9457\n",
      "Epoch 357/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6055 - val_loss: 1.1678\n",
      "Epoch 358/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.6170 - val_loss: 0.8493\n",
      "Epoch 359/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.6170 - val_loss: 1.1277\n",
      "Epoch 360/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.6085 - val_loss: 1.0363\n",
      "Epoch 361/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.6016 - val_loss: 0.8879\n",
      "Epoch 362/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.6087 - val_loss: 1.1670\n",
      "Epoch 363/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.6122 - val_loss: 0.9819\n",
      "Epoch 364/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.6082 - val_loss: 1.0287\n",
      "Epoch 365/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.6100 - val_loss: 1.0211\n",
      "Epoch 366/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.6022 - val_loss: 1.0397\n",
      "Epoch 367/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.5985 - val_loss: 0.9986\n",
      "Epoch 368/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.6051 - val_loss: 0.9623\n",
      "Epoch 369/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.6043 - val_loss: 1.2019\n",
      "Epoch 370/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.6152 - val_loss: 0.8512\n",
      "Epoch 371/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.6151 - val_loss: 1.1048\n",
      "Epoch 372/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.5994 - val_loss: 1.0736\n",
      "Epoch 373/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.5973 - val_loss: 0.8641\n",
      "Epoch 374/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.6092 - val_loss: 1.1845\n",
      "Epoch 375/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.6152 - val_loss: 0.9372\n",
      "Epoch 376/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.6053 - val_loss: 1.0288\n",
      "Epoch 377/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.5953 - val_loss: 1.1553\n",
      "Epoch 378/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5998 - val_loss: 0.8986\n",
      "Epoch 379/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6095 - val_loss: 1.1223\n",
      "Epoch 380/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.6017 - val_loss: 1.0270\n",
      "Epoch 381/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.5944 - val_loss: 1.0120\n",
      "Epoch 382/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.5951 - val_loss: 1.1032\n",
      "Epoch 383/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5939 - val_loss: 0.9569\n",
      "Epoch 384/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.6013 - val_loss: 1.0508\n",
      "Epoch 385/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 0.5944 - val_loss: 1.1297\n",
      "Epoch 386/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.5953 - val_loss: 0.9513\n",
      "Epoch 387/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 0.6129 - val_loss: 1.2451\n",
      "Epoch 388/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.6170 - val_loss: 0.9613\n",
      "Epoch 389/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.6001 - val_loss: 0.9780\n",
      "Epoch 390/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.5924 - val_loss: 1.2427\n",
      "Epoch 391/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.6164 - val_loss: 0.9234\n",
      "Epoch 392/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.6154 - val_loss: 1.0971\n",
      "Epoch 393/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.5940 - val_loss: 1.0479\n",
      "Epoch 394/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5936 - val_loss: 0.9721\n",
      "Epoch 395/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5928 - val_loss: 1.1772\n",
      "Epoch 396/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5936 - val_loss: 1.0197\n",
      "Epoch 397/2500\n",
      "64/64 [==============================] - 0s 420us/step - loss: 0.5922 - val_loss: 1.1260\n",
      "Epoch 398/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5852 - val_loss: 0.9888\n",
      "Epoch 399/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 0.5936 - val_loss: 1.0944\n",
      "Epoch 400/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5869 - val_loss: 1.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5876 - val_loss: 0.9738\n",
      "Epoch 402/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.5922 - val_loss: 1.1893\n",
      "Epoch 403/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.5996 - val_loss: 0.8910\n",
      "Epoch 404/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5970 - val_loss: 1.0349\n",
      "Epoch 405/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5851 - val_loss: 1.1986\n",
      "Epoch 406/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 0.5999 - val_loss: 0.9720\n",
      "Epoch 407/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.6052 - val_loss: 1.1992\n",
      "Epoch 408/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5892 - val_loss: 1.0320\n",
      "Epoch 409/2500\n",
      "64/64 [==============================] - 0s 362us/step - loss: 0.5850 - val_loss: 0.9959\n",
      "Epoch 410/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5879 - val_loss: 1.1414\n",
      "Epoch 411/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.5857 - val_loss: 1.0474\n",
      "Epoch 412/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.5848 - val_loss: 1.0717\n",
      "Epoch 413/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.5790 - val_loss: 1.1864\n",
      "Epoch 414/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.5829 - val_loss: 0.8858\n",
      "Epoch 415/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.5936 - val_loss: 1.1815\n",
      "Epoch 416/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5836 - val_loss: 0.9809\n",
      "Epoch 417/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5796 - val_loss: 1.1257\n",
      "Epoch 418/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.5763 - val_loss: 1.1461\n",
      "Epoch 419/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.5809 - val_loss: 1.0035\n",
      "Epoch 420/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.5892 - val_loss: 1.0941\n",
      "Epoch 421/2500\n",
      "64/64 [==============================] - 0s 430us/step - loss: 0.5839 - val_loss: 1.0146\n",
      "Epoch 422/2500\n",
      "64/64 [==============================] - 0s 367us/step - loss: 0.5865 - val_loss: 0.9963\n",
      "Epoch 423/2500\n",
      "64/64 [==============================] - 0s 560us/step - loss: 0.5783 - val_loss: 1.2177\n",
      "Epoch 424/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5829 - val_loss: 0.9040\n",
      "Epoch 425/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.5888 - val_loss: 1.2065\n",
      "Epoch 426/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5818 - val_loss: 0.9925\n",
      "Epoch 427/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5765 - val_loss: 1.0328\n",
      "Epoch 428/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 0.5698 - val_loss: 1.2086\n",
      "Epoch 429/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.5763 - val_loss: 0.9218\n",
      "Epoch 430/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.5801 - val_loss: 1.2758\n",
      "Epoch 431/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.5837 - val_loss: 0.8816\n",
      "Epoch 432/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.5868 - val_loss: 1.1939\n",
      "Epoch 433/2500\n",
      "64/64 [==============================] - 0s 439us/step - loss: 0.5722 - val_loss: 1.1580\n",
      "Epoch 434/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.5761 - val_loss: 0.9105\n",
      "Epoch 435/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.5900 - val_loss: 1.2244\n",
      "Epoch 436/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.5811 - val_loss: 0.9548\n",
      "Epoch 437/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.5722 - val_loss: 1.0310\n",
      "Epoch 438/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.5684 - val_loss: 1.2468\n",
      "Epoch 439/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.5869 - val_loss: 1.0358\n",
      "Epoch 440/2500\n",
      "64/64 [==============================] - 0s 510us/step - loss: 0.5779 - val_loss: 1.1005\n",
      "Epoch 441/2500\n",
      "64/64 [==============================] - 0s 348us/step - loss: 0.5637 - val_loss: 1.1276\n",
      "Epoch 442/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.5712 - val_loss: 1.0145\n",
      "Epoch 443/2500\n",
      "64/64 [==============================] - 0s 316us/step - loss: 0.5663 - val_loss: 1.1859\n",
      "Epoch 444/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.5719 - val_loss: 1.1254\n",
      "Epoch 445/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.5648 - val_loss: 0.9758\n",
      "Epoch 446/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5663 - val_loss: 1.2462\n",
      "Epoch 447/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5766 - val_loss: 0.9307\n",
      "Epoch 448/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5767 - val_loss: 1.3520\n",
      "Epoch 449/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5949 - val_loss: 0.9863\n",
      "Epoch 450/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.6088 - val_loss: 1.0699\n",
      "Epoch 451/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5816 - val_loss: 1.1996\n",
      "Epoch 452/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5769 - val_loss: 0.9833\n",
      "Epoch 453/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.5790 - val_loss: 1.0144\n",
      "Epoch 454/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.5883 - val_loss: 1.3060\n",
      "Epoch 455/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.5944 - val_loss: 0.8543\n",
      "Epoch 456/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5809 - val_loss: 1.0904\n",
      "Epoch 457/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5710 - val_loss: 1.2732\n",
      "Epoch 458/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 0.5771 - val_loss: 0.9401\n",
      "Epoch 459/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.5804 - val_loss: 1.2319\n",
      "Epoch 460/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5663 - val_loss: 1.1087\n",
      "Epoch 461/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5565 - val_loss: 0.9701\n",
      "Epoch 462/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.5592 - val_loss: 1.2053\n",
      "Epoch 463/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.5569 - val_loss: 1.0348\n",
      "Epoch 464/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.5576 - val_loss: 1.1449\n",
      "Epoch 465/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.5535 - val_loss: 1.0891\n",
      "Epoch 466/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5541 - val_loss: 1.0877\n",
      "Epoch 467/2500\n",
      "64/64 [==============================] - 0s 416us/step - loss: 0.5510 - val_loss: 1.1307\n",
      "Epoch 468/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.5547 - val_loss: 1.0111\n",
      "Epoch 469/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.5622 - val_loss: 1.1896\n",
      "Epoch 470/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5615 - val_loss: 1.0406\n",
      "Epoch 471/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.5563 - val_loss: 1.1449\n",
      "Epoch 472/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.5485 - val_loss: 1.1839\n",
      "Epoch 473/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 0.5535 - val_loss: 0.9813\n",
      "Epoch 474/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5673 - val_loss: 1.1627\n",
      "Epoch 475/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.5585 - val_loss: 1.1244\n",
      "Epoch 476/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.5473 - val_loss: 1.0550\n",
      "Epoch 477/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5559 - val_loss: 1.1549\n",
      "Epoch 478/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.5493 - val_loss: 1.0699\n",
      "Epoch 479/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.5534 - val_loss: 1.0514\n",
      "Epoch 480/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 0.5480 - val_loss: 1.1918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5470 - val_loss: 1.0105\n",
      "Epoch 482/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.5512 - val_loss: 1.1668\n",
      "Epoch 483/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.5488 - val_loss: 1.0571\n",
      "Epoch 484/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.5488 - val_loss: 1.0204\n",
      "Epoch 485/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.5464 - val_loss: 1.3069\n",
      "Epoch 486/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5498 - val_loss: 0.9414\n",
      "Epoch 487/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.5578 - val_loss: 1.2984\n",
      "Epoch 488/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.5507 - val_loss: 0.9896\n",
      "Epoch 489/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.5436 - val_loss: 1.0991\n",
      "Epoch 490/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.5377 - val_loss: 1.2795\n",
      "Epoch 491/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.5440 - val_loss: 0.9530\n",
      "Epoch 492/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.5510 - val_loss: 1.3275\n",
      "Epoch 493/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.5498 - val_loss: 1.0371\n",
      "Epoch 494/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.5481 - val_loss: 1.1429\n",
      "Epoch 495/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.5487 - val_loss: 1.1595\n",
      "Epoch 496/2500\n",
      "64/64 [==============================] - 0s 573us/step - loss: 0.5413 - val_loss: 0.9291\n",
      "Epoch 497/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5470 - val_loss: 1.2818\n",
      "Epoch 498/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.5528 - val_loss: 1.0743\n",
      "Epoch 499/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5537 - val_loss: 1.1483\n",
      "Epoch 500/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.5578 - val_loss: 1.2835\n",
      "Epoch 501/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 0.5490 - val_loss: 0.9419\n",
      "Epoch 502/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.5471 - val_loss: 1.2106\n",
      "Epoch 503/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5509 - val_loss: 1.1878\n",
      "Epoch 504/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 0.5546 - val_loss: 1.0195\n",
      "Epoch 505/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5549 - val_loss: 1.3140\n",
      "Epoch 506/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.5450 - val_loss: 0.9537\n",
      "Epoch 507/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.5439 - val_loss: 1.0754\n",
      "Epoch 508/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.5354 - val_loss: 1.2803\n",
      "Epoch 509/2500\n",
      "64/64 [==============================] - 0s 392us/step - loss: 0.5333 - val_loss: 0.9788\n",
      "Epoch 510/2500\n",
      "64/64 [==============================] - 0s 506us/step - loss: 0.5404 - val_loss: 1.2056\n",
      "Epoch 511/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.5276 - val_loss: 1.1238\n",
      "Epoch 512/2500\n",
      "64/64 [==============================] - 0s 407us/step - loss: 0.5250 - val_loss: 1.0269\n",
      "Epoch 513/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.5289 - val_loss: 1.2949\n",
      "Epoch 514/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 0.5323 - val_loss: 1.0689\n",
      "Epoch 515/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.5344 - val_loss: 1.1787\n",
      "Epoch 516/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5233 - val_loss: 1.0970\n",
      "Epoch 517/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5225 - val_loss: 1.0126\n",
      "Epoch 518/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5282 - val_loss: 1.2290\n",
      "Epoch 519/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.5253 - val_loss: 1.1384\n",
      "Epoch 520/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.5199 - val_loss: 0.9876\n",
      "Epoch 521/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.5276 - val_loss: 1.3114\n",
      "Epoch 522/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.5373 - val_loss: 0.9244\n",
      "Epoch 523/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5324 - val_loss: 1.1545\n",
      "Epoch 524/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5176 - val_loss: 1.1872\n",
      "Epoch 525/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.5163 - val_loss: 0.9649\n",
      "Epoch 526/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.5275 - val_loss: 1.2521\n",
      "Epoch 527/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5241 - val_loss: 1.0711\n",
      "Epoch 528/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5159 - val_loss: 1.0924\n",
      "Epoch 529/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.5126 - val_loss: 1.2431\n",
      "Epoch 530/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.5181 - val_loss: 1.0248\n",
      "Epoch 531/2500\n",
      "64/64 [==============================] - 0s 405us/step - loss: 0.5204 - val_loss: 1.1770\n",
      "Epoch 532/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5148 - val_loss: 1.0771\n",
      "Epoch 533/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.5108 - val_loss: 1.1194\n",
      "Epoch 534/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5090 - val_loss: 1.1463\n",
      "Epoch 535/2500\n",
      "64/64 [==============================] - 0s 421us/step - loss: 0.5132 - val_loss: 1.1312\n",
      "Epoch 536/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5203 - val_loss: 1.1193\n",
      "Epoch 537/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.5314 - val_loss: 1.1407\n",
      "Epoch 538/2500\n",
      "64/64 [==============================] - 0s 471us/step - loss: 0.5299 - val_loss: 1.0963\n",
      "Epoch 539/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.5197 - val_loss: 1.1651\n",
      "Epoch 540/2500\n",
      "64/64 [==============================] - 0s 475us/step - loss: 0.5060 - val_loss: 1.1813\n",
      "Epoch 541/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5121 - val_loss: 1.1393\n",
      "Epoch 542/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 0.5333 - val_loss: 1.0767\n",
      "Epoch 543/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.5463 - val_loss: 1.0806\n",
      "Epoch 544/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 0.5271 - val_loss: 1.0782\n",
      "Epoch 545/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5163 - val_loss: 1.1776\n",
      "Epoch 546/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5349 - val_loss: 1.0374\n",
      "Epoch 547/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.5424 - val_loss: 1.2030\n",
      "Epoch 548/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.5166 - val_loss: 1.3140\n",
      "Epoch 549/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.5122 - val_loss: 1.0085\n",
      "Epoch 550/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.5509 - val_loss: 1.2830\n",
      "Epoch 551/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5451 - val_loss: 1.0513\n",
      "Epoch 552/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.5224 - val_loss: 0.9451\n",
      "Epoch 553/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 0.5177 - val_loss: 1.2672\n",
      "Epoch 554/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5434 - val_loss: 1.0188\n",
      "Epoch 555/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 0.5331 - val_loss: 1.0481\n",
      "Epoch 556/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.5056 - val_loss: 1.3091\n",
      "Epoch 557/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5189 - val_loss: 0.9985\n",
      "Epoch 558/2500\n",
      "64/64 [==============================] - 0s 317us/step - loss: 0.5627 - val_loss: 1.1674\n",
      "Epoch 559/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5246 - val_loss: 1.3995\n",
      "Epoch 560/2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 79us/step - loss: 0.5279 - val_loss: 0.9302\n",
      "Epoch 561/2500\n",
      "64/64 [==============================] - 0s 306us/step - loss: 0.5889 - val_loss: 1.2840\n",
      "Epoch 562/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.5364 - val_loss: 1.2375\n",
      "Epoch 563/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.5107 - val_loss: 0.9146\n",
      "Epoch 564/2500\n",
      "64/64 [==============================] - 0s 399us/step - loss: 0.5335 - val_loss: 1.2323\n",
      "Epoch 565/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.5185 - val_loss: 1.2141\n",
      "Epoch 566/2500\n",
      "64/64 [==============================] - 0s 321us/step - loss: 0.4956 - val_loss: 0.9917\n",
      "Epoch 567/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5086 - val_loss: 1.2334\n",
      "Epoch 568/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.5026 - val_loss: 1.2246\n",
      "Epoch 569/2500\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.4941 - val_loss: 0.9608\n",
      "Epoch 570/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 0.5137 - val_loss: 1.3072\n",
      "Epoch 571/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 0.5047 - val_loss: 1.0148\n",
      "Epoch 572/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.5023 - val_loss: 1.1037\n",
      "Epoch 573/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4949 - val_loss: 1.2873\n",
      "Epoch 574/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.4969 - val_loss: 1.0085\n",
      "Epoch 575/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.5023 - val_loss: 1.2771\n",
      "Epoch 576/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4930 - val_loss: 1.1376\n",
      "Epoch 577/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.4916 - val_loss: 1.1105\n",
      "Epoch 578/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4870 - val_loss: 1.2242\n",
      "Epoch 579/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.4888 - val_loss: 1.0732\n",
      "Epoch 580/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.4879 - val_loss: 1.2411\n",
      "Epoch 581/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.4885 - val_loss: 1.1857\n",
      "Epoch 582/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 0.4922 - val_loss: 1.1940\n",
      "Epoch 583/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4949 - val_loss: 1.1633\n",
      "Epoch 584/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4943 - val_loss: 1.2233\n",
      "Epoch 585/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.4905 - val_loss: 1.0839\n",
      "Epoch 586/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4885 - val_loss: 1.1873\n",
      "Epoch 587/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4838 - val_loss: 1.1601\n",
      "Epoch 588/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4810 - val_loss: 1.0908\n",
      "Epoch 589/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 0.4806 - val_loss: 1.2232\n",
      "Epoch 590/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4796 - val_loss: 1.1817\n",
      "Epoch 591/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.4847 - val_loss: 1.2816\n",
      "Epoch 592/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.4891 - val_loss: 1.1423\n",
      "Epoch 593/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4955 - val_loss: 1.1122\n",
      "Epoch 594/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4926 - val_loss: 1.1709\n",
      "Epoch 595/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 0.4826 - val_loss: 1.1863\n",
      "Epoch 596/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4779 - val_loss: 1.1358\n",
      "Epoch 597/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4866 - val_loss: 1.3036\n",
      "Epoch 598/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4910 - val_loss: 1.0337\n",
      "Epoch 599/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4928 - val_loss: 1.2113\n",
      "Epoch 600/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4776 - val_loss: 1.2079\n",
      "Epoch 601/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.4816 - val_loss: 1.1316\n",
      "Epoch 602/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.5007 - val_loss: 1.2271\n",
      "Epoch 603/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.5075 - val_loss: 1.1385\n",
      "Epoch 604/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.4969 - val_loss: 1.0299\n",
      "Epoch 605/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.4814 - val_loss: 1.3071\n",
      "Epoch 606/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 0.4923 - val_loss: 1.0033\n",
      "Epoch 607/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.5010 - val_loss: 1.2387\n",
      "Epoch 608/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4826 - val_loss: 1.2803\n",
      "Epoch 609/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4816 - val_loss: 0.9247\n",
      "Epoch 610/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.5076 - val_loss: 1.4377\n",
      "Epoch 611/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.5048 - val_loss: 1.0027\n",
      "Epoch 612/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4899 - val_loss: 1.1804\n",
      "Epoch 613/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4838 - val_loss: 1.3172\n",
      "Epoch 614/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.4842 - val_loss: 1.0667\n",
      "Epoch 615/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.4840 - val_loss: 1.3273\n",
      "Epoch 616/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.4786 - val_loss: 1.1764\n",
      "Epoch 617/2500\n",
      "64/64 [==============================] - 0s 389us/step - loss: 0.4839 - val_loss: 1.1860\n",
      "Epoch 618/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4846 - val_loss: 1.2150\n",
      "Epoch 619/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4755 - val_loss: 1.2024\n",
      "Epoch 620/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4709 - val_loss: 1.1469\n",
      "Epoch 621/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4685 - val_loss: 1.1777\n",
      "Epoch 622/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4725 - val_loss: 1.2322\n",
      "Epoch 623/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.4721 - val_loss: 1.1482\n",
      "Epoch 624/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.4765 - val_loss: 1.3847\n",
      "Epoch 625/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4800 - val_loss: 1.0137\n",
      "Epoch 626/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4873 - val_loss: 1.2020\n",
      "Epoch 627/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4969 - val_loss: 0.8947\n",
      "Epoch 628/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4966 - val_loss: 1.1686\n",
      "Epoch 629/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4821 - val_loss: 1.1309\n",
      "Epoch 630/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4727 - val_loss: 1.0713\n",
      "Epoch 631/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4847 - val_loss: 1.3143\n",
      "Epoch 632/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.4827 - val_loss: 0.9601\n",
      "Epoch 633/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4928 - val_loss: 1.2382\n",
      "Epoch 634/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4815 - val_loss: 1.2214\n",
      "Epoch 635/2500\n",
      "64/64 [==============================] - 0s 411us/step - loss: 0.4737 - val_loss: 0.9972\n",
      "Epoch 636/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4966 - val_loss: 1.4133\n",
      "Epoch 637/2500\n",
      "64/64 [==============================] - 0s 367us/step - loss: 0.5042 - val_loss: 0.9113\n",
      "Epoch 638/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4946 - val_loss: 1.0823\n",
      "Epoch 639/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4697 - val_loss: 1.2800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 640/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.4880 - val_loss: 0.8885\n",
      "Epoch 641/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.5122 - val_loss: 1.3993\n",
      "Epoch 642/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.4934 - val_loss: 1.2247\n",
      "Epoch 643/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.4887 - val_loss: 1.0257\n",
      "Epoch 644/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.5043 - val_loss: 1.3565\n",
      "Epoch 645/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4989 - val_loss: 1.0202\n",
      "Epoch 646/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.4797 - val_loss: 1.0809\n",
      "Epoch 647/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.4929 - val_loss: 1.2453\n",
      "Epoch 648/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4818 - val_loss: 1.0557\n",
      "Epoch 649/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4689 - val_loss: 1.1697\n",
      "Epoch 650/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.4738 - val_loss: 1.1648\n",
      "Epoch 651/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4780 - val_loss: 1.1916\n",
      "Epoch 652/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4663 - val_loss: 1.1540\n",
      "Epoch 653/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4667 - val_loss: 1.2065\n",
      "Epoch 654/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4696 - val_loss: 1.0606\n",
      "Epoch 655/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4712 - val_loss: 1.0888\n",
      "Epoch 656/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.4682 - val_loss: 1.1571\n",
      "Epoch 657/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4643 - val_loss: 1.1462\n",
      "Epoch 658/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4667 - val_loss: 1.1958\n",
      "Epoch 659/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.4634 - val_loss: 1.1288\n",
      "Epoch 660/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4706 - val_loss: 1.1200\n",
      "Epoch 661/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.4653 - val_loss: 1.1523\n",
      "Epoch 662/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4666 - val_loss: 1.0585\n",
      "Epoch 663/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4682 - val_loss: 1.2790\n",
      "Epoch 664/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 0.4651 - val_loss: 1.1607\n",
      "Epoch 665/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4670 - val_loss: 1.1088\n",
      "Epoch 666/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4622 - val_loss: 1.2945\n",
      "Epoch 667/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4803 - val_loss: 0.9051\n",
      "Epoch 668/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.4863 - val_loss: 1.2808\n",
      "Epoch 669/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.4773 - val_loss: 1.1864\n",
      "Epoch 670/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.4612 - val_loss: 1.0923\n",
      "Epoch 671/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 0.4756 - val_loss: 1.3757\n",
      "Epoch 672/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4856 - val_loss: 0.9978\n",
      "Epoch 673/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4754 - val_loss: 1.1936\n",
      "Epoch 674/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4755 - val_loss: 1.1932\n",
      "Epoch 675/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4893 - val_loss: 1.1057\n",
      "Epoch 676/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4852 - val_loss: 1.2669\n",
      "Epoch 677/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.4627 - val_loss: 1.1224\n",
      "Epoch 678/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4665 - val_loss: 1.2566\n",
      "Epoch 679/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4736 - val_loss: 1.1267\n",
      "Epoch 680/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4765 - val_loss: 1.2069\n",
      "Epoch 681/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 0.4577 - val_loss: 1.2780\n",
      "Epoch 682/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.4674 - val_loss: 1.1181\n",
      "Epoch 683/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4772 - val_loss: 1.2433\n",
      "Epoch 684/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.4612 - val_loss: 1.2269\n",
      "Epoch 685/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4635 - val_loss: 1.1282\n",
      "Epoch 686/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4764 - val_loss: 1.3681\n",
      "Epoch 687/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4648 - val_loss: 1.0859\n",
      "Epoch 688/2500\n",
      "64/64 [==============================] - 0s 392us/step - loss: 0.4761 - val_loss: 1.2725\n",
      "Epoch 689/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4846 - val_loss: 1.0280\n",
      "Epoch 690/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 0.4686 - val_loss: 1.1612\n",
      "Epoch 691/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4630 - val_loss: 1.2523\n",
      "Epoch 692/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4715 - val_loss: 1.2656\n",
      "Epoch 693/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.4644 - val_loss: 1.3672\n",
      "Epoch 694/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 0.4661 - val_loss: 1.0074\n",
      "Epoch 695/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4818 - val_loss: 1.2869\n",
      "Epoch 696/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4763 - val_loss: 1.0774\n",
      "Epoch 697/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 0.4633 - val_loss: 1.1845\n",
      "Epoch 698/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.4616 - val_loss: 1.4694\n",
      "Epoch 699/2500\n",
      "64/64 [==============================] - 0s 321us/step - loss: 0.4662 - val_loss: 1.0464\n",
      "Epoch 700/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4866 - val_loss: 1.3837\n",
      "Epoch 701/2500\n",
      "64/64 [==============================] - 0s 384us/step - loss: 0.4645 - val_loss: 1.1568\n",
      "Epoch 702/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4583 - val_loss: 1.1607\n",
      "Epoch 703/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4571 - val_loss: 1.4396\n",
      "Epoch 704/2500\n",
      "64/64 [==============================] - 0s 484us/step - loss: 0.4651 - val_loss: 1.0352\n",
      "Epoch 705/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.4736 - val_loss: 1.4073\n",
      "Epoch 706/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4753 - val_loss: 1.0460\n",
      "Epoch 707/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.4643 - val_loss: 1.2130\n",
      "Epoch 708/2500\n",
      "64/64 [==============================] - 0s 395us/step - loss: 0.4557 - val_loss: 1.3223\n",
      "Epoch 709/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.4557 - val_loss: 1.1636\n",
      "Epoch 710/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.4600 - val_loss: 1.4356\n",
      "Epoch 711/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.4627 - val_loss: 1.0761\n",
      "Epoch 712/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4744 - val_loss: 1.4380\n",
      "Epoch 713/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4685 - val_loss: 1.2358\n",
      "Epoch 714/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 0.4564 - val_loss: 1.1998\n",
      "Epoch 715/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4584 - val_loss: 1.4341\n",
      "Epoch 716/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4591 - val_loss: 1.1003\n",
      "Epoch 717/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4805 - val_loss: 1.4322\n",
      "Epoch 718/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4631 - val_loss: 1.2173\n",
      "Epoch 719/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4717 - val_loss: 1.1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.4694 - val_loss: 1.3190\n",
      "Epoch 721/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 0.4669 - val_loss: 1.1749\n",
      "Epoch 722/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4601 - val_loss: 1.2592\n",
      "Epoch 723/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4689 - val_loss: 1.4352\n",
      "Epoch 724/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 0.4743 - val_loss: 1.1015\n",
      "Epoch 725/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 0.4715 - val_loss: 1.3885\n",
      "Epoch 726/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4656 - val_loss: 1.2175\n",
      "Epoch 727/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.4687 - val_loss: 1.2158\n",
      "Epoch 728/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4613 - val_loss: 1.4743\n",
      "Epoch 729/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4624 - val_loss: 1.0974\n",
      "Epoch 730/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 0.4732 - val_loss: 1.3985\n",
      "Epoch 731/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4643 - val_loss: 1.2076\n",
      "Epoch 732/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4552 - val_loss: 1.1468\n",
      "Epoch 733/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.4565 - val_loss: 1.4387\n",
      "Epoch 734/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4655 - val_loss: 1.0504\n",
      "Epoch 735/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4783 - val_loss: 1.3972\n",
      "Epoch 736/2500\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 0.4624 - val_loss: 1.1857\n",
      "Epoch 737/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4590 - val_loss: 1.3155\n",
      "Epoch 738/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4674 - val_loss: 1.3165\n",
      "Epoch 739/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.4584 - val_loss: 1.1977\n",
      "Epoch 740/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 0.4567 - val_loss: 1.3296\n",
      "Epoch 741/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.4601 - val_loss: 1.1939\n",
      "Epoch 742/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4651 - val_loss: 1.3733\n",
      "Epoch 743/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.4554 - val_loss: 1.2727\n",
      "Epoch 744/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4579 - val_loss: 1.2360\n",
      "Epoch 745/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.4552 - val_loss: 1.2086\n",
      "Epoch 746/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4499 - val_loss: 1.1621\n",
      "Epoch 747/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4525 - val_loss: 1.3250\n",
      "Epoch 748/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.4542 - val_loss: 1.1795\n",
      "Epoch 749/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4551 - val_loss: 1.5234\n",
      "Epoch 750/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4699 - val_loss: 1.0311\n",
      "Epoch 751/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4817 - val_loss: 1.3894\n",
      "Epoch 752/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.4699 - val_loss: 1.1705\n",
      "Epoch 753/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4533 - val_loss: 1.0995\n",
      "Epoch 754/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.4654 - val_loss: 1.5770\n",
      "Epoch 755/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4717 - val_loss: 1.0793\n",
      "Epoch 756/2500\n",
      "64/64 [==============================] - 0s 370us/step - loss: 0.4783 - val_loss: 1.3767\n",
      "Epoch 757/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4534 - val_loss: 1.4078\n",
      "Epoch 758/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 0.4709 - val_loss: 0.9556\n",
      "Epoch 759/2500\n",
      "64/64 [==============================] - 0s 482us/step - loss: 0.5016 - val_loss: 1.5378\n",
      "Epoch 760/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4859 - val_loss: 1.2590\n",
      "Epoch 761/2500\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.4586 - val_loss: 1.1354\n",
      "Epoch 762/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.4831 - val_loss: 1.6615\n",
      "Epoch 763/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5156 - val_loss: 1.0100\n",
      "Epoch 764/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4831 - val_loss: 1.1091\n",
      "Epoch 765/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.4591 - val_loss: 1.4725\n",
      "Epoch 766/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4794 - val_loss: 1.0790\n",
      "Epoch 767/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.4818 - val_loss: 1.2184\n",
      "Epoch 768/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4599 - val_loss: 1.7754\n",
      "Epoch 769/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.5192 - val_loss: 0.8531\n",
      "Epoch 770/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.5438 - val_loss: 1.0909\n",
      "Epoch 771/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.4577 - val_loss: 1.5734\n",
      "Epoch 772/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.5679 - val_loss: 0.9017\n",
      "Epoch 773/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.5420 - val_loss: 1.1135\n",
      "Epoch 774/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 0.4738 - val_loss: 1.6632\n",
      "Epoch 775/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.5531 - val_loss: 0.9152\n",
      "Epoch 776/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4971 - val_loss: 1.1042\n",
      "Epoch 777/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.4855 - val_loss: 1.4249\n",
      "Epoch 778/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.4889 - val_loss: 1.0006\n",
      "Epoch 779/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 0.4876 - val_loss: 1.1177\n",
      "Epoch 780/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4723 - val_loss: 1.3861\n",
      "Epoch 781/2500\n",
      "64/64 [==============================] - 0s 385us/step - loss: 0.4852 - val_loss: 1.0641\n",
      "Epoch 782/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.4998 - val_loss: 1.1292\n",
      "Epoch 783/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 0.4609 - val_loss: 1.2544\n",
      "Epoch 784/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4773 - val_loss: 1.0448\n",
      "Epoch 785/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.4716 - val_loss: 1.1978\n",
      "Epoch 786/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4670 - val_loss: 1.1530\n",
      "Epoch 787/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.4568 - val_loss: 1.0982\n",
      "Epoch 788/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.4675 - val_loss: 1.2363\n",
      "Epoch 789/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4571 - val_loss: 1.0890\n",
      "Epoch 790/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 0.4609 - val_loss: 1.1204\n",
      "Epoch 791/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4519 - val_loss: 1.2765\n",
      "Epoch 792/2500\n",
      "64/64 [==============================] - 0s 340us/step - loss: 0.4516 - val_loss: 1.1722\n",
      "Epoch 793/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4602 - val_loss: 1.1925\n",
      "Epoch 794/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4457 - val_loss: 1.2677\n",
      "Epoch 795/2500\n",
      "64/64 [==============================] - 0s 439us/step - loss: 0.4596 - val_loss: 0.9620\n",
      "Epoch 796/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4608 - val_loss: 1.2380\n",
      "Epoch 797/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4649 - val_loss: 1.1245\n",
      "Epoch 798/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4523 - val_loss: 0.9669\n",
      "Epoch 799/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4645 - val_loss: 1.4374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 800/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4880 - val_loss: 1.1002\n",
      "Epoch 801/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.4551 - val_loss: 1.0705\n",
      "Epoch 802/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4491 - val_loss: 1.4375\n",
      "Epoch 803/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4848 - val_loss: 0.9752\n",
      "Epoch 804/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4736 - val_loss: 1.0623\n",
      "Epoch 805/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.4456 - val_loss: 1.4522\n",
      "Epoch 806/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.4859 - val_loss: 0.9677\n",
      "Epoch 807/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.4783 - val_loss: 1.1879\n",
      "Epoch 808/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 0.4436 - val_loss: 1.3640\n",
      "Epoch 809/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.4671 - val_loss: 0.9254\n",
      "Epoch 810/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4722 - val_loss: 1.1807\n",
      "Epoch 811/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4514 - val_loss: 1.2207\n",
      "Epoch 812/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4532 - val_loss: 0.9752\n",
      "Epoch 813/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4661 - val_loss: 1.4023\n",
      "Epoch 814/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.4644 - val_loss: 1.1255\n",
      "Epoch 815/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4446 - val_loss: 1.1239\n",
      "Epoch 816/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4412 - val_loss: 1.2610\n",
      "Epoch 817/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4544 - val_loss: 1.0732\n",
      "Epoch 818/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.4458 - val_loss: 1.1796\n",
      "Epoch 819/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.4378 - val_loss: 1.3747\n",
      "Epoch 820/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4570 - val_loss: 0.9490\n",
      "Epoch 821/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 0.4745 - val_loss: 1.2820\n",
      "Epoch 822/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4521 - val_loss: 1.2297\n",
      "Epoch 823/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4461 - val_loss: 0.9900\n",
      "Epoch 824/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4611 - val_loss: 1.3725\n",
      "Epoch 825/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.4582 - val_loss: 1.1023\n",
      "Epoch 826/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 0.4438 - val_loss: 1.1839\n",
      "Epoch 827/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4389 - val_loss: 1.1729\n",
      "Epoch 828/2500\n",
      "64/64 [==============================] - 0s 545us/step - loss: 0.4408 - val_loss: 1.1485\n",
      "Epoch 829/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.4391 - val_loss: 1.3689\n",
      "Epoch 830/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4544 - val_loss: 0.9707\n",
      "Epoch 831/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.4650 - val_loss: 1.2384\n",
      "Epoch 832/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4438 - val_loss: 1.2264\n",
      "Epoch 833/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4405 - val_loss: 1.0351\n",
      "Epoch 834/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4557 - val_loss: 1.3979\n",
      "Epoch 835/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4536 - val_loss: 1.1236\n",
      "Epoch 836/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4478 - val_loss: 1.1271\n",
      "Epoch 837/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.4395 - val_loss: 1.2854\n",
      "Epoch 838/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4518 - val_loss: 0.9888\n",
      "Epoch 839/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.4605 - val_loss: 1.2552\n",
      "Epoch 840/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 0.4444 - val_loss: 1.3214\n",
      "Epoch 841/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4424 - val_loss: 1.0930\n",
      "Epoch 842/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.4562 - val_loss: 1.3677\n",
      "Epoch 843/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 0.4560 - val_loss: 1.1085\n",
      "Epoch 844/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4423 - val_loss: 1.2045\n",
      "Epoch 845/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4398 - val_loss: 1.2051\n",
      "Epoch 846/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4385 - val_loss: 1.1896\n",
      "Epoch 847/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4384 - val_loss: 1.2889\n",
      "Epoch 848/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4402 - val_loss: 1.1239\n",
      "Epoch 849/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4440 - val_loss: 1.2952\n",
      "Epoch 850/2500\n",
      "64/64 [==============================] - 0s 385us/step - loss: 0.4422 - val_loss: 1.1472\n",
      "Epoch 851/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4385 - val_loss: 1.1461\n",
      "Epoch 852/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.4381 - val_loss: 1.3921\n",
      "Epoch 853/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4473 - val_loss: 1.0128\n",
      "Epoch 854/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4626 - val_loss: 1.2960\n",
      "Epoch 855/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.4409 - val_loss: 1.3265\n",
      "Epoch 856/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4432 - val_loss: 1.0306\n",
      "Epoch 857/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4626 - val_loss: 1.3703\n",
      "Epoch 858/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4455 - val_loss: 1.2686\n",
      "Epoch 859/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4349 - val_loss: 1.0913\n",
      "Epoch 860/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4485 - val_loss: 1.4537\n",
      "Epoch 861/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4609 - val_loss: 1.0778\n",
      "Epoch 862/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4497 - val_loss: 1.1696\n",
      "Epoch 863/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.4411 - val_loss: 1.3904\n",
      "Epoch 864/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4564 - val_loss: 0.9926\n",
      "Epoch 865/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4588 - val_loss: 1.2730\n",
      "Epoch 866/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4388 - val_loss: 1.3596\n",
      "Epoch 867/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 0.4399 - val_loss: 1.0674\n",
      "Epoch 868/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4663 - val_loss: 1.4339\n",
      "Epoch 869/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4459 - val_loss: 1.2079\n",
      "Epoch 870/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.4351 - val_loss: 1.0986\n",
      "Epoch 871/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.4394 - val_loss: 1.3701\n",
      "Epoch 872/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4507 - val_loss: 1.1670\n",
      "Epoch 873/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 0.4378 - val_loss: 1.2027\n",
      "Epoch 874/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4371 - val_loss: 1.4742\n",
      "Epoch 875/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 0.4539 - val_loss: 0.9974\n",
      "Epoch 876/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4653 - val_loss: 1.2541\n",
      "Epoch 877/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4369 - val_loss: 1.2977\n",
      "Epoch 878/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 0.4368 - val_loss: 1.0875\n",
      "Epoch 879/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4532 - val_loss: 1.4052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 880/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4401 - val_loss: 1.2943\n",
      "Epoch 881/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4338 - val_loss: 1.1783\n",
      "Epoch 882/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4341 - val_loss: 1.2366\n",
      "Epoch 883/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 0.4354 - val_loss: 1.2427\n",
      "Epoch 884/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4329 - val_loss: 1.3242\n",
      "Epoch 885/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4336 - val_loss: 1.2454\n",
      "Epoch 886/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.4355 - val_loss: 1.3757\n",
      "Epoch 887/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4399 - val_loss: 1.0543\n",
      "Epoch 888/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4494 - val_loss: 1.3068\n",
      "Epoch 889/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4403 - val_loss: 1.2492\n",
      "Epoch 890/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4326 - val_loss: 1.1343\n",
      "Epoch 891/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.4459 - val_loss: 1.5516\n",
      "Epoch 892/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4575 - val_loss: 1.1716\n",
      "Epoch 893/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4460 - val_loss: 1.2539\n",
      "Epoch 894/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4325 - val_loss: 1.3281\n",
      "Epoch 895/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4424 - val_loss: 1.1111\n",
      "Epoch 896/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 0.4422 - val_loss: 1.3656\n",
      "Epoch 897/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4370 - val_loss: 1.2704\n",
      "Epoch 898/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 0.4357 - val_loss: 1.2835\n",
      "Epoch 899/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4297 - val_loss: 1.2586\n",
      "Epoch 900/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.4347 - val_loss: 1.0800\n",
      "Epoch 901/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4494 - val_loss: 1.3944\n",
      "Epoch 902/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4435 - val_loss: 1.2684\n",
      "Epoch 903/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4339 - val_loss: 1.2777\n",
      "Epoch 904/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4402 - val_loss: 1.4314\n",
      "Epoch 905/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.4350 - val_loss: 1.0930\n",
      "Epoch 906/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.4600 - val_loss: 1.2855\n",
      "Epoch 907/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4366 - val_loss: 1.4174\n",
      "Epoch 908/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 0.4586 - val_loss: 1.0621\n",
      "Epoch 909/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4643 - val_loss: 1.4338\n",
      "Epoch 910/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4456 - val_loss: 1.4148\n",
      "Epoch 911/2500\n",
      "64/64 [==============================] - 0s 383us/step - loss: 0.4435 - val_loss: 1.1180\n",
      "Epoch 912/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4553 - val_loss: 1.4200\n",
      "Epoch 913/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.4588 - val_loss: 1.2578\n",
      "Epoch 914/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.4345 - val_loss: 1.1327\n",
      "Epoch 915/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4561 - val_loss: 1.3968\n",
      "Epoch 916/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4392 - val_loss: 1.2841\n",
      "Epoch 917/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 0.4432 - val_loss: 1.1589\n",
      "Epoch 918/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4444 - val_loss: 1.5752\n",
      "Epoch 919/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4568 - val_loss: 1.1273\n",
      "Epoch 920/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.4631 - val_loss: 1.2720\n",
      "Epoch 921/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4307 - val_loss: 1.4829\n",
      "Epoch 922/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.4538 - val_loss: 1.0717\n",
      "Epoch 923/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4607 - val_loss: 1.3756\n",
      "Epoch 924/2500\n",
      "64/64 [==============================] - 0s 475us/step - loss: 0.4398 - val_loss: 1.3833\n",
      "Epoch 925/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4344 - val_loss: 1.1421\n",
      "Epoch 926/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.4488 - val_loss: 1.4578\n",
      "Epoch 927/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4415 - val_loss: 1.3089\n",
      "Epoch 928/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4305 - val_loss: 1.2741\n",
      "Epoch 929/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.4327 - val_loss: 1.5119\n",
      "Epoch 930/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4436 - val_loss: 1.1819\n",
      "Epoch 931/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4429 - val_loss: 1.3689\n",
      "Epoch 932/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4332 - val_loss: 1.3221\n",
      "Epoch 933/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.4299 - val_loss: 1.2089\n",
      "Epoch 934/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4332 - val_loss: 1.4794\n",
      "Epoch 935/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4428 - val_loss: 1.1892\n",
      "Epoch 936/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4458 - val_loss: 1.3895\n",
      "Epoch 937/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4362 - val_loss: 1.4656\n",
      "Epoch 938/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4371 - val_loss: 1.1809\n",
      "Epoch 939/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.4445 - val_loss: 1.4444\n",
      "Epoch 940/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4298 - val_loss: 1.3209\n",
      "Epoch 941/2500\n",
      "64/64 [==============================] - 0s 393us/step - loss: 0.4436 - val_loss: 1.3966\n",
      "Epoch 942/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4262 - val_loss: 1.4315\n",
      "Epoch 943/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.4459 - val_loss: 1.1436\n",
      "Epoch 944/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4435 - val_loss: 1.4824\n",
      "Epoch 945/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4462 - val_loss: 1.2593\n",
      "Epoch 946/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 0.4331 - val_loss: 1.2303\n",
      "Epoch 947/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.4335 - val_loss: 1.4715\n",
      "Epoch 948/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4382 - val_loss: 1.1848\n",
      "Epoch 949/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.4449 - val_loss: 1.4334\n",
      "Epoch 950/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4317 - val_loss: 1.4309\n",
      "Epoch 951/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4302 - val_loss: 1.2498\n",
      "Epoch 952/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.4350 - val_loss: 1.4505\n",
      "Epoch 953/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4267 - val_loss: 1.4300\n",
      "Epoch 954/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.4296 - val_loss: 1.2873\n",
      "Epoch 955/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.4265 - val_loss: 1.4201\n",
      "Epoch 956/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 0.4405 - val_loss: 1.1814\n",
      "Epoch 957/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4369 - val_loss: 1.4227\n",
      "Epoch 958/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 0.4384 - val_loss: 1.2419\n",
      "Epoch 959/2500\n",
      "64/64 [==============================] - 0s 531us/step - loss: 0.4287 - val_loss: 1.3324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 960/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 0.4337 - val_loss: 1.3242\n",
      "Epoch 961/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4243 - val_loss: 1.3522\n",
      "Epoch 962/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4312 - val_loss: 1.4097\n",
      "Epoch 963/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4256 - val_loss: 1.2204\n",
      "Epoch 964/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 0.4359 - val_loss: 1.5184\n",
      "Epoch 965/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4397 - val_loss: 1.2483\n",
      "Epoch 966/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4400 - val_loss: 1.3562\n",
      "Epoch 967/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4289 - val_loss: 1.4900\n",
      "Epoch 968/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 0.4452 - val_loss: 1.0654\n",
      "Epoch 969/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.4527 - val_loss: 1.3526\n",
      "Epoch 970/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4325 - val_loss: 1.3890\n",
      "Epoch 971/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 0.4331 - val_loss: 1.2504\n",
      "Epoch 972/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.4366 - val_loss: 1.5879\n",
      "Epoch 973/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4581 - val_loss: 1.2763\n",
      "Epoch 974/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.4269 - val_loss: 1.3200\n",
      "Epoch 975/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.4292 - val_loss: 1.3646\n",
      "Epoch 976/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4275 - val_loss: 1.2328\n",
      "Epoch 977/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4312 - val_loss: 1.4933\n",
      "Epoch 978/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.4322 - val_loss: 1.2666\n",
      "Epoch 979/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 0.4375 - val_loss: 1.3897\n",
      "Epoch 980/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.4269 - val_loss: 1.3605\n",
      "Epoch 981/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.4275 - val_loss: 1.1833\n",
      "Epoch 982/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.4381 - val_loss: 1.5481\n",
      "Epoch 983/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4413 - val_loss: 1.2115\n",
      "Epoch 984/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4333 - val_loss: 1.2145\n",
      "Epoch 985/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.4311 - val_loss: 1.5487\n",
      "Epoch 986/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4519 - val_loss: 1.0989\n",
      "Epoch 987/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4461 - val_loss: 1.3816\n",
      "Epoch 988/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4277 - val_loss: 1.4558\n",
      "Epoch 989/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4269 - val_loss: 1.2293\n",
      "Epoch 990/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.4404 - val_loss: 1.5010\n",
      "Epoch 991/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4316 - val_loss: 1.2958\n",
      "Epoch 992/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.4226 - val_loss: 1.2008\n",
      "Epoch 993/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 0.4265 - val_loss: 1.3997\n",
      "Epoch 994/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4307 - val_loss: 1.2242\n",
      "Epoch 995/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4294 - val_loss: 1.4726\n",
      "Epoch 996/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4274 - val_loss: 1.3376\n",
      "Epoch 997/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 0.4244 - val_loss: 1.3400\n",
      "Epoch 998/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4211 - val_loss: 1.3480\n",
      "Epoch 999/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 0.4236 - val_loss: 1.2694\n",
      "Epoch 1000/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4244 - val_loss: 1.4456\n",
      "Epoch 1001/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4229 - val_loss: 1.2855\n",
      "Epoch 1002/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4243 - val_loss: 1.4035\n",
      "Epoch 1003/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.4217 - val_loss: 1.3155\n",
      "Epoch 1004/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4212 - val_loss: 1.3999\n",
      "Epoch 1005/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.4205 - val_loss: 1.3314\n",
      "Epoch 1006/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.4206 - val_loss: 1.3505\n",
      "Epoch 1007/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4201 - val_loss: 1.3574\n",
      "Epoch 1008/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4216 - val_loss: 1.3578\n",
      "Epoch 1009/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 0.4198 - val_loss: 1.2982\n",
      "Epoch 1010/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4216 - val_loss: 1.3242\n",
      "Epoch 1011/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4233 - val_loss: 1.4070\n",
      "Epoch 1012/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.4258 - val_loss: 1.2799\n",
      "Epoch 1013/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4287 - val_loss: 1.4665\n",
      "Epoch 1014/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.4280 - val_loss: 1.1155\n",
      "Epoch 1015/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4406 - val_loss: 1.4143\n",
      "Epoch 1016/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4297 - val_loss: 1.4795\n",
      "Epoch 1017/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4292 - val_loss: 1.1034\n",
      "Epoch 1018/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 0.4646 - val_loss: 1.5796\n",
      "Epoch 1019/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4474 - val_loss: 1.1895\n",
      "Epoch 1020/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4261 - val_loss: 1.1393\n",
      "Epoch 1021/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 0.4301 - val_loss: 1.4739\n",
      "Epoch 1022/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4336 - val_loss: 1.2697\n",
      "Epoch 1023/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4292 - val_loss: 1.3818\n",
      "Epoch 1024/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.4196 - val_loss: 1.5141\n",
      "Epoch 1025/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4374 - val_loss: 1.0542\n",
      "Epoch 1026/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.4626 - val_loss: 1.4883\n",
      "Epoch 1027/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.4362 - val_loss: 1.3806\n",
      "Epoch 1028/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4242 - val_loss: 1.2180\n",
      "Epoch 1029/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4456 - val_loss: 1.6617\n",
      "Epoch 1030/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.4541 - val_loss: 1.1553\n",
      "Epoch 1031/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4382 - val_loss: 1.2815\n",
      "Epoch 1032/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4232 - val_loss: 1.5075\n",
      "Epoch 1033/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.4435 - val_loss: 1.0781\n",
      "Epoch 1034/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.4546 - val_loss: 1.3983\n",
      "Epoch 1035/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4278 - val_loss: 1.4831\n",
      "Epoch 1036/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4340 - val_loss: 1.0833\n",
      "Epoch 1037/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4531 - val_loss: 1.5363\n",
      "Epoch 1038/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.4337 - val_loss: 1.3198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1039/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4247 - val_loss: 1.2584\n",
      "Epoch 1040/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4234 - val_loss: 1.4958\n",
      "Epoch 1041/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.4338 - val_loss: 1.1726\n",
      "Epoch 1042/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4305 - val_loss: 1.3249\n",
      "Epoch 1043/2500\n",
      "64/64 [==============================] - 0s 365us/step - loss: 0.4221 - val_loss: 1.4442\n",
      "Epoch 1044/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4248 - val_loss: 1.2349\n",
      "Epoch 1045/2500\n",
      "64/64 [==============================] - 0s 422us/step - loss: 0.4305 - val_loss: 1.4160\n",
      "Epoch 1046/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4216 - val_loss: 1.4107\n",
      "Epoch 1047/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.4217 - val_loss: 1.2749\n",
      "Epoch 1048/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4282 - val_loss: 1.4048\n",
      "Epoch 1049/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4282 - val_loss: 1.3147\n",
      "Epoch 1050/2500\n",
      "64/64 [==============================] - 0s 363us/step - loss: 0.4197 - val_loss: 1.3662\n",
      "Epoch 1051/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.4238 - val_loss: 1.3991\n",
      "Epoch 1052/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.4245 - val_loss: 1.2927\n",
      "Epoch 1053/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 0.4233 - val_loss: 1.3950\n",
      "Epoch 1054/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4198 - val_loss: 1.3213\n",
      "Epoch 1055/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4262 - val_loss: 1.2421\n",
      "Epoch 1056/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.4296 - val_loss: 1.5258\n",
      "Epoch 1057/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4342 - val_loss: 1.1779\n",
      "Epoch 1058/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4427 - val_loss: 1.3789\n",
      "Epoch 1059/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.4336 - val_loss: 1.5069\n",
      "Epoch 1060/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.4342 - val_loss: 1.1062\n",
      "Epoch 1061/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4518 - val_loss: 1.5023\n",
      "Epoch 1062/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4393 - val_loss: 1.3569\n",
      "Epoch 1063/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 0.4320 - val_loss: 1.2387\n",
      "Epoch 1064/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4307 - val_loss: 1.5074\n",
      "Epoch 1065/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4373 - val_loss: 1.1915\n",
      "Epoch 1066/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4337 - val_loss: 1.2887\n",
      "Epoch 1067/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.4251 - val_loss: 1.5154\n",
      "Epoch 1068/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4341 - val_loss: 1.1009\n",
      "Epoch 1069/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4543 - val_loss: 1.4870\n",
      "Epoch 1070/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4262 - val_loss: 1.4032\n",
      "Epoch 1071/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 0.4240 - val_loss: 1.1786\n",
      "Epoch 1072/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4299 - val_loss: 1.4123\n",
      "Epoch 1073/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4199 - val_loss: 1.3676\n",
      "Epoch 1074/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4164 - val_loss: 1.2347\n",
      "Epoch 1075/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.4210 - val_loss: 1.4176\n",
      "Epoch 1076/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4169 - val_loss: 1.3884\n",
      "Epoch 1077/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4168 - val_loss: 1.1774\n",
      "Epoch 1078/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.4318 - val_loss: 1.5292\n",
      "Epoch 1079/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 0.4354 - val_loss: 1.1369\n",
      "Epoch 1080/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4331 - val_loss: 1.3508\n",
      "Epoch 1081/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 0.4166 - val_loss: 1.4845\n",
      "Epoch 1082/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4205 - val_loss: 1.2331\n",
      "Epoch 1083/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4248 - val_loss: 1.3812\n",
      "Epoch 1084/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.4202 - val_loss: 1.3943\n",
      "Epoch 1085/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.4214 - val_loss: 1.1732\n",
      "Epoch 1086/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4414 - val_loss: 1.4485\n",
      "Epoch 1087/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4266 - val_loss: 1.3200\n",
      "Epoch 1088/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4214 - val_loss: 1.2853\n",
      "Epoch 1089/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4334 - val_loss: 1.4268\n",
      "Epoch 1090/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.4210 - val_loss: 1.3293\n",
      "Epoch 1091/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4201 - val_loss: 1.2882\n",
      "Epoch 1092/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4232 - val_loss: 1.3597\n",
      "Epoch 1093/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.4310 - val_loss: 1.2453\n",
      "Epoch 1094/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4287 - val_loss: 1.3819\n",
      "Epoch 1095/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4197 - val_loss: 1.3991\n",
      "Epoch 1096/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4179 - val_loss: 1.2648\n",
      "Epoch 1097/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.4312 - val_loss: 1.3995\n",
      "Epoch 1098/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4213 - val_loss: 1.3563\n",
      "Epoch 1099/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4203 - val_loss: 1.2327\n",
      "Epoch 1100/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4179 - val_loss: 1.4162\n",
      "Epoch 1101/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 0.4221 - val_loss: 1.3603\n",
      "Epoch 1102/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4194 - val_loss: 1.2702\n",
      "Epoch 1103/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4168 - val_loss: 1.4526\n",
      "Epoch 1104/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 0.4202 - val_loss: 1.1696\n",
      "Epoch 1105/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4312 - val_loss: 1.3969\n",
      "Epoch 1106/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.4211 - val_loss: 1.4480\n",
      "Epoch 1107/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 0.4176 - val_loss: 1.1243\n",
      "Epoch 1108/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4361 - val_loss: 1.4058\n",
      "Epoch 1109/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4239 - val_loss: 1.4911\n",
      "Epoch 1110/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 0.4248 - val_loss: 1.0483\n",
      "Epoch 1111/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 0.4610 - val_loss: 1.6280\n",
      "Epoch 1112/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4425 - val_loss: 1.3071\n",
      "Epoch 1113/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4232 - val_loss: 1.1352\n",
      "Epoch 1114/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.4278 - val_loss: 1.4683\n",
      "Epoch 1115/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4310 - val_loss: 1.2372\n",
      "Epoch 1116/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 0.4171 - val_loss: 1.3261\n",
      "Epoch 1117/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4189 - val_loss: 1.5971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1118/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4291 - val_loss: 1.1684\n",
      "Epoch 1119/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4273 - val_loss: 1.3382\n",
      "Epoch 1120/2500\n",
      "64/64 [==============================] - 0s 319us/step - loss: 0.4146 - val_loss: 1.4121\n",
      "Epoch 1121/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4176 - val_loss: 1.2130\n",
      "Epoch 1122/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 0.4251 - val_loss: 1.4226\n",
      "Epoch 1123/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4147 - val_loss: 1.4092\n",
      "Epoch 1124/2500\n",
      "64/64 [==============================] - 0s 456us/step - loss: 0.4156 - val_loss: 1.2040\n",
      "Epoch 1125/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4204 - val_loss: 1.4255\n",
      "Epoch 1126/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4143 - val_loss: 1.3682\n",
      "Epoch 1127/2500\n",
      "64/64 [==============================] - 0s 912us/step - loss: 0.4179 - val_loss: 1.3788\n",
      "Epoch 1128/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4166 - val_loss: 1.3465\n",
      "Epoch 1129/2500\n",
      "64/64 [==============================] - 0s 900us/step - loss: 0.4155 - val_loss: 1.2554\n",
      "Epoch 1130/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4170 - val_loss: 1.3789\n",
      "Epoch 1131/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4171 - val_loss: 1.4321\n",
      "Epoch 1132/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.4201 - val_loss: 1.2491\n",
      "Epoch 1133/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4245 - val_loss: 1.4195\n",
      "Epoch 1134/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4170 - val_loss: 1.2859\n",
      "Epoch 1135/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.4192 - val_loss: 1.2855\n",
      "Epoch 1136/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.4228 - val_loss: 1.4870\n",
      "Epoch 1137/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.4194 - val_loss: 1.3316\n",
      "Epoch 1138/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.4268 - val_loss: 1.3348\n",
      "Epoch 1139/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4133 - val_loss: 1.2904\n",
      "Epoch 1140/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4220 - val_loss: 1.1879\n",
      "Epoch 1141/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4189 - val_loss: 1.4786\n",
      "Epoch 1142/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4220 - val_loss: 1.4494\n",
      "Epoch 1143/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4218 - val_loss: 1.2429\n",
      "Epoch 1144/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4227 - val_loss: 1.4122\n",
      "Epoch 1145/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4266 - val_loss: 1.1735\n",
      "Epoch 1146/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4247 - val_loss: 1.3214\n",
      "Epoch 1147/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.4201 - val_loss: 1.5447\n",
      "Epoch 1148/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4262 - val_loss: 1.2040\n",
      "Epoch 1149/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4291 - val_loss: 1.4505\n",
      "Epoch 1150/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4215 - val_loss: 1.3260\n",
      "Epoch 1151/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4188 - val_loss: 1.0995\n",
      "Epoch 1152/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.4355 - val_loss: 1.5698\n",
      "Epoch 1153/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4341 - val_loss: 1.3896\n",
      "Epoch 1154/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4199 - val_loss: 1.1116\n",
      "Epoch 1155/2500\n",
      "64/64 [==============================] - 0s 321us/step - loss: 0.4488 - val_loss: 1.5451\n",
      "Epoch 1156/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4345 - val_loss: 1.1603\n",
      "Epoch 1157/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4350 - val_loss: 1.2815\n",
      "Epoch 1158/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.4267 - val_loss: 1.5256\n",
      "Epoch 1159/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 0.4399 - val_loss: 1.1258\n",
      "Epoch 1160/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4326 - val_loss: 1.3565\n",
      "Epoch 1161/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4267 - val_loss: 1.4222\n",
      "Epoch 1162/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4158 - val_loss: 1.1759\n",
      "Epoch 1163/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4268 - val_loss: 1.3926\n",
      "Epoch 1164/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.4167 - val_loss: 1.4469\n",
      "Epoch 1165/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4201 - val_loss: 1.2897\n",
      "Epoch 1166/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4201 - val_loss: 1.5130\n",
      "Epoch 1167/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.4227 - val_loss: 1.2304\n",
      "Epoch 1168/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4268 - val_loss: 1.3320\n",
      "Epoch 1169/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4158 - val_loss: 1.3248\n",
      "Epoch 1170/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4121 - val_loss: 1.2626\n",
      "Epoch 1171/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 0.4258 - val_loss: 1.5617\n",
      "Epoch 1172/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4279 - val_loss: 1.2526\n",
      "Epoch 1173/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.4183 - val_loss: 1.2422\n",
      "Epoch 1174/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.4155 - val_loss: 1.3443\n",
      "Epoch 1175/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4254 - val_loss: 1.2090\n",
      "Epoch 1176/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4192 - val_loss: 1.3947\n",
      "Epoch 1177/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.4115 - val_loss: 1.5630\n",
      "Epoch 1178/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.4239 - val_loss: 1.1678\n",
      "Epoch 1179/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4352 - val_loss: 1.4324\n",
      "Epoch 1180/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.4173 - val_loss: 1.3875\n",
      "Epoch 1181/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4183 - val_loss: 1.1237\n",
      "Epoch 1182/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4330 - val_loss: 1.5038\n",
      "Epoch 1183/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.4236 - val_loss: 1.2269\n",
      "Epoch 1184/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4212 - val_loss: 1.2372\n",
      "Epoch 1185/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.4185 - val_loss: 1.5205\n",
      "Epoch 1186/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4231 - val_loss: 1.2189\n",
      "Epoch 1187/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 0.4236 - val_loss: 1.3533\n",
      "Epoch 1188/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4213 - val_loss: 1.3730\n",
      "Epoch 1189/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4166 - val_loss: 1.1528\n",
      "Epoch 1190/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 0.4238 - val_loss: 1.4549\n",
      "Epoch 1191/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4212 - val_loss: 1.2681\n",
      "Epoch 1192/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4230 - val_loss: 1.3280\n",
      "Epoch 1193/2500\n",
      "64/64 [==============================] - 0s 279us/step - loss: 0.4143 - val_loss: 1.4096\n",
      "Epoch 1194/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.4273 - val_loss: 1.0327\n",
      "Epoch 1195/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4429 - val_loss: 1.3692\n",
      "Epoch 1196/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4304 - val_loss: 1.5178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1197/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4183 - val_loss: 1.2972\n",
      "Epoch 1198/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.4385 - val_loss: 1.4521\n",
      "Epoch 1199/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4166 - val_loss: 1.3187\n",
      "Epoch 1200/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.4467 - val_loss: 1.1578\n",
      "Epoch 1201/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4260 - val_loss: 1.3668\n",
      "Epoch 1202/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4337 - val_loss: 1.2638\n",
      "Epoch 1203/2500\n",
      "64/64 [==============================] - 0s 349us/step - loss: 0.4260 - val_loss: 1.3057\n",
      "Epoch 1204/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4332 - val_loss: 1.2950\n",
      "Epoch 1205/2500\n",
      "64/64 [==============================] - 0s 424us/step - loss: 0.4169 - val_loss: 1.3111\n",
      "Epoch 1206/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4216 - val_loss: 1.4994\n",
      "Epoch 1207/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4484 - val_loss: 1.2837\n",
      "Epoch 1208/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4418 - val_loss: 1.3800\n",
      "Epoch 1209/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.4266 - val_loss: 1.4127\n",
      "Epoch 1210/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.4245 - val_loss: 1.1689\n",
      "Epoch 1211/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.4592 - val_loss: 1.3777\n",
      "Epoch 1212/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 0.4315 - val_loss: 1.3725\n",
      "Epoch 1213/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4252 - val_loss: 1.1995\n",
      "Epoch 1214/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4292 - val_loss: 1.5083\n",
      "Epoch 1215/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4374 - val_loss: 1.3212\n",
      "Epoch 1216/2500\n",
      "64/64 [==============================] - 0s 323us/step - loss: 0.4135 - val_loss: 1.2427\n",
      "Epoch 1217/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4241 - val_loss: 1.4699\n",
      "Epoch 1218/2500\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.4214 - val_loss: 1.2749\n",
      "Epoch 1219/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4186 - val_loss: 1.2048\n",
      "Epoch 1220/2500\n",
      "64/64 [==============================] - 0s 341us/step - loss: 0.4147 - val_loss: 1.4147\n",
      "Epoch 1221/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4240 - val_loss: 1.3779\n",
      "Epoch 1222/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4092 - val_loss: 1.3016\n",
      "Epoch 1223/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 0.4182 - val_loss: 1.2945\n",
      "Epoch 1224/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4063 - val_loss: 1.3070\n",
      "Epoch 1225/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4158 - val_loss: 1.2174\n",
      "Epoch 1226/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.4106 - val_loss: 1.3525\n",
      "Epoch 1227/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 0.4078 - val_loss: 1.3907\n",
      "Epoch 1228/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4065 - val_loss: 1.3342\n",
      "Epoch 1229/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.4061 - val_loss: 1.3426\n",
      "Epoch 1230/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.4123 - val_loss: 1.2801\n",
      "Epoch 1231/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4061 - val_loss: 1.4108\n",
      "Epoch 1232/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4101 - val_loss: 1.2567\n",
      "Epoch 1233/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4070 - val_loss: 1.3078\n",
      "Epoch 1234/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4042 - val_loss: 1.3573\n",
      "Epoch 1235/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4061 - val_loss: 1.2723\n",
      "Epoch 1236/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4066 - val_loss: 1.2848\n",
      "Epoch 1237/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.4036 - val_loss: 1.3836\n",
      "Epoch 1238/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.4077 - val_loss: 1.1839\n",
      "Epoch 1239/2500\n",
      "64/64 [==============================] - 0s 396us/step - loss: 0.4096 - val_loss: 1.3418\n",
      "Epoch 1240/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4079 - val_loss: 1.3534\n",
      "Epoch 1241/2500\n",
      "64/64 [==============================] - 0s 476us/step - loss: 0.4054 - val_loss: 1.1917\n",
      "Epoch 1242/2500\n",
      "64/64 [==============================] - 0s 409us/step - loss: 0.4155 - val_loss: 1.4552\n",
      "Epoch 1243/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4122 - val_loss: 1.2733\n",
      "Epoch 1244/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4075 - val_loss: 1.2628\n",
      "Epoch 1245/2500\n",
      "64/64 [==============================] - 0s 396us/step - loss: 0.4050 - val_loss: 1.3852\n",
      "Epoch 1246/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.4087 - val_loss: 1.1857\n",
      "Epoch 1247/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.4182 - val_loss: 1.3996\n",
      "Epoch 1248/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4069 - val_loss: 1.4538\n",
      "Epoch 1249/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.4097 - val_loss: 1.1997\n",
      "Epoch 1250/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.4100 - val_loss: 1.3691\n",
      "Epoch 1251/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.4116 - val_loss: 1.2394\n",
      "Epoch 1252/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.4016 - val_loss: 1.2783\n",
      "Epoch 1253/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 0.4046 - val_loss: 1.4627\n",
      "Epoch 1254/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4047 - val_loss: 1.3874\n",
      "Epoch 1255/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 0.4055 - val_loss: 1.3014\n",
      "Epoch 1256/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.4064 - val_loss: 1.3050\n",
      "Epoch 1257/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4014 - val_loss: 1.2540\n",
      "Epoch 1258/2500\n",
      "64/64 [==============================] - 0s 305us/step - loss: 0.4017 - val_loss: 1.3160\n",
      "Epoch 1259/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4041 - val_loss: 1.3470\n",
      "Epoch 1260/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4099 - val_loss: 1.2637\n",
      "Epoch 1261/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4048 - val_loss: 1.3684\n",
      "Epoch 1262/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 0.4069 - val_loss: 1.2992\n",
      "Epoch 1263/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.4085 - val_loss: 1.3364\n",
      "Epoch 1264/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.4086 - val_loss: 1.3314\n",
      "Epoch 1265/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.4052 - val_loss: 1.3491\n",
      "Epoch 1266/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4038 - val_loss: 1.3165\n",
      "Epoch 1267/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4062 - val_loss: 1.3378\n",
      "Epoch 1268/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4117 - val_loss: 1.1890\n",
      "Epoch 1269/2500\n",
      "64/64 [==============================] - 0s 397us/step - loss: 0.4189 - val_loss: 1.3540\n",
      "Epoch 1270/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.4101 - val_loss: 1.4332\n",
      "Epoch 1271/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4135 - val_loss: 1.2282\n",
      "Epoch 1272/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4247 - val_loss: 1.4345\n",
      "Epoch 1273/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4187 - val_loss: 1.2349\n",
      "Epoch 1274/2500\n",
      "64/64 [==============================] - 0s 440us/step - loss: 0.4023 - val_loss: 1.1972\n",
      "Epoch 1275/2500\n",
      "64/64 [==============================] - 0s 540us/step - loss: 0.4184 - val_loss: 1.4351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1276/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.4178 - val_loss: 1.2465\n",
      "Epoch 1277/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 0.4218 - val_loss: 1.3479\n",
      "Epoch 1278/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4027 - val_loss: 1.4220\n",
      "Epoch 1279/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4181 - val_loss: 1.2323\n",
      "Epoch 1280/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4169 - val_loss: 1.2782\n",
      "Epoch 1281/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 0.4170 - val_loss: 1.4395\n",
      "Epoch 1282/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4072 - val_loss: 1.2977\n",
      "Epoch 1283/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.4187 - val_loss: 1.3823\n",
      "Epoch 1284/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.4047 - val_loss: 1.2803\n",
      "Epoch 1285/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4159 - val_loss: 1.1809\n",
      "Epoch 1286/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 0.4072 - val_loss: 1.3551\n",
      "Epoch 1287/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.4016 - val_loss: 1.2829\n",
      "Epoch 1288/2500\n",
      "64/64 [==============================] - 0s 280us/step - loss: 0.4022 - val_loss: 1.4500\n",
      "Epoch 1289/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.4039 - val_loss: 1.4071\n",
      "Epoch 1290/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4010 - val_loss: 1.2469\n",
      "Epoch 1291/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.4059 - val_loss: 1.3735\n",
      "Epoch 1292/2500\n",
      "64/64 [==============================] - 0s 497us/step - loss: 0.4059 - val_loss: 1.2733\n",
      "Epoch 1293/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4031 - val_loss: 1.3052\n",
      "Epoch 1294/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.4030 - val_loss: 1.4119\n",
      "Epoch 1295/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4095 - val_loss: 1.1925\n",
      "Epoch 1296/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.4151 - val_loss: 1.3563\n",
      "Epoch 1297/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4071 - val_loss: 1.4115\n",
      "Epoch 1298/2500\n",
      "64/64 [==============================] - 0s 316us/step - loss: 0.4026 - val_loss: 1.2442\n",
      "Epoch 1299/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4084 - val_loss: 1.4105\n",
      "Epoch 1300/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 0.4057 - val_loss: 1.2353\n",
      "Epoch 1301/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.4079 - val_loss: 1.3223\n",
      "Epoch 1302/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4002 - val_loss: 1.3570\n",
      "Epoch 1303/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.4105 - val_loss: 1.1984\n",
      "Epoch 1304/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4038 - val_loss: 1.3642\n",
      "Epoch 1305/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4093 - val_loss: 1.3639\n",
      "Epoch 1306/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.4012 - val_loss: 1.4077\n",
      "Epoch 1307/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4075 - val_loss: 1.3794\n",
      "Epoch 1308/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3988 - val_loss: 1.1079\n",
      "Epoch 1309/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4223 - val_loss: 1.3154\n",
      "Epoch 1310/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.4037 - val_loss: 1.4227\n",
      "Epoch 1311/2500\n",
      "64/64 [==============================] - 0s 340us/step - loss: 0.4156 - val_loss: 1.2507\n",
      "Epoch 1312/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4159 - val_loss: 1.4871\n",
      "Epoch 1313/2500\n",
      "64/64 [==============================] - 0s 417us/step - loss: 0.4183 - val_loss: 1.2684\n",
      "Epoch 1314/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.4000 - val_loss: 1.3033\n",
      "Epoch 1315/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4137 - val_loss: 1.3758\n",
      "Epoch 1316/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.4018 - val_loss: 1.4705\n",
      "Epoch 1317/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.4052 - val_loss: 1.2568\n",
      "Epoch 1318/2500\n",
      "64/64 [==============================] - 0s 349us/step - loss: 0.4012 - val_loss: 1.3090\n",
      "Epoch 1319/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3997 - val_loss: 1.4092\n",
      "Epoch 1320/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4029 - val_loss: 1.2527\n",
      "Epoch 1321/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.4018 - val_loss: 1.3792\n",
      "Epoch 1322/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.3964 - val_loss: 1.4386\n",
      "Epoch 1323/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 0.4035 - val_loss: 1.2717\n",
      "Epoch 1324/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4099 - val_loss: 1.3350\n",
      "Epoch 1325/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4039 - val_loss: 1.3437\n",
      "Epoch 1326/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 0.3970 - val_loss: 1.2835\n",
      "Epoch 1327/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.4056 - val_loss: 1.4254\n",
      "Epoch 1328/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4080 - val_loss: 1.3224\n",
      "Epoch 1329/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 0.4049 - val_loss: 1.1672\n",
      "Epoch 1330/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 0.4003 - val_loss: 1.2859\n",
      "Epoch 1331/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4007 - val_loss: 1.3417\n",
      "Epoch 1332/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4008 - val_loss: 1.4515\n",
      "Epoch 1333/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.4041 - val_loss: 1.3061\n",
      "Epoch 1334/2500\n",
      "64/64 [==============================] - 0s 339us/step - loss: 0.3952 - val_loss: 1.3154\n",
      "Epoch 1335/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4019 - val_loss: 1.3035\n",
      "Epoch 1336/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.3991 - val_loss: 1.2754\n",
      "Epoch 1337/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4008 - val_loss: 1.4435\n",
      "Epoch 1338/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3969 - val_loss: 1.4400\n",
      "Epoch 1339/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.3950 - val_loss: 1.2455\n",
      "Epoch 1340/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 0.3967 - val_loss: 1.3768\n",
      "Epoch 1341/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4013 - val_loss: 1.3185\n",
      "Epoch 1342/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3977 - val_loss: 1.2505\n",
      "Epoch 1343/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4000 - val_loss: 1.4246\n",
      "Epoch 1344/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.3965 - val_loss: 1.3921\n",
      "Epoch 1345/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4028 - val_loss: 1.0537\n",
      "Epoch 1346/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.4270 - val_loss: 1.5345\n",
      "Epoch 1347/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4329 - val_loss: 1.2611\n",
      "Epoch 1348/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4088 - val_loss: 1.2012\n",
      "Epoch 1349/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4115 - val_loss: 1.5160\n",
      "Epoch 1350/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4208 - val_loss: 1.1206\n",
      "Epoch 1351/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.4141 - val_loss: 1.2573\n",
      "Epoch 1352/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3980 - val_loss: 1.5628\n",
      "Epoch 1353/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.4321 - val_loss: 1.1015\n",
      "Epoch 1354/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 0.4222 - val_loss: 1.4325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1355/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.4144 - val_loss: 1.4646\n",
      "Epoch 1356/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 0.4047 - val_loss: 1.2052\n",
      "Epoch 1357/2500\n",
      "64/64 [==============================] - 0s 533us/step - loss: 0.4301 - val_loss: 1.4610\n",
      "Epoch 1358/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 0.4092 - val_loss: 1.1501\n",
      "Epoch 1359/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 0.4079 - val_loss: 1.1966\n",
      "Epoch 1360/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.3983 - val_loss: 1.5794\n",
      "Epoch 1361/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.4124 - val_loss: 1.3251\n",
      "Epoch 1362/2500\n",
      "64/64 [==============================] - 0s 406us/step - loss: 0.4137 - val_loss: 1.2924\n",
      "Epoch 1363/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4010 - val_loss: 1.2887\n",
      "Epoch 1364/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.4028 - val_loss: 1.2770\n",
      "Epoch 1365/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4042 - val_loss: 1.3130\n",
      "Epoch 1366/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4102 - val_loss: 1.4637\n",
      "Epoch 1367/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4005 - val_loss: 1.3216\n",
      "Epoch 1368/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3933 - val_loss: 1.2489\n",
      "Epoch 1369/2500\n",
      "64/64 [==============================] - 0s 383us/step - loss: 0.4088 - val_loss: 1.2541\n",
      "Epoch 1370/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.4139 - val_loss: 1.3933\n",
      "Epoch 1371/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 0.4018 - val_loss: 1.3661\n",
      "Epoch 1372/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.3931 - val_loss: 1.2085\n",
      "Epoch 1373/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4128 - val_loss: 1.4401\n",
      "Epoch 1374/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.4208 - val_loss: 1.3811\n",
      "Epoch 1375/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.4015 - val_loss: 1.1962\n",
      "Epoch 1376/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4064 - val_loss: 1.4785\n",
      "Epoch 1377/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4096 - val_loss: 1.1989\n",
      "Epoch 1378/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.4113 - val_loss: 1.2486\n",
      "Epoch 1379/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.4062 - val_loss: 1.5081\n",
      "Epoch 1380/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4058 - val_loss: 1.1041\n",
      "Epoch 1381/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.4135 - val_loss: 1.3454\n",
      "Epoch 1382/2500\n",
      "64/64 [==============================] - 0s 455us/step - loss: 0.4069 - val_loss: 1.4145\n",
      "Epoch 1383/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 0.3956 - val_loss: 1.2375\n",
      "Epoch 1384/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4123 - val_loss: 1.5335\n",
      "Epoch 1385/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3979 - val_loss: 1.3607\n",
      "Epoch 1386/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 0.3998 - val_loss: 1.0984\n",
      "Epoch 1387/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4126 - val_loss: 1.3269\n",
      "Epoch 1388/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4049 - val_loss: 1.3284\n",
      "Epoch 1389/2500\n",
      "64/64 [==============================] - 0s 362us/step - loss: 0.3900 - val_loss: 1.3663\n",
      "Epoch 1390/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.3951 - val_loss: 1.4025\n",
      "Epoch 1391/2500\n",
      "64/64 [==============================] - 0s 380us/step - loss: 0.4039 - val_loss: 1.2735\n",
      "Epoch 1392/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3988 - val_loss: 1.3075\n",
      "Epoch 1393/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 0.3976 - val_loss: 1.3438\n",
      "Epoch 1394/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3885 - val_loss: 1.4021\n",
      "Epoch 1395/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3905 - val_loss: 1.3738\n",
      "Epoch 1396/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.3876 - val_loss: 1.1813\n",
      "Epoch 1397/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.3925 - val_loss: 1.3547\n",
      "Epoch 1398/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3917 - val_loss: 1.3501\n",
      "Epoch 1399/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.3902 - val_loss: 1.1964\n",
      "Epoch 1400/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3943 - val_loss: 1.4433\n",
      "Epoch 1401/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.3968 - val_loss: 1.2727\n",
      "Epoch 1402/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.3875 - val_loss: 1.2744\n",
      "Epoch 1403/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.3896 - val_loss: 1.3923\n",
      "Epoch 1404/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3854 - val_loss: 1.3254\n",
      "Epoch 1405/2500\n",
      "64/64 [==============================] - 0s 368us/step - loss: 0.3826 - val_loss: 1.3016\n",
      "Epoch 1406/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.3856 - val_loss: 1.4653\n",
      "Epoch 1407/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3939 - val_loss: 1.2098\n",
      "Epoch 1408/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 0.3991 - val_loss: 1.3791\n",
      "Epoch 1409/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.3902 - val_loss: 1.2829\n",
      "Epoch 1410/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.3947 - val_loss: 1.2530\n",
      "Epoch 1411/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.3910 - val_loss: 1.4770\n",
      "Epoch 1412/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3970 - val_loss: 1.3755\n",
      "Epoch 1413/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3870 - val_loss: 1.0969\n",
      "Epoch 1414/2500\n",
      "64/64 [==============================] - 0s 287us/step - loss: 0.4113 - val_loss: 1.4379\n",
      "Epoch 1415/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4062 - val_loss: 1.4278\n",
      "Epoch 1416/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3948 - val_loss: 1.0884\n",
      "Epoch 1417/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 0.4298 - val_loss: 1.6045\n",
      "Epoch 1418/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4228 - val_loss: 1.2226\n",
      "Epoch 1419/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4091 - val_loss: 1.2420\n",
      "Epoch 1420/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 0.3976 - val_loss: 1.5773\n",
      "Epoch 1421/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.4274 - val_loss: 1.1078\n",
      "Epoch 1422/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.4085 - val_loss: 1.2141\n",
      "Epoch 1423/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.4056 - val_loss: 1.5401\n",
      "Epoch 1424/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4063 - val_loss: 1.0858\n",
      "Epoch 1425/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.4328 - val_loss: 1.3713\n",
      "Epoch 1426/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.4010 - val_loss: 1.5258\n",
      "Epoch 1427/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4077 - val_loss: 1.0815\n",
      "Epoch 1428/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.4269 - val_loss: 1.4569\n",
      "Epoch 1429/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.3902 - val_loss: 1.3859\n",
      "Epoch 1430/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3940 - val_loss: 1.0846\n",
      "Epoch 1431/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4026 - val_loss: 1.3674\n",
      "Epoch 1432/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.3951 - val_loss: 1.4193\n",
      "Epoch 1433/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4048 - val_loss: 1.3291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1434/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4098 - val_loss: 1.3199\n",
      "Epoch 1435/2500\n",
      "64/64 [==============================] - 0s 319us/step - loss: 0.3797 - val_loss: 1.3850\n",
      "Epoch 1436/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3951 - val_loss: 1.0234\n",
      "Epoch 1437/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.4356 - val_loss: 1.6266\n",
      "Epoch 1438/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.4176 - val_loss: 1.3878\n",
      "Epoch 1439/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3932 - val_loss: 1.2129\n",
      "Epoch 1440/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.4004 - val_loss: 1.4197\n",
      "Epoch 1441/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4046 - val_loss: 1.3608\n",
      "Epoch 1442/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3873 - val_loss: 1.1808\n",
      "Epoch 1443/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.4041 - val_loss: 1.5855\n",
      "Epoch 1444/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.4100 - val_loss: 1.1835\n",
      "Epoch 1445/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.4118 - val_loss: 1.2430\n",
      "Epoch 1446/2500\n",
      "64/64 [==============================] - 0s 298us/step - loss: 0.4096 - val_loss: 1.4997\n",
      "Epoch 1447/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4154 - val_loss: 1.2634\n",
      "Epoch 1448/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4021 - val_loss: 1.2678\n",
      "Epoch 1449/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.3902 - val_loss: 1.4365\n",
      "Epoch 1450/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.4136 - val_loss: 1.2258\n",
      "Epoch 1451/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.4030 - val_loss: 1.3369\n",
      "Epoch 1452/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.3845 - val_loss: 1.4111\n",
      "Epoch 1453/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.3879 - val_loss: 1.2201\n",
      "Epoch 1454/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.4004 - val_loss: 1.4207\n",
      "Epoch 1455/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3971 - val_loss: 1.4906\n",
      "Epoch 1456/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4090 - val_loss: 1.3258\n",
      "Epoch 1457/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.3877 - val_loss: 1.3023\n",
      "Epoch 1458/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3910 - val_loss: 1.2734\n",
      "Epoch 1459/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4280 - val_loss: 1.4454\n",
      "Epoch 1460/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4407 - val_loss: 1.2915\n",
      "Epoch 1461/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.4024 - val_loss: 1.3460\n",
      "Epoch 1462/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3841 - val_loss: 1.2360\n",
      "Epoch 1463/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.4219 - val_loss: 1.4283\n",
      "Epoch 1464/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.4685 - val_loss: 1.4908\n",
      "Epoch 1465/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.4180 - val_loss: 1.1159\n",
      "Epoch 1466/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3979 - val_loss: 1.3203\n",
      "Epoch 1467/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4312 - val_loss: 1.4344\n",
      "Epoch 1468/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.3952 - val_loss: 1.3728\n",
      "Epoch 1469/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.4309 - val_loss: 1.4363\n",
      "Epoch 1470/2500\n",
      "64/64 [==============================] - 0s 444us/step - loss: 0.3924 - val_loss: 1.2985\n",
      "Epoch 1471/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.4010 - val_loss: 1.0480\n",
      "Epoch 1472/2500\n",
      "64/64 [==============================] - 0s 422us/step - loss: 0.4232 - val_loss: 1.4871\n",
      "Epoch 1473/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.3882 - val_loss: 1.4107\n",
      "Epoch 1474/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.4064 - val_loss: 1.2002\n",
      "Epoch 1475/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4018 - val_loss: 1.3142\n",
      "Epoch 1476/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 0.4024 - val_loss: 1.2708\n",
      "Epoch 1477/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3780 - val_loss: 1.4239\n",
      "Epoch 1478/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.3869 - val_loss: 1.4757\n",
      "Epoch 1479/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.3846 - val_loss: 1.2101\n",
      "Epoch 1480/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.3814 - val_loss: 1.2401\n",
      "Epoch 1481/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.3846 - val_loss: 1.4198\n",
      "Epoch 1482/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3822 - val_loss: 1.3311\n",
      "Epoch 1483/2500\n",
      "64/64 [==============================] - 0s 461us/step - loss: 0.3925 - val_loss: 1.3437\n",
      "Epoch 1484/2500\n",
      "64/64 [==============================] - 0s 322us/step - loss: 0.3775 - val_loss: 1.3726\n",
      "Epoch 1485/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3874 - val_loss: 1.0661\n",
      "Epoch 1486/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3946 - val_loss: 1.3913\n",
      "Epoch 1487/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.3885 - val_loss: 1.2897\n",
      "Epoch 1488/2500\n",
      "64/64 [==============================] - 0s 370us/step - loss: 0.3842 - val_loss: 1.3283\n",
      "Epoch 1489/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.3742 - val_loss: 1.4118\n",
      "Epoch 1490/2500\n",
      "64/64 [==============================] - 0s 424us/step - loss: 0.3882 - val_loss: 1.2284\n",
      "Epoch 1491/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3935 - val_loss: 1.3881\n",
      "Epoch 1492/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 0.3952 - val_loss: 1.3247\n",
      "Epoch 1493/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3753 - val_loss: 1.2168\n",
      "Epoch 1494/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 0.3892 - val_loss: 1.3447\n",
      "Epoch 1495/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3741 - val_loss: 1.4864\n",
      "Epoch 1496/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3869 - val_loss: 1.3143\n",
      "Epoch 1497/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3830 - val_loss: 1.2585\n",
      "Epoch 1498/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 0.3783 - val_loss: 1.1919\n",
      "Epoch 1499/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.3791 - val_loss: 1.2454\n",
      "Epoch 1500/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.3755 - val_loss: 1.4801\n",
      "Epoch 1501/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.3850 - val_loss: 1.3158\n",
      "Epoch 1502/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.3779 - val_loss: 1.3498\n",
      "Epoch 1503/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3830 - val_loss: 1.3214\n",
      "Epoch 1504/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.3758 - val_loss: 1.3126\n",
      "Epoch 1505/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3772 - val_loss: 1.2797\n",
      "Epoch 1506/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3722 - val_loss: 1.2961\n",
      "Epoch 1507/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.3748 - val_loss: 1.2916\n",
      "Epoch 1508/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.3740 - val_loss: 1.4809\n",
      "Epoch 1509/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3825 - val_loss: 1.1494\n",
      "Epoch 1510/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.3887 - val_loss: 1.3849\n",
      "Epoch 1511/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.3899 - val_loss: 1.2721\n",
      "Epoch 1512/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.3794 - val_loss: 1.3064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1513/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.3809 - val_loss: 1.4363\n",
      "Epoch 1514/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.3806 - val_loss: 1.0373\n",
      "Epoch 1515/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4141 - val_loss: 1.4537\n",
      "Epoch 1516/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.3781 - val_loss: 1.4430\n",
      "Epoch 1517/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.3894 - val_loss: 1.0976\n",
      "Epoch 1518/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4069 - val_loss: 1.4964\n",
      "Epoch 1519/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4134 - val_loss: 1.2296\n",
      "Epoch 1520/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.3725 - val_loss: 1.1964\n",
      "Epoch 1521/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 0.3924 - val_loss: 1.6666\n",
      "Epoch 1522/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.4178 - val_loss: 1.0424\n",
      "Epoch 1523/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4191 - val_loss: 1.2939\n",
      "Epoch 1524/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.3715 - val_loss: 1.5257\n",
      "Epoch 1525/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3930 - val_loss: 1.0860\n",
      "Epoch 1526/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.4081 - val_loss: 1.4405\n",
      "Epoch 1527/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3883 - val_loss: 1.3446\n",
      "Epoch 1528/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 0.3779 - val_loss: 1.1809\n",
      "Epoch 1529/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.4030 - val_loss: 1.5596\n",
      "Epoch 1530/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 0.4002 - val_loss: 1.2220\n",
      "Epoch 1531/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3794 - val_loss: 1.1233\n",
      "Epoch 1532/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3754 - val_loss: 1.4751\n",
      "Epoch 1533/2500\n",
      "64/64 [==============================] - 0s 429us/step - loss: 0.4062 - val_loss: 1.1518\n",
      "Epoch 1534/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4004 - val_loss: 1.3483\n",
      "Epoch 1535/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.3863 - val_loss: 1.4784\n",
      "Epoch 1536/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3912 - val_loss: 1.1064\n",
      "Epoch 1537/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.4349 - val_loss: 1.5847\n",
      "Epoch 1538/2500\n",
      "64/64 [==============================] - 0s 428us/step - loss: 0.4269 - val_loss: 1.2263\n",
      "Epoch 1539/2500\n",
      "64/64 [==============================] - 0s 455us/step - loss: 0.4161 - val_loss: 1.1668\n",
      "Epoch 1540/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4009 - val_loss: 1.5248\n",
      "Epoch 1541/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 0.3924 - val_loss: 1.2137\n",
      "Epoch 1542/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3716 - val_loss: 1.2342\n",
      "Epoch 1543/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3823 - val_loss: 1.4627\n",
      "Epoch 1544/2500\n",
      "64/64 [==============================] - 0s 322us/step - loss: 0.3827 - val_loss: 1.2334\n",
      "Epoch 1545/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.3717 - val_loss: 1.3593\n",
      "Epoch 1546/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.3654 - val_loss: 1.3920\n",
      "Epoch 1547/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.3723 - val_loss: 1.2421\n",
      "Epoch 1548/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3743 - val_loss: 1.3158\n",
      "Epoch 1549/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.3703 - val_loss: 1.4068\n",
      "Epoch 1550/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3670 - val_loss: 1.2761\n",
      "Epoch 1551/2500\n",
      "64/64 [==============================] - 0s 512us/step - loss: 0.3663 - val_loss: 1.3251\n",
      "Epoch 1552/2500\n",
      "64/64 [==============================] - 0s 379us/step - loss: 0.3651 - val_loss: 1.3844\n",
      "Epoch 1553/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.3735 - val_loss: 1.2220\n",
      "Epoch 1554/2500\n",
      "64/64 [==============================] - 0s 444us/step - loss: 0.3785 - val_loss: 1.4406\n",
      "Epoch 1555/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3763 - val_loss: 1.2493\n",
      "Epoch 1556/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.3728 - val_loss: 1.3369\n",
      "Epoch 1557/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.3658 - val_loss: 1.3448\n",
      "Epoch 1558/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3606 - val_loss: 1.2472\n",
      "Epoch 1559/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.3635 - val_loss: 1.4568\n",
      "Epoch 1560/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 0.3708 - val_loss: 1.2909\n",
      "Epoch 1561/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.3670 - val_loss: 1.2295\n",
      "Epoch 1562/2500\n",
      "64/64 [==============================] - 0s 553us/step - loss: 0.3636 - val_loss: 1.4253\n",
      "Epoch 1563/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 0.3655 - val_loss: 1.2785\n",
      "Epoch 1564/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3625 - val_loss: 1.3126\n",
      "Epoch 1565/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3579 - val_loss: 1.4372\n",
      "Epoch 1566/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 0.3636 - val_loss: 1.3373\n",
      "Epoch 1567/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3584 - val_loss: 1.3994\n",
      "Epoch 1568/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3597 - val_loss: 1.3427\n",
      "Epoch 1569/2500\n",
      "64/64 [==============================] - 0s 372us/step - loss: 0.3600 - val_loss: 1.3036\n",
      "Epoch 1570/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.3610 - val_loss: 1.4045\n",
      "Epoch 1571/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.3699 - val_loss: 1.3146\n",
      "Epoch 1572/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 0.3707 - val_loss: 1.2924\n",
      "Epoch 1573/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.3625 - val_loss: 1.2999\n",
      "Epoch 1574/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.3685 - val_loss: 1.3300\n",
      "Epoch 1575/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.3650 - val_loss: 1.4511\n",
      "Epoch 1576/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3662 - val_loss: 1.2619\n",
      "Epoch 1577/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 0.3745 - val_loss: 1.4025\n",
      "Epoch 1578/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.3695 - val_loss: 1.2398\n",
      "Epoch 1579/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3679 - val_loss: 1.3103\n",
      "Epoch 1580/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.3638 - val_loss: 1.3196\n",
      "Epoch 1581/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 0.3762 - val_loss: 1.3622\n",
      "Epoch 1582/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3902 - val_loss: 1.4385\n",
      "Epoch 1583/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.4033 - val_loss: 1.1836\n",
      "Epoch 1584/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.4139 - val_loss: 1.2772\n",
      "Epoch 1585/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.4058 - val_loss: 1.3854\n",
      "Epoch 1586/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3867 - val_loss: 1.5456\n",
      "Epoch 1587/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.3773 - val_loss: 1.2278\n",
      "Epoch 1588/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.3676 - val_loss: 1.2974\n",
      "Epoch 1589/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.3822 - val_loss: 1.3778\n",
      "Epoch 1590/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 0.3802 - val_loss: 1.2870\n",
      "Epoch 1591/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.3803 - val_loss: 1.5281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1592/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 0.3669 - val_loss: 1.2880\n",
      "Epoch 1593/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3567 - val_loss: 1.2353\n",
      "Epoch 1594/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3681 - val_loss: 1.3873\n",
      "Epoch 1595/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 0.3758 - val_loss: 1.2432\n",
      "Epoch 1596/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.3627 - val_loss: 1.2540\n",
      "Epoch 1597/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3603 - val_loss: 1.5284\n",
      "Epoch 1598/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 0.3605 - val_loss: 1.2830\n",
      "Epoch 1599/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3558 - val_loss: 1.2179\n",
      "Epoch 1600/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.3553 - val_loss: 1.2984\n",
      "Epoch 1601/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.3555 - val_loss: 1.3311\n",
      "Epoch 1602/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3546 - val_loss: 1.4711\n",
      "Epoch 1603/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3583 - val_loss: 1.3006\n",
      "Epoch 1604/2500\n",
      "64/64 [==============================] - 0s 366us/step - loss: 0.3529 - val_loss: 1.1810\n",
      "Epoch 1605/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3596 - val_loss: 1.3672\n",
      "Epoch 1606/2500\n",
      "64/64 [==============================] - 0s 447us/step - loss: 0.3590 - val_loss: 1.5032\n",
      "Epoch 1607/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3678 - val_loss: 1.2130\n",
      "Epoch 1608/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 0.3619 - val_loss: 1.3360\n",
      "Epoch 1609/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3609 - val_loss: 1.3040\n",
      "Epoch 1610/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3527 - val_loss: 1.3000\n",
      "Epoch 1611/2500\n",
      "64/64 [==============================] - 0s 412us/step - loss: 0.3601 - val_loss: 1.3460\n",
      "Epoch 1612/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3523 - val_loss: 1.3395\n",
      "Epoch 1613/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3540 - val_loss: 1.3029\n",
      "Epoch 1614/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3540 - val_loss: 1.3995\n",
      "Epoch 1615/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.3521 - val_loss: 1.3097\n",
      "Epoch 1616/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3537 - val_loss: 1.3155\n",
      "Epoch 1617/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3500 - val_loss: 1.3347\n",
      "Epoch 1618/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.3523 - val_loss: 1.3637\n",
      "Epoch 1619/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 0.3558 - val_loss: 1.2408\n",
      "Epoch 1620/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.3590 - val_loss: 1.3514\n",
      "Epoch 1621/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.3595 - val_loss: 1.3483\n",
      "Epoch 1622/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3556 - val_loss: 1.3743\n",
      "Epoch 1623/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3549 - val_loss: 1.3515\n",
      "Epoch 1624/2500\n",
      "64/64 [==============================] - 0s 475us/step - loss: 0.3512 - val_loss: 1.3797\n",
      "Epoch 1625/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 0.3534 - val_loss: 1.3919\n",
      "Epoch 1626/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3506 - val_loss: 1.2970\n",
      "Epoch 1627/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3543 - val_loss: 1.3455\n",
      "Epoch 1628/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 0.3507 - val_loss: 1.3192\n",
      "Epoch 1629/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 0.3595 - val_loss: 1.3715\n",
      "Epoch 1630/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.3512 - val_loss: 1.2936\n",
      "Epoch 1631/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.3565 - val_loss: 1.4223\n",
      "Epoch 1632/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.3634 - val_loss: 1.3883\n",
      "Epoch 1633/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.3632 - val_loss: 1.2243\n",
      "Epoch 1634/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3648 - val_loss: 1.3945\n",
      "Epoch 1635/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3593 - val_loss: 1.4161\n",
      "Epoch 1636/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.3577 - val_loss: 1.3344\n",
      "Epoch 1637/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3530 - val_loss: 1.3301\n",
      "Epoch 1638/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.3571 - val_loss: 1.3372\n",
      "Epoch 1639/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.3491 - val_loss: 1.3184\n",
      "Epoch 1640/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3631 - val_loss: 1.4581\n",
      "Epoch 1641/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3582 - val_loss: 1.2658\n",
      "Epoch 1642/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.3682 - val_loss: 1.3059\n",
      "Epoch 1643/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.3674 - val_loss: 1.4383\n",
      "Epoch 1644/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3820 - val_loss: 1.2331\n",
      "Epoch 1645/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3811 - val_loss: 1.4045\n",
      "Epoch 1646/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 0.3867 - val_loss: 1.4503\n",
      "Epoch 1647/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3938 - val_loss: 1.4107\n",
      "Epoch 1648/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3766 - val_loss: 1.2646\n",
      "Epoch 1649/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.3542 - val_loss: 1.2958\n",
      "Epoch 1650/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3667 - val_loss: 1.4110\n",
      "Epoch 1651/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3705 - val_loss: 1.3816\n",
      "Epoch 1652/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.3764 - val_loss: 1.3992\n",
      "Epoch 1653/2500\n",
      "64/64 [==============================] - 0s 339us/step - loss: 0.3592 - val_loss: 1.1491\n",
      "Epoch 1654/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3621 - val_loss: 1.3280\n",
      "Epoch 1655/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 0.3501 - val_loss: 1.4583\n",
      "Epoch 1656/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.3522 - val_loss: 1.1935\n",
      "Epoch 1657/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3684 - val_loss: 1.4383\n",
      "Epoch 1658/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.3622 - val_loss: 1.3049\n",
      "Epoch 1659/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3505 - val_loss: 1.3101\n",
      "Epoch 1660/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3527 - val_loss: 1.4064\n",
      "Epoch 1661/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 0.3503 - val_loss: 1.3269\n",
      "Epoch 1662/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3502 - val_loss: 1.4096\n",
      "Epoch 1663/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3473 - val_loss: 1.3974\n",
      "Epoch 1664/2500\n",
      "64/64 [==============================] - 0s 311us/step - loss: 0.3486 - val_loss: 1.2172\n",
      "Epoch 1665/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3483 - val_loss: 1.2452\n",
      "Epoch 1666/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3481 - val_loss: 1.3889\n",
      "Epoch 1667/2500\n",
      "64/64 [==============================] - 0s 392us/step - loss: 0.3418 - val_loss: 1.4550\n",
      "Epoch 1668/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.3506 - val_loss: 1.2842\n",
      "Epoch 1669/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 0.3477 - val_loss: 1.3234\n",
      "Epoch 1670/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 0.3496 - val_loss: 1.2979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1671/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3535 - val_loss: 1.2998\n",
      "Epoch 1672/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.3589 - val_loss: 1.4779\n",
      "Epoch 1673/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.3694 - val_loss: 1.3744\n",
      "Epoch 1674/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.4003 - val_loss: 1.3945\n",
      "Epoch 1675/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 0.3997 - val_loss: 1.3012\n",
      "Epoch 1676/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.4022 - val_loss: 1.3207\n",
      "Epoch 1677/2500\n",
      "64/64 [==============================] - 0s 330us/step - loss: 0.3746 - val_loss: 1.3227\n",
      "Epoch 1678/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3498 - val_loss: 1.4568\n",
      "Epoch 1679/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.3489 - val_loss: 1.2238\n",
      "Epoch 1680/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.3951 - val_loss: 1.4134\n",
      "Epoch 1681/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4142 - val_loss: 1.4632\n",
      "Epoch 1682/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.4288 - val_loss: 1.2013\n",
      "Epoch 1683/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 0.4374 - val_loss: 1.4543\n",
      "Epoch 1684/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3644 - val_loss: 1.3587\n",
      "Epoch 1685/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 0.4000 - val_loss: 1.3461\n",
      "Epoch 1686/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4947 - val_loss: 1.4698\n",
      "Epoch 1687/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.3765 - val_loss: 1.5330\n",
      "Epoch 1688/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4374 - val_loss: 1.1692\n",
      "Epoch 1689/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.5835 - val_loss: 1.1591\n",
      "Epoch 1690/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3776 - val_loss: 1.8811\n",
      "Epoch 1691/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5601 - val_loss: 1.1548\n",
      "Epoch 1692/2500\n",
      "64/64 [==============================] - 0s 407us/step - loss: 0.6628 - val_loss: 1.1898\n",
      "Epoch 1693/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.4120 - val_loss: 2.0807\n",
      "Epoch 1694/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 0.7459 - val_loss: 1.1846\n",
      "Epoch 1695/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.5179 - val_loss: 0.8956\n",
      "Epoch 1696/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.5994 - val_loss: 1.7575\n",
      "Epoch 1697/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.5488 - val_loss: 1.3461\n",
      "Epoch 1698/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.4344 - val_loss: 0.9817\n",
      "Epoch 1699/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.5311 - val_loss: 1.3014\n",
      "Epoch 1700/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.4737 - val_loss: 1.4682\n",
      "Epoch 1701/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.4616 - val_loss: 1.3332\n",
      "Epoch 1702/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.4214 - val_loss: 1.3481\n",
      "Epoch 1703/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.4517 - val_loss: 1.1685\n",
      "Epoch 1704/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.4132 - val_loss: 1.3214\n",
      "Epoch 1705/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.4050 - val_loss: 1.4361\n",
      "Epoch 1706/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.4144 - val_loss: 1.1470\n",
      "Epoch 1707/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 0.4047 - val_loss: 1.1602\n",
      "Epoch 1708/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3916 - val_loss: 1.4463\n",
      "Epoch 1709/2500\n",
      "64/64 [==============================] - 0s 410us/step - loss: 0.4053 - val_loss: 1.2670\n",
      "Epoch 1710/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3780 - val_loss: 1.1894\n",
      "Epoch 1711/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 0.4177 - val_loss: 1.4376\n",
      "Epoch 1712/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.3745 - val_loss: 1.2901\n",
      "Epoch 1713/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.3951 - val_loss: 1.1048\n",
      "Epoch 1714/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3711 - val_loss: 1.2811\n",
      "Epoch 1715/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4021 - val_loss: 1.2516\n",
      "Epoch 1716/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.3541 - val_loss: 1.2877\n",
      "Epoch 1717/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3775 - val_loss: 1.3532\n",
      "Epoch 1718/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3563 - val_loss: 1.2475\n",
      "Epoch 1719/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3630 - val_loss: 1.1307\n",
      "Epoch 1720/2500\n",
      "64/64 [==============================] - 0s 323us/step - loss: 0.3564 - val_loss: 1.2371\n",
      "Epoch 1721/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3557 - val_loss: 1.2154\n",
      "Epoch 1722/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.3452 - val_loss: 1.2178\n",
      "Epoch 1723/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3615 - val_loss: 1.3320\n",
      "Epoch 1724/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3531 - val_loss: 1.2485\n",
      "Epoch 1725/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3485 - val_loss: 1.2537\n",
      "Epoch 1726/2500\n",
      "64/64 [==============================] - 0s 325us/step - loss: 0.3437 - val_loss: 1.2573\n",
      "Epoch 1727/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3484 - val_loss: 1.1874\n",
      "Epoch 1728/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3438 - val_loss: 1.2355\n",
      "Epoch 1729/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3444 - val_loss: 1.3650\n",
      "Epoch 1730/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 0.3508 - val_loss: 1.0941\n",
      "Epoch 1731/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3562 - val_loss: 1.2111\n",
      "Epoch 1732/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.3471 - val_loss: 1.3349\n",
      "Epoch 1733/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.3498 - val_loss: 1.2241\n",
      "Epoch 1734/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.3481 - val_loss: 1.3118\n",
      "Epoch 1735/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3423 - val_loss: 1.2804\n",
      "Epoch 1736/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.3466 - val_loss: 1.2304\n",
      "Epoch 1737/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.3371 - val_loss: 1.2443\n",
      "Epoch 1738/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 0.3442 - val_loss: 1.1717\n",
      "Epoch 1739/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3428 - val_loss: 1.2228\n",
      "Epoch 1740/2500\n",
      "64/64 [==============================] - 0s 316us/step - loss: 0.3426 - val_loss: 1.2769\n",
      "Epoch 1741/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.3386 - val_loss: 1.4139\n",
      "Epoch 1742/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3502 - val_loss: 1.1753\n",
      "Epoch 1743/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 0.3529 - val_loss: 1.3229\n",
      "Epoch 1744/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3474 - val_loss: 1.2673\n",
      "Epoch 1745/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.3377 - val_loss: 1.2525\n",
      "Epoch 1746/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3479 - val_loss: 1.3364\n",
      "Epoch 1747/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.3368 - val_loss: 1.2647\n",
      "Epoch 1748/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3441 - val_loss: 1.2518\n",
      "Epoch 1749/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3419 - val_loss: 1.3239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1750/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.3427 - val_loss: 1.2421\n",
      "Epoch 1751/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.3389 - val_loss: 1.2234\n",
      "Epoch 1752/2500\n",
      "64/64 [==============================] - 0s 276us/step - loss: 0.3458 - val_loss: 1.2637\n",
      "Epoch 1753/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3410 - val_loss: 1.3049\n",
      "Epoch 1754/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.3433 - val_loss: 1.1467\n",
      "Epoch 1755/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3465 - val_loss: 1.3058\n",
      "Epoch 1756/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3474 - val_loss: 1.3397\n",
      "Epoch 1757/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 0.3365 - val_loss: 1.1873\n",
      "Epoch 1758/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3578 - val_loss: 1.4452\n",
      "Epoch 1759/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.3487 - val_loss: 1.2061\n",
      "Epoch 1760/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 0.3433 - val_loss: 1.1795\n",
      "Epoch 1761/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.3509 - val_loss: 1.3572\n",
      "Epoch 1762/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3418 - val_loss: 1.3429\n",
      "Epoch 1763/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 0.3365 - val_loss: 1.1961\n",
      "Epoch 1764/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.3462 - val_loss: 1.3343\n",
      "Epoch 1765/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 0.3400 - val_loss: 1.3803\n",
      "Epoch 1766/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.3383 - val_loss: 1.1680\n",
      "Epoch 1767/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.3500 - val_loss: 1.2984\n",
      "Epoch 1768/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.3429 - val_loss: 1.3013\n",
      "Epoch 1769/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3374 - val_loss: 1.2699\n",
      "Epoch 1770/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3410 - val_loss: 1.4096\n",
      "Epoch 1771/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.3419 - val_loss: 1.2034\n",
      "Epoch 1772/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.3585 - val_loss: 1.2693\n",
      "Epoch 1773/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3431 - val_loss: 1.2137\n",
      "Epoch 1774/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.3509 - val_loss: 1.2259\n",
      "Epoch 1775/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 0.3392 - val_loss: 1.3290\n",
      "Epoch 1776/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3415 - val_loss: 1.2819\n",
      "Epoch 1777/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.3496 - val_loss: 1.3578\n",
      "Epoch 1778/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 0.3339 - val_loss: 1.3119\n",
      "Epoch 1779/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3347 - val_loss: 1.2213\n",
      "Epoch 1780/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3366 - val_loss: 1.2049\n",
      "Epoch 1781/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.3335 - val_loss: 1.3126\n",
      "Epoch 1782/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3338 - val_loss: 1.3282\n",
      "Epoch 1783/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3335 - val_loss: 1.4040\n",
      "Epoch 1784/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3405 - val_loss: 1.2221\n",
      "Epoch 1785/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.3396 - val_loss: 1.2970\n",
      "Epoch 1786/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.3419 - val_loss: 1.2334\n",
      "Epoch 1787/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3333 - val_loss: 1.2359\n",
      "Epoch 1788/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3372 - val_loss: 1.4017\n",
      "Epoch 1789/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.3351 - val_loss: 1.3427\n",
      "Epoch 1790/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.3388 - val_loss: 1.3034\n",
      "Epoch 1791/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 0.3337 - val_loss: 1.3107\n",
      "Epoch 1792/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.3308 - val_loss: 1.1580\n",
      "Epoch 1793/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3441 - val_loss: 1.2768\n",
      "Epoch 1794/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3433 - val_loss: 1.3117\n",
      "Epoch 1795/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.3346 - val_loss: 1.3155\n",
      "Epoch 1796/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3326 - val_loss: 1.3502\n",
      "Epoch 1797/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3451 - val_loss: 1.2489\n",
      "Epoch 1798/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.3453 - val_loss: 1.3227\n",
      "Epoch 1799/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.3318 - val_loss: 1.3181\n",
      "Epoch 1800/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3350 - val_loss: 1.2420\n",
      "Epoch 1801/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3446 - val_loss: 1.4076\n",
      "Epoch 1802/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 0.3445 - val_loss: 1.2794\n",
      "Epoch 1803/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3347 - val_loss: 1.2765\n",
      "Epoch 1804/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3358 - val_loss: 1.3553\n",
      "Epoch 1805/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3501 - val_loss: 1.3112\n",
      "Epoch 1806/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3385 - val_loss: 1.3100\n",
      "Epoch 1807/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 0.3323 - val_loss: 1.2888\n",
      "Epoch 1808/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.3354 - val_loss: 1.2330\n",
      "Epoch 1809/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 0.3501 - val_loss: 1.3569\n",
      "Epoch 1810/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.3492 - val_loss: 1.2633\n",
      "Epoch 1811/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.3418 - val_loss: 1.2662\n",
      "Epoch 1812/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 0.3386 - val_loss: 1.2620\n",
      "Epoch 1813/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.3431 - val_loss: 1.2646\n",
      "Epoch 1814/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.3347 - val_loss: 1.4577\n",
      "Epoch 1815/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3421 - val_loss: 1.2246\n",
      "Epoch 1816/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3439 - val_loss: 1.2270\n",
      "Epoch 1817/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3381 - val_loss: 1.3315\n",
      "Epoch 1818/2500\n",
      "64/64 [==============================] - 0s 396us/step - loss: 0.3381 - val_loss: 1.2772\n",
      "Epoch 1819/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3299 - val_loss: 1.3123\n",
      "Epoch 1820/2500\n",
      "64/64 [==============================] - 0s 352us/step - loss: 0.3349 - val_loss: 1.3302\n",
      "Epoch 1821/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3333 - val_loss: 1.2933\n",
      "Epoch 1822/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3360 - val_loss: 1.2899\n",
      "Epoch 1823/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 0.3283 - val_loss: 1.3075\n",
      "Epoch 1824/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3316 - val_loss: 1.2637\n",
      "Epoch 1825/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3315 - val_loss: 1.3478\n",
      "Epoch 1826/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.3307 - val_loss: 1.2156\n",
      "Epoch 1827/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3284 - val_loss: 1.2999\n",
      "Epoch 1828/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3271 - val_loss: 1.2706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1829/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3240 - val_loss: 1.2584\n",
      "Epoch 1830/2500\n",
      "64/64 [==============================] - 0s 424us/step - loss: 0.3257 - val_loss: 1.3790\n",
      "Epoch 1831/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3324 - val_loss: 1.1616\n",
      "Epoch 1832/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.3370 - val_loss: 1.2656\n",
      "Epoch 1833/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3281 - val_loss: 1.3823\n",
      "Epoch 1834/2500\n",
      "64/64 [==============================] - 0s 271us/step - loss: 0.3289 - val_loss: 1.2943\n",
      "Epoch 1835/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3323 - val_loss: 1.3930\n",
      "Epoch 1836/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.3323 - val_loss: 1.2484\n",
      "Epoch 1837/2500\n",
      "64/64 [==============================] - 0s 346us/step - loss: 0.3237 - val_loss: 1.1707\n",
      "Epoch 1838/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.3300 - val_loss: 1.3684\n",
      "Epoch 1839/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.3297 - val_loss: 1.3399\n",
      "Epoch 1840/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 0.3292 - val_loss: 1.3292\n",
      "Epoch 1841/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 0.3252 - val_loss: 1.3276\n",
      "Epoch 1842/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3263 - val_loss: 1.2145\n",
      "Epoch 1843/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3246 - val_loss: 1.2767\n",
      "Epoch 1844/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.3229 - val_loss: 1.3479\n",
      "Epoch 1845/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.3255 - val_loss: 1.3041\n",
      "Epoch 1846/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3274 - val_loss: 1.2204\n",
      "Epoch 1847/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.3241 - val_loss: 1.3035\n",
      "Epoch 1848/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.3281 - val_loss: 1.2612\n",
      "Epoch 1849/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.3256 - val_loss: 1.3450\n",
      "Epoch 1850/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3252 - val_loss: 1.4504\n",
      "Epoch 1851/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.3316 - val_loss: 1.1915\n",
      "Epoch 1852/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.3356 - val_loss: 1.2747\n",
      "Epoch 1853/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 0.3242 - val_loss: 1.3437\n",
      "Epoch 1854/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 0.3228 - val_loss: 1.3068\n",
      "Epoch 1855/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.3288 - val_loss: 1.4439\n",
      "Epoch 1856/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3336 - val_loss: 1.1747\n",
      "Epoch 1857/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 0.3355 - val_loss: 1.3165\n",
      "Epoch 1858/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3296 - val_loss: 1.3305\n",
      "Epoch 1859/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.3289 - val_loss: 1.2613\n",
      "Epoch 1860/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.3251 - val_loss: 1.3375\n",
      "Epoch 1861/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.3332 - val_loss: 1.2991\n",
      "Epoch 1862/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.3244 - val_loss: 1.1546\n",
      "Epoch 1863/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.3282 - val_loss: 1.2702\n",
      "Epoch 1864/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.3337 - val_loss: 1.2152\n",
      "Epoch 1865/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3306 - val_loss: 1.4642\n",
      "Epoch 1866/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 0.3421 - val_loss: 1.3376\n",
      "Epoch 1867/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.3276 - val_loss: 1.2519\n",
      "Epoch 1868/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3339 - val_loss: 1.3512\n",
      "Epoch 1869/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 0.3359 - val_loss: 1.3209\n",
      "Epoch 1870/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.3612 - val_loss: 1.3119\n",
      "Epoch 1871/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3433 - val_loss: 1.1995\n",
      "Epoch 1872/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3434 - val_loss: 1.3495\n",
      "Epoch 1873/2500\n",
      "64/64 [==============================] - 0s 442us/step - loss: 0.3238 - val_loss: 1.4352\n",
      "Epoch 1874/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.3421 - val_loss: 1.1332\n",
      "Epoch 1875/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.3426 - val_loss: 1.2952\n",
      "Epoch 1876/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3409 - val_loss: 1.2858\n",
      "Epoch 1877/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.3305 - val_loss: 1.3722\n",
      "Epoch 1878/2500\n",
      "64/64 [==============================] - 0s 380us/step - loss: 0.3427 - val_loss: 1.1730\n",
      "Epoch 1879/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3353 - val_loss: 1.2393\n",
      "Epoch 1880/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 0.3473 - val_loss: 1.3313\n",
      "Epoch 1881/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.3663 - val_loss: 1.3660\n",
      "Epoch 1882/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3475 - val_loss: 1.3417\n",
      "Epoch 1883/2500\n",
      "64/64 [==============================] - 0s 444us/step - loss: 0.3534 - val_loss: 1.1396\n",
      "Epoch 1884/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 0.3460 - val_loss: 1.2562\n",
      "Epoch 1885/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 0.3464 - val_loss: 1.4311\n",
      "Epoch 1886/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3362 - val_loss: 1.1563\n",
      "Epoch 1887/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3633 - val_loss: 1.4078\n",
      "Epoch 1888/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3365 - val_loss: 1.3986\n",
      "Epoch 1889/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 0.3578 - val_loss: 1.0434\n",
      "Epoch 1890/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3578 - val_loss: 1.3375\n",
      "Epoch 1891/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.4004 - val_loss: 1.1641\n",
      "Epoch 1892/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.3312 - val_loss: 1.3662\n",
      "Epoch 1893/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3597 - val_loss: 1.5544\n",
      "Epoch 1894/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3413 - val_loss: 1.1229\n",
      "Epoch 1895/2500\n",
      "64/64 [==============================] - 0s 349us/step - loss: 0.3971 - val_loss: 1.4553\n",
      "Epoch 1896/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3612 - val_loss: 1.3723\n",
      "Epoch 1897/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.4043 - val_loss: 1.0814\n",
      "Epoch 1898/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.3732 - val_loss: 1.3433\n",
      "Epoch 1899/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3904 - val_loss: 1.2432\n",
      "Epoch 1900/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.3432 - val_loss: 1.3803\n",
      "Epoch 1901/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3891 - val_loss: 1.3987\n",
      "Epoch 1902/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3409 - val_loss: 1.3136\n",
      "Epoch 1903/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.3385 - val_loss: 1.1570\n",
      "Epoch 1904/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.3413 - val_loss: 1.3036\n",
      "Epoch 1905/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3409 - val_loss: 1.3715\n",
      "Epoch 1906/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3335 - val_loss: 1.1008\n",
      "Epoch 1907/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.3605 - val_loss: 1.4150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1908/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.3344 - val_loss: 1.4075\n",
      "Epoch 1909/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3388 - val_loss: 1.0900\n",
      "Epoch 1910/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3661 - val_loss: 1.4555\n",
      "Epoch 1911/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3673 - val_loss: 1.2657\n",
      "Epoch 1912/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.3208 - val_loss: 1.2407\n",
      "Epoch 1913/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.3544 - val_loss: 1.5623\n",
      "Epoch 1914/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3515 - val_loss: 1.1793\n",
      "Epoch 1915/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3561 - val_loss: 1.2899\n",
      "Epoch 1916/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 0.3643 - val_loss: 1.3422\n",
      "Epoch 1917/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 0.3487 - val_loss: 1.2450\n",
      "Epoch 1918/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3217 - val_loss: 1.2523\n",
      "Epoch 1919/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 0.3390 - val_loss: 1.4204\n",
      "Epoch 1920/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3367 - val_loss: 1.3655\n",
      "Epoch 1921/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3402 - val_loss: 1.2231\n",
      "Epoch 1922/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3225 - val_loss: 1.1930\n",
      "Epoch 1923/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3373 - val_loss: 1.2389\n",
      "Epoch 1924/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 0.3407 - val_loss: 1.3494\n",
      "Epoch 1925/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.3379 - val_loss: 1.4323\n",
      "Epoch 1926/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.3228 - val_loss: 1.2670\n",
      "Epoch 1927/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3346 - val_loss: 1.2509\n",
      "Epoch 1928/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 0.3284 - val_loss: 1.4272\n",
      "Epoch 1929/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.3343 - val_loss: 1.2575\n",
      "Epoch 1930/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.3264 - val_loss: 1.1937\n",
      "Epoch 1931/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 0.3203 - val_loss: 1.2527\n",
      "Epoch 1932/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3298 - val_loss: 1.2767\n",
      "Epoch 1933/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3242 - val_loss: 1.4254\n",
      "Epoch 1934/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.3234 - val_loss: 1.2815\n",
      "Epoch 1935/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3193 - val_loss: 1.2445\n",
      "Epoch 1936/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3259 - val_loss: 1.3612\n",
      "Epoch 1937/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.3211 - val_loss: 1.3363\n",
      "Epoch 1938/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.3281 - val_loss: 1.3585\n",
      "Epoch 1939/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.3174 - val_loss: 1.3030\n",
      "Epoch 1940/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3194 - val_loss: 1.2727\n",
      "Epoch 1941/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.3191 - val_loss: 1.4307\n",
      "Epoch 1942/2500\n",
      "64/64 [==============================] - 0s 342us/step - loss: 0.3167 - val_loss: 1.3767\n",
      "Epoch 1943/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 0.3138 - val_loss: 1.2126\n",
      "Epoch 1944/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 0.3188 - val_loss: 1.2860\n",
      "Epoch 1945/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.3161 - val_loss: 1.2540\n",
      "Epoch 1946/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 0.3146 - val_loss: 1.2930\n",
      "Epoch 1947/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.3141 - val_loss: 1.3941\n",
      "Epoch 1948/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 0.3150 - val_loss: 1.2654\n",
      "Epoch 1949/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3202 - val_loss: 1.3776\n",
      "Epoch 1950/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3214 - val_loss: 1.3127\n",
      "Epoch 1951/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3243 - val_loss: 1.2394\n",
      "Epoch 1952/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.3185 - val_loss: 1.2828\n",
      "Epoch 1953/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.3135 - val_loss: 1.3323\n",
      "Epoch 1954/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.3150 - val_loss: 1.4100\n",
      "Epoch 1955/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 0.3235 - val_loss: 1.3382\n",
      "Epoch 1956/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.3157 - val_loss: 1.3568\n",
      "Epoch 1957/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3193 - val_loss: 1.2422\n",
      "Epoch 1958/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3197 - val_loss: 1.3555\n",
      "Epoch 1959/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3135 - val_loss: 1.2987\n",
      "Epoch 1960/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.3172 - val_loss: 1.2850\n",
      "Epoch 1961/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 0.3153 - val_loss: 1.3538\n",
      "Epoch 1962/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3141 - val_loss: 1.2498\n",
      "Epoch 1963/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3108 - val_loss: 1.3075\n",
      "Epoch 1964/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 0.3107 - val_loss: 1.3816\n",
      "Epoch 1965/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3134 - val_loss: 1.3090\n",
      "Epoch 1966/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3220 - val_loss: 1.4237\n",
      "Epoch 1967/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3184 - val_loss: 1.1606\n",
      "Epoch 1968/2500\n",
      "64/64 [==============================] - 0s 352us/step - loss: 0.3222 - val_loss: 1.3005\n",
      "Epoch 1969/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.3139 - val_loss: 1.3256\n",
      "Epoch 1970/2500\n",
      "64/64 [==============================] - 0s 414us/step - loss: 0.3105 - val_loss: 1.2905\n",
      "Epoch 1971/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3213 - val_loss: 1.4748\n",
      "Epoch 1972/2500\n",
      "64/64 [==============================] - 0s 522us/step - loss: 0.3242 - val_loss: 1.1679\n",
      "Epoch 1973/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.3360 - val_loss: 1.3646\n",
      "Epoch 1974/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3247 - val_loss: 1.3262\n",
      "Epoch 1975/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3152 - val_loss: 1.2652\n",
      "Epoch 1976/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 0.3146 - val_loss: 1.4333\n",
      "Epoch 1977/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 0.3190 - val_loss: 1.3661\n",
      "Epoch 1978/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.3200 - val_loss: 1.2639\n",
      "Epoch 1979/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3248 - val_loss: 1.3037\n",
      "Epoch 1980/2500\n",
      "64/64 [==============================] - 0s 246us/step - loss: 0.3154 - val_loss: 1.2696\n",
      "Epoch 1981/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3111 - val_loss: 1.2914\n",
      "Epoch 1982/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3150 - val_loss: 1.3489\n",
      "Epoch 1983/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 0.3201 - val_loss: 1.3856\n",
      "Epoch 1984/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.3220 - val_loss: 1.2570\n",
      "Epoch 1985/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3233 - val_loss: 1.3107\n",
      "Epoch 1986/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3220 - val_loss: 1.2780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1987/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.3102 - val_loss: 1.3200\n",
      "Epoch 1988/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3156 - val_loss: 1.4054\n",
      "Epoch 1989/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3182 - val_loss: 1.2180\n",
      "Epoch 1990/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3163 - val_loss: 1.2350\n",
      "Epoch 1991/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.3125 - val_loss: 1.3691\n",
      "Epoch 1992/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.3058 - val_loss: 1.3673\n",
      "Epoch 1993/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3074 - val_loss: 1.3354\n",
      "Epoch 1994/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 0.3102 - val_loss: 1.3779\n",
      "Epoch 1995/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3151 - val_loss: 1.1648\n",
      "Epoch 1996/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 0.3136 - val_loss: 1.2313\n",
      "Epoch 1997/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 0.3220 - val_loss: 1.3903\n",
      "Epoch 1998/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.3199 - val_loss: 1.2823\n",
      "Epoch 1999/2500\n",
      "64/64 [==============================] - 0s 340us/step - loss: 0.3264 - val_loss: 1.4172\n",
      "Epoch 2000/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3146 - val_loss: 1.3328\n",
      "Epoch 2001/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.3097 - val_loss: 1.3533\n",
      "Epoch 2002/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3082 - val_loss: 1.3652\n",
      "Epoch 2003/2500\n",
      "64/64 [==============================] - 0s 323us/step - loss: 0.3045 - val_loss: 1.2845\n",
      "Epoch 2004/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.3236 - val_loss: 1.3529\n",
      "Epoch 2005/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3138 - val_loss: 1.4463\n",
      "Epoch 2006/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 0.3366 - val_loss: 1.2789\n",
      "Epoch 2007/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.3520 - val_loss: 1.2376\n",
      "Epoch 2008/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.3455 - val_loss: 1.3966\n",
      "Epoch 2009/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3393 - val_loss: 1.2805\n",
      "Epoch 2010/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.3306 - val_loss: 1.3520\n",
      "Epoch 2011/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.3204 - val_loss: 1.2961\n",
      "Epoch 2012/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3086 - val_loss: 1.2077\n",
      "Epoch 2013/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.3189 - val_loss: 1.4391\n",
      "Epoch 2014/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.3186 - val_loss: 1.2835\n",
      "Epoch 2015/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 0.3123 - val_loss: 1.4247\n",
      "Epoch 2016/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 0.3161 - val_loss: 1.2268\n",
      "Epoch 2017/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3072 - val_loss: 1.2053\n",
      "Epoch 2018/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.3165 - val_loss: 1.3939\n",
      "Epoch 2019/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 0.3128 - val_loss: 1.3477\n",
      "Epoch 2020/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3233 - val_loss: 1.5282\n",
      "Epoch 2021/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3245 - val_loss: 1.1668\n",
      "Epoch 2022/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.3421 - val_loss: 1.4046\n",
      "Epoch 2023/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3290 - val_loss: 1.3027\n",
      "Epoch 2024/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.3259 - val_loss: 1.3106\n",
      "Epoch 2025/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3094 - val_loss: 1.2587\n",
      "Epoch 2026/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.3100 - val_loss: 1.3436\n",
      "Epoch 2027/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.3071 - val_loss: 1.3711\n",
      "Epoch 2028/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3140 - val_loss: 1.3230\n",
      "Epoch 2029/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3081 - val_loss: 1.2848\n",
      "Epoch 2030/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 0.3112 - val_loss: 1.2815\n",
      "Epoch 2031/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.3091 - val_loss: 1.4351\n",
      "Epoch 2032/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 0.3126 - val_loss: 1.2812\n",
      "Epoch 2033/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 0.3076 - val_loss: 1.2959\n",
      "Epoch 2034/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.3056 - val_loss: 1.4010\n",
      "Epoch 2035/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.3035 - val_loss: 1.2932\n",
      "Epoch 2036/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 0.3142 - val_loss: 1.3644\n",
      "Epoch 2037/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.3086 - val_loss: 1.2806\n",
      "Epoch 2038/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3181 - val_loss: 1.3527\n",
      "Epoch 2039/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3333 - val_loss: 1.4157\n",
      "Epoch 2040/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 0.3301 - val_loss: 1.2809\n",
      "Epoch 2041/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3048 - val_loss: 1.1955\n",
      "Epoch 2042/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.3157 - val_loss: 1.4640\n",
      "Epoch 2043/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.3153 - val_loss: 1.3070\n",
      "Epoch 2044/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3071 - val_loss: 1.2943\n",
      "Epoch 2045/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3012 - val_loss: 1.3732\n",
      "Epoch 2046/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3028 - val_loss: 1.3374\n",
      "Epoch 2047/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3047 - val_loss: 1.3928\n",
      "Epoch 2048/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 0.3007 - val_loss: 1.4428\n",
      "Epoch 2049/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.3059 - val_loss: 1.2248\n",
      "Epoch 2050/2500\n",
      "64/64 [==============================] - 0s 444us/step - loss: 0.3109 - val_loss: 1.2755\n",
      "Epoch 2051/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.3030 - val_loss: 1.3379\n",
      "Epoch 2052/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 0.3082 - val_loss: 1.3344\n",
      "Epoch 2053/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.3072 - val_loss: 1.3048\n",
      "Epoch 2054/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.2981 - val_loss: 1.3327\n",
      "Epoch 2055/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.3144 - val_loss: 1.3482\n",
      "Epoch 2056/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 0.3058 - val_loss: 1.3014\n",
      "Epoch 2057/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.3112 - val_loss: 1.2968\n",
      "Epoch 2058/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.3186 - val_loss: 1.2857\n",
      "Epoch 2059/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.3076 - val_loss: 1.4027\n",
      "Epoch 2060/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.3220 - val_loss: 1.3211\n",
      "Epoch 2061/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.2996 - val_loss: 1.2950\n",
      "Epoch 2062/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 0.3317 - val_loss: 1.3675\n",
      "Epoch 2063/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3200 - val_loss: 1.4017\n",
      "Epoch 2064/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3325 - val_loss: 1.4327\n",
      "Epoch 2065/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3244 - val_loss: 1.1779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2066/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.3220 - val_loss: 1.4582\n",
      "Epoch 2067/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.3166 - val_loss: 1.3457\n",
      "Epoch 2068/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.3117 - val_loss: 1.2249\n",
      "Epoch 2069/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 0.3047 - val_loss: 1.2883\n",
      "Epoch 2070/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.3003 - val_loss: 1.2945\n",
      "Epoch 2071/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.3123 - val_loss: 1.3103\n",
      "Epoch 2072/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.3058 - val_loss: 1.3235\n",
      "Epoch 2073/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 0.3055 - val_loss: 1.3711\n",
      "Epoch 2074/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.2969 - val_loss: 1.3459\n",
      "Epoch 2075/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.2995 - val_loss: 1.3487\n",
      "Epoch 2076/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 0.2984 - val_loss: 1.3482\n",
      "Epoch 2077/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2998 - val_loss: 1.3220\n",
      "Epoch 2078/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.2959 - val_loss: 1.3794\n",
      "Epoch 2079/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.2999 - val_loss: 1.3686\n",
      "Epoch 2080/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.3002 - val_loss: 1.2158\n",
      "Epoch 2081/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.2981 - val_loss: 1.3188\n",
      "Epoch 2082/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3050 - val_loss: 1.3192\n",
      "Epoch 2083/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 0.2993 - val_loss: 1.3847\n",
      "Epoch 2084/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.2985 - val_loss: 1.3539\n",
      "Epoch 2085/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3122 - val_loss: 1.3969\n",
      "Epoch 2086/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 0.3025 - val_loss: 1.2481\n",
      "Epoch 2087/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3138 - val_loss: 1.3988\n",
      "Epoch 2088/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3221 - val_loss: 1.2504\n",
      "Epoch 2089/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.3151 - val_loss: 1.4624\n",
      "Epoch 2090/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.3132 - val_loss: 1.3531\n",
      "Epoch 2091/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3000 - val_loss: 1.2650\n",
      "Epoch 2092/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3134 - val_loss: 1.3824\n",
      "Epoch 2093/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.2963 - val_loss: 1.2678\n",
      "Epoch 2094/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3071 - val_loss: 1.3795\n",
      "Epoch 2095/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.3157 - val_loss: 1.2265\n",
      "Epoch 2096/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3153 - val_loss: 1.4105\n",
      "Epoch 2097/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.3313 - val_loss: 1.3200\n",
      "Epoch 2098/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.3218 - val_loss: 1.3693\n",
      "Epoch 2099/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.3130 - val_loss: 1.2808\n",
      "Epoch 2100/2500\n",
      "64/64 [==============================] - 0s 418us/step - loss: 0.3140 - val_loss: 1.4084\n",
      "Epoch 2101/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 0.3115 - val_loss: 1.2194\n",
      "Epoch 2102/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3169 - val_loss: 1.2907\n",
      "Epoch 2103/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3143 - val_loss: 1.3317\n",
      "Epoch 2104/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 0.3024 - val_loss: 1.3856\n",
      "Epoch 2105/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.3049 - val_loss: 1.4967\n",
      "Epoch 2106/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3055 - val_loss: 1.4191\n",
      "Epoch 2107/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 0.2994 - val_loss: 1.2753\n",
      "Epoch 2108/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 0.3001 - val_loss: 1.3215\n",
      "Epoch 2109/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3141 - val_loss: 1.2657\n",
      "Epoch 2110/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.3023 - val_loss: 1.3191\n",
      "Epoch 2111/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.3084 - val_loss: 1.4117\n",
      "Epoch 2112/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3043 - val_loss: 1.2576\n",
      "Epoch 2113/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.3057 - val_loss: 1.4267\n",
      "Epoch 2114/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.3009 - val_loss: 1.2877\n",
      "Epoch 2115/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.2963 - val_loss: 1.3051\n",
      "Epoch 2116/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.3139 - val_loss: 1.2827\n",
      "Epoch 2117/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.2995 - val_loss: 1.3409\n",
      "Epoch 2118/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 0.3004 - val_loss: 1.3607\n",
      "Epoch 2119/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3027 - val_loss: 1.4934\n",
      "Epoch 2120/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.2970 - val_loss: 1.3597\n",
      "Epoch 2121/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3006 - val_loss: 1.2255\n",
      "Epoch 2122/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.2924 - val_loss: 1.3315\n",
      "Epoch 2123/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.2986 - val_loss: 1.3148\n",
      "Epoch 2124/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 0.3116 - val_loss: 1.5318\n",
      "Epoch 2125/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.3078 - val_loss: 1.2783\n",
      "Epoch 2126/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3117 - val_loss: 1.2484\n",
      "Epoch 2127/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.3008 - val_loss: 1.3292\n",
      "Epoch 2128/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.2966 - val_loss: 1.3482\n",
      "Epoch 2129/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 0.2970 - val_loss: 1.3884\n",
      "Epoch 2130/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 0.2969 - val_loss: 1.4044\n",
      "Epoch 2131/2500\n",
      "64/64 [==============================] - 0s 299us/step - loss: 0.2985 - val_loss: 1.2013\n",
      "Epoch 2132/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.3036 - val_loss: 1.3467\n",
      "Epoch 2133/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 0.2919 - val_loss: 1.4004\n",
      "Epoch 2134/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 0.2913 - val_loss: 1.3050\n",
      "Epoch 2135/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.2962 - val_loss: 1.3978\n",
      "Epoch 2136/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 0.3006 - val_loss: 1.2019\n",
      "Epoch 2137/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3070 - val_loss: 1.3546\n",
      "Epoch 2138/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3152 - val_loss: 1.3227\n",
      "Epoch 2139/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.3201 - val_loss: 1.5741\n",
      "Epoch 2140/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 0.3317 - val_loss: 1.2961\n",
      "Epoch 2141/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3290 - val_loss: 1.5006\n",
      "Epoch 2142/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.3337 - val_loss: 1.2026\n",
      "Epoch 2143/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3273 - val_loss: 1.4346\n",
      "Epoch 2144/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.3178 - val_loss: 1.3647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2145/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3013 - val_loss: 1.4661\n",
      "Epoch 2146/2500\n",
      "64/64 [==============================] - 0s 306us/step - loss: 0.2985 - val_loss: 1.2832\n",
      "Epoch 2147/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.2990 - val_loss: 1.2145\n",
      "Epoch 2148/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.3140 - val_loss: 1.4494\n",
      "Epoch 2149/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 0.3137 - val_loss: 1.3393\n",
      "Epoch 2150/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3285 - val_loss: 1.4314\n",
      "Epoch 2151/2500\n",
      "64/64 [==============================] - 0s 382us/step - loss: 0.3036 - val_loss: 1.2247\n",
      "Epoch 2152/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2994 - val_loss: 1.2821\n",
      "Epoch 2153/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 0.2967 - val_loss: 1.4856\n",
      "Epoch 2154/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.3036 - val_loss: 1.2658\n",
      "Epoch 2155/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 0.3277 - val_loss: 1.3513\n",
      "Epoch 2156/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 0.3240 - val_loss: 1.2172\n",
      "Epoch 2157/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.3318 - val_loss: 1.3104\n",
      "Epoch 2158/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 0.3362 - val_loss: 1.3490\n",
      "Epoch 2159/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.3015 - val_loss: 1.4667\n",
      "Epoch 2160/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 0.2991 - val_loss: 1.3993\n",
      "Epoch 2161/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.2988 - val_loss: 1.3492\n",
      "Epoch 2162/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 0.3145 - val_loss: 1.4649\n",
      "Epoch 2163/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.3180 - val_loss: 1.2061\n",
      "Epoch 2164/2500\n",
      "64/64 [==============================] - 0s 363us/step - loss: 0.3081 - val_loss: 1.4892\n",
      "Epoch 2165/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.2993 - val_loss: 1.2641\n",
      "Epoch 2166/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.2939 - val_loss: 1.2815\n",
      "Epoch 2167/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.2925 - val_loss: 1.4397\n",
      "Epoch 2168/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.2964 - val_loss: 1.3465\n",
      "Epoch 2169/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3040 - val_loss: 1.3463\n",
      "Epoch 2170/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3011 - val_loss: 1.3562\n",
      "Epoch 2171/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2961 - val_loss: 1.3193\n",
      "Epoch 2172/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 0.2908 - val_loss: 1.3875\n",
      "Epoch 2173/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.2939 - val_loss: 1.2386\n",
      "Epoch 2174/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.3132 - val_loss: 1.3582\n",
      "Epoch 2175/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3005 - val_loss: 1.3314\n",
      "Epoch 2176/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3160 - val_loss: 1.4134\n",
      "Epoch 2177/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.2943 - val_loss: 1.2652\n",
      "Epoch 2178/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.3054 - val_loss: 1.3570\n",
      "Epoch 2179/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 0.2916 - val_loss: 1.4929\n",
      "Epoch 2180/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3178 - val_loss: 1.1844\n",
      "Epoch 2181/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3309 - val_loss: 1.4104\n",
      "Epoch 2182/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.3261 - val_loss: 1.2236\n",
      "Epoch 2183/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.3030 - val_loss: 1.3615\n",
      "Epoch 2184/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3101 - val_loss: 1.5686\n",
      "Epoch 2185/2500\n",
      "64/64 [==============================] - 0s 442us/step - loss: 0.3122 - val_loss: 1.2330\n",
      "Epoch 2186/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.3043 - val_loss: 1.3761\n",
      "Epoch 2187/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.2976 - val_loss: 1.3788\n",
      "Epoch 2188/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3053 - val_loss: 1.1774\n",
      "Epoch 2189/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.3603 - val_loss: 1.4647\n",
      "Epoch 2190/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.2985 - val_loss: 1.4817\n",
      "Epoch 2191/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 0.3357 - val_loss: 1.2116\n",
      "Epoch 2192/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.3605 - val_loss: 1.5209\n",
      "Epoch 2193/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 0.3324 - val_loss: 1.2754\n",
      "Epoch 2194/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3137 - val_loss: 1.3873\n",
      "Epoch 2195/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 0.3585 - val_loss: 1.3359\n",
      "Epoch 2196/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 0.3148 - val_loss: 1.2596\n",
      "Epoch 2197/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 0.2980 - val_loss: 1.1827\n",
      "Epoch 2198/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.3073 - val_loss: 1.3978\n",
      "Epoch 2199/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 0.3092 - val_loss: 1.2542\n",
      "Epoch 2200/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.3452 - val_loss: 1.4097\n",
      "Epoch 2201/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.2933 - val_loss: 1.3290\n",
      "Epoch 2202/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.3501 - val_loss: 1.2935\n",
      "Epoch 2203/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 0.3227 - val_loss: 1.2369\n",
      "Epoch 2204/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3432 - val_loss: 1.5956\n",
      "Epoch 2205/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.3324 - val_loss: 1.1802\n",
      "Epoch 2206/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.3576 - val_loss: 1.4092\n",
      "Epoch 2207/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.3045 - val_loss: 1.3557\n",
      "Epoch 2208/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.3308 - val_loss: 1.2300\n",
      "Epoch 2209/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 0.3745 - val_loss: 1.4592\n",
      "Epoch 2210/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3105 - val_loss: 1.5467\n",
      "Epoch 2211/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.3417 - val_loss: 1.2440\n",
      "Epoch 2212/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 0.3613 - val_loss: 1.2278\n",
      "Epoch 2213/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.3236 - val_loss: 1.5033\n",
      "Epoch 2214/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3409 - val_loss: 1.2108\n",
      "Epoch 2215/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.3272 - val_loss: 1.4342\n",
      "Epoch 2216/2500\n",
      "64/64 [==============================] - 0s 290us/step - loss: 0.2983 - val_loss: 1.5770\n",
      "Epoch 2217/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.3606 - val_loss: 0.9312\n",
      "Epoch 2218/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.4972 - val_loss: 1.7532\n",
      "Epoch 2219/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 0.4441 - val_loss: 1.1926\n",
      "Epoch 2220/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.4118 - val_loss: 1.2415\n",
      "Epoch 2221/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.4014 - val_loss: 1.5425\n",
      "Epoch 2222/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 0.3158 - val_loss: 1.3795\n",
      "Epoch 2223/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.4250 - val_loss: 1.4654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2224/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.4819 - val_loss: 1.3581\n",
      "Epoch 2225/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.3119 - val_loss: 1.5592\n",
      "Epoch 2226/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.4821 - val_loss: 1.2762\n",
      "Epoch 2227/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.4957 - val_loss: 0.9934\n",
      "Epoch 2228/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3985 - val_loss: 1.4124\n",
      "Epoch 2229/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4555 - val_loss: 1.4078\n",
      "Epoch 2230/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3569 - val_loss: 1.0042\n",
      "Epoch 2231/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 0.4721 - val_loss: 1.4285\n",
      "Epoch 2232/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.4080 - val_loss: 1.3405\n",
      "Epoch 2233/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.3508 - val_loss: 1.2742\n",
      "Epoch 2234/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.3529 - val_loss: 1.3551\n",
      "Epoch 2235/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 0.3270 - val_loss: 1.3327\n",
      "Epoch 2236/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.3746 - val_loss: 1.4179\n",
      "Epoch 2237/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3126 - val_loss: 1.2863\n",
      "Epoch 2238/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 0.3358 - val_loss: 1.1982\n",
      "Epoch 2239/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 0.3174 - val_loss: 1.2608\n",
      "Epoch 2240/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.3098 - val_loss: 1.1652\n",
      "Epoch 2241/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3067 - val_loss: 1.1390\n",
      "Epoch 2242/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 0.3157 - val_loss: 1.3564\n",
      "Epoch 2243/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.3029 - val_loss: 1.1597\n",
      "Epoch 2244/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.3101 - val_loss: 1.1260\n",
      "Epoch 2245/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 0.3026 - val_loss: 1.3109\n",
      "Epoch 2246/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.3046 - val_loss: 1.2420\n",
      "Epoch 2247/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 0.2935 - val_loss: 1.1447\n",
      "Epoch 2248/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 0.3059 - val_loss: 1.4312\n",
      "Epoch 2249/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3028 - val_loss: 1.2629\n",
      "Epoch 2250/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.2984 - val_loss: 1.1980\n",
      "Epoch 2251/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.3006 - val_loss: 1.3126\n",
      "Epoch 2252/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.2925 - val_loss: 1.3309\n",
      "Epoch 2253/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.2931 - val_loss: 1.2075\n",
      "Epoch 2254/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.2902 - val_loss: 1.2890\n",
      "Epoch 2255/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.2974 - val_loss: 1.2393\n",
      "Epoch 2256/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.2887 - val_loss: 1.2584\n",
      "Epoch 2257/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.2893 - val_loss: 1.3853\n",
      "Epoch 2258/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.2919 - val_loss: 1.2252\n",
      "Epoch 2259/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.2899 - val_loss: 1.2604\n",
      "Epoch 2260/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.2913 - val_loss: 1.3716\n",
      "Epoch 2261/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.2901 - val_loss: 1.1863\n",
      "Epoch 2262/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.2924 - val_loss: 1.2795\n",
      "Epoch 2263/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.2856 - val_loss: 1.3249\n",
      "Epoch 2264/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 0.2846 - val_loss: 1.2271\n",
      "Epoch 2265/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.2883 - val_loss: 1.2897\n",
      "Epoch 2266/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.2841 - val_loss: 1.2653\n",
      "Epoch 2267/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.2880 - val_loss: 1.2874\n",
      "Epoch 2268/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.2831 - val_loss: 1.2380\n",
      "Epoch 2269/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.2857 - val_loss: 1.1849\n",
      "Epoch 2270/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.2852 - val_loss: 1.2445\n",
      "Epoch 2271/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.2827 - val_loss: 1.3418\n",
      "Epoch 2272/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 0.2856 - val_loss: 1.2495\n",
      "Epoch 2273/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 0.2894 - val_loss: 1.3628\n",
      "Epoch 2274/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.2871 - val_loss: 1.3230\n",
      "Epoch 2275/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 0.2796 - val_loss: 1.1958\n",
      "Epoch 2276/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.2870 - val_loss: 1.2789\n",
      "Epoch 2277/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.2791 - val_loss: 1.3373\n",
      "Epoch 2278/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 0.2825 - val_loss: 1.2323\n",
      "Epoch 2279/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 0.2851 - val_loss: 1.3323\n",
      "Epoch 2280/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2802 - val_loss: 1.3506\n",
      "Epoch 2281/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.2912 - val_loss: 1.1369\n",
      "Epoch 2282/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 0.3003 - val_loss: 1.2390\n",
      "Epoch 2283/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 0.2840 - val_loss: 1.3342\n",
      "Epoch 2284/2500\n",
      "64/64 [==============================] - 0s 325us/step - loss: 0.2995 - val_loss: 1.3376\n",
      "Epoch 2285/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.2854 - val_loss: 1.2406\n",
      "Epoch 2286/2500\n",
      "64/64 [==============================] - 0s 456us/step - loss: 0.3014 - val_loss: 1.2173\n",
      "Epoch 2287/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.2913 - val_loss: 1.4075\n",
      "Epoch 2288/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.3078 - val_loss: 1.2418\n",
      "Epoch 2289/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.2947 - val_loss: 1.2191\n",
      "Epoch 2290/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 0.2873 - val_loss: 1.3359\n",
      "Epoch 2291/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.2826 - val_loss: 1.3194\n",
      "Epoch 2292/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.2956 - val_loss: 1.2503\n",
      "Epoch 2293/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.2955 - val_loss: 1.3887\n",
      "Epoch 2294/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.2920 - val_loss: 1.3269\n",
      "Epoch 2295/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.3021 - val_loss: 1.2172\n",
      "Epoch 2296/2500\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.3032 - val_loss: 1.2388\n",
      "Epoch 2297/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.2882 - val_loss: 1.3599\n",
      "Epoch 2298/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 0.3025 - val_loss: 1.4028\n",
      "Epoch 2299/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 0.3052 - val_loss: 1.1876\n",
      "Epoch 2300/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 0.3083 - val_loss: 1.2551\n",
      "Epoch 2301/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.2961 - val_loss: 1.2867\n",
      "Epoch 2302/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.2932 - val_loss: 1.2709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2303/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 0.3111 - val_loss: 1.3518\n",
      "Epoch 2304/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.2805 - val_loss: 1.3817\n",
      "Epoch 2305/2500\n",
      "64/64 [==============================] - 0s 494us/step - loss: 0.3106 - val_loss: 1.2652\n",
      "Epoch 2306/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.2899 - val_loss: 1.3922\n",
      "Epoch 2307/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.2985 - val_loss: 1.2831\n",
      "Epoch 2308/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2843 - val_loss: 1.2715\n",
      "Epoch 2309/2500\n",
      "64/64 [==============================] - 0s 431us/step - loss: 0.2891 - val_loss: 1.3000\n",
      "Epoch 2310/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.2879 - val_loss: 1.1965\n",
      "Epoch 2311/2500\n",
      "64/64 [==============================] - 0s 339us/step - loss: 0.2932 - val_loss: 1.3123\n",
      "Epoch 2312/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.2740 - val_loss: 1.3700\n",
      "Epoch 2313/2500\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.2916 - val_loss: 1.3327\n",
      "Epoch 2314/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 0.2832 - val_loss: 1.3366\n",
      "Epoch 2315/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.2853 - val_loss: 1.3222\n",
      "Epoch 2316/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2849 - val_loss: 1.2236\n",
      "Epoch 2317/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.2791 - val_loss: 1.3267\n",
      "Epoch 2318/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.2850 - val_loss: 1.3315\n",
      "Epoch 2319/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.2713 - val_loss: 1.3726\n",
      "Epoch 2320/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.2771 - val_loss: 1.3269\n",
      "Epoch 2321/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.2747 - val_loss: 1.2266\n",
      "Epoch 2322/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.2725 - val_loss: 1.3347\n",
      "Epoch 2323/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 0.2802 - val_loss: 1.3024\n",
      "Epoch 2324/2500\n",
      "64/64 [==============================] - 0s 323us/step - loss: 0.2733 - val_loss: 1.2802\n",
      "Epoch 2325/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.2733 - val_loss: 1.3804\n",
      "Epoch 2326/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 0.2775 - val_loss: 1.3688\n",
      "Epoch 2327/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2751 - val_loss: 1.3293\n",
      "Epoch 2328/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.2751 - val_loss: 1.3309\n",
      "Epoch 2329/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.2769 - val_loss: 1.3281\n",
      "Epoch 2330/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 0.2724 - val_loss: 1.3314\n",
      "Epoch 2331/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 0.2742 - val_loss: 1.2794\n",
      "Epoch 2332/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 0.2728 - val_loss: 1.2848\n",
      "Epoch 2333/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.2716 - val_loss: 1.3319\n",
      "Epoch 2334/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.2718 - val_loss: 1.2889\n",
      "Epoch 2335/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.2702 - val_loss: 1.3762\n",
      "Epoch 2336/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2697 - val_loss: 1.3994\n",
      "Epoch 2337/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.2697 - val_loss: 1.3128\n",
      "Epoch 2338/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 0.2692 - val_loss: 1.3309\n",
      "Epoch 2339/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.2704 - val_loss: 1.3688\n",
      "Epoch 2340/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 0.2696 - val_loss: 1.3320\n",
      "Epoch 2341/2500\n",
      "64/64 [==============================] - 0s 334us/step - loss: 0.2688 - val_loss: 1.3379\n",
      "Epoch 2342/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.2705 - val_loss: 1.3515\n",
      "Epoch 2343/2500\n",
      "64/64 [==============================] - 0s 326us/step - loss: 0.2714 - val_loss: 1.3363\n",
      "Epoch 2344/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.2725 - val_loss: 1.2904\n",
      "Epoch 2345/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.2742 - val_loss: 1.3375\n",
      "Epoch 2346/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 0.2708 - val_loss: 1.4136\n",
      "Epoch 2347/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.2727 - val_loss: 1.3685\n",
      "Epoch 2348/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.2690 - val_loss: 1.3173\n",
      "Epoch 2349/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.2677 - val_loss: 1.3527\n",
      "Epoch 2350/2500\n",
      "64/64 [==============================] - 0s 271us/step - loss: 0.2700 - val_loss: 1.2842\n",
      "Epoch 2351/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.2697 - val_loss: 1.3395\n",
      "Epoch 2352/2500\n",
      "64/64 [==============================] - 0s 293us/step - loss: 0.2674 - val_loss: 1.4219\n",
      "Epoch 2353/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.2747 - val_loss: 1.2827\n",
      "Epoch 2354/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.2672 - val_loss: 1.2349\n",
      "Epoch 2355/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.2753 - val_loss: 1.3198\n",
      "Epoch 2356/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.2692 - val_loss: 1.3534\n",
      "Epoch 2357/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 0.2725 - val_loss: 1.4091\n",
      "Epoch 2358/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.2699 - val_loss: 1.3452\n",
      "Epoch 2359/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.2717 - val_loss: 1.3390\n",
      "Epoch 2360/2500\n",
      "64/64 [==============================] - 0s 399us/step - loss: 0.2752 - val_loss: 1.3298\n",
      "Epoch 2361/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2672 - val_loss: 1.3001\n",
      "Epoch 2362/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 0.2734 - val_loss: 1.4193\n",
      "Epoch 2363/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.2744 - val_loss: 1.2826\n",
      "Epoch 2364/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 0.2672 - val_loss: 1.2767\n",
      "Epoch 2365/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.2774 - val_loss: 1.4007\n",
      "Epoch 2366/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.2736 - val_loss: 1.4250\n",
      "Epoch 2367/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.2774 - val_loss: 1.3126\n",
      "Epoch 2368/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 0.2923 - val_loss: 1.3478\n",
      "Epoch 2369/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.2712 - val_loss: 1.4124\n",
      "Epoch 2370/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.2843 - val_loss: 1.3505\n",
      "Epoch 2371/2500\n",
      "64/64 [==============================] - 0s 374us/step - loss: 0.2771 - val_loss: 1.3735\n",
      "Epoch 2372/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 0.2737 - val_loss: 1.4584\n",
      "Epoch 2373/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 0.2719 - val_loss: 1.3857\n",
      "Epoch 2374/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2812 - val_loss: 1.3029\n",
      "Epoch 2375/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.2775 - val_loss: 1.2684\n",
      "Epoch 2376/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.2812 - val_loss: 1.3634\n",
      "Epoch 2377/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.2702 - val_loss: 1.4314\n",
      "Epoch 2378/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.2950 - val_loss: 1.3965\n",
      "Epoch 2379/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.2702 - val_loss: 1.3590\n",
      "Epoch 2380/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 0.2828 - val_loss: 1.3364\n",
      "Epoch 2381/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.2709 - val_loss: 1.3259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2382/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.2830 - val_loss: 1.3744\n",
      "Epoch 2383/2500\n",
      "64/64 [==============================] - 0s 405us/step - loss: 0.2692 - val_loss: 1.4000\n",
      "Epoch 2384/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 0.2719 - val_loss: 1.3778\n",
      "Epoch 2385/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 0.2717 - val_loss: 1.3623\n",
      "Epoch 2386/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.2739 - val_loss: 1.3960\n",
      "Epoch 2387/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.2674 - val_loss: 1.3520\n",
      "Epoch 2388/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 0.2690 - val_loss: 1.3276\n",
      "Epoch 2389/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.2673 - val_loss: 1.3994\n",
      "Epoch 2390/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 0.2638 - val_loss: 1.3630\n",
      "Epoch 2391/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 0.2646 - val_loss: 1.3381\n",
      "Epoch 2392/2500\n",
      "64/64 [==============================] - 0s 420us/step - loss: 0.2648 - val_loss: 1.3810\n",
      "Epoch 2393/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.2677 - val_loss: 1.4236\n",
      "Epoch 2394/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 0.2643 - val_loss: 1.3567\n",
      "Epoch 2395/2500\n",
      "64/64 [==============================] - 0s 399us/step - loss: 0.2698 - val_loss: 1.3689\n",
      "Epoch 2396/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 0.2619 - val_loss: 1.3828\n",
      "Epoch 2397/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2670 - val_loss: 1.3312\n",
      "Epoch 2398/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 0.2623 - val_loss: 1.3432\n",
      "Epoch 2399/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.2709 - val_loss: 1.4798\n",
      "Epoch 2400/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 0.2684 - val_loss: 1.4467\n",
      "Epoch 2401/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.2702 - val_loss: 1.2894\n",
      "Epoch 2402/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.2764 - val_loss: 1.3708\n",
      "Epoch 2403/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.2693 - val_loss: 1.4045\n",
      "Epoch 2404/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 0.2742 - val_loss: 1.3882\n",
      "Epoch 2405/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.2712 - val_loss: 1.3636\n",
      "Epoch 2406/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.2688 - val_loss: 1.3577\n",
      "Epoch 2407/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.2731 - val_loss: 1.4192\n",
      "Epoch 2408/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2723 - val_loss: 1.4026\n",
      "Epoch 2409/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 0.2710 - val_loss: 1.4453\n",
      "Epoch 2410/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.2716 - val_loss: 1.2933\n",
      "Epoch 2411/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.2647 - val_loss: 1.3480\n",
      "Epoch 2412/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.2715 - val_loss: 1.4197\n",
      "Epoch 2413/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.2691 - val_loss: 1.3589\n",
      "Epoch 2414/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.2618 - val_loss: 1.3729\n",
      "Epoch 2415/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2703 - val_loss: 1.3432\n",
      "Epoch 2416/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.2726 - val_loss: 1.4367\n",
      "Epoch 2417/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.2709 - val_loss: 1.2682\n",
      "Epoch 2418/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.2773 - val_loss: 1.4583\n",
      "Epoch 2419/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.2704 - val_loss: 1.3746\n",
      "Epoch 2420/2500\n",
      "64/64 [==============================] - 0s 325us/step - loss: 0.2707 - val_loss: 1.3976\n",
      "Epoch 2421/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.2709 - val_loss: 1.4280\n",
      "Epoch 2422/2500\n",
      "64/64 [==============================] - 0s 333us/step - loss: 0.2663 - val_loss: 1.3923\n",
      "Epoch 2423/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.2637 - val_loss: 1.3761\n",
      "Epoch 2424/2500\n",
      "64/64 [==============================] - 0s 443us/step - loss: 0.2658 - val_loss: 1.3680\n",
      "Epoch 2425/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.2709 - val_loss: 1.4105\n",
      "Epoch 2426/2500\n",
      "64/64 [==============================] - 0s 340us/step - loss: 0.2637 - val_loss: 1.3143\n",
      "Epoch 2427/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.2756 - val_loss: 1.4146\n",
      "Epoch 2428/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 0.2666 - val_loss: 1.3396\n",
      "Epoch 2429/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.2649 - val_loss: 1.3019\n",
      "Epoch 2430/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.2744 - val_loss: 1.4715\n",
      "Epoch 2431/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.2704 - val_loss: 1.3244\n",
      "Epoch 2432/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.2792 - val_loss: 1.4252\n",
      "Epoch 2433/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 0.2875 - val_loss: 1.2832\n",
      "Epoch 2434/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 0.2807 - val_loss: 1.4517\n",
      "Epoch 2435/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.2836 - val_loss: 1.4283\n",
      "Epoch 2436/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.2778 - val_loss: 1.4383\n",
      "Epoch 2437/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.2707 - val_loss: 1.3304\n",
      "Epoch 2438/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.2727 - val_loss: 1.3422\n",
      "Epoch 2439/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 0.2745 - val_loss: 1.3684\n",
      "Epoch 2440/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.2651 - val_loss: 1.3426\n",
      "Epoch 2441/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.2771 - val_loss: 1.4844\n",
      "Epoch 2442/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.2732 - val_loss: 1.3293\n",
      "Epoch 2443/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.2677 - val_loss: 1.3733\n",
      "Epoch 2444/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.2700 - val_loss: 1.2799\n",
      "Epoch 2445/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 0.2708 - val_loss: 1.4053\n",
      "Epoch 2446/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.2659 - val_loss: 1.4106\n",
      "Epoch 2447/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 0.2695 - val_loss: 1.4527\n",
      "Epoch 2448/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 0.2626 - val_loss: 1.3615\n",
      "Epoch 2449/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 0.2628 - val_loss: 1.2709\n",
      "Epoch 2450/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 0.2666 - val_loss: 1.4088\n",
      "Epoch 2451/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.2627 - val_loss: 1.4442\n",
      "Epoch 2452/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 0.2669 - val_loss: 1.3806\n",
      "Epoch 2453/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.2628 - val_loss: 1.3191\n",
      "Epoch 2454/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 0.2615 - val_loss: 1.4190\n",
      "Epoch 2455/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.2629 - val_loss: 1.4036\n",
      "Epoch 2456/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.2676 - val_loss: 1.2957\n",
      "Epoch 2457/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.2649 - val_loss: 1.4708\n",
      "Epoch 2458/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.2741 - val_loss: 1.3298\n",
      "Epoch 2459/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 0.2800 - val_loss: 1.5554\n",
      "Epoch 2460/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.2897 - val_loss: 1.3290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2461/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3101 - val_loss: 1.5760\n",
      "Epoch 2462/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.3278 - val_loss: 1.2270\n",
      "Epoch 2463/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 0.3340 - val_loss: 1.6428\n",
      "Epoch 2464/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 0.3355 - val_loss: 1.3122\n",
      "Epoch 2465/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.3104 - val_loss: 1.4113\n",
      "Epoch 2466/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 0.2816 - val_loss: 1.3858\n",
      "Epoch 2467/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 0.2700 - val_loss: 1.4580\n",
      "Epoch 2468/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.2819 - val_loss: 1.4439\n",
      "Epoch 2469/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 0.2865 - val_loss: 1.2482\n",
      "Epoch 2470/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 0.2811 - val_loss: 1.4366\n",
      "Epoch 2471/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.2831 - val_loss: 1.3045\n",
      "Epoch 2472/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.2679 - val_loss: 1.4243\n",
      "Epoch 2473/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 0.2636 - val_loss: 1.4688\n",
      "Epoch 2474/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.2639 - val_loss: 1.3414\n",
      "Epoch 2475/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 0.2624 - val_loss: 1.4490\n",
      "Epoch 2476/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 0.2635 - val_loss: 1.4261\n",
      "Epoch 2477/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 0.2651 - val_loss: 1.4223\n",
      "Epoch 2478/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 0.2587 - val_loss: 1.3174\n",
      "Epoch 2479/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 0.2630 - val_loss: 1.3873\n",
      "Epoch 2480/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.2589 - val_loss: 1.4124\n",
      "Epoch 2481/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 0.2587 - val_loss: 1.3102\n",
      "Epoch 2482/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 0.2589 - val_loss: 1.3858\n",
      "Epoch 2483/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.2590 - val_loss: 1.3672\n",
      "Epoch 2484/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.2616 - val_loss: 1.4057\n",
      "Epoch 2485/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.2588 - val_loss: 1.3551\n",
      "Epoch 2486/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.2561 - val_loss: 1.3685\n",
      "Epoch 2487/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.2596 - val_loss: 1.4616\n",
      "Epoch 2488/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 0.2603 - val_loss: 1.4018\n",
      "Epoch 2489/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2626 - val_loss: 1.3299\n",
      "Epoch 2490/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 0.2670 - val_loss: 1.3522\n",
      "Epoch 2491/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 0.2565 - val_loss: 1.3937\n",
      "Epoch 2492/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.2673 - val_loss: 1.4232\n",
      "Epoch 2493/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.2670 - val_loss: 1.2959\n",
      "Epoch 2494/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 0.2631 - val_loss: 1.3936\n",
      "Epoch 2495/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 0.2647 - val_loss: 1.3895\n",
      "Epoch 2496/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.2610 - val_loss: 1.4435\n",
      "Epoch 2497/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 0.2576 - val_loss: 1.4061\n",
      "Epoch 2498/2500\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.2549 - val_loss: 1.3022\n",
      "Epoch 2499/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.2653 - val_loss: 1.4835\n",
      "Epoch 2500/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 0.2632 - val_loss: 1.4188\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "no_reg = model.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is trained.  Let's see what the solution looks like.\n",
    "\n",
    "We will also get the validation data set that `keras` created for us.  By plotting the validation data, we will gain some insight into how well the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "X_val = no_reg.validation_data[0]\n",
    "Y_val = no_reg.validation_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(0.0, 5, 1000)\n",
    "y_pred = model.predict(X_range)\n",
    "\n",
    "# Now plot everything\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,8))\n",
    "ax.plot(X_true, Y_true, ls='-.', lw=4, label='True function')\n",
    "ax.plot(X_train, Y_train, '.', label='Training data')\n",
    "ax.plot(X_val, Y_val, '.', label='Validation data')\n",
    "ax.plot(X_range, y_pred, lw=4, label='Prediction')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction looks pretty bad.  The neural network model is trying to go through all the training points.  This is a classic case of overfitting.  The solution has a lot of oscillations and it rarely fits the validation data.  It may be a good idea to use some kind of regularization.\n",
    "\n",
    "Let's begin with some penalization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalization\n",
    "As mentioned in lecture, the loss function can be augmented by an additional term called the penalization term.  Mathematically, the goal is to find the set of weights $W$ that minimize the functional $$J_{R}\\left(W; X, y\\right) = J\\left(W; X, y\\right) + \\alpha\\Omega\\left(W\\right)$$\n",
    "where $\\alpha$ is called the regularization (or penalization) parameter.  In this lab, $\\displaystyle J\\left(W; X, y\\right)$ is the MSE loss function.\n",
    "\n",
    "Next, we consider the effect of two different forms for the penalization term: $L_{1}$ and $L_{2}$ penalization.  For reference, \n",
    "$$\\Omega_{L_{1}} = \\frac{1}{2}\\left\\|W\\right\\|_{1}$$\n",
    "and \n",
    "$$\\Omega_{L_{2}} = \\frac{1}{2}\\|W\\|^{2}_{2}.$$\n",
    "\n",
    "Note that the biases are not being penalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Fit the same network as above ($5$ hidden layers, $100$ nodes per layer, linear output layer), but this time use $L_{2}$ and $L_{1}$ regularization.\n",
    "\n",
    "**Deliverables:**\n",
    "* Make two figures, one on top of the other.\n",
    "* The first figure should contain the following:\n",
    "  - True solution\n",
    "  - Training data\n",
    "  - Validation data\n",
    "  - Neural network prediction without regularization\n",
    "  - Neural network prediction with $L_{2}$ regularization\n",
    "* The second figure should contain the following:\n",
    "  - True solution\n",
    "  - Training data\n",
    "  - Validation data\n",
    "  - Neural network prediction without regularization\n",
    "  - Neural network prediction with $L_{1}$ regularization\n",
    "* **Make sure everything is clearly labeled!**\n",
    "* Discuss the results.\n",
    "\n",
    "**Hints:**\n",
    "* Use `kernel_regularizer=regularizers.l2(alpha)` after the `activation` argument in each of your layers.\n",
    "* Choose a value for `alpha` that you think works well.  You may need to play around with this a little bit.\n",
    "* See the `Keras` documentation on regularization:  [Usage of regularizers](https://keras.io/regularizers/)\n",
    "* Here's some pseudo-code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from keras import regularizers\n",
    "\n",
    "num_layers = 5\n",
    "N = 100\n",
    "alpha = \n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "### Create network\n",
    "model_L2 = \n",
    "model_L2.add()\n",
    "\n",
    "\n",
    "### Compile network\n",
    "model_L2.compile()\n",
    "\n",
    "### Fit model\n",
    "L2_reg = model_L2.fit()\n",
    "\n",
    "### Extract validation data\n",
    "X_val_L2 = \n",
    "Y_val_L2 = \n",
    "\n",
    "### REPEAT FOR L1\n",
    "###\n",
    "###\n",
    "###\n",
    "\n",
    "# PLOT\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20,14), sharex=True)\n",
    "\n",
    "ax[0].plot() # Top plots\n",
    "### ...\n",
    "\n",
    "ax[0].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[0].tick_params(labelsize=20)\n",
    "ax[0].legend(loc=1, fontsize=20)\n",
    "\n",
    "\n",
    "ax[1].plot() # Bottom plots\n",
    "### ...\n",
    "ax[1].set_xlabel(r'$Y$', fontsize=20)\n",
    "ax[1].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[1].tick_params(labelsize=20)\n",
    "ax[1].legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 8.4886 - val_loss: 6.2393\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 7.4537 - val_loss: 5.9089\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 7.2344 - val_loss: 5.9361\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 7.3425 - val_loss: 5.8566\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 7.2668 - val_loss: 5.7155\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 7.0854 - val_loss: 5.6541\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 495us/step - loss: 6.9740 - val_loss: 5.6841\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 431us/step - loss: 6.9661 - val_loss: 5.7071\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 6.9723 - val_loss: 5.6535\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 342us/step - loss: 6.9205 - val_loss: 5.5268\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 6.8109 - val_loss: 5.3662\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 6.6808 - val_loss: 5.2142\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 459us/step - loss: 6.5712 - val_loss: 5.0966\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 6.5016 - val_loss: 5.0045\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 356us/step - loss: 6.4507 - val_loss: 4.9057\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 6.3724 - val_loss: 4.7925\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 6.2547 - val_loss: 4.6931\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 6.1326 - val_loss: 4.6375\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 6.0498 - val_loss: 4.6040\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 601us/step - loss: 6.0004 - val_loss: 4.5286\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 436us/step - loss: 5.9342 - val_loss: 4.3953\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 5.8411 - val_loss: 4.2721\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 5.7850 - val_loss: 4.2237\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 5.8014 - val_loss: 4.2162\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 5.8089 - val_loss: 4.2461\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 5.7978 - val_loss: 4.3349\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 346us/step - loss: 5.8355 - val_loss: 4.3561\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 5.8478 - val_loss: 4.2779\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 5.8049 - val_loss: 4.2056\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 5.7765 - val_loss: 4.1673\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 5.7486 - val_loss: 4.1468\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 5.6968 - val_loss: 4.1569\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 5.6597 - val_loss: 4.1807\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 5.6478 - val_loss: 4.1806\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 363us/step - loss: 5.6357 - val_loss: 4.1551\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 5.6181 - val_loss: 4.1297\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 459us/step - loss: 5.6096 - val_loss: 4.1183\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 5.6104 - val_loss: 4.1151\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 5.6049 - val_loss: 4.1159\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 445us/step - loss: 5.5892 - val_loss: 4.1220\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 482us/step - loss: 5.5735 - val_loss: 4.1253\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 416us/step - loss: 5.5609 - val_loss: 4.1096\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 5.5429 - val_loss: 4.0720\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 470us/step - loss: 5.5178 - val_loss: 4.0291\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 5.4956 - val_loss: 3.9960\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 5.4785 - val_loss: 3.9762\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 276us/step - loss: 5.4573 - val_loss: 3.9718\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 5.4403 - val_loss: 3.9747\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 5.4292 - val_loss: 3.9605\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 5.4161 - val_loss: 3.9269\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 347us/step - loss: 5.3997 - val_loss: 3.8989\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 5.3870 - val_loss: 3.8867\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 5.3684 - val_loss: 3.8892\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 421us/step - loss: 5.3466 - val_loss: 3.8883\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 5.3268 - val_loss: 3.8630\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 407us/step - loss: 5.3022 - val_loss: 3.8334\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 5.2806 - val_loss: 3.8207\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 5.2592 - val_loss: 3.8249\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 5.2362 - val_loss: 3.8248\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 5.2156 - val_loss: 3.7968\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 5.1897 - val_loss: 3.7664\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 5.1641 - val_loss: 3.7539\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 374us/step - loss: 5.1322 - val_loss: 3.7456\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 5.1003 - val_loss: 3.7013\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 5.0621 - val_loss: 3.6604\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 5.0245 - val_loss: 3.6552\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 4.9828 - val_loss: 3.6095\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 614us/step - loss: 4.9357 - val_loss: 3.5657\n",
      "Epoch 69/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 4.8848 - val_loss: 3.5734\n",
      "Epoch 70/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 4.8290 - val_loss: 3.4759\n",
      "Epoch 71/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 4.7714 - val_loss: 3.6227\n",
      "Epoch 72/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 4.7432 - val_loss: 3.4443\n",
      "Epoch 73/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 4.7924 - val_loss: 3.6649\n",
      "Epoch 74/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 4.6715 - val_loss: 3.3716\n",
      "Epoch 75/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 4.4811 - val_loss: 3.2991\n",
      "Epoch 76/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 4.5290 - val_loss: 3.6603\n",
      "Epoch 77/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 4.5170 - val_loss: 3.1872\n",
      "Epoch 78/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 4.2911 - val_loss: 3.1450\n",
      "Epoch 79/2500\n",
      "64/64 [==============================] - 0s 341us/step - loss: 4.1793 - val_loss: 3.5860\n",
      "Epoch 80/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 4.2814 - val_loss: 3.2206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 4.4452 - val_loss: 3.5542\n",
      "Epoch 82/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 4.1235 - val_loss: 3.0646\n",
      "Epoch 83/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 3.7999 - val_loss: 3.0037\n",
      "Epoch 84/2500\n",
      "64/64 [==============================] - 0s 511us/step - loss: 4.0125 - val_loss: 3.9903\n",
      "Epoch 85/2500\n",
      "64/64 [==============================] - 0s 286us/step - loss: 4.2072 - val_loss: 2.9525\n",
      "Epoch 86/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 3.8812 - val_loss: 2.9057\n",
      "Epoch 87/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 3.4634 - val_loss: 3.7561\n",
      "Epoch 88/2500\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 3.8248 - val_loss: 3.2311\n",
      "Epoch 89/2500\n",
      "64/64 [==============================] - 0s 370us/step - loss: 4.3031 - val_loss: 3.4752\n",
      "Epoch 90/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 3.5212 - val_loss: 3.2017\n",
      "Epoch 91/2500\n",
      "64/64 [==============================] - 0s 531us/step - loss: 3.3140 - val_loss: 3.0768\n",
      "Epoch 92/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 4.0063 - val_loss: 3.7978\n",
      "Epoch 93/2500\n",
      "64/64 [==============================] - 0s 379us/step - loss: 3.5700 - val_loss: 2.9198\n",
      "Epoch 94/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 3.0761 - val_loss: 2.8647\n",
      "Epoch 95/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 3.5304 - val_loss: 4.0151\n",
      "Epoch 96/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 3.5757 - val_loss: 2.7626\n",
      "Epoch 97/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 3.0660 - val_loss: 2.7575\n",
      "Epoch 98/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 3.0791 - val_loss: 3.9998\n",
      "Epoch 99/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 3.4610 - val_loss: 2.8310\n",
      "Epoch 100/2500\n",
      "64/64 [==============================] - 0s 354us/step - loss: 3.3362 - val_loss: 3.0134\n",
      "Epoch 101/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 2.9096 - val_loss: 3.5689\n",
      "Epoch 102/2500\n",
      "64/64 [==============================] - 0s 351us/step - loss: 3.1234 - val_loss: 2.9203\n",
      "Epoch 103/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 3.4439 - val_loss: 3.5308\n",
      "Epoch 104/2500\n",
      "64/64 [==============================] - 0s 369us/step - loss: 3.0650 - val_loss: 3.0929\n",
      "Epoch 105/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.8744 - val_loss: 2.8384\n",
      "Epoch 106/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 3.1580 - val_loss: 3.7231\n",
      "Epoch 107/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 3.1348 - val_loss: 2.8750\n",
      "Epoch 108/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.8701 - val_loss: 2.8309\n",
      "Epoch 109/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 2.9167 - val_loss: 3.6288\n",
      "Epoch 110/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 3.0664 - val_loss: 2.8195\n",
      "Epoch 111/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.9362 - val_loss: 2.9345\n",
      "Epoch 112/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 2.8269 - val_loss: 3.4508\n",
      "Epoch 113/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 2.9613 - val_loss: 2.8158\n",
      "Epoch 114/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 2.9581 - val_loss: 3.0459\n",
      "Epoch 115/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 2.8140 - val_loss: 3.2890\n",
      "Epoch 116/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 2.8804 - val_loss: 2.8076\n",
      "Epoch 117/2500\n",
      "64/64 [==============================] - 0s 388us/step - loss: 2.9320 - val_loss: 3.0980\n",
      "Epoch 118/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 2.8142 - val_loss: 3.1648\n",
      "Epoch 119/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 2.8299 - val_loss: 2.7991\n",
      "Epoch 120/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 2.8919 - val_loss: 3.1140\n",
      "Epoch 121/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.8094 - val_loss: 3.0821\n",
      "Epoch 122/2500\n",
      "64/64 [==============================] - 0s 367us/step - loss: 2.7980 - val_loss: 2.8042\n",
      "Epoch 123/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.8517 - val_loss: 3.1194\n",
      "Epoch 124/2500\n",
      "64/64 [==============================] - 0s 349us/step - loss: 2.8005 - val_loss: 3.0214\n",
      "Epoch 125/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 2.7757 - val_loss: 2.8136\n",
      "Epoch 126/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 2.8163 - val_loss: 3.1137\n",
      "Epoch 127/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.7894 - val_loss: 2.9668\n",
      "Epoch 128/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.7592 - val_loss: 2.8255\n",
      "Epoch 129/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 2.7853 - val_loss: 3.1056\n",
      "Epoch 130/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.7775 - val_loss: 2.9203\n",
      "Epoch 131/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 2.7475 - val_loss: 2.8502\n",
      "Epoch 132/2500\n",
      "64/64 [==============================] - 0s 365us/step - loss: 2.7580 - val_loss: 3.0946\n",
      "Epoch 133/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.7636 - val_loss: 2.8838\n",
      "Epoch 134/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 2.7402 - val_loss: 2.8865\n",
      "Epoch 135/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.7356 - val_loss: 3.0650\n",
      "Epoch 136/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.7458 - val_loss: 2.8549\n",
      "Epoch 137/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 2.7346 - val_loss: 2.9264\n",
      "Epoch 138/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 2.7206 - val_loss: 3.0147\n",
      "Epoch 139/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.7258 - val_loss: 2.8398\n",
      "Epoch 140/2500\n",
      "64/64 [==============================] - 0s 399us/step - loss: 2.7259 - val_loss: 2.9658\n",
      "Epoch 141/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.7121 - val_loss: 2.9540\n",
      "Epoch 142/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 2.7075 - val_loss: 2.8437\n",
      "Epoch 143/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 2.7113 - val_loss: 2.9878\n",
      "Epoch 144/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 2.7051 - val_loss: 2.8956\n",
      "Epoch 145/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.6952 - val_loss: 2.8624\n",
      "Epoch 146/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.6941 - val_loss: 2.9760\n",
      "Epoch 147/2500\n",
      "64/64 [==============================] - 0s 478us/step - loss: 2.6942 - val_loss: 2.8517\n",
      "Epoch 148/2500\n",
      "64/64 [==============================] - 0s 279us/step - loss: 2.6872 - val_loss: 2.8903\n",
      "Epoch 149/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 2.6804 - val_loss: 2.9360\n",
      "Epoch 150/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 2.6796 - val_loss: 2.8320\n",
      "Epoch 151/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.6777 - val_loss: 2.9148\n",
      "Epoch 152/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 2.6711 - val_loss: 2.8855\n",
      "Epoch 153/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.6661 - val_loss: 2.8347\n",
      "Epoch 154/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.6647 - val_loss: 2.9176\n",
      "Epoch 155/2500\n",
      "64/64 [==============================] - 0s 290us/step - loss: 2.6618 - val_loss: 2.8416\n",
      "Epoch 156/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.6561 - val_loss: 2.8519\n",
      "Epoch 157/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.6519 - val_loss: 2.8928\n",
      "Epoch 158/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.6498 - val_loss: 2.8178\n",
      "Epoch 159/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 2.6466 - val_loss: 2.8713\n",
      "Epoch 160/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 2.6417 - val_loss: 2.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.6376 - val_loss: 2.8181\n",
      "Epoch 162/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 2.6350 - val_loss: 2.8739\n",
      "Epoch 163/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.6319 - val_loss: 2.8182\n",
      "Epoch 164/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 2.6275 - val_loss: 2.8339\n",
      "Epoch 165/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.6235 - val_loss: 2.8502\n",
      "Epoch 166/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.6204 - val_loss: 2.8024\n",
      "Epoch 167/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.6174 - val_loss: 2.8462\n",
      "Epoch 168/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 2.6135 - val_loss: 2.8150\n",
      "Epoch 169/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 2.6095 - val_loss: 2.8094\n",
      "Epoch 170/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 2.6054 - val_loss: 2.8356\n",
      "Epoch 171/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 2.6030 - val_loss: 2.7923\n",
      "Epoch 172/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.5996 - val_loss: 2.8225\n",
      "Epoch 173/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.5958 - val_loss: 2.8048\n",
      "Epoch 174/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 2.5921 - val_loss: 2.7923\n",
      "Epoch 175/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 2.5881 - val_loss: 2.8159\n",
      "Epoch 176/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 2.5855 - val_loss: 2.7799\n",
      "Epoch 177/2500\n",
      "64/64 [==============================] - 0s 352us/step - loss: 2.5821 - val_loss: 2.8021\n",
      "Epoch 178/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.5784 - val_loss: 2.7881\n",
      "Epoch 179/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 2.5748 - val_loss: 2.7778\n",
      "Epoch 180/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 2.5715 - val_loss: 2.7951\n",
      "Epoch 181/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.5682 - val_loss: 2.7657\n",
      "Epoch 182/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.5648 - val_loss: 2.7846\n",
      "Epoch 183/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 2.5612 - val_loss: 2.7685\n",
      "Epoch 184/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 2.5577 - val_loss: 2.7646\n",
      "Epoch 185/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.5543 - val_loss: 2.7732\n",
      "Epoch 186/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.5510 - val_loss: 2.7508\n",
      "Epoch 187/2500\n",
      "64/64 [==============================] - 0s 306us/step - loss: 2.5477 - val_loss: 2.7676\n",
      "Epoch 188/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.5442 - val_loss: 2.7482\n",
      "Epoch 189/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.5408 - val_loss: 2.7529\n",
      "Epoch 190/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 2.5374 - val_loss: 2.7506\n",
      "Epoch 191/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.5340 - val_loss: 2.7384\n",
      "Epoch 192/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.5307 - val_loss: 2.7493\n",
      "Epoch 193/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.5273 - val_loss: 2.7301\n",
      "Epoch 194/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 2.5240 - val_loss: 2.7410\n",
      "Epoch 195/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.5206 - val_loss: 2.7277\n",
      "Epoch 196/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.5172 - val_loss: 2.7288\n",
      "Epoch 197/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 2.5138 - val_loss: 2.7272\n",
      "Epoch 198/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.5105 - val_loss: 2.7174\n",
      "Epoch 199/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.5072 - val_loss: 2.7244\n",
      "Epoch 200/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 2.5038 - val_loss: 2.7092\n",
      "Epoch 201/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.5005 - val_loss: 2.7181\n",
      "Epoch 202/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.4972 - val_loss: 2.7040\n",
      "Epoch 203/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.4939 - val_loss: 2.7092\n",
      "Epoch 204/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 2.4905 - val_loss: 2.7004\n",
      "Epoch 205/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.4872 - val_loss: 2.6996\n",
      "Epoch 206/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.4839 - val_loss: 2.6970\n",
      "Epoch 207/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.4806 - val_loss: 2.6905\n",
      "Epoch 208/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.4773 - val_loss: 2.6929\n",
      "Epoch 209/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 2.4740 - val_loss: 2.6822\n",
      "Epoch 210/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.4707 - val_loss: 2.6878\n",
      "Epoch 211/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.4674 - val_loss: 2.6745\n",
      "Epoch 212/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.4641 - val_loss: 2.6823\n",
      "Epoch 213/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 2.4609 - val_loss: 2.6671\n",
      "Epoch 214/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.4576 - val_loss: 2.6768\n",
      "Epoch 215/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.4543 - val_loss: 2.6594\n",
      "Epoch 216/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 2.4511 - val_loss: 2.6720\n",
      "Epoch 217/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.4478 - val_loss: 2.6508\n",
      "Epoch 218/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.4446 - val_loss: 2.6687\n",
      "Epoch 219/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.4414 - val_loss: 2.6402\n",
      "Epoch 220/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.4382 - val_loss: 2.6684\n",
      "Epoch 221/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.4351 - val_loss: 2.6259\n",
      "Epoch 222/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.4321 - val_loss: 2.6744\n",
      "Epoch 223/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.4294 - val_loss: 2.6044\n",
      "Epoch 224/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.4271 - val_loss: 2.6942\n",
      "Epoch 225/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.4256 - val_loss: 2.5695\n",
      "Epoch 226/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 2.4259 - val_loss: 2.7460\n",
      "Epoch 227/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 2.4294 - val_loss: 2.5153\n",
      "Epoch 228/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.4403 - val_loss: 2.8744\n",
      "Epoch 229/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.4629 - val_loss: 2.4567\n",
      "Epoch 230/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.5097 - val_loss: 3.1197\n",
      "Epoch 231/2500\n",
      "64/64 [==============================] - 0s 284us/step - loss: 2.5671 - val_loss: 2.4472\n",
      "Epoch 232/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.6432 - val_loss: 3.2106\n",
      "Epoch 233/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 2.6215 - val_loss: 2.4133\n",
      "Epoch 234/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.5337 - val_loss: 2.6914\n",
      "Epoch 235/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 2.4128 - val_loss: 2.6624\n",
      "Epoch 236/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.4073 - val_loss: 2.3869\n",
      "Epoch 237/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.4814 - val_loss: 2.8530\n",
      "Epoch 238/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 2.4741 - val_loss: 2.4295\n",
      "Epoch 239/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.4044 - val_loss: 2.4594\n",
      "Epoch 240/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.3887 - val_loss: 2.7595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.4327 - val_loss: 2.3848\n",
      "Epoch 242/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.4346 - val_loss: 2.6221\n",
      "Epoch 243/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 2.3829 - val_loss: 2.5875\n",
      "Epoch 244/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 2.3715 - val_loss: 2.4125\n",
      "Epoch 245/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.4019 - val_loss: 2.7601\n",
      "Epoch 246/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.4047 - val_loss: 2.4494\n",
      "Epoch 247/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 2.3748 - val_loss: 2.5625\n",
      "Epoch 248/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.3513 - val_loss: 2.6529\n",
      "Epoch 249/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 2.3589 - val_loss: 2.4468\n",
      "Epoch 250/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 2.3781 - val_loss: 2.7642\n",
      "Epoch 251/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.3796 - val_loss: 2.4638\n",
      "Epoch 252/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.3646 - val_loss: 2.6475\n",
      "Epoch 253/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 2.3434 - val_loss: 2.5685\n",
      "Epoch 254/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.3331 - val_loss: 2.5106\n",
      "Epoch 255/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.3361 - val_loss: 2.6887\n",
      "Epoch 256/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.3442 - val_loss: 2.4596\n",
      "Epoch 257/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.3480 - val_loss: 2.6887\n",
      "Epoch 258/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 2.3407 - val_loss: 2.4777\n",
      "Epoch 259/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.3279 - val_loss: 2.5731\n",
      "Epoch 260/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.3165 - val_loss: 2.5552\n",
      "Epoch 261/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.3127 - val_loss: 2.4717\n",
      "Epoch 262/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.3149 - val_loss: 2.6126\n",
      "Epoch 263/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 2.3163 - val_loss: 2.4471\n",
      "Epoch 264/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 2.3126 - val_loss: 2.5642\n",
      "Epoch 265/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.3045 - val_loss: 2.4911\n",
      "Epoch 266/2500\n",
      "64/64 [==============================] - 0s 421us/step - loss: 2.2978 - val_loss: 2.4754\n",
      "Epoch 267/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 2.2956 - val_loss: 2.5516\n",
      "Epoch 268/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 2.2959 - val_loss: 2.4378\n",
      "Epoch 269/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.2947 - val_loss: 2.5464\n",
      "Epoch 270/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.2901 - val_loss: 2.4605\n",
      "Epoch 271/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.2843 - val_loss: 2.4887\n",
      "Epoch 272/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 2.2800 - val_loss: 2.5115\n",
      "Epoch 273/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 2.2780 - val_loss: 2.4469\n",
      "Epoch 274/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.2769 - val_loss: 2.5376\n",
      "Epoch 275/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.2749 - val_loss: 2.4425\n",
      "Epoch 276/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.2716 - val_loss: 2.5198\n",
      "Epoch 277/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.2672 - val_loss: 2.4643\n",
      "Epoch 278/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.2630 - val_loss: 2.4831\n",
      "Epoch 279/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.2596 - val_loss: 2.4934\n",
      "Epoch 280/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.2570 - val_loss: 2.4530\n",
      "Epoch 281/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 2.2549 - val_loss: 2.5118\n",
      "Epoch 282/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.2529 - val_loss: 2.4369\n",
      "Epoch 283/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.2506 - val_loss: 2.5116\n",
      "Epoch 284/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.2478 - val_loss: 2.4322\n",
      "Epoch 285/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 2.2446 - val_loss: 2.4965\n",
      "Epoch 286/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 2.2412 - val_loss: 2.4346\n",
      "Epoch 287/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.2378 - val_loss: 2.4741\n",
      "Epoch 288/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 2.2344 - val_loss: 2.4406\n",
      "Epoch 289/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 2.2313 - val_loss: 2.4515\n",
      "Epoch 290/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.2283 - val_loss: 2.4469\n",
      "Epoch 291/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.2254 - val_loss: 2.4322\n",
      "Epoch 292/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.2228 - val_loss: 2.4515\n",
      "Epoch 293/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 2.2202 - val_loss: 2.4172\n",
      "Epoch 294/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 2.2176 - val_loss: 2.4541\n",
      "Epoch 295/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 2.2151 - val_loss: 2.4052\n",
      "Epoch 296/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 2.2126 - val_loss: 2.4565\n",
      "Epoch 297/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.2102 - val_loss: 2.3940\n",
      "Epoch 298/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.2079 - val_loss: 2.4615\n",
      "Epoch 299/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.2057 - val_loss: 2.3805\n",
      "Epoch 300/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 2.2039 - val_loss: 2.4742\n",
      "Epoch 301/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.2025 - val_loss: 2.3603\n",
      "Epoch 302/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 2.2023 - val_loss: 2.5041\n",
      "Epoch 303/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.2035 - val_loss: 2.3296\n",
      "Epoch 304/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 2.2083 - val_loss: 2.5702\n",
      "Epoch 305/2500\n",
      "64/64 [==============================] - 0s 276us/step - loss: 2.2174 - val_loss: 2.2903\n",
      "Epoch 306/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.2385 - val_loss: 2.7137\n",
      "Epoch 307/2500\n",
      "64/64 [==============================] - 0s 357us/step - loss: 2.2696 - val_loss: 2.2701\n",
      "Epoch 308/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.3308 - val_loss: 2.9275\n",
      "Epoch 309/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.3772 - val_loss: 2.2790\n",
      "Epoch 310/2500\n",
      "64/64 [==============================] - 0s 394us/step - loss: 2.4310 - val_loss: 2.8395\n",
      "Epoch 311/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.3464 - val_loss: 2.2257\n",
      "Epoch 312/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 2.2382 - val_loss: 2.3348\n",
      "Epoch 313/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 2.1734 - val_loss: 2.5166\n",
      "Epoch 314/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 2.2165 - val_loss: 2.2004\n",
      "Epoch 315/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 2.2765 - val_loss: 2.5642\n",
      "Epoch 316/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.2337 - val_loss: 2.2609\n",
      "Epoch 317/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 2.1725 - val_loss: 2.2488\n",
      "Epoch 318/2500\n",
      "64/64 [==============================] - 0s 277us/step - loss: 2.1747 - val_loss: 2.5483\n",
      "Epoch 319/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.2146 - val_loss: 2.2157\n",
      "Epoch 320/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.2233 - val_loss: 2.4815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.1784 - val_loss: 2.3257\n",
      "Epoch 322/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 2.1479 - val_loss: 2.2874\n",
      "Epoch 323/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 2.1568 - val_loss: 2.5547\n",
      "Epoch 324/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.1835 - val_loss: 2.2624\n",
      "Epoch 325/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.2024 - val_loss: 2.6007\n",
      "Epoch 326/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.1910 - val_loss: 2.2852\n",
      "Epoch 327/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 2.1690 - val_loss: 2.4629\n",
      "Epoch 328/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 2.1440 - val_loss: 2.3640\n",
      "Epoch 329/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.1315 - val_loss: 2.3320\n",
      "Epoch 330/2500\n",
      "64/64 [==============================] - 0s 348us/step - loss: 2.1330 - val_loss: 2.4749\n",
      "Epoch 331/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.1425 - val_loss: 2.2791\n",
      "Epoch 332/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.1511 - val_loss: 2.5013\n",
      "Epoch 333/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 2.1485 - val_loss: 2.2781\n",
      "Epoch 334/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.1382 - val_loss: 2.4058\n",
      "Epoch 335/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.1241 - val_loss: 2.3317\n",
      "Epoch 336/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 2.1161 - val_loss: 2.2984\n",
      "Epoch 337/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 2.1170 - val_loss: 2.4040\n",
      "Epoch 338/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.1214 - val_loss: 2.2609\n",
      "Epoch 339/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 2.1224 - val_loss: 2.3933\n",
      "Epoch 340/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.1166 - val_loss: 2.2867\n",
      "Epoch 341/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.1088 - val_loss: 2.3199\n",
      "Epoch 342/2500\n",
      "64/64 [==============================] - 0s 210us/step - loss: 2.1041 - val_loss: 2.3517\n",
      "Epoch 343/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.1040 - val_loss: 2.2751\n",
      "Epoch 344/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.1056 - val_loss: 2.3878\n",
      "Epoch 345/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.1052 - val_loss: 2.2762\n",
      "Epoch 346/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 2.1020 - val_loss: 2.3647\n",
      "Epoch 347/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 2.0970 - val_loss: 2.3079\n",
      "Epoch 348/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.0926 - val_loss: 2.3212\n",
      "Epoch 349/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.0901 - val_loss: 2.3491\n",
      "Epoch 350/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.0893 - val_loss: 2.2919\n",
      "Epoch 351/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 2.0891 - val_loss: 2.3734\n",
      "Epoch 352/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.0886 - val_loss: 2.2815\n",
      "Epoch 353/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.0872 - val_loss: 2.3691\n",
      "Epoch 354/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.0847 - val_loss: 2.2847\n",
      "Epoch 355/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.0816 - val_loss: 2.3430\n",
      "Epoch 356/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 2.0779 - val_loss: 2.2975\n",
      "Epoch 357/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.0754 - val_loss: 2.3107\n",
      "Epoch 358/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.0731 - val_loss: 2.3137\n",
      "Epoch 359/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0714 - val_loss: 2.2850\n",
      "Epoch 360/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 2.0701 - val_loss: 2.3247\n",
      "Epoch 361/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.0688 - val_loss: 2.2714\n",
      "Epoch 362/2500\n",
      "64/64 [==============================] - 0s 356us/step - loss: 2.0674 - val_loss: 2.3243\n",
      "Epoch 363/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.0656 - val_loss: 2.2693\n",
      "Epoch 364/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0635 - val_loss: 2.3134\n",
      "Epoch 365/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 2.0613 - val_loss: 2.2755\n",
      "Epoch 366/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.0590 - val_loss: 2.2983\n",
      "Epoch 367/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.0569 - val_loss: 2.2856\n",
      "Epoch 368/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.0549 - val_loss: 2.2845\n",
      "Epoch 369/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.0531 - val_loss: 2.2953\n",
      "Epoch 370/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 2.0515 - val_loss: 2.2742\n",
      "Epoch 371/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.0499 - val_loss: 2.3020\n",
      "Epoch 372/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 2.0483 - val_loss: 2.2668\n",
      "Epoch 373/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.0468 - val_loss: 2.3050\n",
      "Epoch 374/2500\n",
      "64/64 [==============================] - 0s 306us/step - loss: 2.0452 - val_loss: 2.2605\n",
      "Epoch 375/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.0437 - val_loss: 2.3055\n",
      "Epoch 376/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.0421 - val_loss: 2.2543\n",
      "Epoch 377/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.0405 - val_loss: 2.3049\n",
      "Epoch 378/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.0389 - val_loss: 2.2476\n",
      "Epoch 379/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.0374 - val_loss: 2.3042\n",
      "Epoch 380/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.0359 - val_loss: 2.2401\n",
      "Epoch 381/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.0344 - val_loss: 2.3043\n",
      "Epoch 382/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 2.0330 - val_loss: 2.2319\n",
      "Epoch 383/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 2.0317 - val_loss: 2.3059\n",
      "Epoch 384/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.0304 - val_loss: 2.2228\n",
      "Epoch 385/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0294 - val_loss: 2.3102\n",
      "Epoch 386/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 2.0284 - val_loss: 2.2127\n",
      "Epoch 387/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.0277 - val_loss: 2.3182\n",
      "Epoch 388/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.0272 - val_loss: 2.2011\n",
      "Epoch 389/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 2.0272 - val_loss: 2.3314\n",
      "Epoch 390/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.0274 - val_loss: 2.1877\n",
      "Epoch 391/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.0287 - val_loss: 2.3513\n",
      "Epoch 392/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.0300 - val_loss: 2.1724\n",
      "Epoch 393/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.0332 - val_loss: 2.3780\n",
      "Epoch 394/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.0360 - val_loss: 2.1569\n",
      "Epoch 395/2500\n",
      "64/64 [==============================] - 0s 366us/step - loss: 2.0409 - val_loss: 2.4044\n",
      "Epoch 396/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 2.0436 - val_loss: 2.1443\n",
      "Epoch 397/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 2.0479 - val_loss: 2.4110\n",
      "Epoch 398/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.0456 - val_loss: 2.1375\n",
      "Epoch 399/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0430 - val_loss: 2.3736\n",
      "Epoch 400/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.0321 - val_loss: 2.1452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 2.0209 - val_loss: 2.2958\n",
      "Epoch 402/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 2.0081 - val_loss: 2.1821\n",
      "Epoch 403/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.9988 - val_loss: 2.2191\n",
      "Epoch 404/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.9941 - val_loss: 2.2442\n",
      "Epoch 405/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.9939 - val_loss: 2.1741\n",
      "Epoch 406/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.9966 - val_loss: 2.3020\n",
      "Epoch 407/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 1.9999 - val_loss: 2.1563\n",
      "Epoch 408/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.0033 - val_loss: 2.3352\n",
      "Epoch 409/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 2.0045 - val_loss: 2.1506\n",
      "Epoch 410/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 2.0055 - val_loss: 2.3434\n",
      "Epoch 411/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.0037 - val_loss: 2.1493\n",
      "Epoch 412/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.0020 - val_loss: 2.3310\n",
      "Epoch 413/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.9978 - val_loss: 2.1514\n",
      "Epoch 414/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.9938 - val_loss: 2.3006\n",
      "Epoch 415/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 1.9882 - val_loss: 2.1603\n",
      "Epoch 416/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.9829 - val_loss: 2.2573\n",
      "Epoch 417/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.9775 - val_loss: 2.1797\n",
      "Epoch 418/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 1.9732 - val_loss: 2.2129\n",
      "Epoch 419/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.9702 - val_loss: 2.2072\n",
      "Epoch 420/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.9685 - val_loss: 2.1797\n",
      "Epoch 421/2500\n",
      "64/64 [==============================] - 0s 451us/step - loss: 1.9679 - val_loss: 2.2328\n",
      "Epoch 422/2500\n",
      "64/64 [==============================] - 0s 474us/step - loss: 1.9677 - val_loss: 2.1619\n",
      "Epoch 423/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.9675 - val_loss: 2.2467\n",
      "Epoch 424/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.9667 - val_loss: 2.1567\n",
      "Epoch 425/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.9656 - val_loss: 2.2464\n",
      "Epoch 426/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.9637 - val_loss: 2.1594\n",
      "Epoch 427/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.9616 - val_loss: 2.2361\n",
      "Epoch 428/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9592 - val_loss: 2.1664\n",
      "Epoch 429/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.9569 - val_loss: 2.2207\n",
      "Epoch 430/2500\n",
      "64/64 [==============================] - 0s 479us/step - loss: 1.9546 - val_loss: 2.1751\n",
      "Epoch 431/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.9525 - val_loss: 2.2044\n",
      "Epoch 432/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.9505 - val_loss: 2.1837\n",
      "Epoch 433/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.9488 - val_loss: 2.1895\n",
      "Epoch 434/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.9472 - val_loss: 2.1908\n",
      "Epoch 435/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.9457 - val_loss: 2.1769\n",
      "Epoch 436/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.9444 - val_loss: 2.1958\n",
      "Epoch 437/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.9431 - val_loss: 2.1667\n",
      "Epoch 438/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.9418 - val_loss: 2.1985\n",
      "Epoch 439/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.9405 - val_loss: 2.1588\n",
      "Epoch 440/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.9392 - val_loss: 2.1992\n",
      "Epoch 441/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.9376 - val_loss: 2.1529\n",
      "Epoch 442/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.9366 - val_loss: 2.1985\n",
      "Epoch 443/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.9352 - val_loss: 2.1485\n",
      "Epoch 444/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.9339 - val_loss: 2.1971\n",
      "Epoch 445/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.9325 - val_loss: 2.1449\n",
      "Epoch 446/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.9311 - val_loss: 2.1954\n",
      "Epoch 447/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.9297 - val_loss: 2.1415\n",
      "Epoch 448/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.9283 - val_loss: 2.1941\n",
      "Epoch 449/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.9269 - val_loss: 2.1379\n",
      "Epoch 450/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.9256 - val_loss: 2.1937\n",
      "Epoch 451/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.9243 - val_loss: 2.1333\n",
      "Epoch 452/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.9231 - val_loss: 2.1949\n",
      "Epoch 453/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9219 - val_loss: 2.1271\n",
      "Epoch 454/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.9209 - val_loss: 2.1983\n",
      "Epoch 455/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.9199 - val_loss: 2.1191\n",
      "Epoch 456/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.9191 - val_loss: 2.2046\n",
      "Epoch 457/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.9185 - val_loss: 2.1088\n",
      "Epoch 458/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9183 - val_loss: 2.2149\n",
      "Epoch 459/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.9182 - val_loss: 2.0961\n",
      "Epoch 460/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9188 - val_loss: 2.2303\n",
      "Epoch 461/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.9196 - val_loss: 2.0816\n",
      "Epoch 462/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.9214 - val_loss: 2.2505\n",
      "Epoch 463/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.9231 - val_loss: 2.0668\n",
      "Epoch 464/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.9263 - val_loss: 2.2726\n",
      "Epoch 465/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.9285 - val_loss: 2.0533\n",
      "Epoch 466/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.9322 - val_loss: 2.2864\n",
      "Epoch 467/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.9323 - val_loss: 2.0446\n",
      "Epoch 468/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.9329 - val_loss: 2.2725\n",
      "Epoch 469/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.9273 - val_loss: 2.0460\n",
      "Epoch 470/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.9210 - val_loss: 2.2217\n",
      "Epoch 471/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.9109 - val_loss: 2.0668\n",
      "Epoch 472/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.9020 - val_loss: 2.1552\n",
      "Epoch 473/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.8947 - val_loss: 2.1111\n",
      "Epoch 474/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 1.8907 - val_loss: 2.1036\n",
      "Epoch 475/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.8898 - val_loss: 2.1639\n",
      "Epoch 476/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8911 - val_loss: 2.0762\n",
      "Epoch 477/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.8934 - val_loss: 2.2064\n",
      "Epoch 478/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.8957 - val_loss: 2.0635\n",
      "Epoch 479/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.8981 - val_loss: 2.2324\n",
      "Epoch 480/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.8992 - val_loss: 2.0560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.9006 - val_loss: 2.2422\n",
      "Epoch 482/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.8998 - val_loss: 2.0505\n",
      "Epoch 483/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 1.8993 - val_loss: 2.2328\n",
      "Epoch 484/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.8961 - val_loss: 2.0490\n",
      "Epoch 485/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8926 - val_loss: 2.2013\n",
      "Epoch 486/2500\n",
      "64/64 [==============================] - 0s 329us/step - loss: 1.8871 - val_loss: 2.0577\n",
      "Epoch 487/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8815 - val_loss: 2.1527\n",
      "Epoch 488/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.8759 - val_loss: 2.0821\n",
      "Epoch 489/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.8717 - val_loss: 2.1045\n",
      "Epoch 490/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.8693 - val_loss: 2.1170\n",
      "Epoch 491/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.8685 - val_loss: 2.0727\n",
      "Epoch 492/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.8688 - val_loss: 2.1470\n",
      "Epoch 493/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.8692 - val_loss: 2.0594\n",
      "Epoch 494/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.8691 - val_loss: 2.1601\n",
      "Epoch 495/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.8686 - val_loss: 2.0593\n",
      "Epoch 496/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.8672 - val_loss: 2.1559\n",
      "Epoch 497/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.8651 - val_loss: 2.0664\n",
      "Epoch 498/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.8628 - val_loss: 2.1411\n",
      "Epoch 499/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.8603 - val_loss: 2.0770\n",
      "Epoch 500/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.8581 - val_loss: 2.1225\n",
      "Epoch 501/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.8560 - val_loss: 2.0883\n",
      "Epoch 502/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.8542 - val_loss: 2.1040\n",
      "Epoch 503/2500\n",
      "64/64 [==============================] - 0s 330us/step - loss: 1.8526 - val_loss: 2.0985\n",
      "Epoch 504/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.8513 - val_loss: 2.0879\n",
      "Epoch 505/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.8502 - val_loss: 2.1063\n",
      "Epoch 506/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.8491 - val_loss: 2.0756\n",
      "Epoch 507/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.8482 - val_loss: 2.1105\n",
      "Epoch 508/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8472 - val_loss: 2.0673\n",
      "Epoch 509/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.8462 - val_loss: 2.1106\n",
      "Epoch 510/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.8450 - val_loss: 2.0633\n",
      "Epoch 511/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.8438 - val_loss: 2.1071\n",
      "Epoch 512/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.8425 - val_loss: 2.0628\n",
      "Epoch 513/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.8411 - val_loss: 2.1012\n",
      "Epoch 514/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 1.8397 - val_loss: 2.0647\n",
      "Epoch 515/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.8383 - val_loss: 2.0941\n",
      "Epoch 516/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.8369 - val_loss: 2.0680\n",
      "Epoch 517/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 1.8353 - val_loss: 2.0871\n",
      "Epoch 518/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.8342 - val_loss: 2.0716\n",
      "Epoch 519/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.8329 - val_loss: 2.0805\n",
      "Epoch 520/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 1.8317 - val_loss: 2.0745\n",
      "Epoch 521/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.8302 - val_loss: 2.0747\n",
      "Epoch 522/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.8292 - val_loss: 2.0764\n",
      "Epoch 523/2500\n",
      "64/64 [==============================] - 0s 365us/step - loss: 1.8280 - val_loss: 2.0693\n",
      "Epoch 524/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.8266 - val_loss: 2.0772\n",
      "Epoch 525/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.8257 - val_loss: 2.0642\n",
      "Epoch 526/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.8245 - val_loss: 2.0773\n",
      "Epoch 527/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8234 - val_loss: 2.0593\n",
      "Epoch 528/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.8222 - val_loss: 2.0769\n",
      "Epoch 529/2500\n",
      "64/64 [==============================] - 0s 356us/step - loss: 1.8211 - val_loss: 2.0545\n",
      "Epoch 530/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.8200 - val_loss: 2.0765\n",
      "Epoch 531/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.8189 - val_loss: 2.0498\n",
      "Epoch 532/2500\n",
      "64/64 [==============================] - 0s 389us/step - loss: 1.8177 - val_loss: 2.0763\n",
      "Epoch 533/2500\n",
      "64/64 [==============================] - 0s 551us/step - loss: 1.8166 - val_loss: 2.0451\n",
      "Epoch 534/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.8156 - val_loss: 2.0767\n",
      "Epoch 535/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.8145 - val_loss: 2.0402\n",
      "Epoch 536/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.8134 - val_loss: 2.0780\n",
      "Epoch 537/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.8124 - val_loss: 2.0348\n",
      "Epoch 538/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.8115 - val_loss: 2.0805\n",
      "Epoch 539/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.8105 - val_loss: 2.0285\n",
      "Epoch 540/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.8097 - val_loss: 2.0849\n",
      "Epoch 541/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.8089 - val_loss: 2.0207\n",
      "Epoch 542/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.8083 - val_loss: 2.0918\n",
      "Epoch 543/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.8078 - val_loss: 2.0110\n",
      "Epoch 544/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.8076 - val_loss: 2.1023\n",
      "Epoch 545/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.8076 - val_loss: 1.9990\n",
      "Epoch 546/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.8081 - val_loss: 2.1174\n",
      "Epoch 547/2500\n",
      "64/64 [==============================] - 0s 267us/step - loss: 1.8089 - val_loss: 1.9850\n",
      "Epoch 548/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.8105 - val_loss: 2.1375\n",
      "Epoch 549/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.8122 - val_loss: 1.9700\n",
      "Epoch 550/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.8153 - val_loss: 2.1607\n",
      "Epoch 551/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 1.8177 - val_loss: 1.9560\n",
      "Epoch 552/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.8216 - val_loss: 2.1780\n",
      "Epoch 553/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.8226 - val_loss: 1.9464\n",
      "Epoch 554/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.8242 - val_loss: 2.1733\n",
      "Epoch 555/2500\n",
      "64/64 [==============================] - 0s 375us/step - loss: 1.8210 - val_loss: 1.9445\n",
      "Epoch 556/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.8168 - val_loss: 2.1335\n",
      "Epoch 557/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 1.8080 - val_loss: 1.9597\n",
      "Epoch 558/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.7998 - val_loss: 2.0698\n",
      "Epoch 559/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.7917 - val_loss: 1.9987\n",
      "Epoch 560/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.7865 - val_loss: 2.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.7845 - val_loss: 2.0515\n",
      "Epoch 562/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.7848 - val_loss: 1.9826\n",
      "Epoch 563/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.7871 - val_loss: 2.0975\n",
      "Epoch 564/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.7895 - val_loss: 1.9691\n",
      "Epoch 565/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.7920 - val_loss: 2.1259\n",
      "Epoch 566/2500\n",
      "64/64 [==============================] - 0s 436us/step - loss: 1.7932 - val_loss: 1.9628\n",
      "Epoch 567/2500\n",
      "64/64 [==============================] - 0s 293us/step - loss: 1.7942 - val_loss: 2.1357\n",
      "Epoch 568/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.7938 - val_loss: 1.9588\n",
      "Epoch 569/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.7932 - val_loss: 2.1266\n",
      "Epoch 570/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 1.7904 - val_loss: 1.9583\n",
      "Epoch 571/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.7874 - val_loss: 2.0975\n",
      "Epoch 572/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7827 - val_loss: 1.9671\n",
      "Epoch 573/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.7780 - val_loss: 2.0528\n",
      "Epoch 574/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.7734 - val_loss: 1.9906\n",
      "Epoch 575/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7699 - val_loss: 2.0087\n",
      "Epoch 576/2500\n",
      "64/64 [==============================] - 0s 400us/step - loss: 1.7680 - val_loss: 2.0230\n",
      "Epoch 577/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.7675 - val_loss: 1.9798\n",
      "Epoch 578/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 1.7676 - val_loss: 2.0495\n",
      "Epoch 579/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.7682 - val_loss: 1.9689\n",
      "Epoch 580/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.7681 - val_loss: 2.0590\n",
      "Epoch 581/2500\n",
      "64/64 [==============================] - 0s 356us/step - loss: 1.7672 - val_loss: 1.9711\n",
      "Epoch 582/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.7658 - val_loss: 2.0520\n",
      "Epoch 583/2500\n",
      "64/64 [==============================] - 0s 375us/step - loss: 1.7638 - val_loss: 1.9812\n",
      "Epoch 584/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.7618 - val_loss: 2.0356\n",
      "Epoch 585/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.7597 - val_loss: 1.9949\n",
      "Epoch 586/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.7580 - val_loss: 2.0166\n",
      "Epoch 587/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.7565 - val_loss: 2.0086\n",
      "Epoch 588/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.7553 - val_loss: 1.9995\n",
      "Epoch 589/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.7542 - val_loss: 2.0192\n",
      "Epoch 590/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7537 - val_loss: 1.9865\n",
      "Epoch 591/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.7530 - val_loss: 2.0245\n",
      "Epoch 592/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.7522 - val_loss: 1.9785\n",
      "Epoch 593/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.7514 - val_loss: 2.0234\n",
      "Epoch 594/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.7504 - val_loss: 1.9759\n",
      "Epoch 595/2500\n",
      "64/64 [==============================] - 0s 372us/step - loss: 1.7493 - val_loss: 2.0169\n",
      "Epoch 596/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.7481 - val_loss: 1.9780\n",
      "Epoch 597/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.7468 - val_loss: 2.0070\n",
      "Epoch 598/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.7455 - val_loss: 1.9836\n",
      "Epoch 599/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.7443 - val_loss: 1.9964\n",
      "Epoch 600/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.7429 - val_loss: 1.9906\n",
      "Epoch 601/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.7421 - val_loss: 1.9875\n",
      "Epoch 602/2500\n",
      "64/64 [==============================] - 0s 321us/step - loss: 1.7411 - val_loss: 1.9969\n",
      "Epoch 603/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7402 - val_loss: 1.9811\n",
      "Epoch 604/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.7393 - val_loss: 2.0010\n",
      "Epoch 605/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.7384 - val_loss: 1.9771\n",
      "Epoch 606/2500\n",
      "64/64 [==============================] - 0s 293us/step - loss: 1.7374 - val_loss: 2.0021\n",
      "Epoch 607/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.7365 - val_loss: 1.9747\n",
      "Epoch 608/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 1.7355 - val_loss: 2.0004\n",
      "Epoch 609/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.7345 - val_loss: 1.9736\n",
      "Epoch 610/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7335 - val_loss: 1.9967\n",
      "Epoch 611/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.7324 - val_loss: 1.9733\n",
      "Epoch 612/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7314 - val_loss: 1.9916\n",
      "Epoch 613/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.7304 - val_loss: 1.9735\n",
      "Epoch 614/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.7293 - val_loss: 1.9860\n",
      "Epoch 615/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.7283 - val_loss: 1.9743\n",
      "Epoch 616/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.7273 - val_loss: 1.9807\n",
      "Epoch 617/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.7263 - val_loss: 1.9752\n",
      "Epoch 618/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.7253 - val_loss: 1.9759\n",
      "Epoch 619/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.7243 - val_loss: 1.9760\n",
      "Epoch 620/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.7234 - val_loss: 1.9720\n",
      "Epoch 621/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.7224 - val_loss: 1.9766\n",
      "Epoch 622/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.7215 - val_loss: 1.9689\n",
      "Epoch 623/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.7203 - val_loss: 1.9766\n",
      "Epoch 624/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.7196 - val_loss: 1.9664\n",
      "Epoch 625/2500\n",
      "64/64 [==============================] - 0s 311us/step - loss: 1.7186 - val_loss: 1.9761\n",
      "Epoch 626/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.7177 - val_loss: 1.9643\n",
      "Epoch 627/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.7167 - val_loss: 1.9750\n",
      "Epoch 628/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.7158 - val_loss: 1.9624\n",
      "Epoch 629/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.7148 - val_loss: 1.9735\n",
      "Epoch 630/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7139 - val_loss: 1.9605\n",
      "Epoch 631/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.7129 - val_loss: 1.9717\n",
      "Epoch 632/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.7120 - val_loss: 1.9586\n",
      "Epoch 633/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.7110 - val_loss: 1.9697\n",
      "Epoch 634/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7099 - val_loss: 1.9567\n",
      "Epoch 635/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.7092 - val_loss: 1.9676\n",
      "Epoch 636/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7082 - val_loss: 1.9549\n",
      "Epoch 637/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.7073 - val_loss: 1.9657\n",
      "Epoch 638/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.7063 - val_loss: 1.9532\n",
      "Epoch 639/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.7054 - val_loss: 1.9639\n",
      "Epoch 640/2500\n",
      "64/64 [==============================] - 0s 314us/step - loss: 1.7045 - val_loss: 1.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.7036 - val_loss: 1.9623\n",
      "Epoch 642/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7026 - val_loss: 1.9498\n",
      "Epoch 643/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.7017 - val_loss: 1.9610\n",
      "Epoch 644/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.7008 - val_loss: 1.9480\n",
      "Epoch 645/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.6999 - val_loss: 1.9598\n",
      "Epoch 646/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6990 - val_loss: 1.9460\n",
      "Epoch 647/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.6981 - val_loss: 1.9589\n",
      "Epoch 648/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6971 - val_loss: 1.9436\n",
      "Epoch 649/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.6962 - val_loss: 1.9582\n",
      "Epoch 650/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6954 - val_loss: 1.9409\n",
      "Epoch 651/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.6945 - val_loss: 1.9579\n",
      "Epoch 652/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6936 - val_loss: 1.9378\n",
      "Epoch 653/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.6927 - val_loss: 1.9579\n",
      "Epoch 654/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6918 - val_loss: 1.9342\n",
      "Epoch 655/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.6910 - val_loss: 1.9585\n",
      "Epoch 656/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6902 - val_loss: 1.9301\n",
      "Epoch 657/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.6894 - val_loss: 1.9600\n",
      "Epoch 658/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.6886 - val_loss: 1.9252\n",
      "Epoch 659/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.6878 - val_loss: 1.9625\n",
      "Epoch 660/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.6871 - val_loss: 1.9194\n",
      "Epoch 661/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.6864 - val_loss: 1.9665\n",
      "Epoch 662/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.6858 - val_loss: 1.9126\n",
      "Epoch 663/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6853 - val_loss: 1.9723\n",
      "Epoch 664/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6849 - val_loss: 1.9043\n",
      "Epoch 665/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.6847 - val_loss: 1.9807\n",
      "Epoch 666/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.6846 - val_loss: 1.8946\n",
      "Epoch 667/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.6848 - val_loss: 1.9920\n",
      "Epoch 668/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6851 - val_loss: 1.8833\n",
      "Epoch 669/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6859 - val_loss: 2.0065\n",
      "Epoch 670/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.6868 - val_loss: 1.8713\n",
      "Epoch 671/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.6883 - val_loss: 2.0227\n",
      "Epoch 672/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.6896 - val_loss: 1.8597\n",
      "Epoch 673/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.6917 - val_loss: 2.0372\n",
      "Epoch 674/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.6927 - val_loss: 1.8501\n",
      "Epoch 675/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6944 - val_loss: 2.0418\n",
      "Epoch 676/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6936 - val_loss: 1.8459\n",
      "Epoch 677/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6924 - val_loss: 2.0256\n",
      "Epoch 678/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.6885 - val_loss: 1.8518\n",
      "Epoch 679/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.6839 - val_loss: 1.9877\n",
      "Epoch 680/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.6780 - val_loss: 1.8724\n",
      "Epoch 681/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.6728 - val_loss: 1.9431\n",
      "Epoch 682/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.6687 - val_loss: 1.9063\n",
      "Epoch 683/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.6662 - val_loss: 1.9080\n",
      "Epoch 684/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.6654 - val_loss: 1.9443\n",
      "Epoch 685/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.6656 - val_loss: 1.8872\n",
      "Epoch 686/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6666 - val_loss: 1.9759\n",
      "Epoch 687/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6677 - val_loss: 1.8757\n",
      "Epoch 688/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6690 - val_loss: 1.9967\n",
      "Epoch 689/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.6698 - val_loss: 1.8677\n",
      "Epoch 690/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 1.6703 - val_loss: 2.0049\n",
      "Epoch 691/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.6704 - val_loss: 1.8615\n",
      "Epoch 692/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.6700 - val_loss: 1.9982\n",
      "Epoch 693/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.6683 - val_loss: 1.8599\n",
      "Epoch 694/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 1.6662 - val_loss: 1.9748\n",
      "Epoch 695/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.6630 - val_loss: 1.8677\n",
      "Epoch 696/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 1.6598 - val_loss: 1.9398\n",
      "Epoch 697/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.6565 - val_loss: 1.8878\n",
      "Epoch 698/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6541 - val_loss: 1.9055\n",
      "Epoch 699/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6526 - val_loss: 1.9149\n",
      "Epoch 700/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.6520 - val_loss: 1.8829\n",
      "Epoch 701/2500\n",
      "64/64 [==============================] - 0s 43us/step - loss: 1.6521 - val_loss: 1.9382\n",
      "Epoch 702/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6522 - val_loss: 1.8736\n",
      "Epoch 703/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6522 - val_loss: 1.9496\n",
      "Epoch 704/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.6517 - val_loss: 1.8741\n",
      "Epoch 705/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.6509 - val_loss: 1.9481\n",
      "Epoch 706/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.6497 - val_loss: 1.8799\n",
      "Epoch 707/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6483 - val_loss: 1.9374\n",
      "Epoch 708/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.6468 - val_loss: 1.8883\n",
      "Epoch 709/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.6453 - val_loss: 1.9221\n",
      "Epoch 710/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.6440 - val_loss: 1.8976\n",
      "Epoch 711/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.6429 - val_loss: 1.9061\n",
      "Epoch 712/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.6419 - val_loss: 1.9063\n",
      "Epoch 713/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.6411 - val_loss: 1.8927\n",
      "Epoch 714/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.6405 - val_loss: 1.9126\n",
      "Epoch 715/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.6399 - val_loss: 1.8839\n",
      "Epoch 716/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 1.6392 - val_loss: 1.9148\n",
      "Epoch 717/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.6386 - val_loss: 1.8803\n",
      "Epoch 718/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 1.6378 - val_loss: 1.9124\n",
      "Epoch 719/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.6369 - val_loss: 1.8814\n",
      "Epoch 720/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.6360 - val_loss: 1.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 721/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.6351 - val_loss: 1.8859\n",
      "Epoch 722/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.6341 - val_loss: 1.8994\n",
      "Epoch 723/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.6332 - val_loss: 1.8919\n",
      "Epoch 724/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 1.6324 - val_loss: 1.8926\n",
      "Epoch 725/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.6316 - val_loss: 1.8973\n",
      "Epoch 726/2500\n",
      "64/64 [==============================] - 0s 296us/step - loss: 1.6309 - val_loss: 1.8873\n",
      "Epoch 727/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.6301 - val_loss: 1.9006\n",
      "Epoch 728/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.6294 - val_loss: 1.8835\n",
      "Epoch 729/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.6287 - val_loss: 1.9011\n",
      "Epoch 730/2500\n",
      "64/64 [==============================] - 0s 411us/step - loss: 1.6279 - val_loss: 1.8813\n",
      "Epoch 731/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.6272 - val_loss: 1.8992\n",
      "Epoch 732/2500\n",
      "64/64 [==============================] - 0s 395us/step - loss: 1.6264 - val_loss: 1.8805\n",
      "Epoch 733/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.6256 - val_loss: 1.8953\n",
      "Epoch 734/2500\n",
      "64/64 [==============================] - 0s 858us/step - loss: 1.6248 - val_loss: 1.8809\n",
      "Epoch 735/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6239 - val_loss: 1.8905\n",
      "Epoch 736/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.6231 - val_loss: 1.8820\n",
      "Epoch 737/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.6224 - val_loss: 1.8857\n",
      "Epoch 738/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.6216 - val_loss: 1.8835\n",
      "Epoch 739/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6208 - val_loss: 1.8815\n",
      "Epoch 740/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.6200 - val_loss: 1.8847\n",
      "Epoch 741/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.6193 - val_loss: 1.8784\n",
      "Epoch 742/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6185 - val_loss: 1.8853\n",
      "Epoch 743/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.6178 - val_loss: 1.8764\n",
      "Epoch 744/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.6171 - val_loss: 1.8850\n",
      "Epoch 745/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.6163 - val_loss: 1.8753\n",
      "Epoch 746/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.6155 - val_loss: 1.8838\n",
      "Epoch 747/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.6148 - val_loss: 1.8747\n",
      "Epoch 748/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.6140 - val_loss: 1.8818\n",
      "Epoch 749/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6133 - val_loss: 1.8745\n",
      "Epoch 750/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 1.6125 - val_loss: 1.8793\n",
      "Epoch 751/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.6118 - val_loss: 1.8743\n",
      "Epoch 752/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6110 - val_loss: 1.8765\n",
      "Epoch 753/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.6103 - val_loss: 1.8741\n",
      "Epoch 754/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.6095 - val_loss: 1.8738\n",
      "Epoch 755/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.6088 - val_loss: 1.8737\n",
      "Epoch 756/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6080 - val_loss: 1.8715\n",
      "Epoch 757/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6073 - val_loss: 1.8731\n",
      "Epoch 758/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.6066 - val_loss: 1.8695\n",
      "Epoch 759/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.6058 - val_loss: 1.8723\n",
      "Epoch 760/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.6051 - val_loss: 1.8679\n",
      "Epoch 761/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.6044 - val_loss: 1.8713\n",
      "Epoch 762/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.6036 - val_loss: 1.8667\n",
      "Epoch 763/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.6029 - val_loss: 1.8700\n",
      "Epoch 764/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.6022 - val_loss: 1.8657\n",
      "Epoch 765/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.6014 - val_loss: 1.8686\n",
      "Epoch 766/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.6007 - val_loss: 1.8649\n",
      "Epoch 767/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 1.6000 - val_loss: 1.8671\n",
      "Epoch 768/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5993 - val_loss: 1.8642\n",
      "Epoch 769/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5985 - val_loss: 1.8654\n",
      "Epoch 770/2500\n",
      "64/64 [==============================] - 0s 428us/step - loss: 1.5978 - val_loss: 1.8633\n",
      "Epoch 771/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5971 - val_loss: 1.8638\n",
      "Epoch 772/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.5964 - val_loss: 1.8625\n",
      "Epoch 773/2500\n",
      "64/64 [==============================] - 0s 403us/step - loss: 1.5957 - val_loss: 1.8621\n",
      "Epoch 774/2500\n",
      "64/64 [==============================] - 0s 440us/step - loss: 1.5949 - val_loss: 1.8615\n",
      "Epoch 775/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.5942 - val_loss: 1.8605\n",
      "Epoch 776/2500\n",
      "64/64 [==============================] - 0s 643us/step - loss: 1.5935 - val_loss: 1.8605\n",
      "Epoch 777/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5928 - val_loss: 1.8590\n",
      "Epoch 778/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.5921 - val_loss: 1.8595\n",
      "Epoch 779/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.5914 - val_loss: 1.8576\n",
      "Epoch 780/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5907 - val_loss: 1.8584\n",
      "Epoch 781/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.5900 - val_loss: 1.8564\n",
      "Epoch 782/2500\n",
      "64/64 [==============================] - 0s 347us/step - loss: 1.5892 - val_loss: 1.8573\n",
      "Epoch 783/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5885 - val_loss: 1.8552\n",
      "Epoch 784/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.5878 - val_loss: 1.8561\n",
      "Epoch 785/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 1.5871 - val_loss: 1.8541\n",
      "Epoch 786/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.5864 - val_loss: 1.8549\n",
      "Epoch 787/2500\n",
      "64/64 [==============================] - 0s 348us/step - loss: 1.5857 - val_loss: 1.8530\n",
      "Epoch 788/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.5850 - val_loss: 1.8537\n",
      "Epoch 789/2500\n",
      "64/64 [==============================] - 0s 379us/step - loss: 1.5842 - val_loss: 1.8519\n",
      "Epoch 790/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.5836 - val_loss: 1.8524\n",
      "Epoch 791/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.5829 - val_loss: 1.8508\n",
      "Epoch 792/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5822 - val_loss: 1.8511\n",
      "Epoch 793/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.5815 - val_loss: 1.8497\n",
      "Epoch 794/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 1.5809 - val_loss: 1.8499\n",
      "Epoch 795/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.5802 - val_loss: 1.8486\n",
      "Epoch 796/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5795 - val_loss: 1.8486\n",
      "Epoch 797/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.5788 - val_loss: 1.8475\n",
      "Epoch 798/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.5781 - val_loss: 1.8474\n",
      "Epoch 799/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5774 - val_loss: 1.8464\n",
      "Epoch 800/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.5767 - val_loss: 1.8461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.5760 - val_loss: 1.8453\n",
      "Epoch 802/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.5754 - val_loss: 1.8449\n",
      "Epoch 803/2500\n",
      "64/64 [==============================] - 0s 412us/step - loss: 1.5747 - val_loss: 1.8442\n",
      "Epoch 804/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.5740 - val_loss: 1.8438\n",
      "Epoch 805/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5733 - val_loss: 1.8431\n",
      "Epoch 806/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.5726 - val_loss: 1.8426\n",
      "Epoch 807/2500\n",
      "64/64 [==============================] - 0s 388us/step - loss: 1.5718 - val_loss: 1.8420\n",
      "Epoch 808/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5713 - val_loss: 1.8415\n",
      "Epoch 809/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.5706 - val_loss: 1.8410\n",
      "Epoch 810/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.5699 - val_loss: 1.8403\n",
      "Epoch 811/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5693 - val_loss: 1.8398\n",
      "Epoch 812/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5686 - val_loss: 1.8392\n",
      "Epoch 813/2500\n",
      "64/64 [==============================] - 0s 296us/step - loss: 1.5679 - val_loss: 1.8387\n",
      "Epoch 814/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.5673 - val_loss: 1.8380\n",
      "Epoch 815/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.5666 - val_loss: 1.8376\n",
      "Epoch 816/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5659 - val_loss: 1.8369\n",
      "Epoch 817/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.5653 - val_loss: 1.8365\n",
      "Epoch 818/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5646 - val_loss: 1.8358\n",
      "Epoch 819/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.5638 - val_loss: 1.8354\n",
      "Epoch 820/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5633 - val_loss: 1.8347\n",
      "Epoch 821/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.5626 - val_loss: 1.8343\n",
      "Epoch 822/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.5619 - val_loss: 1.8336\n",
      "Epoch 823/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.5613 - val_loss: 1.8333\n",
      "Epoch 824/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.5606 - val_loss: 1.8325\n",
      "Epoch 825/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5600 - val_loss: 1.8322\n",
      "Epoch 826/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.5593 - val_loss: 1.8314\n",
      "Epoch 827/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 1.5587 - val_loss: 1.8311\n",
      "Epoch 828/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5580 - val_loss: 1.8303\n",
      "Epoch 829/2500\n",
      "64/64 [==============================] - 0s 433us/step - loss: 1.5573 - val_loss: 1.8301\n",
      "Epoch 830/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 1.5567 - val_loss: 1.8292\n",
      "Epoch 831/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.5560 - val_loss: 1.8291\n",
      "Epoch 832/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 1.5554 - val_loss: 1.8281\n",
      "Epoch 833/2500\n",
      "64/64 [==============================] - 0s 429us/step - loss: 1.5548 - val_loss: 1.8280\n",
      "Epoch 834/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.5541 - val_loss: 1.8270\n",
      "Epoch 835/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.5535 - val_loss: 1.8270\n",
      "Epoch 836/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.5528 - val_loss: 1.8259\n",
      "Epoch 837/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5522 - val_loss: 1.8260\n",
      "Epoch 838/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.5515 - val_loss: 1.8248\n",
      "Epoch 839/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5509 - val_loss: 1.8250\n",
      "Epoch 840/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5502 - val_loss: 1.8237\n",
      "Epoch 841/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5496 - val_loss: 1.8240\n",
      "Epoch 842/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 1.5490 - val_loss: 1.8226\n",
      "Epoch 843/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.5483 - val_loss: 1.8230\n",
      "Epoch 844/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.5477 - val_loss: 1.8215\n",
      "Epoch 845/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5471 - val_loss: 1.8221\n",
      "Epoch 846/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.5464 - val_loss: 1.8203\n",
      "Epoch 847/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.5458 - val_loss: 1.8212\n",
      "Epoch 848/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.5452 - val_loss: 1.8192\n",
      "Epoch 849/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.5445 - val_loss: 1.8203\n",
      "Epoch 850/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5439 - val_loss: 1.8180\n",
      "Epoch 851/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.5433 - val_loss: 1.8194\n",
      "Epoch 852/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.5426 - val_loss: 1.8168\n",
      "Epoch 853/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.5420 - val_loss: 1.8186\n",
      "Epoch 854/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.5414 - val_loss: 1.8155\n",
      "Epoch 855/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.5408 - val_loss: 1.8179\n",
      "Epoch 856/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.5401 - val_loss: 1.8142\n",
      "Epoch 857/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.5395 - val_loss: 1.8172\n",
      "Epoch 858/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.5389 - val_loss: 1.8128\n",
      "Epoch 859/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.5383 - val_loss: 1.8167\n",
      "Epoch 860/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 1.5377 - val_loss: 1.8113\n",
      "Epoch 861/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5371 - val_loss: 1.8162\n",
      "Epoch 862/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5364 - val_loss: 1.8097\n",
      "Epoch 863/2500\n",
      "64/64 [==============================] - 0s 422us/step - loss: 1.5358 - val_loss: 1.8160\n",
      "Epoch 864/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5352 - val_loss: 1.8079\n",
      "Epoch 865/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 1.5346 - val_loss: 1.8159\n",
      "Epoch 866/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5339 - val_loss: 1.8059\n",
      "Epoch 867/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5334 - val_loss: 1.8161\n",
      "Epoch 868/2500\n",
      "64/64 [==============================] - 0s 369us/step - loss: 1.5328 - val_loss: 1.8036\n",
      "Epoch 869/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.5322 - val_loss: 1.8167\n",
      "Epoch 870/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.5316 - val_loss: 1.8009\n",
      "Epoch 871/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.5311 - val_loss: 1.8178\n",
      "Epoch 872/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.5305 - val_loss: 1.7978\n",
      "Epoch 873/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.5299 - val_loss: 1.8195\n",
      "Epoch 874/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5294 - val_loss: 1.7940\n",
      "Epoch 875/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.5289 - val_loss: 1.8221\n",
      "Epoch 876/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 1.5284 - val_loss: 1.7894\n",
      "Epoch 877/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5280 - val_loss: 1.8258\n",
      "Epoch 878/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.5275 - val_loss: 1.7838\n",
      "Epoch 879/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5272 - val_loss: 1.8309\n",
      "Epoch 880/2500\n",
      "64/64 [==============================] - 0s 340us/step - loss: 1.5269 - val_loss: 1.7771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 881/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5267 - val_loss: 1.8379\n",
      "Epoch 882/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.5266 - val_loss: 1.7692\n",
      "Epoch 883/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.5267 - val_loss: 1.8470\n",
      "Epoch 884/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.5269 - val_loss: 1.7601\n",
      "Epoch 885/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5274 - val_loss: 1.8582\n",
      "Epoch 886/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.5279 - val_loss: 1.7501\n",
      "Epoch 887/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5289 - val_loss: 1.8711\n",
      "Epoch 888/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.5297 - val_loss: 1.7402\n",
      "Epoch 889/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.5310 - val_loss: 1.8831\n",
      "Epoch 890/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.5318 - val_loss: 1.7319\n",
      "Epoch 891/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.5329 - val_loss: 1.8882\n",
      "Epoch 892/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.5327 - val_loss: 1.7282\n",
      "Epoch 893/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.5323 - val_loss: 1.8800\n",
      "Epoch 894/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.5300 - val_loss: 1.7318\n",
      "Epoch 895/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5277 - val_loss: 1.8567\n",
      "Epoch 896/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.5241 - val_loss: 1.7457\n",
      "Epoch 897/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 1.5207 - val_loss: 1.8250\n",
      "Epoch 898/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.5175 - val_loss: 1.7698\n",
      "Epoch 899/2500\n",
      "64/64 [==============================] - 0s 526us/step - loss: 1.5152 - val_loss: 1.7961\n",
      "Epoch 900/2500\n",
      "64/64 [==============================] - 0s 961us/step - loss: 1.5137 - val_loss: 1.7988\n",
      "Epoch 901/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.5132 - val_loss: 1.7762\n",
      "Epoch 902/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 1.5132 - val_loss: 1.8251\n",
      "Epoch 903/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.5136 - val_loss: 1.7645\n",
      "Epoch 904/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 1.5142 - val_loss: 1.8434\n",
      "Epoch 905/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.5146 - val_loss: 1.7574\n",
      "Epoch 906/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.5150 - val_loss: 1.8509\n",
      "Epoch 907/2500\n",
      "64/64 [==============================] - 0s 332us/step - loss: 1.5148 - val_loss: 1.7530\n",
      "Epoch 908/2500\n",
      "64/64 [==============================] - 0s 423us/step - loss: 1.5145 - val_loss: 1.8465\n",
      "Epoch 909/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.5135 - val_loss: 1.7522\n",
      "Epoch 910/2500\n",
      "64/64 [==============================] - 0s 380us/step - loss: 1.5123 - val_loss: 1.8310\n",
      "Epoch 911/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.5107 - val_loss: 1.7579\n",
      "Epoch 912/2500\n",
      "64/64 [==============================] - 0s 393us/step - loss: 1.5090 - val_loss: 1.8087\n",
      "Epoch 913/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.5074 - val_loss: 1.7708\n",
      "Epoch 914/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.5059 - val_loss: 1.7868\n",
      "Epoch 915/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.5051 - val_loss: 1.7881\n",
      "Epoch 916/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5046 - val_loss: 1.7715\n",
      "Epoch 917/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.5043 - val_loss: 1.8038\n",
      "Epoch 918/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.5041 - val_loss: 1.7644\n",
      "Epoch 919/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5039 - val_loss: 1.8127\n",
      "Epoch 920/2500\n",
      "64/64 [==============================] - 0s 317us/step - loss: 1.5036 - val_loss: 1.7639\n",
      "Epoch 921/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.5031 - val_loss: 1.8135\n",
      "Epoch 922/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.5024 - val_loss: 1.7673\n",
      "Epoch 923/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 1.5017 - val_loss: 1.8074\n",
      "Epoch 924/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.5008 - val_loss: 1.7729\n",
      "Epoch 925/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.5000 - val_loss: 1.7973\n",
      "Epoch 926/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.4992 - val_loss: 1.7793\n",
      "Epoch 927/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.4984 - val_loss: 1.7862\n",
      "Epoch 928/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4978 - val_loss: 1.7854\n",
      "Epoch 929/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4973 - val_loss: 1.7767\n",
      "Epoch 930/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 1.4968 - val_loss: 1.7898\n",
      "Epoch 931/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4963 - val_loss: 1.7704\n",
      "Epoch 932/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4958 - val_loss: 1.7915\n",
      "Epoch 933/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.4954 - val_loss: 1.7681\n",
      "Epoch 934/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4948 - val_loss: 1.7902\n",
      "Epoch 935/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 1.4942 - val_loss: 1.7692\n",
      "Epoch 936/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4936 - val_loss: 1.7866\n",
      "Epoch 937/2500\n",
      "64/64 [==============================] - 0s 409us/step - loss: 1.4930 - val_loss: 1.7728\n",
      "Epoch 938/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.4924 - val_loss: 1.7819\n",
      "Epoch 939/2500\n",
      "64/64 [==============================] - 0s 360us/step - loss: 1.4918 - val_loss: 1.7772\n",
      "Epoch 940/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.4913 - val_loss: 1.7774\n",
      "Epoch 941/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.4907 - val_loss: 1.7811\n",
      "Epoch 942/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4902 - val_loss: 1.7738\n",
      "Epoch 943/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4897 - val_loss: 1.7832\n",
      "Epoch 944/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 1.4892 - val_loss: 1.7712\n",
      "Epoch 945/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4887 - val_loss: 1.7832\n",
      "Epoch 946/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4881 - val_loss: 1.7699\n",
      "Epoch 947/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.4875 - val_loss: 1.7813\n",
      "Epoch 948/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.4871 - val_loss: 1.7699\n",
      "Epoch 949/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4865 - val_loss: 1.7781\n",
      "Epoch 950/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.4860 - val_loss: 1.7707\n",
      "Epoch 951/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.4854 - val_loss: 1.7746\n",
      "Epoch 952/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4849 - val_loss: 1.7720\n",
      "Epoch 953/2500\n",
      "64/64 [==============================] - 0s 422us/step - loss: 1.4843 - val_loss: 1.7714\n",
      "Epoch 954/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4838 - val_loss: 1.7733\n",
      "Epoch 955/2500\n",
      "64/64 [==============================] - 0s 288us/step - loss: 1.4833 - val_loss: 1.7691\n",
      "Epoch 956/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4828 - val_loss: 1.7740\n",
      "Epoch 957/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4822 - val_loss: 1.7677\n",
      "Epoch 958/2500\n",
      "64/64 [==============================] - 0s 369us/step - loss: 1.4817 - val_loss: 1.7739\n",
      "Epoch 959/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.4812 - val_loss: 1.7672\n",
      "Epoch 960/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.4807 - val_loss: 1.7730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 961/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.4802 - val_loss: 1.7673\n",
      "Epoch 962/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.4796 - val_loss: 1.7714\n",
      "Epoch 963/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4791 - val_loss: 1.7676\n",
      "Epoch 964/2500\n",
      "64/64 [==============================] - 0s 299us/step - loss: 1.4784 - val_loss: 1.7695\n",
      "Epoch 965/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4781 - val_loss: 1.7679\n",
      "Epoch 966/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4775 - val_loss: 1.7674\n",
      "Epoch 967/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.4770 - val_loss: 1.7679\n",
      "Epoch 968/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4765 - val_loss: 1.7656\n",
      "Epoch 969/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4760 - val_loss: 1.7676\n",
      "Epoch 970/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4754 - val_loss: 1.7642\n",
      "Epoch 971/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.4750 - val_loss: 1.7670\n",
      "Epoch 972/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.4745 - val_loss: 1.7633\n",
      "Epoch 973/2500\n",
      "64/64 [==============================] - 0s 466us/step - loss: 1.4739 - val_loss: 1.7661\n",
      "Epoch 974/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.4734 - val_loss: 1.7629\n",
      "Epoch 975/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.4729 - val_loss: 1.7650\n",
      "Epoch 976/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4724 - val_loss: 1.7627\n",
      "Epoch 977/2500\n",
      "64/64 [==============================] - 0s 504us/step - loss: 1.4719 - val_loss: 1.7637\n",
      "Epoch 978/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.4714 - val_loss: 1.7626\n",
      "Epoch 979/2500\n",
      "64/64 [==============================] - 0s 482us/step - loss: 1.4709 - val_loss: 1.7625\n",
      "Epoch 980/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.4704 - val_loss: 1.7624\n",
      "Epoch 981/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.4699 - val_loss: 1.7614\n",
      "Epoch 982/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4694 - val_loss: 1.7621\n",
      "Epoch 983/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.4689 - val_loss: 1.7603\n",
      "Epoch 984/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.4684 - val_loss: 1.7615\n",
      "Epoch 985/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4679 - val_loss: 1.7595\n",
      "Epoch 986/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.4674 - val_loss: 1.7607\n",
      "Epoch 987/2500\n",
      "64/64 [==============================] - 0s 297us/step - loss: 1.4669 - val_loss: 1.7587\n",
      "Epoch 988/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4664 - val_loss: 1.7597\n",
      "Epoch 989/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.4659 - val_loss: 1.7581\n",
      "Epoch 990/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.4654 - val_loss: 1.7586\n",
      "Epoch 991/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4649 - val_loss: 1.7576\n",
      "Epoch 992/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.4644 - val_loss: 1.7576\n",
      "Epoch 993/2500\n",
      "64/64 [==============================] - 0s 426us/step - loss: 1.4639 - val_loss: 1.7571\n",
      "Epoch 994/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 1.4632 - val_loss: 1.7566\n",
      "Epoch 995/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.4629 - val_loss: 1.7566\n",
      "Epoch 996/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4624 - val_loss: 1.7558\n",
      "Epoch 997/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.4619 - val_loss: 1.7561\n",
      "Epoch 998/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 1.4614 - val_loss: 1.7550\n",
      "Epoch 999/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4609 - val_loss: 1.7554\n",
      "Epoch 1000/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.4604 - val_loss: 1.7543\n",
      "Epoch 1001/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 1.4599 - val_loss: 1.7547\n",
      "Epoch 1002/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4594 - val_loss: 1.7536\n",
      "Epoch 1003/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.4589 - val_loss: 1.7538\n",
      "Epoch 1004/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.4585 - val_loss: 1.7530\n",
      "Epoch 1005/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.4580 - val_loss: 1.7530\n",
      "Epoch 1006/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.4575 - val_loss: 1.7524\n",
      "Epoch 1007/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.4569 - val_loss: 1.7521\n",
      "Epoch 1008/2500\n",
      "64/64 [==============================] - 0s 494us/step - loss: 1.4565 - val_loss: 1.7517\n",
      "Epoch 1009/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.4560 - val_loss: 1.7513\n",
      "Epoch 1010/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.4555 - val_loss: 1.7511\n",
      "Epoch 1011/2500\n",
      "64/64 [==============================] - 0s 463us/step - loss: 1.4551 - val_loss: 1.7505\n",
      "Epoch 1012/2500\n",
      "64/64 [==============================] - 0s 507us/step - loss: 1.4546 - val_loss: 1.7504\n",
      "Epoch 1013/2500\n",
      "64/64 [==============================] - 0s 375us/step - loss: 1.4541 - val_loss: 1.7497\n",
      "Epoch 1014/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4536 - val_loss: 1.7497\n",
      "Epoch 1015/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4530 - val_loss: 1.7490\n",
      "Epoch 1016/2500\n",
      "64/64 [==============================] - 0s 326us/step - loss: 1.4527 - val_loss: 1.7490\n",
      "Epoch 1017/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4522 - val_loss: 1.7484\n",
      "Epoch 1018/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.4517 - val_loss: 1.7483\n",
      "Epoch 1019/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.4512 - val_loss: 1.7477\n",
      "Epoch 1020/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4507 - val_loss: 1.7475\n",
      "Epoch 1021/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4503 - val_loss: 1.7471\n",
      "Epoch 1022/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.4498 - val_loss: 1.7468\n",
      "Epoch 1023/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 1.4493 - val_loss: 1.7464\n",
      "Epoch 1024/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.4488 - val_loss: 1.7460\n",
      "Epoch 1025/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.4484 - val_loss: 1.7458\n",
      "Epoch 1026/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4478 - val_loss: 1.7453\n",
      "Epoch 1027/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.4474 - val_loss: 1.7451\n",
      "Epoch 1028/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4470 - val_loss: 1.7446\n",
      "Epoch 1029/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4465 - val_loss: 1.7444\n",
      "Epoch 1030/2500\n",
      "64/64 [==============================] - 0s 327us/step - loss: 1.4460 - val_loss: 1.7439\n",
      "Epoch 1031/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4455 - val_loss: 1.7437\n",
      "Epoch 1032/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4450 - val_loss: 1.7432\n",
      "Epoch 1033/2500\n",
      "64/64 [==============================] - 0s 829us/step - loss: 1.4446 - val_loss: 1.7430\n",
      "Epoch 1034/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.4441 - val_loss: 1.7425\n",
      "Epoch 1035/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.4437 - val_loss: 1.7423\n",
      "Epoch 1036/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.4432 - val_loss: 1.7419\n",
      "Epoch 1037/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4427 - val_loss: 1.7416\n",
      "Epoch 1038/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.4423 - val_loss: 1.7412\n",
      "Epoch 1039/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.4418 - val_loss: 1.7409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.4414 - val_loss: 1.7406\n",
      "Epoch 1041/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4409 - val_loss: 1.7402\n",
      "Epoch 1042/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 1.4404 - val_loss: 1.7399\n",
      "Epoch 1043/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.4400 - val_loss: 1.7395\n",
      "Epoch 1044/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4395 - val_loss: 1.7392\n",
      "Epoch 1045/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.4389 - val_loss: 1.7388\n",
      "Epoch 1046/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.4386 - val_loss: 1.7386\n",
      "Epoch 1047/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4381 - val_loss: 1.7382\n",
      "Epoch 1048/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.4377 - val_loss: 1.7379\n",
      "Epoch 1049/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 1.4372 - val_loss: 1.7375\n",
      "Epoch 1050/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.4366 - val_loss: 1.7372\n",
      "Epoch 1051/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.4363 - val_loss: 1.7368\n",
      "Epoch 1052/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.4359 - val_loss: 1.7365\n",
      "Epoch 1053/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4354 - val_loss: 1.7362\n",
      "Epoch 1054/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4349 - val_loss: 1.7359\n",
      "Epoch 1055/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.4344 - val_loss: 1.7355\n",
      "Epoch 1056/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4340 - val_loss: 1.7352\n",
      "Epoch 1057/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4336 - val_loss: 1.7349\n",
      "Epoch 1058/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.4331 - val_loss: 1.7345\n",
      "Epoch 1059/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.4327 - val_loss: 1.7342\n",
      "Epoch 1060/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4322 - val_loss: 1.7339\n",
      "Epoch 1061/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4318 - val_loss: 1.7336\n",
      "Epoch 1062/2500\n",
      "64/64 [==============================] - 0s 490us/step - loss: 1.4313 - val_loss: 1.7332\n",
      "Epoch 1063/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.4309 - val_loss: 1.7329\n",
      "Epoch 1064/2500\n",
      "64/64 [==============================] - 0s 350us/step - loss: 1.4303 - val_loss: 1.7326\n",
      "Epoch 1065/2500\n",
      "64/64 [==============================] - 0s 519us/step - loss: 1.4300 - val_loss: 1.7323\n",
      "Epoch 1066/2500\n",
      "64/64 [==============================] - 0s 345us/step - loss: 1.4296 - val_loss: 1.7319\n",
      "Epoch 1067/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4291 - val_loss: 1.7316\n",
      "Epoch 1068/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4287 - val_loss: 1.7313\n",
      "Epoch 1069/2500\n",
      "64/64 [==============================] - 0s 267us/step - loss: 1.4282 - val_loss: 1.7310\n",
      "Epoch 1070/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4278 - val_loss: 1.7307\n",
      "Epoch 1071/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4273 - val_loss: 1.7303\n",
      "Epoch 1072/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.4269 - val_loss: 1.7300\n",
      "Epoch 1073/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.4265 - val_loss: 1.7297\n",
      "Epoch 1074/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.4260 - val_loss: 1.7294\n",
      "Epoch 1075/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4256 - val_loss: 1.7290\n",
      "Epoch 1076/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.4251 - val_loss: 1.7288\n",
      "Epoch 1077/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.4247 - val_loss: 1.7284\n",
      "Epoch 1078/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4243 - val_loss: 1.7281\n",
      "Epoch 1079/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4238 - val_loss: 1.7278\n",
      "Epoch 1080/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 1.4234 - val_loss: 1.7275\n",
      "Epoch 1081/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4229 - val_loss: 1.7272\n",
      "Epoch 1082/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.4225 - val_loss: 1.7268\n",
      "Epoch 1083/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4221 - val_loss: 1.7265\n",
      "Epoch 1084/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 1.4216 - val_loss: 1.7262\n",
      "Epoch 1085/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.4212 - val_loss: 1.7259\n",
      "Epoch 1086/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.4208 - val_loss: 1.7256\n",
      "Epoch 1087/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.4203 - val_loss: 1.7253\n",
      "Epoch 1088/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.4199 - val_loss: 1.7250\n",
      "Epoch 1089/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 1.4195 - val_loss: 1.7247\n",
      "Epoch 1090/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4191 - val_loss: 1.7243\n",
      "Epoch 1091/2500\n",
      "64/64 [==============================] - 0s 449us/step - loss: 1.4186 - val_loss: 1.7240\n",
      "Epoch 1092/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4182 - val_loss: 1.7237\n",
      "Epoch 1093/2500\n",
      "64/64 [==============================] - 0s 640us/step - loss: 1.4178 - val_loss: 1.7234\n",
      "Epoch 1094/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.4173 - val_loss: 1.7231\n",
      "Epoch 1095/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4169 - val_loss: 1.7228\n",
      "Epoch 1096/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.4165 - val_loss: 1.7225\n",
      "Epoch 1097/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.4161 - val_loss: 1.7222\n",
      "Epoch 1098/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4156 - val_loss: 1.7219\n",
      "Epoch 1099/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.4151 - val_loss: 1.7216\n",
      "Epoch 1100/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.4147 - val_loss: 1.7213\n",
      "Epoch 1101/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.4144 - val_loss: 1.7210\n",
      "Epoch 1102/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4139 - val_loss: 1.7207\n",
      "Epoch 1103/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.4135 - val_loss: 1.7204\n",
      "Epoch 1104/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.4131 - val_loss: 1.7201\n",
      "Epoch 1105/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.4127 - val_loss: 1.7197\n",
      "Epoch 1106/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.4122 - val_loss: 1.7194\n",
      "Epoch 1107/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4118 - val_loss: 1.7191\n",
      "Epoch 1108/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4114 - val_loss: 1.7188\n",
      "Epoch 1109/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.4110 - val_loss: 1.7185\n",
      "Epoch 1110/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4106 - val_loss: 1.7182\n",
      "Epoch 1111/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4101 - val_loss: 1.7179\n",
      "Epoch 1112/2500\n",
      "64/64 [==============================] - 0s 455us/step - loss: 1.4097 - val_loss: 1.7176\n",
      "Epoch 1113/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.4093 - val_loss: 1.7173\n",
      "Epoch 1114/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 1.4089 - val_loss: 1.7170\n",
      "Epoch 1115/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4084 - val_loss: 1.7167\n",
      "Epoch 1116/2500\n",
      "64/64 [==============================] - 0s 298us/step - loss: 1.4081 - val_loss: 1.7165\n",
      "Epoch 1117/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.4077 - val_loss: 1.7161\n",
      "Epoch 1118/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4072 - val_loss: 1.7159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1119/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 1.4067 - val_loss: 1.7155\n",
      "Epoch 1120/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4064 - val_loss: 1.7153\n",
      "Epoch 1121/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.4060 - val_loss: 1.7150\n",
      "Epoch 1122/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4055 - val_loss: 1.7147\n",
      "Epoch 1123/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 1.4052 - val_loss: 1.7144\n",
      "Epoch 1124/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4048 - val_loss: 1.7141\n",
      "Epoch 1125/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 1.4044 - val_loss: 1.7138\n",
      "Epoch 1126/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.4039 - val_loss: 1.7135\n",
      "Epoch 1127/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.4035 - val_loss: 1.7132\n",
      "Epoch 1128/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4030 - val_loss: 1.7129\n",
      "Epoch 1129/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.4027 - val_loss: 1.7126\n",
      "Epoch 1130/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4023 - val_loss: 1.7123\n",
      "Epoch 1131/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.4019 - val_loss: 1.7120\n",
      "Epoch 1132/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.4015 - val_loss: 1.7117\n",
      "Epoch 1133/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4011 - val_loss: 1.7114\n",
      "Epoch 1134/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4007 - val_loss: 1.7112\n",
      "Epoch 1135/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.4003 - val_loss: 1.7109\n",
      "Epoch 1136/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 1.3999 - val_loss: 1.7106\n",
      "Epoch 1137/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3995 - val_loss: 1.7103\n",
      "Epoch 1138/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.3991 - val_loss: 1.7100\n",
      "Epoch 1139/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.3987 - val_loss: 1.7097\n",
      "Epoch 1140/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3983 - val_loss: 1.7094\n",
      "Epoch 1141/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.3979 - val_loss: 1.7091\n",
      "Epoch 1142/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.3975 - val_loss: 1.7088\n",
      "Epoch 1143/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3971 - val_loss: 1.7086\n",
      "Epoch 1144/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3967 - val_loss: 1.7083\n",
      "Epoch 1145/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3963 - val_loss: 1.7080\n",
      "Epoch 1146/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.3959 - val_loss: 1.7077\n",
      "Epoch 1147/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3955 - val_loss: 1.7074\n",
      "Epoch 1148/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.3951 - val_loss: 1.7071\n",
      "Epoch 1149/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3947 - val_loss: 1.7068\n",
      "Epoch 1150/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3943 - val_loss: 1.7066\n",
      "Epoch 1151/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3939 - val_loss: 1.7063\n",
      "Epoch 1152/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.3934 - val_loss: 1.7060\n",
      "Epoch 1153/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.3931 - val_loss: 1.7057\n",
      "Epoch 1154/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3927 - val_loss: 1.7054\n",
      "Epoch 1155/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3923 - val_loss: 1.7051\n",
      "Epoch 1156/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3919 - val_loss: 1.7049\n",
      "Epoch 1157/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.3915 - val_loss: 1.7046\n",
      "Epoch 1158/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3911 - val_loss: 1.7043\n",
      "Epoch 1159/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3908 - val_loss: 1.7040\n",
      "Epoch 1160/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3904 - val_loss: 1.7038\n",
      "Epoch 1161/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.3900 - val_loss: 1.7035\n",
      "Epoch 1162/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.3895 - val_loss: 1.7032\n",
      "Epoch 1163/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.3892 - val_loss: 1.7029\n",
      "Epoch 1164/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.3888 - val_loss: 1.7026\n",
      "Epoch 1165/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.3884 - val_loss: 1.7023\n",
      "Epoch 1166/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3880 - val_loss: 1.7021\n",
      "Epoch 1167/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.3876 - val_loss: 1.7018\n",
      "Epoch 1168/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3873 - val_loss: 1.7015\n",
      "Epoch 1169/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3869 - val_loss: 1.7012\n",
      "Epoch 1170/2500\n",
      "64/64 [==============================] - 0s 372us/step - loss: 1.3865 - val_loss: 1.7010\n",
      "Epoch 1171/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3861 - val_loss: 1.7007\n",
      "Epoch 1172/2500\n",
      "64/64 [==============================] - 0s 515us/step - loss: 1.3857 - val_loss: 1.7004\n",
      "Epoch 1173/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.3853 - val_loss: 1.7001\n",
      "Epoch 1174/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.3849 - val_loss: 1.6999\n",
      "Epoch 1175/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3846 - val_loss: 1.6996\n",
      "Epoch 1176/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3842 - val_loss: 1.6993\n",
      "Epoch 1177/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3838 - val_loss: 1.6990\n",
      "Epoch 1178/2500\n",
      "64/64 [==============================] - 0s 326us/step - loss: 1.3834 - val_loss: 1.6988\n",
      "Epoch 1179/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3830 - val_loss: 1.6985\n",
      "Epoch 1180/2500\n",
      "64/64 [==============================] - 0s 342us/step - loss: 1.3825 - val_loss: 1.6982\n",
      "Epoch 1181/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.3823 - val_loss: 1.6979\n",
      "Epoch 1182/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.3818 - val_loss: 1.6977\n",
      "Epoch 1183/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3815 - val_loss: 1.6974\n",
      "Epoch 1184/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3811 - val_loss: 1.6971\n",
      "Epoch 1185/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3808 - val_loss: 1.6968\n",
      "Epoch 1186/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 1.3804 - val_loss: 1.6966\n",
      "Epoch 1187/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3799 - val_loss: 1.6963\n",
      "Epoch 1188/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3796 - val_loss: 1.6960\n",
      "Epoch 1189/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 1.3793 - val_loss: 1.6958\n",
      "Epoch 1190/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3789 - val_loss: 1.6955\n",
      "Epoch 1191/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3785 - val_loss: 1.6952\n",
      "Epoch 1192/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.3781 - val_loss: 1.6950\n",
      "Epoch 1193/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3778 - val_loss: 1.6947\n",
      "Epoch 1194/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3774 - val_loss: 1.6944\n",
      "Epoch 1195/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.3769 - val_loss: 1.6941\n",
      "Epoch 1196/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.3766 - val_loss: 1.6939\n",
      "Epoch 1197/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.3763 - val_loss: 1.6936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1198/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.3759 - val_loss: 1.6934\n",
      "Epoch 1199/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3755 - val_loss: 1.6931\n",
      "Epoch 1200/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3752 - val_loss: 1.6928\n",
      "Epoch 1201/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.3748 - val_loss: 1.6925\n",
      "Epoch 1202/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.3744 - val_loss: 1.6923\n",
      "Epoch 1203/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.3740 - val_loss: 1.6920\n",
      "Epoch 1204/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 1.3737 - val_loss: 1.6918\n",
      "Epoch 1205/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3733 - val_loss: 1.6915\n",
      "Epoch 1206/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3729 - val_loss: 1.6912\n",
      "Epoch 1207/2500\n",
      "64/64 [==============================] - 0s 408us/step - loss: 1.3726 - val_loss: 1.6909\n",
      "Epoch 1208/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3722 - val_loss: 1.6907\n",
      "Epoch 1209/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.3718 - val_loss: 1.6904\n",
      "Epoch 1210/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3715 - val_loss: 1.6902\n",
      "Epoch 1211/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3711 - val_loss: 1.6899\n",
      "Epoch 1212/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3707 - val_loss: 1.6896\n",
      "Epoch 1213/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3704 - val_loss: 1.6894\n",
      "Epoch 1214/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.3699 - val_loss: 1.6891\n",
      "Epoch 1215/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.3697 - val_loss: 1.6888\n",
      "Epoch 1216/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3693 - val_loss: 1.6886\n",
      "Epoch 1217/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.3689 - val_loss: 1.6883\n",
      "Epoch 1218/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3686 - val_loss: 1.6880\n",
      "Epoch 1219/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.3682 - val_loss: 1.6878\n",
      "Epoch 1220/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3678 - val_loss: 1.6875\n",
      "Epoch 1221/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3675 - val_loss: 1.6873\n",
      "Epoch 1222/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3671 - val_loss: 1.6870\n",
      "Epoch 1223/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 1.3668 - val_loss: 1.6868\n",
      "Epoch 1224/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3664 - val_loss: 1.6865\n",
      "Epoch 1225/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 1.3661 - val_loss: 1.6862\n",
      "Epoch 1226/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3657 - val_loss: 1.6860\n",
      "Epoch 1227/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3653 - val_loss: 1.6857\n",
      "Epoch 1228/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 1.3650 - val_loss: 1.6854\n",
      "Epoch 1229/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3646 - val_loss: 1.6852\n",
      "Epoch 1230/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3643 - val_loss: 1.6849\n",
      "Epoch 1231/2500\n",
      "64/64 [==============================] - 0s 436us/step - loss: 1.3639 - val_loss: 1.6847\n",
      "Epoch 1232/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.3636 - val_loss: 1.6844\n",
      "Epoch 1233/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3632 - val_loss: 1.6842\n",
      "Epoch 1234/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3628 - val_loss: 1.6839\n",
      "Epoch 1235/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.3625 - val_loss: 1.6836\n",
      "Epoch 1236/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.3621 - val_loss: 1.6834\n",
      "Epoch 1237/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.3618 - val_loss: 1.6831\n",
      "Epoch 1238/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 1.3614 - val_loss: 1.6829\n",
      "Epoch 1239/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.3611 - val_loss: 1.6826\n",
      "Epoch 1240/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.3607 - val_loss: 1.6823\n",
      "Epoch 1241/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3604 - val_loss: 1.6821\n",
      "Epoch 1242/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3600 - val_loss: 1.6818\n",
      "Epoch 1243/2500\n",
      "64/64 [==============================] - 0s 423us/step - loss: 1.3597 - val_loss: 1.6816\n",
      "Epoch 1244/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3593 - val_loss: 1.6813\n",
      "Epoch 1245/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 1.3589 - val_loss: 1.6811\n",
      "Epoch 1246/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3586 - val_loss: 1.6808\n",
      "Epoch 1247/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 1.3583 - val_loss: 1.6806\n",
      "Epoch 1248/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.3579 - val_loss: 1.6803\n",
      "Epoch 1249/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 1.3576 - val_loss: 1.6801\n",
      "Epoch 1250/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3572 - val_loss: 1.6798\n",
      "Epoch 1251/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.3569 - val_loss: 1.6795\n",
      "Epoch 1252/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 1.3564 - val_loss: 1.6793\n",
      "Epoch 1253/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3562 - val_loss: 1.6790\n",
      "Epoch 1254/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 1.3558 - val_loss: 1.6788\n",
      "Epoch 1255/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3555 - val_loss: 1.6785\n",
      "Epoch 1256/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3552 - val_loss: 1.6782\n",
      "Epoch 1257/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3548 - val_loss: 1.6780\n",
      "Epoch 1258/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3545 - val_loss: 1.6777\n",
      "Epoch 1259/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3541 - val_loss: 1.6775\n",
      "Epoch 1260/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3538 - val_loss: 1.6772\n",
      "Epoch 1261/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3534 - val_loss: 1.6770\n",
      "Epoch 1262/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.3531 - val_loss: 1.6767\n",
      "Epoch 1263/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 1.3528 - val_loss: 1.6765\n",
      "Epoch 1264/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3524 - val_loss: 1.6762\n",
      "Epoch 1265/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3521 - val_loss: 1.6760\n",
      "Epoch 1266/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.3517 - val_loss: 1.6757\n",
      "Epoch 1267/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3514 - val_loss: 1.6755\n",
      "Epoch 1268/2500\n",
      "64/64 [==============================] - 0s 320us/step - loss: 1.3510 - val_loss: 1.6752\n",
      "Epoch 1269/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.3507 - val_loss: 1.6750\n",
      "Epoch 1270/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 1.3504 - val_loss: 1.6747\n",
      "Epoch 1271/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.3500 - val_loss: 1.6745\n",
      "Epoch 1272/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3497 - val_loss: 1.6742\n",
      "Epoch 1273/2500\n",
      "64/64 [==============================] - 0s 541us/step - loss: 1.3494 - val_loss: 1.6740\n",
      "Epoch 1274/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3490 - val_loss: 1.6737\n",
      "Epoch 1275/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.3487 - val_loss: 1.6735\n",
      "Epoch 1276/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3483 - val_loss: 1.6732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1277/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3480 - val_loss: 1.6730\n",
      "Epoch 1278/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3477 - val_loss: 1.6727\n",
      "Epoch 1279/2500\n",
      "64/64 [==============================] - 0s 457us/step - loss: 1.3473 - val_loss: 1.6725\n",
      "Epoch 1280/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3470 - val_loss: 1.6722\n",
      "Epoch 1281/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 1.3467 - val_loss: 1.6720\n",
      "Epoch 1282/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3463 - val_loss: 1.6717\n",
      "Epoch 1283/2500\n",
      "64/64 [==============================] - 0s 476us/step - loss: 1.3460 - val_loss: 1.6715\n",
      "Epoch 1284/2500\n",
      "64/64 [==============================] - 0s 381us/step - loss: 1.3457 - val_loss: 1.6712\n",
      "Epoch 1285/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3453 - val_loss: 1.6710\n",
      "Epoch 1286/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3450 - val_loss: 1.6707\n",
      "Epoch 1287/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3447 - val_loss: 1.6706\n",
      "Epoch 1288/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.3443 - val_loss: 1.6702\n",
      "Epoch 1289/2500\n",
      "64/64 [==============================] - 0s 466us/step - loss: 1.3440 - val_loss: 1.6701\n",
      "Epoch 1290/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.3437 - val_loss: 1.6697\n",
      "Epoch 1291/2500\n",
      "64/64 [==============================] - 0s 290us/step - loss: 1.3433 - val_loss: 1.6696\n",
      "Epoch 1292/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3430 - val_loss: 1.6692\n",
      "Epoch 1293/2500\n",
      "64/64 [==============================] - 0s 407us/step - loss: 1.3427 - val_loss: 1.6691\n",
      "Epoch 1294/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3424 - val_loss: 1.6687\n",
      "Epoch 1295/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3420 - val_loss: 1.6686\n",
      "Epoch 1296/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3417 - val_loss: 1.6682\n",
      "Epoch 1297/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.3414 - val_loss: 1.6681\n",
      "Epoch 1298/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3410 - val_loss: 1.6677\n",
      "Epoch 1299/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.3407 - val_loss: 1.6676\n",
      "Epoch 1300/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3404 - val_loss: 1.6672\n",
      "Epoch 1301/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.3401 - val_loss: 1.6672\n",
      "Epoch 1302/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.3397 - val_loss: 1.6667\n",
      "Epoch 1303/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3394 - val_loss: 1.6667\n",
      "Epoch 1304/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.3391 - val_loss: 1.6662\n",
      "Epoch 1305/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.3388 - val_loss: 1.6662\n",
      "Epoch 1306/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3384 - val_loss: 1.6657\n",
      "Epoch 1307/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3381 - val_loss: 1.6657\n",
      "Epoch 1308/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.3378 - val_loss: 1.6652\n",
      "Epoch 1309/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3375 - val_loss: 1.6653\n",
      "Epoch 1310/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.3371 - val_loss: 1.6647\n",
      "Epoch 1311/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.3368 - val_loss: 1.6648\n",
      "Epoch 1312/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.3365 - val_loss: 1.6641\n",
      "Epoch 1313/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.3362 - val_loss: 1.6644\n",
      "Epoch 1314/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.3359 - val_loss: 1.6636\n",
      "Epoch 1315/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.3355 - val_loss: 1.6639\n",
      "Epoch 1316/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3352 - val_loss: 1.6631\n",
      "Epoch 1317/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3349 - val_loss: 1.6635\n",
      "Epoch 1318/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3346 - val_loss: 1.6626\n",
      "Epoch 1319/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3342 - val_loss: 1.6630\n",
      "Epoch 1320/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.3339 - val_loss: 1.6620\n",
      "Epoch 1321/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3336 - val_loss: 1.6626\n",
      "Epoch 1322/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3333 - val_loss: 1.6615\n",
      "Epoch 1323/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3330 - val_loss: 1.6622\n",
      "Epoch 1324/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3327 - val_loss: 1.6609\n",
      "Epoch 1325/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3323 - val_loss: 1.6618\n",
      "Epoch 1326/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.3320 - val_loss: 1.6604\n",
      "Epoch 1327/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 1.3317 - val_loss: 1.6614\n",
      "Epoch 1328/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3314 - val_loss: 1.6598\n",
      "Epoch 1329/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3311 - val_loss: 1.6610\n",
      "Epoch 1330/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 1.3308 - val_loss: 1.6592\n",
      "Epoch 1331/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.3304 - val_loss: 1.6607\n",
      "Epoch 1332/2500\n",
      "64/64 [==============================] - 0s 471us/step - loss: 1.3301 - val_loss: 1.6585\n",
      "Epoch 1333/2500\n",
      "64/64 [==============================] - 0s 406us/step - loss: 1.3298 - val_loss: 1.6603\n",
      "Epoch 1334/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3295 - val_loss: 1.6579\n",
      "Epoch 1335/2500\n",
      "64/64 [==============================] - 0s 277us/step - loss: 1.3292 - val_loss: 1.6600\n",
      "Epoch 1336/2500\n",
      "64/64 [==============================] - 0s 496us/step - loss: 1.3289 - val_loss: 1.6572\n",
      "Epoch 1337/2500\n",
      "64/64 [==============================] - 0s 491us/step - loss: 1.3286 - val_loss: 1.6598\n",
      "Epoch 1338/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3283 - val_loss: 1.6565\n",
      "Epoch 1339/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3279 - val_loss: 1.6596\n",
      "Epoch 1340/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3276 - val_loss: 1.6557\n",
      "Epoch 1341/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.3273 - val_loss: 1.6594\n",
      "Epoch 1342/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3270 - val_loss: 1.6549\n",
      "Epoch 1343/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3267 - val_loss: 1.6593\n",
      "Epoch 1344/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3264 - val_loss: 1.6540\n",
      "Epoch 1345/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3261 - val_loss: 1.6593\n",
      "Epoch 1346/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.3258 - val_loss: 1.6530\n",
      "Epoch 1347/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.3255 - val_loss: 1.6594\n",
      "Epoch 1348/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3252 - val_loss: 1.6519\n",
      "Epoch 1349/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.3249 - val_loss: 1.6596\n",
      "Epoch 1350/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3246 - val_loss: 1.6507\n",
      "Epoch 1351/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.3243 - val_loss: 1.6600\n",
      "Epoch 1352/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.3240 - val_loss: 1.6493\n",
      "Epoch 1353/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.3237 - val_loss: 1.6605\n",
      "Epoch 1354/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.3234 - val_loss: 1.6478\n",
      "Epoch 1355/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3231 - val_loss: 1.6613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1356/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3228 - val_loss: 1.6460\n",
      "Epoch 1357/2500\n",
      "64/64 [==============================] - 0s 300us/step - loss: 1.3225 - val_loss: 1.6623\n",
      "Epoch 1358/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3222 - val_loss: 1.6439\n",
      "Epoch 1359/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.3220 - val_loss: 1.6637\n",
      "Epoch 1360/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3217 - val_loss: 1.6415\n",
      "Epoch 1361/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.3214 - val_loss: 1.6654\n",
      "Epoch 1362/2500\n",
      "64/64 [==============================] - 0s 344us/step - loss: 1.3212 - val_loss: 1.6388\n",
      "Epoch 1363/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 1.3210 - val_loss: 1.6676\n",
      "Epoch 1364/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.3208 - val_loss: 1.6357\n",
      "Epoch 1365/2500\n",
      "64/64 [==============================] - 0s 357us/step - loss: 1.3206 - val_loss: 1.6703\n",
      "Epoch 1366/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3204 - val_loss: 1.6322\n",
      "Epoch 1367/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3202 - val_loss: 1.6735\n",
      "Epoch 1368/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.3200 - val_loss: 1.6282\n",
      "Epoch 1369/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3200 - val_loss: 1.6772\n",
      "Epoch 1370/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3199 - val_loss: 1.6240\n",
      "Epoch 1371/2500\n",
      "64/64 [==============================] - 0s 423us/step - loss: 1.3198 - val_loss: 1.6811\n",
      "Epoch 1372/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3198 - val_loss: 1.6199\n",
      "Epoch 1373/2500\n",
      "64/64 [==============================] - 0s 337us/step - loss: 1.3197 - val_loss: 1.6847\n",
      "Epoch 1374/2500\n",
      "64/64 [==============================] - 0s 509us/step - loss: 1.3197 - val_loss: 1.6162\n",
      "Epoch 1375/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.3197 - val_loss: 1.6874\n",
      "Epoch 1376/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.3196 - val_loss: 1.6134\n",
      "Epoch 1377/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.3195 - val_loss: 1.6884\n",
      "Epoch 1378/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.3192 - val_loss: 1.6121\n",
      "Epoch 1379/2500\n",
      "64/64 [==============================] - 0s 293us/step - loss: 1.3190 - val_loss: 1.6869\n",
      "Epoch 1380/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3185 - val_loss: 1.6131\n",
      "Epoch 1381/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3180 - val_loss: 1.6825\n",
      "Epoch 1382/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.3174 - val_loss: 1.6166\n",
      "Epoch 1383/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.3167 - val_loss: 1.6753\n",
      "Epoch 1384/2500\n",
      "64/64 [==============================] - 0s 328us/step - loss: 1.3159 - val_loss: 1.6228\n",
      "Epoch 1385/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3152 - val_loss: 1.6664\n",
      "Epoch 1386/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3145 - val_loss: 1.6309\n",
      "Epoch 1387/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.3139 - val_loss: 1.6572\n",
      "Epoch 1388/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.3133 - val_loss: 1.6398\n",
      "Epoch 1389/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.3128 - val_loss: 1.6488\n",
      "Epoch 1390/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3125 - val_loss: 1.6480\n",
      "Epoch 1391/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3122 - val_loss: 1.6419\n",
      "Epoch 1392/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3119 - val_loss: 1.6544\n",
      "Epoch 1393/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3117 - val_loss: 1.6365\n",
      "Epoch 1394/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3115 - val_loss: 1.6582\n",
      "Epoch 1395/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3113 - val_loss: 1.6327\n",
      "Epoch 1396/2500\n",
      "64/64 [==============================] - 0s 299us/step - loss: 1.3111 - val_loss: 1.6594\n",
      "Epoch 1397/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3108 - val_loss: 1.6306\n",
      "Epoch 1398/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3106 - val_loss: 1.6581\n",
      "Epoch 1399/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.3103 - val_loss: 1.6305\n",
      "Epoch 1400/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3099 - val_loss: 1.6551\n",
      "Epoch 1401/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.3096 - val_loss: 1.6322\n",
      "Epoch 1402/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3092 - val_loss: 1.6511\n",
      "Epoch 1403/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.3088 - val_loss: 1.6352\n",
      "Epoch 1404/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3085 - val_loss: 1.6468\n",
      "Epoch 1405/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3081 - val_loss: 1.6390\n",
      "Epoch 1406/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3078 - val_loss: 1.6430\n",
      "Epoch 1407/2500\n",
      "64/64 [==============================] - 0s 462us/step - loss: 1.3075 - val_loss: 1.6427\n",
      "Epoch 1408/2500\n",
      "64/64 [==============================] - 0s 396us/step - loss: 1.3072 - val_loss: 1.6398\n",
      "Epoch 1409/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.3069 - val_loss: 1.6455\n",
      "Epoch 1410/2500\n",
      "64/64 [==============================] - 0s 469us/step - loss: 1.3067 - val_loss: 1.6374\n",
      "Epoch 1411/2500\n",
      "64/64 [==============================] - 0s 506us/step - loss: 1.3064 - val_loss: 1.6471\n",
      "Epoch 1412/2500\n",
      "64/64 [==============================] - 0s 414us/step - loss: 1.3061 - val_loss: 1.6357\n",
      "Epoch 1413/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 1.3059 - val_loss: 1.6473\n",
      "Epoch 1414/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.3056 - val_loss: 1.6347\n",
      "Epoch 1415/2500\n",
      "64/64 [==============================] - 0s 535us/step - loss: 1.3053 - val_loss: 1.6463\n",
      "Epoch 1416/2500\n",
      "64/64 [==============================] - 0s 857us/step - loss: 1.3050 - val_loss: 1.6344\n",
      "Epoch 1417/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 1.3047 - val_loss: 1.6446\n",
      "Epoch 1418/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.3044 - val_loss: 1.6347\n",
      "Epoch 1419/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.3041 - val_loss: 1.6425\n",
      "Epoch 1420/2500\n",
      "64/64 [==============================] - 0s 505us/step - loss: 1.3038 - val_loss: 1.6357\n",
      "Epoch 1421/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3035 - val_loss: 1.6403\n",
      "Epoch 1422/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.3032 - val_loss: 1.6369\n",
      "Epoch 1423/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.3029 - val_loss: 1.6384\n",
      "Epoch 1424/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.3026 - val_loss: 1.6382\n",
      "Epoch 1425/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3024 - val_loss: 1.6368\n",
      "Epoch 1426/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.3021 - val_loss: 1.6391\n",
      "Epoch 1427/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.3018 - val_loss: 1.6355\n",
      "Epoch 1428/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.3015 - val_loss: 1.6396\n",
      "Epoch 1429/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3012 - val_loss: 1.6346\n",
      "Epoch 1430/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.3010 - val_loss: 1.6395\n",
      "Epoch 1431/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3007 - val_loss: 1.6340\n",
      "Epoch 1432/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.3004 - val_loss: 1.6389\n",
      "Epoch 1433/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3001 - val_loss: 1.6337\n",
      "Epoch 1434/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2998 - val_loss: 1.6379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1435/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.2996 - val_loss: 1.6335\n",
      "Epoch 1436/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2993 - val_loss: 1.6367\n",
      "Epoch 1437/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2990 - val_loss: 1.6336\n",
      "Epoch 1438/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2987 - val_loss: 1.6355\n",
      "Epoch 1439/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.2984 - val_loss: 1.6338\n",
      "Epoch 1440/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2981 - val_loss: 1.6344\n",
      "Epoch 1441/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2979 - val_loss: 1.6339\n",
      "Epoch 1442/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.2976 - val_loss: 1.6334\n",
      "Epoch 1443/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2973 - val_loss: 1.6341\n",
      "Epoch 1444/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2970 - val_loss: 1.6327\n",
      "Epoch 1445/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2968 - val_loss: 1.6340\n",
      "Epoch 1446/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.2965 - val_loss: 1.6320\n",
      "Epoch 1447/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2962 - val_loss: 1.6338\n",
      "Epoch 1448/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 1.2959 - val_loss: 1.6315\n",
      "Epoch 1449/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.2957 - val_loss: 1.6333\n",
      "Epoch 1450/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2954 - val_loss: 1.6310\n",
      "Epoch 1451/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2951 - val_loss: 1.6327\n",
      "Epoch 1452/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.2948 - val_loss: 1.6307\n",
      "Epoch 1453/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2946 - val_loss: 1.6320\n",
      "Epoch 1454/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2943 - val_loss: 1.6304\n",
      "Epoch 1455/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2940 - val_loss: 1.6313\n",
      "Epoch 1456/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2937 - val_loss: 1.6301\n",
      "Epoch 1457/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2935 - val_loss: 1.6305\n",
      "Epoch 1458/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.2932 - val_loss: 1.6299\n",
      "Epoch 1459/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2929 - val_loss: 1.6298\n",
      "Epoch 1460/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.2926 - val_loss: 1.6297\n",
      "Epoch 1461/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2924 - val_loss: 1.6292\n",
      "Epoch 1462/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2921 - val_loss: 1.6294\n",
      "Epoch 1463/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2918 - val_loss: 1.6287\n",
      "Epoch 1464/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.2915 - val_loss: 1.6291\n",
      "Epoch 1465/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.2913 - val_loss: 1.6281\n",
      "Epoch 1466/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2910 - val_loss: 1.6287\n",
      "Epoch 1467/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2907 - val_loss: 1.6277\n",
      "Epoch 1468/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2905 - val_loss: 1.6282\n",
      "Epoch 1469/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.2902 - val_loss: 1.6272\n",
      "Epoch 1470/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2899 - val_loss: 1.6277\n",
      "Epoch 1471/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 1.2896 - val_loss: 1.6268\n",
      "Epoch 1472/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2894 - val_loss: 1.6271\n",
      "Epoch 1473/2500\n",
      "64/64 [==============================] - 0s 485us/step - loss: 1.2891 - val_loss: 1.6264\n",
      "Epoch 1474/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2888 - val_loss: 1.6266\n",
      "Epoch 1475/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2886 - val_loss: 1.6260\n",
      "Epoch 1476/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2883 - val_loss: 1.6260\n",
      "Epoch 1477/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2880 - val_loss: 1.6257\n",
      "Epoch 1478/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2878 - val_loss: 1.6255\n",
      "Epoch 1479/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2875 - val_loss: 1.6253\n",
      "Epoch 1480/2500\n",
      "64/64 [==============================] - 0s 417us/step - loss: 1.2872 - val_loss: 1.6250\n",
      "Epoch 1481/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2870 - val_loss: 1.6249\n",
      "Epoch 1482/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.2867 - val_loss: 1.6245\n",
      "Epoch 1483/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2864 - val_loss: 1.6245\n",
      "Epoch 1484/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2862 - val_loss: 1.6240\n",
      "Epoch 1485/2500\n",
      "64/64 [==============================] - 0s 360us/step - loss: 1.2859 - val_loss: 1.6240\n",
      "Epoch 1486/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2856 - val_loss: 1.6235\n",
      "Epoch 1487/2500\n",
      "64/64 [==============================] - 0s 423us/step - loss: 1.2854 - val_loss: 1.6236\n",
      "Epoch 1488/2500\n",
      "64/64 [==============================] - 0s 368us/step - loss: 1.2851 - val_loss: 1.6231\n",
      "Epoch 1489/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2848 - val_loss: 1.6231\n",
      "Epoch 1490/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2846 - val_loss: 1.6226\n",
      "Epoch 1491/2500\n",
      "64/64 [==============================] - 0s 352us/step - loss: 1.2843 - val_loss: 1.6226\n",
      "Epoch 1492/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2840 - val_loss: 1.6222\n",
      "Epoch 1493/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.2838 - val_loss: 1.6221\n",
      "Epoch 1494/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2835 - val_loss: 1.6217\n",
      "Epoch 1495/2500\n",
      "64/64 [==============================] - 0s 334us/step - loss: 1.2832 - val_loss: 1.6216\n",
      "Epoch 1496/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2830 - val_loss: 1.6213\n",
      "Epoch 1497/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2827 - val_loss: 1.6211\n",
      "Epoch 1498/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2825 - val_loss: 1.6209\n",
      "Epoch 1499/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2822 - val_loss: 1.6206\n",
      "Epoch 1500/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2819 - val_loss: 1.6205\n",
      "Epoch 1501/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2816 - val_loss: 1.6202\n",
      "Epoch 1502/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2814 - val_loss: 1.6200\n",
      "Epoch 1503/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2811 - val_loss: 1.6197\n",
      "Epoch 1504/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2809 - val_loss: 1.6196\n",
      "Epoch 1505/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2806 - val_loss: 1.6192\n",
      "Epoch 1506/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.2804 - val_loss: 1.6191\n",
      "Epoch 1507/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2801 - val_loss: 1.6188\n",
      "Epoch 1508/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2798 - val_loss: 1.6187\n",
      "Epoch 1509/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2796 - val_loss: 1.6183\n",
      "Epoch 1510/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2793 - val_loss: 1.6182\n",
      "Epoch 1511/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.2791 - val_loss: 1.6179\n",
      "Epoch 1512/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2788 - val_loss: 1.6177\n",
      "Epoch 1513/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2785 - val_loss: 1.6174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1514/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2783 - val_loss: 1.6173\n",
      "Epoch 1515/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.2780 - val_loss: 1.6170\n",
      "Epoch 1516/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2778 - val_loss: 1.6168\n",
      "Epoch 1517/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2775 - val_loss: 1.6165\n",
      "Epoch 1518/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2772 - val_loss: 1.6163\n",
      "Epoch 1519/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2770 - val_loss: 1.6161\n",
      "Epoch 1520/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 1.2767 - val_loss: 1.6159\n",
      "Epoch 1521/2500\n",
      "64/64 [==============================] - 0s 589us/step - loss: 1.2765 - val_loss: 1.6156\n",
      "Epoch 1522/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.2762 - val_loss: 1.6154\n",
      "Epoch 1523/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2760 - val_loss: 1.6152\n",
      "Epoch 1524/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2757 - val_loss: 1.6149\n",
      "Epoch 1525/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 1.2754 - val_loss: 1.6147\n",
      "Epoch 1526/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2752 - val_loss: 1.6145\n",
      "Epoch 1527/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2749 - val_loss: 1.6143\n",
      "Epoch 1528/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2747 - val_loss: 1.6140\n",
      "Epoch 1529/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2744 - val_loss: 1.6138\n",
      "Epoch 1530/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2742 - val_loss: 1.6136\n",
      "Epoch 1531/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2739 - val_loss: 1.6134\n",
      "Epoch 1532/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2737 - val_loss: 1.6131\n",
      "Epoch 1533/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2734 - val_loss: 1.6129\n",
      "Epoch 1534/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2732 - val_loss: 1.6126\n",
      "Epoch 1535/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2729 - val_loss: 1.6125\n",
      "Epoch 1536/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.2726 - val_loss: 1.6122\n",
      "Epoch 1537/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2724 - val_loss: 1.6120\n",
      "Epoch 1538/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2721 - val_loss: 1.6117\n",
      "Epoch 1539/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2719 - val_loss: 1.6115\n",
      "Epoch 1540/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2716 - val_loss: 1.6113\n",
      "Epoch 1541/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.2714 - val_loss: 1.6111\n",
      "Epoch 1542/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.2711 - val_loss: 1.6108\n",
      "Epoch 1543/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2709 - val_loss: 1.6106\n",
      "Epoch 1544/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2706 - val_loss: 1.6104\n",
      "Epoch 1545/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.2704 - val_loss: 1.6102\n",
      "Epoch 1546/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 1.2701 - val_loss: 1.6099\n",
      "Epoch 1547/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2699 - val_loss: 1.6097\n",
      "Epoch 1548/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2696 - val_loss: 1.6095\n",
      "Epoch 1549/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2694 - val_loss: 1.6093\n",
      "Epoch 1550/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2691 - val_loss: 1.6090\n",
      "Epoch 1551/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2689 - val_loss: 1.6088\n",
      "Epoch 1552/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2686 - val_loss: 1.6086\n",
      "Epoch 1553/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2684 - val_loss: 1.6083\n",
      "Epoch 1554/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2681 - val_loss: 1.6081\n",
      "Epoch 1555/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.2679 - val_loss: 1.6079\n",
      "Epoch 1556/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2676 - val_loss: 1.6077\n",
      "Epoch 1557/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2674 - val_loss: 1.6074\n",
      "Epoch 1558/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2671 - val_loss: 1.6072\n",
      "Epoch 1559/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 1.2668 - val_loss: 1.6070\n",
      "Epoch 1560/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.2666 - val_loss: 1.6068\n",
      "Epoch 1561/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.2664 - val_loss: 1.6065\n",
      "Epoch 1562/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2661 - val_loss: 1.6063\n",
      "Epoch 1563/2500\n",
      "64/64 [==============================] - 0s 344us/step - loss: 1.2659 - val_loss: 1.6061\n",
      "Epoch 1564/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 1.2656 - val_loss: 1.6059\n",
      "Epoch 1565/2500\n",
      "64/64 [==============================] - 0s 457us/step - loss: 1.2654 - val_loss: 1.6056\n",
      "Epoch 1566/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.2651 - val_loss: 1.6054\n",
      "Epoch 1567/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2649 - val_loss: 1.6052\n",
      "Epoch 1568/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.2647 - val_loss: 1.6050\n",
      "Epoch 1569/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2644 - val_loss: 1.6047\n",
      "Epoch 1570/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2642 - val_loss: 1.6045\n",
      "Epoch 1571/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.2639 - val_loss: 1.6043\n",
      "Epoch 1572/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2637 - val_loss: 1.6040\n",
      "Epoch 1573/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2634 - val_loss: 1.6038\n",
      "Epoch 1574/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2632 - val_loss: 1.6036\n",
      "Epoch 1575/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2629 - val_loss: 1.6034\n",
      "Epoch 1576/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.2627 - val_loss: 1.6031\n",
      "Epoch 1577/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2624 - val_loss: 1.6029\n",
      "Epoch 1578/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2622 - val_loss: 1.6027\n",
      "Epoch 1579/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2620 - val_loss: 1.6025\n",
      "Epoch 1580/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2617 - val_loss: 1.6022\n",
      "Epoch 1581/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.2615 - val_loss: 1.6020\n",
      "Epoch 1582/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.2612 - val_loss: 1.6018\n",
      "Epoch 1583/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2610 - val_loss: 1.6016\n",
      "Epoch 1584/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.2607 - val_loss: 1.6013\n",
      "Epoch 1585/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2605 - val_loss: 1.6011\n",
      "Epoch 1586/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2603 - val_loss: 1.6009\n",
      "Epoch 1587/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.2600 - val_loss: 1.6007\n",
      "Epoch 1588/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2598 - val_loss: 1.6004\n",
      "Epoch 1589/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2595 - val_loss: 1.6002\n",
      "Epoch 1590/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.2593 - val_loss: 1.6000\n",
      "Epoch 1591/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.2591 - val_loss: 1.5998\n",
      "Epoch 1592/2500\n",
      "64/64 [==============================] - 0s 352us/step - loss: 1.2588 - val_loss: 1.5995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1593/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2586 - val_loss: 1.5993\n",
      "Epoch 1594/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.2583 - val_loss: 1.5991\n",
      "Epoch 1595/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2581 - val_loss: 1.5988\n",
      "Epoch 1596/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2579 - val_loss: 1.5986\n",
      "Epoch 1597/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.2576 - val_loss: 1.5984\n",
      "Epoch 1598/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2574 - val_loss: 1.5982\n",
      "Epoch 1599/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2571 - val_loss: 1.5979\n",
      "Epoch 1600/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2569 - val_loss: 1.5977\n",
      "Epoch 1601/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2567 - val_loss: 1.5975\n",
      "Epoch 1602/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.2564 - val_loss: 1.5973\n",
      "Epoch 1603/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2562 - val_loss: 1.5970\n",
      "Epoch 1604/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2559 - val_loss: 1.5968\n",
      "Epoch 1605/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2557 - val_loss: 1.5966\n",
      "Epoch 1606/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2555 - val_loss: 1.5964\n",
      "Epoch 1607/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.2552 - val_loss: 1.5961\n",
      "Epoch 1608/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2550 - val_loss: 1.5959\n",
      "Epoch 1609/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2548 - val_loss: 1.5957\n",
      "Epoch 1610/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2545 - val_loss: 1.5955\n",
      "Epoch 1611/2500\n",
      "64/64 [==============================] - 0s 400us/step - loss: 1.2543 - val_loss: 1.5952\n",
      "Epoch 1612/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2540 - val_loss: 1.5950\n",
      "Epoch 1613/2500\n",
      "64/64 [==============================] - 0s 314us/step - loss: 1.2538 - val_loss: 1.5948\n",
      "Epoch 1614/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2536 - val_loss: 1.5946\n",
      "Epoch 1615/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2533 - val_loss: 1.5943\n",
      "Epoch 1616/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2531 - val_loss: 1.5941\n",
      "Epoch 1617/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.2529 - val_loss: 1.5939\n",
      "Epoch 1618/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.2526 - val_loss: 1.5937\n",
      "Epoch 1619/2500\n",
      "64/64 [==============================] - 0s 279us/step - loss: 1.2524 - val_loss: 1.5934\n",
      "Epoch 1620/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2522 - val_loss: 1.5932\n",
      "Epoch 1621/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2519 - val_loss: 1.5930\n",
      "Epoch 1622/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.2517 - val_loss: 1.5928\n",
      "Epoch 1623/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2515 - val_loss: 1.5925\n",
      "Epoch 1624/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2512 - val_loss: 1.5923\n",
      "Epoch 1625/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.2509 - val_loss: 1.5921\n",
      "Epoch 1626/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 1.2507 - val_loss: 1.5919\n",
      "Epoch 1627/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2505 - val_loss: 1.5916\n",
      "Epoch 1628/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2503 - val_loss: 1.5914\n",
      "Epoch 1629/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2500 - val_loss: 1.5912\n",
      "Epoch 1630/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.2498 - val_loss: 1.5910\n",
      "Epoch 1631/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2496 - val_loss: 1.5907\n",
      "Epoch 1632/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2494 - val_loss: 1.5905\n",
      "Epoch 1633/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2491 - val_loss: 1.5903\n",
      "Epoch 1634/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.2489 - val_loss: 1.5901\n",
      "Epoch 1635/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2487 - val_loss: 1.5898\n",
      "Epoch 1636/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2484 - val_loss: 1.5896\n",
      "Epoch 1637/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2482 - val_loss: 1.5894\n",
      "Epoch 1638/2500\n",
      "64/64 [==============================] - 0s 396us/step - loss: 1.2480 - val_loss: 1.5892\n",
      "Epoch 1639/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2477 - val_loss: 1.5890\n",
      "Epoch 1640/2500\n",
      "64/64 [==============================] - 0s 300us/step - loss: 1.2475 - val_loss: 1.5887\n",
      "Epoch 1641/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.2473 - val_loss: 1.5885\n",
      "Epoch 1642/2500\n",
      "64/64 [==============================] - 0s 372us/step - loss: 1.2470 - val_loss: 1.5883\n",
      "Epoch 1643/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2468 - val_loss: 1.5881\n",
      "Epoch 1644/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 1.2466 - val_loss: 1.5878\n",
      "Epoch 1645/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2463 - val_loss: 1.5876\n",
      "Epoch 1646/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2461 - val_loss: 1.5874\n",
      "Epoch 1647/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.2459 - val_loss: 1.5872\n",
      "Epoch 1648/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.2457 - val_loss: 1.5869\n",
      "Epoch 1649/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2454 - val_loss: 1.5867\n",
      "Epoch 1650/2500\n",
      "64/64 [==============================] - 0s 426us/step - loss: 1.2452 - val_loss: 1.5865\n",
      "Epoch 1651/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.2450 - val_loss: 1.5863\n",
      "Epoch 1652/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.2447 - val_loss: 1.5860\n",
      "Epoch 1653/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2445 - val_loss: 1.5858\n",
      "Epoch 1654/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2443 - val_loss: 1.5856\n",
      "Epoch 1655/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.2441 - val_loss: 1.5854\n",
      "Epoch 1656/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.2438 - val_loss: 1.5851\n",
      "Epoch 1657/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2436 - val_loss: 1.5849\n",
      "Epoch 1658/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2434 - val_loss: 1.5847\n",
      "Epoch 1659/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2431 - val_loss: 1.5845\n",
      "Epoch 1660/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.2429 - val_loss: 1.5842\n",
      "Epoch 1661/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2427 - val_loss: 1.5840\n",
      "Epoch 1662/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2425 - val_loss: 1.5838\n",
      "Epoch 1663/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2422 - val_loss: 1.5836\n",
      "Epoch 1664/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.2420 - val_loss: 1.5833\n",
      "Epoch 1665/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2418 - val_loss: 1.5831\n",
      "Epoch 1666/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.2416 - val_loss: 1.5829\n",
      "Epoch 1667/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2413 - val_loss: 1.5827\n",
      "Epoch 1668/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2411 - val_loss: 1.5825\n",
      "Epoch 1669/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2409 - val_loss: 1.5822\n",
      "Epoch 1670/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2407 - val_loss: 1.5820\n",
      "Epoch 1671/2500\n",
      "64/64 [==============================] - 0s 296us/step - loss: 1.2404 - val_loss: 1.5818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1672/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.2402 - val_loss: 1.5816\n",
      "Epoch 1673/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2400 - val_loss: 1.5813\n",
      "Epoch 1674/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.2398 - val_loss: 1.5811\n",
      "Epoch 1675/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.2395 - val_loss: 1.5809\n",
      "Epoch 1676/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2393 - val_loss: 1.5807\n",
      "Epoch 1677/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2391 - val_loss: 1.5804\n",
      "Epoch 1678/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2389 - val_loss: 1.5802\n",
      "Epoch 1679/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2386 - val_loss: 1.5800\n",
      "Epoch 1680/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.2384 - val_loss: 1.5798\n",
      "Epoch 1681/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.2382 - val_loss: 1.5796\n",
      "Epoch 1682/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2380 - val_loss: 1.5793\n",
      "Epoch 1683/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2377 - val_loss: 1.5791\n",
      "Epoch 1684/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2375 - val_loss: 1.5789\n",
      "Epoch 1685/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.2373 - val_loss: 1.5787\n",
      "Epoch 1686/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.2371 - val_loss: 1.5784\n",
      "Epoch 1687/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2369 - val_loss: 1.5782\n",
      "Epoch 1688/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.2366 - val_loss: 1.5780\n",
      "Epoch 1689/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.2364 - val_loss: 1.5778\n",
      "Epoch 1690/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2362 - val_loss: 1.5775\n",
      "Epoch 1691/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.2360 - val_loss: 1.5773\n",
      "Epoch 1692/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.2358 - val_loss: 1.5771\n",
      "Epoch 1693/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2355 - val_loss: 1.5769\n",
      "Epoch 1694/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2353 - val_loss: 1.5767\n",
      "Epoch 1695/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2351 - val_loss: 1.5764\n",
      "Epoch 1696/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2349 - val_loss: 1.5762\n",
      "Epoch 1697/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2347 - val_loss: 1.5760\n",
      "Epoch 1698/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 1.2344 - val_loss: 1.5758\n",
      "Epoch 1699/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2342 - val_loss: 1.5755\n",
      "Epoch 1700/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2340 - val_loss: 1.5753\n",
      "Epoch 1701/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2338 - val_loss: 1.5751\n",
      "Epoch 1702/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2336 - val_loss: 1.5749\n",
      "Epoch 1703/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2333 - val_loss: 1.5747\n",
      "Epoch 1704/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2331 - val_loss: 1.5744\n",
      "Epoch 1705/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2329 - val_loss: 1.5742\n",
      "Epoch 1706/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2327 - val_loss: 1.5740\n",
      "Epoch 1707/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2325 - val_loss: 1.5738\n",
      "Epoch 1708/2500\n",
      "64/64 [==============================] - 0s 392us/step - loss: 1.2322 - val_loss: 1.5735\n",
      "Epoch 1709/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2320 - val_loss: 1.5733\n",
      "Epoch 1710/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.2318 - val_loss: 1.5731\n",
      "Epoch 1711/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2316 - val_loss: 1.5729\n",
      "Epoch 1712/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2314 - val_loss: 1.5727\n",
      "Epoch 1713/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2312 - val_loss: 1.5724\n",
      "Epoch 1714/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.2309 - val_loss: 1.5722\n",
      "Epoch 1715/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2307 - val_loss: 1.5720\n",
      "Epoch 1716/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2305 - val_loss: 1.5718\n",
      "Epoch 1717/2500\n",
      "64/64 [==============================] - 0s 262us/step - loss: 1.2303 - val_loss: 1.5715\n",
      "Epoch 1718/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2301 - val_loss: 1.5713\n",
      "Epoch 1719/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2299 - val_loss: 1.5711\n",
      "Epoch 1720/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2296 - val_loss: 1.5709\n",
      "Epoch 1721/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.2294 - val_loss: 1.5706\n",
      "Epoch 1722/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 1.2292 - val_loss: 1.5704\n",
      "Epoch 1723/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.2290 - val_loss: 1.5702\n",
      "Epoch 1724/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2288 - val_loss: 1.5700\n",
      "Epoch 1725/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2286 - val_loss: 1.5698\n",
      "Epoch 1726/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2283 - val_loss: 1.5696\n",
      "Epoch 1727/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2281 - val_loss: 1.5693\n",
      "Epoch 1728/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2279 - val_loss: 1.5691\n",
      "Epoch 1729/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.2277 - val_loss: 1.5689\n",
      "Epoch 1730/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.2275 - val_loss: 1.5687\n",
      "Epoch 1731/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2273 - val_loss: 1.5684\n",
      "Epoch 1732/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2271 - val_loss: 1.5682\n",
      "Epoch 1733/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2268 - val_loss: 1.5680\n",
      "Epoch 1734/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2266 - val_loss: 1.5678\n",
      "Epoch 1735/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2264 - val_loss: 1.5675\n",
      "Epoch 1736/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2262 - val_loss: 1.5673\n",
      "Epoch 1737/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.2260 - val_loss: 1.5671\n",
      "Epoch 1738/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2258 - val_loss: 1.5669\n",
      "Epoch 1739/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2256 - val_loss: 1.5667\n",
      "Epoch 1740/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2253 - val_loss: 1.5664\n",
      "Epoch 1741/2500\n",
      "64/64 [==============================] - 0s 468us/step - loss: 1.2251 - val_loss: 1.5662\n",
      "Epoch 1742/2500\n",
      "64/64 [==============================] - 0s 429us/step - loss: 1.2249 - val_loss: 1.5660\n",
      "Epoch 1743/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2247 - val_loss: 1.5658\n",
      "Epoch 1744/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 1.2245 - val_loss: 1.5656\n",
      "Epoch 1745/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2243 - val_loss: 1.5653\n",
      "Epoch 1746/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2241 - val_loss: 1.5651\n",
      "Epoch 1747/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2239 - val_loss: 1.5649\n",
      "Epoch 1748/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.2237 - val_loss: 1.5647\n",
      "Epoch 1749/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2234 - val_loss: 1.5645\n",
      "Epoch 1750/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2232 - val_loss: 1.5642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1751/2500\n",
      "64/64 [==============================] - 0s 388us/step - loss: 1.2230 - val_loss: 1.5640\n",
      "Epoch 1752/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2228 - val_loss: 1.5638\n",
      "Epoch 1753/2500\n",
      "64/64 [==============================] - 0s 325us/step - loss: 1.2226 - val_loss: 1.5636\n",
      "Epoch 1754/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2224 - val_loss: 1.5633\n",
      "Epoch 1755/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2222 - val_loss: 1.5631\n",
      "Epoch 1756/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2220 - val_loss: 1.5629\n",
      "Epoch 1757/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.2217 - val_loss: 1.5627\n",
      "Epoch 1758/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2216 - val_loss: 1.5625\n",
      "Epoch 1759/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2213 - val_loss: 1.5622\n",
      "Epoch 1760/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 1.2211 - val_loss: 1.5620\n",
      "Epoch 1761/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2209 - val_loss: 1.5618\n",
      "Epoch 1762/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2207 - val_loss: 1.5616\n",
      "Epoch 1763/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.2205 - val_loss: 1.5614\n",
      "Epoch 1764/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.2203 - val_loss: 1.5611\n",
      "Epoch 1765/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2201 - val_loss: 1.5609\n",
      "Epoch 1766/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2199 - val_loss: 1.5607\n",
      "Epoch 1767/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2197 - val_loss: 1.5605\n",
      "Epoch 1768/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2195 - val_loss: 1.5603\n",
      "Epoch 1769/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2193 - val_loss: 1.5600\n",
      "Epoch 1770/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2190 - val_loss: 1.5598\n",
      "Epoch 1771/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2188 - val_loss: 1.5596\n",
      "Epoch 1772/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.2186 - val_loss: 1.5594\n",
      "Epoch 1773/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2184 - val_loss: 1.5591\n",
      "Epoch 1774/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2182 - val_loss: 1.5589\n",
      "Epoch 1775/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2180 - val_loss: 1.5587\n",
      "Epoch 1776/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2178 - val_loss: 1.5585\n",
      "Epoch 1777/2500\n",
      "64/64 [==============================] - 0s 513us/step - loss: 1.2176 - val_loss: 1.5583\n",
      "Epoch 1778/2500\n",
      "64/64 [==============================] - 0s 374us/step - loss: 1.2174 - val_loss: 1.5580\n",
      "Epoch 1779/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.2172 - val_loss: 1.5578\n",
      "Epoch 1780/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2170 - val_loss: 1.5576\n",
      "Epoch 1781/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.2168 - val_loss: 1.5574\n",
      "Epoch 1782/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.2166 - val_loss: 1.5572\n",
      "Epoch 1783/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.2164 - val_loss: 1.5569\n",
      "Epoch 1784/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2162 - val_loss: 1.5567\n",
      "Epoch 1785/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2160 - val_loss: 1.5565\n",
      "Epoch 1786/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.2157 - val_loss: 1.5563\n",
      "Epoch 1787/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2155 - val_loss: 1.5561\n",
      "Epoch 1788/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2153 - val_loss: 1.5558\n",
      "Epoch 1789/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2151 - val_loss: 1.5556\n",
      "Epoch 1790/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.2149 - val_loss: 1.5554\n",
      "Epoch 1791/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2147 - val_loss: 1.5552\n",
      "Epoch 1792/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2145 - val_loss: 1.5549\n",
      "Epoch 1793/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2143 - val_loss: 1.5548\n",
      "Epoch 1794/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.2141 - val_loss: 1.5545\n",
      "Epoch 1795/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.2139 - val_loss: 1.5543\n",
      "Epoch 1796/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2137 - val_loss: 1.5541\n",
      "Epoch 1797/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.2135 - val_loss: 1.5539\n",
      "Epoch 1798/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2133 - val_loss: 1.5536\n",
      "Epoch 1799/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2131 - val_loss: 1.5534\n",
      "Epoch 1800/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.2129 - val_loss: 1.5532\n",
      "Epoch 1801/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2127 - val_loss: 1.5530\n",
      "Epoch 1802/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2125 - val_loss: 1.5528\n",
      "Epoch 1803/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2123 - val_loss: 1.5525\n",
      "Epoch 1804/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2121 - val_loss: 1.5523\n",
      "Epoch 1805/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2119 - val_loss: 1.5521\n",
      "Epoch 1806/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2117 - val_loss: 1.5519\n",
      "Epoch 1807/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2115 - val_loss: 1.5517\n",
      "Epoch 1808/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2113 - val_loss: 1.5514\n",
      "Epoch 1809/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.2111 - val_loss: 1.5512\n",
      "Epoch 1810/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.2109 - val_loss: 1.5510\n",
      "Epoch 1811/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2107 - val_loss: 1.5508\n",
      "Epoch 1812/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2105 - val_loss: 1.5506\n",
      "Epoch 1813/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2103 - val_loss: 1.5503\n",
      "Epoch 1814/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.2101 - val_loss: 1.5501\n",
      "Epoch 1815/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2099 - val_loss: 1.5499\n",
      "Epoch 1816/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2097 - val_loss: 1.5497\n",
      "Epoch 1817/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2095 - val_loss: 1.5495\n",
      "Epoch 1818/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.2093 - val_loss: 1.5492\n",
      "Epoch 1819/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2091 - val_loss: 1.5490\n",
      "Epoch 1820/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2089 - val_loss: 1.5488\n",
      "Epoch 1821/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2087 - val_loss: 1.5486\n",
      "Epoch 1822/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2085 - val_loss: 1.5484\n",
      "Epoch 1823/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.2083 - val_loss: 1.5481\n",
      "Epoch 1824/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2081 - val_loss: 1.5479\n",
      "Epoch 1825/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 1.2079 - val_loss: 1.5477\n",
      "Epoch 1826/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2077 - val_loss: 1.5475\n",
      "Epoch 1827/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2075 - val_loss: 1.5473\n",
      "Epoch 1828/2500\n",
      "64/64 [==============================] - 0s 487us/step - loss: 1.2073 - val_loss: 1.5471\n",
      "Epoch 1829/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 1.2071 - val_loss: 1.5468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1830/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.2069 - val_loss: 1.5466\n",
      "Epoch 1831/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.2067 - val_loss: 1.5464\n",
      "Epoch 1832/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2065 - val_loss: 1.5462\n",
      "Epoch 1833/2500\n",
      "64/64 [==============================] - 0s 834us/step - loss: 1.2063 - val_loss: 1.5459\n",
      "Epoch 1834/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2061 - val_loss: 1.5457\n",
      "Epoch 1835/2500\n",
      "64/64 [==============================] - 0s 411us/step - loss: 1.2059 - val_loss: 1.5455\n",
      "Epoch 1836/2500\n",
      "64/64 [==============================] - 0s 393us/step - loss: 1.2057 - val_loss: 1.5453\n",
      "Epoch 1837/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2055 - val_loss: 1.5451\n",
      "Epoch 1838/2500\n",
      "64/64 [==============================] - 0s 383us/step - loss: 1.2053 - val_loss: 1.5449\n",
      "Epoch 1839/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.2051 - val_loss: 1.5446\n",
      "Epoch 1840/2500\n",
      "64/64 [==============================] - 0s 495us/step - loss: 1.2049 - val_loss: 1.5444\n",
      "Epoch 1841/2500\n",
      "64/64 [==============================] - 0s 533us/step - loss: 1.2047 - val_loss: 1.5442\n",
      "Epoch 1842/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.2045 - val_loss: 1.5440\n",
      "Epoch 1843/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2043 - val_loss: 1.5438\n",
      "Epoch 1844/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 1.2041 - val_loss: 1.5435\n",
      "Epoch 1845/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2039 - val_loss: 1.5433\n",
      "Epoch 1846/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.2037 - val_loss: 1.5431\n",
      "Epoch 1847/2500\n",
      "64/64 [==============================] - 0s 352us/step - loss: 1.2035 - val_loss: 1.5429\n",
      "Epoch 1848/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2033 - val_loss: 1.5426\n",
      "Epoch 1849/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2031 - val_loss: 1.5424\n",
      "Epoch 1850/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2029 - val_loss: 1.5422\n",
      "Epoch 1851/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2027 - val_loss: 1.5420\n",
      "Epoch 1852/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2025 - val_loss: 1.5418\n",
      "Epoch 1853/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2023 - val_loss: 1.5416\n",
      "Epoch 1854/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.2022 - val_loss: 1.5413\n",
      "Epoch 1855/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2020 - val_loss: 1.5411\n",
      "Epoch 1856/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2018 - val_loss: 1.5409\n",
      "Epoch 1857/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2016 - val_loss: 1.5407\n",
      "Epoch 1858/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2014 - val_loss: 1.5405\n",
      "Epoch 1859/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2012 - val_loss: 1.5402\n",
      "Epoch 1860/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2010 - val_loss: 1.5400\n",
      "Epoch 1861/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.2008 - val_loss: 1.5398\n",
      "Epoch 1862/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2006 - val_loss: 1.5396\n",
      "Epoch 1863/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.2004 - val_loss: 1.5394\n",
      "Epoch 1864/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2002 - val_loss: 1.5391\n",
      "Epoch 1865/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.2000 - val_loss: 1.5389\n",
      "Epoch 1866/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1998 - val_loss: 1.5387\n",
      "Epoch 1867/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1996 - val_loss: 1.5385\n",
      "Epoch 1868/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1994 - val_loss: 1.5383\n",
      "Epoch 1869/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1992 - val_loss: 1.5381\n",
      "Epoch 1870/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1991 - val_loss: 1.5378\n",
      "Epoch 1871/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1989 - val_loss: 1.5376\n",
      "Epoch 1872/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.1987 - val_loss: 1.5374\n",
      "Epoch 1873/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1985 - val_loss: 1.5372\n",
      "Epoch 1874/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1983 - val_loss: 1.5370\n",
      "Epoch 1875/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1981 - val_loss: 1.5367\n",
      "Epoch 1876/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1979 - val_loss: 1.5365\n",
      "Epoch 1877/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1977 - val_loss: 1.5363\n",
      "Epoch 1878/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1975 - val_loss: 1.5361\n",
      "Epoch 1879/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1973 - val_loss: 1.5359\n",
      "Epoch 1880/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1971 - val_loss: 1.5356\n",
      "Epoch 1881/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1969 - val_loss: 1.5354\n",
      "Epoch 1882/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 1.1967 - val_loss: 1.5352\n",
      "Epoch 1883/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1966 - val_loss: 1.5350\n",
      "Epoch 1884/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 1.1964 - val_loss: 1.5348\n",
      "Epoch 1885/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1962 - val_loss: 1.5346\n",
      "Epoch 1886/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1960 - val_loss: 1.5343\n",
      "Epoch 1887/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1958 - val_loss: 1.5341\n",
      "Epoch 1888/2500\n",
      "64/64 [==============================] - 0s 407us/step - loss: 1.1956 - val_loss: 1.5339\n",
      "Epoch 1889/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1954 - val_loss: 1.5337\n",
      "Epoch 1890/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 1.1952 - val_loss: 1.5335\n",
      "Epoch 1891/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1950 - val_loss: 1.5332\n",
      "Epoch 1892/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1948 - val_loss: 1.5330\n",
      "Epoch 1893/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1947 - val_loss: 1.5328\n",
      "Epoch 1894/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1945 - val_loss: 1.5326\n",
      "Epoch 1895/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1943 - val_loss: 1.5324\n",
      "Epoch 1896/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1941 - val_loss: 1.5321\n",
      "Epoch 1897/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 1.1939 - val_loss: 1.5319\n",
      "Epoch 1898/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1937 - val_loss: 1.5317\n",
      "Epoch 1899/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.1935 - val_loss: 1.5315\n",
      "Epoch 1900/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.1933 - val_loss: 1.5313\n",
      "Epoch 1901/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1931 - val_loss: 1.5311\n",
      "Epoch 1902/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1930 - val_loss: 1.5308\n",
      "Epoch 1903/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.1928 - val_loss: 1.5306\n",
      "Epoch 1904/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1926 - val_loss: 1.5304\n",
      "Epoch 1905/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1924 - val_loss: 1.5302\n",
      "Epoch 1906/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1922 - val_loss: 1.5300\n",
      "Epoch 1907/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.1920 - val_loss: 1.5297\n",
      "Epoch 1908/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1918 - val_loss: 1.5295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1909/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1916 - val_loss: 1.5293\n",
      "Epoch 1910/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.1915 - val_loss: 1.5291\n",
      "Epoch 1911/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.1913 - val_loss: 1.5289\n",
      "Epoch 1912/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1911 - val_loss: 1.5286\n",
      "Epoch 1913/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1909 - val_loss: 1.5284\n",
      "Epoch 1914/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1907 - val_loss: 1.5282\n",
      "Epoch 1915/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1905 - val_loss: 1.5280\n",
      "Epoch 1916/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.1903 - val_loss: 1.5278\n",
      "Epoch 1917/2500\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 1.1901 - val_loss: 1.5276\n",
      "Epoch 1918/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.1900 - val_loss: 1.5273\n",
      "Epoch 1919/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.1898 - val_loss: 1.5271\n",
      "Epoch 1920/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1896 - val_loss: 1.5269\n",
      "Epoch 1921/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.1894 - val_loss: 1.5267\n",
      "Epoch 1922/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1892 - val_loss: 1.5265\n",
      "Epoch 1923/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1890 - val_loss: 1.5262\n",
      "Epoch 1924/2500\n",
      "64/64 [==============================] - 0s 247us/step - loss: 1.1888 - val_loss: 1.5260\n",
      "Epoch 1925/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1887 - val_loss: 1.5258\n",
      "Epoch 1926/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1885 - val_loss: 1.5256\n",
      "Epoch 1927/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1883 - val_loss: 1.5254\n",
      "Epoch 1928/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 1.1881 - val_loss: 1.5252\n",
      "Epoch 1929/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.1879 - val_loss: 1.5249\n",
      "Epoch 1930/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1877 - val_loss: 1.5247\n",
      "Epoch 1931/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1875 - val_loss: 1.5245\n",
      "Epoch 1932/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1874 - val_loss: 1.5243\n",
      "Epoch 1933/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1872 - val_loss: 1.5241\n",
      "Epoch 1934/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1870 - val_loss: 1.5238\n",
      "Epoch 1935/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1868 - val_loss: 1.5236\n",
      "Epoch 1936/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.1866 - val_loss: 1.5234\n",
      "Epoch 1937/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1864 - val_loss: 1.5232\n",
      "Epoch 1938/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1863 - val_loss: 1.5230\n",
      "Epoch 1939/2500\n",
      "64/64 [==============================] - 0s 418us/step - loss: 1.1861 - val_loss: 1.5227\n",
      "Epoch 1940/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1859 - val_loss: 1.5225\n",
      "Epoch 1941/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1857 - val_loss: 1.5223\n",
      "Epoch 1942/2500\n",
      "64/64 [==============================] - 0s 983us/step - loss: 1.1855 - val_loss: 1.5221\n",
      "Epoch 1943/2500\n",
      "64/64 [==============================] - 0s 479us/step - loss: 1.1853 - val_loss: 1.5219\n",
      "Epoch 1944/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 1.1852 - val_loss: 1.5217\n",
      "Epoch 1945/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1850 - val_loss: 1.5214\n",
      "Epoch 1946/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.1848 - val_loss: 1.5212\n",
      "Epoch 1947/2500\n",
      "64/64 [==============================] - 0s 326us/step - loss: 1.1846 - val_loss: 1.5210\n",
      "Epoch 1948/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1844 - val_loss: 1.5208\n",
      "Epoch 1949/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1842 - val_loss: 1.5206\n",
      "Epoch 1950/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.1841 - val_loss: 1.5203\n",
      "Epoch 1951/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1839 - val_loss: 1.5201\n",
      "Epoch 1952/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1837 - val_loss: 1.5199\n",
      "Epoch 1953/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 1.1835 - val_loss: 1.5197\n",
      "Epoch 1954/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1833 - val_loss: 1.5195\n",
      "Epoch 1955/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1832 - val_loss: 1.5193\n",
      "Epoch 1956/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.1830 - val_loss: 1.5190\n",
      "Epoch 1957/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1828 - val_loss: 1.5188\n",
      "Epoch 1958/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1826 - val_loss: 1.5186\n",
      "Epoch 1959/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1824 - val_loss: 1.5184\n",
      "Epoch 1960/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1822 - val_loss: 1.5182\n",
      "Epoch 1961/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1821 - val_loss: 1.5179\n",
      "Epoch 1962/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1819 - val_loss: 1.5177\n",
      "Epoch 1963/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1817 - val_loss: 1.5175\n",
      "Epoch 1964/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.1815 - val_loss: 1.5173\n",
      "Epoch 1965/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1813 - val_loss: 1.5171\n",
      "Epoch 1966/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1812 - val_loss: 1.5168\n",
      "Epoch 1967/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1810 - val_loss: 1.5166\n",
      "Epoch 1968/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1808 - val_loss: 1.5164\n",
      "Epoch 1969/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1806 - val_loss: 1.5162\n",
      "Epoch 1970/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.1804 - val_loss: 1.5160\n",
      "Epoch 1971/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1803 - val_loss: 1.5158\n",
      "Epoch 1972/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1801 - val_loss: 1.5155\n",
      "Epoch 1973/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1799 - val_loss: 1.5153\n",
      "Epoch 1974/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.1797 - val_loss: 1.5151\n",
      "Epoch 1975/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1795 - val_loss: 1.5149\n",
      "Epoch 1976/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1793 - val_loss: 1.5147\n",
      "Epoch 1977/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1792 - val_loss: 1.5144\n",
      "Epoch 1978/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1790 - val_loss: 1.5142\n",
      "Epoch 1979/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.1788 - val_loss: 1.5140\n",
      "Epoch 1980/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.1787 - val_loss: 1.5138\n",
      "Epoch 1981/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1784 - val_loss: 1.5136\n",
      "Epoch 1982/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1783 - val_loss: 1.5133\n",
      "Epoch 1983/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1781 - val_loss: 1.5131\n",
      "Epoch 1984/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1779 - val_loss: 1.5129\n",
      "Epoch 1985/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1778 - val_loss: 1.5127\n",
      "Epoch 1986/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1776 - val_loss: 1.5125\n",
      "Epoch 1987/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1774 - val_loss: 1.5123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1988/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1772 - val_loss: 1.5120\n",
      "Epoch 1989/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1771 - val_loss: 1.5118\n",
      "Epoch 1990/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1769 - val_loss: 1.5116\n",
      "Epoch 1991/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 1.1767 - val_loss: 1.5114\n",
      "Epoch 1992/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.1765 - val_loss: 1.5112\n",
      "Epoch 1993/2500\n",
      "64/64 [==============================] - 0s 365us/step - loss: 1.1763 - val_loss: 1.5109\n",
      "Epoch 1994/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1762 - val_loss: 1.5107\n",
      "Epoch 1995/2500\n",
      "64/64 [==============================] - 0s 430us/step - loss: 1.1760 - val_loss: 1.5105\n",
      "Epoch 1996/2500\n",
      "64/64 [==============================] - 0s 503us/step - loss: 1.1758 - val_loss: 1.5103\n",
      "Epoch 1997/2500\n",
      "64/64 [==============================] - 0s 410us/step - loss: 1.1756 - val_loss: 1.5101\n",
      "Epoch 1998/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1755 - val_loss: 1.5098\n",
      "Epoch 1999/2500\n",
      "64/64 [==============================] - 0s 370us/step - loss: 1.1753 - val_loss: 1.5096\n",
      "Epoch 2000/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 1.1751 - val_loss: 1.5094\n",
      "Epoch 2001/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1749 - val_loss: 1.5092\n",
      "Epoch 2002/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1748 - val_loss: 1.5090\n",
      "Epoch 2003/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 1.1746 - val_loss: 1.5088\n",
      "Epoch 2004/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.1744 - val_loss: 1.5085\n",
      "Epoch 2005/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1742 - val_loss: 1.5083\n",
      "Epoch 2006/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 1.1741 - val_loss: 1.5081\n",
      "Epoch 2007/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1739 - val_loss: 1.5079\n",
      "Epoch 2008/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1737 - val_loss: 1.5077\n",
      "Epoch 2009/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1735 - val_loss: 1.5074\n",
      "Epoch 2010/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1733 - val_loss: 1.5072\n",
      "Epoch 2011/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1732 - val_loss: 1.5070\n",
      "Epoch 2012/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1730 - val_loss: 1.5068\n",
      "Epoch 2013/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1728 - val_loss: 1.5066\n",
      "Epoch 2014/2500\n",
      "64/64 [==============================] - 0s 305us/step - loss: 1.1726 - val_loss: 1.5063\n",
      "Epoch 2015/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1725 - val_loss: 1.5061\n",
      "Epoch 2016/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.1723 - val_loss: 1.5059\n",
      "Epoch 2017/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1721 - val_loss: 1.5057\n",
      "Epoch 2018/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1720 - val_loss: 1.5055\n",
      "Epoch 2019/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1718 - val_loss: 1.5052\n",
      "Epoch 2020/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 1.1716 - val_loss: 1.5050\n",
      "Epoch 2021/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1714 - val_loss: 1.5048\n",
      "Epoch 2022/2500\n",
      "64/64 [==============================] - 0s 481us/step - loss: 1.1713 - val_loss: 1.5046\n",
      "Epoch 2023/2500\n",
      "64/64 [==============================] - 0s 209us/step - loss: 1.1711 - val_loss: 1.5044\n",
      "Epoch 2024/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1709 - val_loss: 1.5042\n",
      "Epoch 2025/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1707 - val_loss: 1.5039\n",
      "Epoch 2026/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 1.1706 - val_loss: 1.5037\n",
      "Epoch 2027/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1704 - val_loss: 1.5035\n",
      "Epoch 2028/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.1702 - val_loss: 1.5033\n",
      "Epoch 2029/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1700 - val_loss: 1.5031\n",
      "Epoch 2030/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1699 - val_loss: 1.5028\n",
      "Epoch 2031/2500\n",
      "64/64 [==============================] - 0s 497us/step - loss: 1.1697 - val_loss: 1.5026\n",
      "Epoch 2032/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1695 - val_loss: 1.5024\n",
      "Epoch 2033/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.1694 - val_loss: 1.5022\n",
      "Epoch 2034/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1692 - val_loss: 1.5020\n",
      "Epoch 2035/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 1.1690 - val_loss: 1.5017\n",
      "Epoch 2036/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1688 - val_loss: 1.5015\n",
      "Epoch 2037/2500\n",
      "64/64 [==============================] - 0s 317us/step - loss: 1.1687 - val_loss: 1.5013\n",
      "Epoch 2038/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1685 - val_loss: 1.5011\n",
      "Epoch 2039/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1683 - val_loss: 1.5009\n",
      "Epoch 2040/2500\n",
      "64/64 [==============================] - 0s 330us/step - loss: 1.1681 - val_loss: 1.5006\n",
      "Epoch 2041/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1680 - val_loss: 1.5004\n",
      "Epoch 2042/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.1678 - val_loss: 1.5002\n",
      "Epoch 2043/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1676 - val_loss: 1.5000\n",
      "Epoch 2044/2500\n",
      "64/64 [==============================] - 0s 246us/step - loss: 1.1675 - val_loss: 1.4998\n",
      "Epoch 2045/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.1673 - val_loss: 1.4995\n",
      "Epoch 2046/2500\n",
      "64/64 [==============================] - 0s 300us/step - loss: 1.1671 - val_loss: 1.4993\n",
      "Epoch 2047/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1669 - val_loss: 1.4991\n",
      "Epoch 2048/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1668 - val_loss: 1.4989\n",
      "Epoch 2049/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1666 - val_loss: 1.4987\n",
      "Epoch 2050/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1664 - val_loss: 1.4984\n",
      "Epoch 2051/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1663 - val_loss: 1.4982\n",
      "Epoch 2052/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1661 - val_loss: 1.4980\n",
      "Epoch 2053/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1659 - val_loss: 1.4978\n",
      "Epoch 2054/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 1.1658 - val_loss: 1.4976\n",
      "Epoch 2055/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1656 - val_loss: 1.4973\n",
      "Epoch 2056/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 1.1654 - val_loss: 1.4971\n",
      "Epoch 2057/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1652 - val_loss: 1.4969\n",
      "Epoch 2058/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1651 - val_loss: 1.4967\n",
      "Epoch 2059/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1649 - val_loss: 1.4965\n",
      "Epoch 2060/2500\n",
      "64/64 [==============================] - 0s 311us/step - loss: 1.1647 - val_loss: 1.4962\n",
      "Epoch 2061/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1646 - val_loss: 1.4960\n",
      "Epoch 2062/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1644 - val_loss: 1.4958\n",
      "Epoch 2063/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.1642 - val_loss: 1.4956\n",
      "Epoch 2064/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1641 - val_loss: 1.4954\n",
      "Epoch 2065/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1639 - val_loss: 1.4951\n",
      "Epoch 2066/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1637 - val_loss: 1.4949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2067/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.1635 - val_loss: 1.4947\n",
      "Epoch 2068/2500\n",
      "64/64 [==============================] - 0s 238us/step - loss: 1.1634 - val_loss: 1.4945\n",
      "Epoch 2069/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1632 - val_loss: 1.4943\n",
      "Epoch 2070/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.1630 - val_loss: 1.4940\n",
      "Epoch 2071/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.1629 - val_loss: 1.4938\n",
      "Epoch 2072/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1627 - val_loss: 1.4936\n",
      "Epoch 2073/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1625 - val_loss: 1.4934\n",
      "Epoch 2074/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1624 - val_loss: 1.4932\n",
      "Epoch 2075/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1622 - val_loss: 1.4929\n",
      "Epoch 2076/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1620 - val_loss: 1.4927\n",
      "Epoch 2077/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1619 - val_loss: 1.4925\n",
      "Epoch 2078/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1617 - val_loss: 1.4923\n",
      "Epoch 2079/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1615 - val_loss: 1.4921\n",
      "Epoch 2080/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1614 - val_loss: 1.4918\n",
      "Epoch 2081/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.1612 - val_loss: 1.4916\n",
      "Epoch 2082/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1610 - val_loss: 1.4914\n",
      "Epoch 2083/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1609 - val_loss: 1.4912\n",
      "Epoch 2084/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1607 - val_loss: 1.4910\n",
      "Epoch 2085/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1605 - val_loss: 1.4907\n",
      "Epoch 2086/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1604 - val_loss: 1.4905\n",
      "Epoch 2087/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1602 - val_loss: 1.4903\n",
      "Epoch 2088/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.1600 - val_loss: 1.4901\n",
      "Epoch 2089/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1599 - val_loss: 1.4899\n",
      "Epoch 2090/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 1.1597 - val_loss: 1.4896\n",
      "Epoch 2091/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.1595 - val_loss: 1.4894\n",
      "Epoch 2092/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.1594 - val_loss: 1.4892\n",
      "Epoch 2093/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.1592 - val_loss: 1.4890\n",
      "Epoch 2094/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1590 - val_loss: 1.4888\n",
      "Epoch 2095/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.1589 - val_loss: 1.4885\n",
      "Epoch 2096/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1587 - val_loss: 1.4883\n",
      "Epoch 2097/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1585 - val_loss: 1.4881\n",
      "Epoch 2098/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1584 - val_loss: 1.4879\n",
      "Epoch 2099/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.1582 - val_loss: 1.4876\n",
      "Epoch 2100/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1580 - val_loss: 1.4874\n",
      "Epoch 2101/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1579 - val_loss: 1.4872\n",
      "Epoch 2102/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 1.1577 - val_loss: 1.4870\n",
      "Epoch 2103/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1575 - val_loss: 1.4868\n",
      "Epoch 2104/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1574 - val_loss: 1.4865\n",
      "Epoch 2105/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1572 - val_loss: 1.4863\n",
      "Epoch 2106/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.1570 - val_loss: 1.4861\n",
      "Epoch 2107/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 1.1569 - val_loss: 1.4859\n",
      "Epoch 2108/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.1567 - val_loss: 1.4857\n",
      "Epoch 2109/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1566 - val_loss: 1.4854\n",
      "Epoch 2110/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1564 - val_loss: 1.4852\n",
      "Epoch 2111/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1562 - val_loss: 1.4850\n",
      "Epoch 2112/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1561 - val_loss: 1.4848\n",
      "Epoch 2113/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1559 - val_loss: 1.4845\n",
      "Epoch 2114/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1557 - val_loss: 1.4843\n",
      "Epoch 2115/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1556 - val_loss: 1.4841\n",
      "Epoch 2116/2500\n",
      "64/64 [==============================] - 0s 393us/step - loss: 1.1554 - val_loss: 1.4839\n",
      "Epoch 2117/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1552 - val_loss: 1.4837\n",
      "Epoch 2118/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.1551 - val_loss: 1.4834\n",
      "Epoch 2119/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1549 - val_loss: 1.4832\n",
      "Epoch 2120/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1547 - val_loss: 1.4830\n",
      "Epoch 2121/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.1546 - val_loss: 1.4828\n",
      "Epoch 2122/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1544 - val_loss: 1.4826\n",
      "Epoch 2123/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1543 - val_loss: 1.4823\n",
      "Epoch 2124/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1541 - val_loss: 1.4821\n",
      "Epoch 2125/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1539 - val_loss: 1.4819\n",
      "Epoch 2126/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1538 - val_loss: 1.4817\n",
      "Epoch 2127/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1536 - val_loss: 1.4814\n",
      "Epoch 2128/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.1534 - val_loss: 1.4812\n",
      "Epoch 2129/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1533 - val_loss: 1.4810\n",
      "Epoch 2130/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1531 - val_loss: 1.4808\n",
      "Epoch 2131/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1530 - val_loss: 1.4806\n",
      "Epoch 2132/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1528 - val_loss: 1.4803\n",
      "Epoch 2133/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.1526 - val_loss: 1.4801\n",
      "Epoch 2134/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.1525 - val_loss: 1.4799\n",
      "Epoch 2135/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.1523 - val_loss: 1.4797\n",
      "Epoch 2136/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1521 - val_loss: 1.4794\n",
      "Epoch 2137/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1520 - val_loss: 1.4792\n",
      "Epoch 2138/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1518 - val_loss: 1.4790\n",
      "Epoch 2139/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1516 - val_loss: 1.4788\n",
      "Epoch 2140/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1515 - val_loss: 1.4786\n",
      "Epoch 2141/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1513 - val_loss: 1.4783\n",
      "Epoch 2142/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1512 - val_loss: 1.4781\n",
      "Epoch 2143/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1510 - val_loss: 1.4779\n",
      "Epoch 2144/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.1509 - val_loss: 1.4777\n",
      "Epoch 2145/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1507 - val_loss: 1.4774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2146/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.1505 - val_loss: 1.4772\n",
      "Epoch 2147/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1504 - val_loss: 1.4770\n",
      "Epoch 2148/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1502 - val_loss: 1.4768\n",
      "Epoch 2149/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1500 - val_loss: 1.4766\n",
      "Epoch 2150/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1499 - val_loss: 1.4763\n",
      "Epoch 2151/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.1497 - val_loss: 1.4761\n",
      "Epoch 2152/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.1496 - val_loss: 1.4759\n",
      "Epoch 2153/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1494 - val_loss: 1.4757\n",
      "Epoch 2154/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1492 - val_loss: 1.4754\n",
      "Epoch 2155/2500\n",
      "64/64 [==============================] - 0s 203us/step - loss: 1.1491 - val_loss: 1.4752\n",
      "Epoch 2156/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1489 - val_loss: 1.4750\n",
      "Epoch 2157/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1487 - val_loss: 1.4748\n",
      "Epoch 2158/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1486 - val_loss: 1.4745\n",
      "Epoch 2159/2500\n",
      "64/64 [==============================] - 0s 276us/step - loss: 1.1484 - val_loss: 1.4743\n",
      "Epoch 2160/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1483 - val_loss: 1.4741\n",
      "Epoch 2161/2500\n",
      "64/64 [==============================] - 0s 286us/step - loss: 1.1481 - val_loss: 1.4739\n",
      "Epoch 2162/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1480 - val_loss: 1.4737\n",
      "Epoch 2163/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1478 - val_loss: 1.4734\n",
      "Epoch 2164/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.1477 - val_loss: 1.4732\n",
      "Epoch 2165/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1475 - val_loss: 1.4730\n",
      "Epoch 2166/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1473 - val_loss: 1.4728\n",
      "Epoch 2167/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.1472 - val_loss: 1.4725\n",
      "Epoch 2168/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.1470 - val_loss: 1.4723\n",
      "Epoch 2169/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1469 - val_loss: 1.4721\n",
      "Epoch 2170/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 1.1467 - val_loss: 1.4719\n",
      "Epoch 2171/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1465 - val_loss: 1.4716\n",
      "Epoch 2172/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.1464 - val_loss: 1.4714\n",
      "Epoch 2173/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1462 - val_loss: 1.4712\n",
      "Epoch 2174/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1461 - val_loss: 1.4710\n",
      "Epoch 2175/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1459 - val_loss: 1.4708\n",
      "Epoch 2176/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1457 - val_loss: 1.4705\n",
      "Epoch 2177/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1456 - val_loss: 1.4703\n",
      "Epoch 2178/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1454 - val_loss: 1.4701\n",
      "Epoch 2179/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.1453 - val_loss: 1.4699\n",
      "Epoch 2180/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1451 - val_loss: 1.4696\n",
      "Epoch 2181/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1450 - val_loss: 1.4694\n",
      "Epoch 2182/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1448 - val_loss: 1.4692\n",
      "Epoch 2183/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1446 - val_loss: 1.4690\n",
      "Epoch 2184/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.1445 - val_loss: 1.4687\n",
      "Epoch 2185/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1443 - val_loss: 1.4685\n",
      "Epoch 2186/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1442 - val_loss: 1.4683\n",
      "Epoch 2187/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1440 - val_loss: 1.4681\n",
      "Epoch 2188/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 1.1439 - val_loss: 1.4678\n",
      "Epoch 2189/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1437 - val_loss: 1.4676\n",
      "Epoch 2190/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1435 - val_loss: 1.4674\n",
      "Epoch 2191/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.1434 - val_loss: 1.4672\n",
      "Epoch 2192/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1432 - val_loss: 1.4670\n",
      "Epoch 2193/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1431 - val_loss: 1.4667\n",
      "Epoch 2194/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1429 - val_loss: 1.4665\n",
      "Epoch 2195/2500\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.1428 - val_loss: 1.4663\n",
      "Epoch 2196/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1426 - val_loss: 1.4661\n",
      "Epoch 2197/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1425 - val_loss: 1.4658\n",
      "Epoch 2198/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1423 - val_loss: 1.4656\n",
      "Epoch 2199/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 1.1421 - val_loss: 1.4654\n",
      "Epoch 2200/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1420 - val_loss: 1.4652\n",
      "Epoch 2201/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.1418 - val_loss: 1.4649\n",
      "Epoch 2202/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1417 - val_loss: 1.4647\n",
      "Epoch 2203/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1415 - val_loss: 1.4645\n",
      "Epoch 2204/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1414 - val_loss: 1.4643\n",
      "Epoch 2205/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1412 - val_loss: 1.4640\n",
      "Epoch 2206/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1411 - val_loss: 1.4638\n",
      "Epoch 2207/2500\n",
      "64/64 [==============================] - 0s 276us/step - loss: 1.1409 - val_loss: 1.4636\n",
      "Epoch 2208/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1407 - val_loss: 1.4634\n",
      "Epoch 2209/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.1406 - val_loss: 1.4631\n",
      "Epoch 2210/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1404 - val_loss: 1.4629\n",
      "Epoch 2211/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.1403 - val_loss: 1.4627\n",
      "Epoch 2212/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1401 - val_loss: 1.4625\n",
      "Epoch 2213/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1400 - val_loss: 1.4622\n",
      "Epoch 2214/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.1398 - val_loss: 1.4620\n",
      "Epoch 2215/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.1397 - val_loss: 1.4618\n",
      "Epoch 2216/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1395 - val_loss: 1.4616\n",
      "Epoch 2217/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1393 - val_loss: 1.4613\n",
      "Epoch 2218/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1392 - val_loss: 1.4611\n",
      "Epoch 2219/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1390 - val_loss: 1.4609\n",
      "Epoch 2220/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1389 - val_loss: 1.4607\n",
      "Epoch 2221/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1387 - val_loss: 1.4604\n",
      "Epoch 2222/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.1386 - val_loss: 1.4602\n",
      "Epoch 2223/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1384 - val_loss: 1.4600\n",
      "Epoch 2224/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1383 - val_loss: 1.4597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2225/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1381 - val_loss: 1.4595\n",
      "Epoch 2226/2500\n",
      "64/64 [==============================] - 0s 344us/step - loss: 1.1380 - val_loss: 1.4593\n",
      "Epoch 2227/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1378 - val_loss: 1.4591\n",
      "Epoch 2228/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1377 - val_loss: 1.4588\n",
      "Epoch 2229/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1375 - val_loss: 1.4586\n",
      "Epoch 2230/2500\n",
      "64/64 [==============================] - 0s 312us/step - loss: 1.1374 - val_loss: 1.4584\n",
      "Epoch 2231/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1372 - val_loss: 1.4582\n",
      "Epoch 2232/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1370 - val_loss: 1.4579\n",
      "Epoch 2233/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 1.1369 - val_loss: 1.4577\n",
      "Epoch 2234/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1367 - val_loss: 1.4575\n",
      "Epoch 2235/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.1366 - val_loss: 1.4573\n",
      "Epoch 2236/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1364 - val_loss: 1.4570\n",
      "Epoch 2237/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1363 - val_loss: 1.4568\n",
      "Epoch 2238/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1361 - val_loss: 1.4566\n",
      "Epoch 2239/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 1.1360 - val_loss: 1.4564\n",
      "Epoch 2240/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1358 - val_loss: 1.4561\n",
      "Epoch 2241/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1357 - val_loss: 1.4559\n",
      "Epoch 2242/2500\n",
      "64/64 [==============================] - 0s 227us/step - loss: 1.1355 - val_loss: 1.4557\n",
      "Epoch 2243/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1354 - val_loss: 1.4555\n",
      "Epoch 2244/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1352 - val_loss: 1.4552\n",
      "Epoch 2245/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.1351 - val_loss: 1.4550\n",
      "Epoch 2246/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1349 - val_loss: 1.4548\n",
      "Epoch 2247/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1348 - val_loss: 1.4546\n",
      "Epoch 2248/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.1346 - val_loss: 1.4543\n",
      "Epoch 2249/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.1345 - val_loss: 1.4541\n",
      "Epoch 2250/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1343 - val_loss: 1.4539\n",
      "Epoch 2251/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1342 - val_loss: 1.4537\n",
      "Epoch 2252/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1340 - val_loss: 1.4534\n",
      "Epoch 2253/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 1.1339 - val_loss: 1.4532\n",
      "Epoch 2254/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1337 - val_loss: 1.4530\n",
      "Epoch 2255/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1336 - val_loss: 1.4527\n",
      "Epoch 2256/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1334 - val_loss: 1.4525\n",
      "Epoch 2257/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.1333 - val_loss: 1.4523\n",
      "Epoch 2258/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1331 - val_loss: 1.4521\n",
      "Epoch 2259/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1330 - val_loss: 1.4518\n",
      "Epoch 2260/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1328 - val_loss: 1.4516\n",
      "Epoch 2261/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1327 - val_loss: 1.4514\n",
      "Epoch 2262/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1325 - val_loss: 1.4512\n",
      "Epoch 2263/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1324 - val_loss: 1.4509\n",
      "Epoch 2264/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.1322 - val_loss: 1.4507\n",
      "Epoch 2265/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1321 - val_loss: 1.4505\n",
      "Epoch 2266/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1319 - val_loss: 1.4503\n",
      "Epoch 2267/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1318 - val_loss: 1.4500\n",
      "Epoch 2268/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1316 - val_loss: 1.4498\n",
      "Epoch 2269/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1315 - val_loss: 1.4496\n",
      "Epoch 2270/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1313 - val_loss: 1.4494\n",
      "Epoch 2271/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1312 - val_loss: 1.4491\n",
      "Epoch 2272/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1310 - val_loss: 1.4489\n",
      "Epoch 2273/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1309 - val_loss: 1.4487\n",
      "Epoch 2274/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1307 - val_loss: 1.4484\n",
      "Epoch 2275/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1306 - val_loss: 1.4482\n",
      "Epoch 2276/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.1304 - val_loss: 1.4480\n",
      "Epoch 2277/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.1303 - val_loss: 1.4478\n",
      "Epoch 2278/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1301 - val_loss: 1.4475\n",
      "Epoch 2279/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1300 - val_loss: 1.4473\n",
      "Epoch 2280/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1298 - val_loss: 1.4471\n",
      "Epoch 2281/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1297 - val_loss: 1.4469\n",
      "Epoch 2282/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1295 - val_loss: 1.4466\n",
      "Epoch 2283/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1294 - val_loss: 1.4464\n",
      "Epoch 2284/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 1.1292 - val_loss: 1.4462\n",
      "Epoch 2285/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1291 - val_loss: 1.4459\n",
      "Epoch 2286/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.1289 - val_loss: 1.4457\n",
      "Epoch 2287/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.1288 - val_loss: 1.4455\n",
      "Epoch 2288/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1286 - val_loss: 1.4453\n",
      "Epoch 2289/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1285 - val_loss: 1.4450\n",
      "Epoch 2290/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 1.1283 - val_loss: 1.4448\n",
      "Epoch 2291/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1282 - val_loss: 1.4446\n",
      "Epoch 2292/2500\n",
      "64/64 [==============================] - 0s 377us/step - loss: 1.1280 - val_loss: 1.4444\n",
      "Epoch 2293/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1279 - val_loss: 1.4441\n",
      "Epoch 2294/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1277 - val_loss: 1.4439\n",
      "Epoch 2295/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.1276 - val_loss: 1.4437\n",
      "Epoch 2296/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1274 - val_loss: 1.4434\n",
      "Epoch 2297/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1273 - val_loss: 1.4432\n",
      "Epoch 2298/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.1272 - val_loss: 1.4430\n",
      "Epoch 2299/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1270 - val_loss: 1.4428\n",
      "Epoch 2300/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1269 - val_loss: 1.4425\n",
      "Epoch 2301/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1267 - val_loss: 1.4423\n",
      "Epoch 2302/2500\n",
      "64/64 [==============================] - 0s 443us/step - loss: 1.1266 - val_loss: 1.4421\n",
      "Epoch 2303/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1264 - val_loss: 1.4419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2304/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 1.1263 - val_loss: 1.4416\n",
      "Epoch 2305/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1261 - val_loss: 1.4414\n",
      "Epoch 2306/2500\n",
      "64/64 [==============================] - 0s 511us/step - loss: 1.1260 - val_loss: 1.4412\n",
      "Epoch 2307/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1258 - val_loss: 1.4409\n",
      "Epoch 2308/2500\n",
      "64/64 [==============================] - 0s 487us/step - loss: 1.1257 - val_loss: 1.4407\n",
      "Epoch 2309/2500\n",
      "64/64 [==============================] - 0s 540us/step - loss: 1.1255 - val_loss: 1.4405\n",
      "Epoch 2310/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 1.1254 - val_loss: 1.4403\n",
      "Epoch 2311/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1253 - val_loss: 1.4400\n",
      "Epoch 2312/2500\n",
      "64/64 [==============================] - 0s 481us/step - loss: 1.1251 - val_loss: 1.4398\n",
      "Epoch 2313/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 1.1250 - val_loss: 1.4396\n",
      "Epoch 2314/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1248 - val_loss: 1.4394\n",
      "Epoch 2315/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1247 - val_loss: 1.4391\n",
      "Epoch 2316/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1245 - val_loss: 1.4389\n",
      "Epoch 2317/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.1244 - val_loss: 1.4387\n",
      "Epoch 2318/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1242 - val_loss: 1.4384\n",
      "Epoch 2319/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1241 - val_loss: 1.4382\n",
      "Epoch 2320/2500\n",
      "64/64 [==============================] - 0s 411us/step - loss: 1.1239 - val_loss: 1.4380\n",
      "Epoch 2321/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.1238 - val_loss: 1.4378\n",
      "Epoch 2322/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1237 - val_loss: 1.4375\n",
      "Epoch 2323/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1235 - val_loss: 1.4373\n",
      "Epoch 2324/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1234 - val_loss: 1.4371\n",
      "Epoch 2325/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.1232 - val_loss: 1.4369\n",
      "Epoch 2326/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1231 - val_loss: 1.4366\n",
      "Epoch 2327/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1229 - val_loss: 1.4364\n",
      "Epoch 2328/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 1.1228 - val_loss: 1.4362\n",
      "Epoch 2329/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1226 - val_loss: 1.4359\n",
      "Epoch 2330/2500\n",
      "64/64 [==============================] - 0s 375us/step - loss: 1.1225 - val_loss: 1.4357\n",
      "Epoch 2331/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1224 - val_loss: 1.4355\n",
      "Epoch 2332/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1222 - val_loss: 1.4353\n",
      "Epoch 2333/2500\n",
      "64/64 [==============================] - 0s 406us/step - loss: 1.1221 - val_loss: 1.4350\n",
      "Epoch 2334/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1219 - val_loss: 1.4348\n",
      "Epoch 2335/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1218 - val_loss: 1.4346\n",
      "Epoch 2336/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1216 - val_loss: 1.4343\n",
      "Epoch 2337/2500\n",
      "64/64 [==============================] - 0s 342us/step - loss: 1.1215 - val_loss: 1.4341\n",
      "Epoch 2338/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1213 - val_loss: 1.4339\n",
      "Epoch 2339/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 1.1212 - val_loss: 1.4337\n",
      "Epoch 2340/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.1211 - val_loss: 1.4334\n",
      "Epoch 2341/2500\n",
      "64/64 [==============================] - 0s 508us/step - loss: 1.1209 - val_loss: 1.4332\n",
      "Epoch 2342/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 1.1208 - val_loss: 1.4330\n",
      "Epoch 2343/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1206 - val_loss: 1.4328\n",
      "Epoch 2344/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1205 - val_loss: 1.4325\n",
      "Epoch 2345/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 1.1203 - val_loss: 1.4323\n",
      "Epoch 2346/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1202 - val_loss: 1.4321\n",
      "Epoch 2347/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 1.1201 - val_loss: 1.4318\n",
      "Epoch 2348/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1199 - val_loss: 1.4316\n",
      "Epoch 2349/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1198 - val_loss: 1.4314\n",
      "Epoch 2350/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1196 - val_loss: 1.4312\n",
      "Epoch 2351/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.1195 - val_loss: 1.4309\n",
      "Epoch 2352/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1193 - val_loss: 1.4307\n",
      "Epoch 2353/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1192 - val_loss: 1.4305\n",
      "Epoch 2354/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 1.1191 - val_loss: 1.4303\n",
      "Epoch 2355/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.1189 - val_loss: 1.4300\n",
      "Epoch 2356/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 1.1188 - val_loss: 1.4298\n",
      "Epoch 2357/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1186 - val_loss: 1.4296\n",
      "Epoch 2358/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1185 - val_loss: 1.4293\n",
      "Epoch 2359/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1184 - val_loss: 1.4291\n",
      "Epoch 2360/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 1.1182 - val_loss: 1.4289\n",
      "Epoch 2361/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1181 - val_loss: 1.4287\n",
      "Epoch 2362/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1179 - val_loss: 1.4284\n",
      "Epoch 2363/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1178 - val_loss: 1.4282\n",
      "Epoch 2364/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1176 - val_loss: 1.4280\n",
      "Epoch 2365/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.1175 - val_loss: 1.4278\n",
      "Epoch 2366/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1174 - val_loss: 1.4275\n",
      "Epoch 2367/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1172 - val_loss: 1.4273\n",
      "Epoch 2368/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1171 - val_loss: 1.4271\n",
      "Epoch 2369/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1169 - val_loss: 1.4268\n",
      "Epoch 2370/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 1.1168 - val_loss: 1.4266\n",
      "Epoch 2371/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1167 - val_loss: 1.4264\n",
      "Epoch 2372/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1165 - val_loss: 1.4262\n",
      "Epoch 2373/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.1164 - val_loss: 1.4259\n",
      "Epoch 2374/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1162 - val_loss: 1.4257\n",
      "Epoch 2375/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1161 - val_loss: 1.4255\n",
      "Epoch 2376/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1160 - val_loss: 1.4253\n",
      "Epoch 2377/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 1.1158 - val_loss: 1.4250\n",
      "Epoch 2378/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1157 - val_loss: 1.4248\n",
      "Epoch 2379/2500\n",
      "64/64 [==============================] - 0s 376us/step - loss: 1.1155 - val_loss: 1.4246\n",
      "Epoch 2380/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1154 - val_loss: 1.4243\n",
      "Epoch 2381/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1153 - val_loss: 1.4241\n",
      "Epoch 2382/2500\n",
      "64/64 [==============================] - 0s 490us/step - loss: 1.1151 - val_loss: 1.4239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2383/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 1.1150 - val_loss: 1.4237\n",
      "Epoch 2384/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1148 - val_loss: 1.4234\n",
      "Epoch 2385/2500\n",
      "64/64 [==============================] - 0s 889us/step - loss: 1.1147 - val_loss: 1.4232\n",
      "Epoch 2386/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1146 - val_loss: 1.4230\n",
      "Epoch 2387/2500\n",
      "64/64 [==============================] - 0s 333us/step - loss: 1.1144 - val_loss: 1.4228\n",
      "Epoch 2388/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1143 - val_loss: 1.4225\n",
      "Epoch 2389/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.1141 - val_loss: 1.4223\n",
      "Epoch 2390/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1140 - val_loss: 1.4221\n",
      "Epoch 2391/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1139 - val_loss: 1.4219\n",
      "Epoch 2392/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1137 - val_loss: 1.4216\n",
      "Epoch 2393/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1136 - val_loss: 1.4214\n",
      "Epoch 2394/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1135 - val_loss: 1.4212\n",
      "Epoch 2395/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.1133 - val_loss: 1.4209\n",
      "Epoch 2396/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1132 - val_loss: 1.4207\n",
      "Epoch 2397/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1130 - val_loss: 1.4205\n",
      "Epoch 2398/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.1129 - val_loss: 1.4203\n",
      "Epoch 2399/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1128 - val_loss: 1.4200\n",
      "Epoch 2400/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1126 - val_loss: 1.4198\n",
      "Epoch 2401/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1125 - val_loss: 1.4196\n",
      "Epoch 2402/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.1123 - val_loss: 1.4194\n",
      "Epoch 2403/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1122 - val_loss: 1.4191\n",
      "Epoch 2404/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1121 - val_loss: 1.4189\n",
      "Epoch 2405/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1119 - val_loss: 1.4187\n",
      "Epoch 2406/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.1118 - val_loss: 1.4185\n",
      "Epoch 2407/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1117 - val_loss: 1.4182\n",
      "Epoch 2408/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 1.1115 - val_loss: 1.4180\n",
      "Epoch 2409/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1114 - val_loss: 1.4178\n",
      "Epoch 2410/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1112 - val_loss: 1.4176\n",
      "Epoch 2411/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1111 - val_loss: 1.4173\n",
      "Epoch 2412/2500\n",
      "64/64 [==============================] - 0s 325us/step - loss: 1.1110 - val_loss: 1.4171\n",
      "Epoch 2413/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1108 - val_loss: 1.4169\n",
      "Epoch 2414/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 1.1107 - val_loss: 1.4167\n",
      "Epoch 2415/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1106 - val_loss: 1.4164\n",
      "Epoch 2416/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.1104 - val_loss: 1.4162\n",
      "Epoch 2417/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1103 - val_loss: 1.4160\n",
      "Epoch 2418/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1102 - val_loss: 1.4158\n",
      "Epoch 2419/2500\n",
      "64/64 [==============================] - 0s 420us/step - loss: 1.1100 - val_loss: 1.4155\n",
      "Epoch 2420/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1099 - val_loss: 1.4153\n",
      "Epoch 2421/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.1097 - val_loss: 1.4151\n",
      "Epoch 2422/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1096 - val_loss: 1.4149\n",
      "Epoch 2423/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 1.1095 - val_loss: 1.4146\n",
      "Epoch 2424/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1093 - val_loss: 1.4144\n",
      "Epoch 2425/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1092 - val_loss: 1.4142\n",
      "Epoch 2426/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 1.1091 - val_loss: 1.4140\n",
      "Epoch 2427/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1089 - val_loss: 1.4137\n",
      "Epoch 2428/2500\n",
      "64/64 [==============================] - 0s 312us/step - loss: 1.1088 - val_loss: 1.4135\n",
      "Epoch 2429/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 1.1087 - val_loss: 1.4133\n",
      "Epoch 2430/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.1085 - val_loss: 1.4131\n",
      "Epoch 2431/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1084 - val_loss: 1.4128\n",
      "Epoch 2432/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1083 - val_loss: 1.4126\n",
      "Epoch 2433/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1081 - val_loss: 1.4124\n",
      "Epoch 2434/2500\n",
      "64/64 [==============================] - 0s 333us/step - loss: 1.1080 - val_loss: 1.4122\n",
      "Epoch 2435/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1078 - val_loss: 1.4119\n",
      "Epoch 2436/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1077 - val_loss: 1.4117\n",
      "Epoch 2437/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1076 - val_loss: 1.4115\n",
      "Epoch 2438/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1074 - val_loss: 1.4113\n",
      "Epoch 2439/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1073 - val_loss: 1.4110\n",
      "Epoch 2440/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1072 - val_loss: 1.4108\n",
      "Epoch 2441/2500\n",
      "64/64 [==============================] - 0s 345us/step - loss: 1.1070 - val_loss: 1.4106\n",
      "Epoch 2442/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1069 - val_loss: 1.4104\n",
      "Epoch 2443/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1068 - val_loss: 1.4101\n",
      "Epoch 2444/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1066 - val_loss: 1.4099\n",
      "Epoch 2445/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.1065 - val_loss: 1.4097\n",
      "Epoch 2446/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1064 - val_loss: 1.4095\n",
      "Epoch 2447/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1062 - val_loss: 1.4093\n",
      "Epoch 2448/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1061 - val_loss: 1.4090\n",
      "Epoch 2449/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1060 - val_loss: 1.4088\n",
      "Epoch 2450/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1058 - val_loss: 1.4086\n",
      "Epoch 2451/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1057 - val_loss: 1.4084\n",
      "Epoch 2452/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1056 - val_loss: 1.4081\n",
      "Epoch 2453/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1054 - val_loss: 1.4079\n",
      "Epoch 2454/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1053 - val_loss: 1.4077\n",
      "Epoch 2455/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1052 - val_loss: 1.4075\n",
      "Epoch 2456/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1050 - val_loss: 1.4073\n",
      "Epoch 2457/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1049 - val_loss: 1.4070\n",
      "Epoch 2458/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.1048 - val_loss: 1.4068\n",
      "Epoch 2459/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1046 - val_loss: 1.4066\n",
      "Epoch 2460/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1045 - val_loss: 1.4064\n",
      "Epoch 2461/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1044 - val_loss: 1.4061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2462/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1042 - val_loss: 1.4059\n",
      "Epoch 2463/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1041 - val_loss: 1.4057\n",
      "Epoch 2464/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1040 - val_loss: 1.4055\n",
      "Epoch 2465/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1038 - val_loss: 1.4053\n",
      "Epoch 2466/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.1037 - val_loss: 1.4050\n",
      "Epoch 2467/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1036 - val_loss: 1.4048\n",
      "Epoch 2468/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1034 - val_loss: 1.4046\n",
      "Epoch 2469/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1033 - val_loss: 1.4044\n",
      "Epoch 2470/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1032 - val_loss: 1.4042\n",
      "Epoch 2471/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1031 - val_loss: 1.4039\n",
      "Epoch 2472/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1029 - val_loss: 1.4037\n",
      "Epoch 2473/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1028 - val_loss: 1.4035\n",
      "Epoch 2474/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1027 - val_loss: 1.4033\n",
      "Epoch 2475/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1025 - val_loss: 1.4030\n",
      "Epoch 2476/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1024 - val_loss: 1.4028\n",
      "Epoch 2477/2500\n",
      "64/64 [==============================] - 0s 290us/step - loss: 1.1023 - val_loss: 1.4026\n",
      "Epoch 2478/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.1021 - val_loss: 1.4024\n",
      "Epoch 2479/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1020 - val_loss: 1.4022\n",
      "Epoch 2480/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.1019 - val_loss: 1.4019\n",
      "Epoch 2481/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1017 - val_loss: 1.4017\n",
      "Epoch 2482/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 1.1016 - val_loss: 1.4015\n",
      "Epoch 2483/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.1015 - val_loss: 1.4013\n",
      "Epoch 2484/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.1013 - val_loss: 1.4011\n",
      "Epoch 2485/2500\n",
      "64/64 [==============================] - 0s 607us/step - loss: 1.1012 - val_loss: 1.4008\n",
      "Epoch 2486/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 1.1011 - val_loss: 1.4006\n",
      "Epoch 2487/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1010 - val_loss: 1.4004\n",
      "Epoch 2488/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 1.1008 - val_loss: 1.4002\n",
      "Epoch 2489/2500\n",
      "64/64 [==============================] - 0s 576us/step - loss: 1.1007 - val_loss: 1.4000\n",
      "Epoch 2490/2500\n",
      "64/64 [==============================] - 0s 301us/step - loss: 1.1006 - val_loss: 1.3998\n",
      "Epoch 2491/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1004 - val_loss: 1.3995\n",
      "Epoch 2492/2500\n",
      "64/64 [==============================] - 0s 412us/step - loss: 1.1003 - val_loss: 1.3993\n",
      "Epoch 2493/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1002 - val_loss: 1.3991\n",
      "Epoch 2494/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 1.1000 - val_loss: 1.3989\n",
      "Epoch 2495/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.0999 - val_loss: 1.3987\n",
      "Epoch 2496/2500\n",
      "64/64 [==============================] - 0s 412us/step - loss: 1.0998 - val_loss: 1.3984\n",
      "Epoch 2497/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.0997 - val_loss: 1.3982\n",
      "Epoch 2498/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.0995 - val_loss: 1.3980\n",
      "Epoch 2499/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.0994 - val_loss: 1.3978\n",
      "Epoch 2500/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.0993 - val_loss: 1.3976\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "num_layers = 5\n",
    "N = 100\n",
    "alpha = 0.005\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model_L2 = models.Sequential()\n",
    "\n",
    "model_L2.add(layers.Dense(N, input_dim=input_dim, kernel_initializer='normal', activation='tanh', \n",
    "                          kernel_regularizer=regularizers.l2(alpha)))\n",
    "\n",
    "for h in range(num_layers):\n",
    "    model_L2.add(layers.Dense(N, activation='tanh', kernel_regularizer=regularizers.l2(alpha)))\n",
    "    \n",
    "model_L2.add(layers.Dense(1, activation='linear', kernel_regularizer=regularizers.l2(alpha)))\n",
    "\n",
    "model_L2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "L2_reg = model_L2.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Validation set\n",
    "X_val_L2 = L2_reg.validation_data[0]\n",
    "Y_val_L2 = L2_reg.validation_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 27.3567 - val_loss: 25.4889\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 26.6992 - val_loss: 25.0306\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 26.3300 - val_loss: 24.8770\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 26.2543 - val_loss: 24.6917\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 26.0908 - val_loss: 24.4349\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8122 - val_loss: 24.2058\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 25.5445 - val_loss: 24.0448\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 25.3488 - val_loss: 23.9095\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 42us/step - loss: 25.1931 - val_loss: 23.7417\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 414us/step - loss: 25.0204 - val_loss: 23.5170\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 24.8047 - val_loss: 23.2456\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 24.5552 - val_loss: 22.9553\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 24.2994 - val_loss: 22.6782\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 24.0667 - val_loss: 22.4294\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 23.8643 - val_loss: 22.1967\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 23.6667 - val_loss: 21.9615\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 23.4446 - val_loss: 21.7322\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 374us/step - loss: 23.2065 - val_loss: 21.5367\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 22.9893 - val_loss: 21.3818\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 22.8140 - val_loss: 21.2291\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 22.6565 - val_loss: 21.0358\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 22.4833 - val_loss: 20.8195\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 22.3109 - val_loss: 20.6311\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.1769 - val_loss: 20.4834\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 416us/step - loss: 22.0659 - val_loss: 20.3467\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 486us/step - loss: 21.9272 - val_loss: 20.2258\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 21.7740 - val_loss: 20.1222\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 21.6337 - val_loss: 19.9958\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 21.4887 - val_loss: 19.8228\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 426us/step - loss: 21.3203 - val_loss: 19.6300\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 21.1462 - val_loss: 19.4503\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 20.9848 - val_loss: 19.2911\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 379us/step - loss: 20.8306 - val_loss: 19.1459\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 20.6739 - val_loss: 19.0131\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 20.5188 - val_loss: 18.8896\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 20.3717 - val_loss: 18.7654\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 20.2304 - val_loss: 18.6302\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 300us/step - loss: 20.0878 - val_loss: 18.4818\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 19.9416 - val_loss: 18.3263\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 19.7947 - val_loss: 18.1690\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 19.6479 - val_loss: 18.0169\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 19.5032 - val_loss: 17.8680\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 19.3555 - val_loss: 17.7227\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 19.2051 - val_loss: 17.5812\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.0552 - val_loss: 17.4410\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 18.9078 - val_loss: 17.2974\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 18.7616 - val_loss: 17.1473\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.6152 - val_loss: 16.9906\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 18.4675 - val_loss: 16.8354\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 18.3232 - val_loss: 16.6849\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 18.1808 - val_loss: 16.5401\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.0383 - val_loss: 16.3997\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 17.8940 - val_loss: 16.2642\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 17.7518 - val_loss: 16.1282\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 17.6101 - val_loss: 15.9882\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 17.4683 - val_loss: 15.8436\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 17.3261 - val_loss: 15.6976\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 17.1844 - val_loss: 15.5541\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 17.0439 - val_loss: 15.4149\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 16.9041 - val_loss: 15.2797\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 16.7645 - val_loss: 15.1473\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 16.6257 - val_loss: 15.0151\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 16.4881 - val_loss: 14.8804\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 16.3507 - val_loss: 14.7427\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 16.2134 - val_loss: 14.6035\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 16.0765 - val_loss: 14.4651\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 15.9403 - val_loss: 14.3292\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 15.8049 - val_loss: 14.1962\n",
      "Epoch 69/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 15.6700 - val_loss: 14.0648\n",
      "Epoch 70/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 15.5357 - val_loss: 13.9337\n",
      "Epoch 71/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 15.4021 - val_loss: 13.8013\n",
      "Epoch 72/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 15.2691 - val_loss: 13.6674\n",
      "Epoch 73/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 15.1364 - val_loss: 13.5332\n",
      "Epoch 74/2500\n",
      "64/64 [==============================] - 0s 267us/step - loss: 15.0044 - val_loss: 13.4004\n",
      "Epoch 75/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 14.8734 - val_loss: 13.2699\n",
      "Epoch 76/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 14.7431 - val_loss: 13.1417\n",
      "Epoch 77/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 14.6135 - val_loss: 13.0150\n",
      "Epoch 78/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 14.4846 - val_loss: 12.8882\n",
      "Epoch 79/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 14.3561 - val_loss: 12.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 14.2279 - val_loss: 12.6326\n",
      "Epoch 81/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 14.1002 - val_loss: 12.5052\n",
      "Epoch 82/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 13.9733 - val_loss: 12.3792\n",
      "Epoch 83/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 13.8472 - val_loss: 12.2551\n",
      "Epoch 84/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 13.7220 - val_loss: 12.1325\n",
      "Epoch 85/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 13.5975 - val_loss: 12.0106\n",
      "Epoch 86/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 13.4737 - val_loss: 11.8891\n",
      "Epoch 87/2500\n",
      "64/64 [==============================] - 0s 412us/step - loss: 13.3508 - val_loss: 11.7672\n",
      "Epoch 88/2500\n",
      "64/64 [==============================] - 0s 576us/step - loss: 13.2281 - val_loss: 11.6454\n",
      "Epoch 89/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 13.1059 - val_loss: 11.5247\n",
      "Epoch 90/2500\n",
      "64/64 [==============================] - 0s 501us/step - loss: 12.9846 - val_loss: 11.4050\n",
      "Epoch 91/2500\n",
      "64/64 [==============================] - 0s 439us/step - loss: 12.8639 - val_loss: 11.2865\n",
      "Epoch 92/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 12.7439 - val_loss: 11.1688\n",
      "Epoch 93/2500\n",
      "64/64 [==============================] - 0s 361us/step - loss: 12.6245 - val_loss: 11.0515\n",
      "Epoch 94/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 12.5058 - val_loss: 10.9345\n",
      "Epoch 95/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 12.3878 - val_loss: 10.8180\n",
      "Epoch 96/2500\n",
      "64/64 [==============================] - 0s 525us/step - loss: 12.2705 - val_loss: 10.7020\n",
      "Epoch 97/2500\n",
      "64/64 [==============================] - 0s 495us/step - loss: 12.1537 - val_loss: 10.5870\n",
      "Epoch 98/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 12.0152 - val_loss: 10.4730\n",
      "Epoch 99/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 11.9221 - val_loss: 10.3599\n",
      "Epoch 100/2500\n",
      "64/64 [==============================] - 0s 353us/step - loss: 11.8072 - val_loss: 10.2476\n",
      "Epoch 101/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 11.6930 - val_loss: 10.1360\n",
      "Epoch 102/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 11.5796 - val_loss: 10.0247\n",
      "Epoch 103/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 11.4666 - val_loss: 9.9140\n",
      "Epoch 104/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 11.3542 - val_loss: 9.8042\n",
      "Epoch 105/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 11.2424 - val_loss: 9.6953\n",
      "Epoch 106/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 11.1312 - val_loss: 9.5872\n",
      "Epoch 107/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 11.0205 - val_loss: 9.4797\n",
      "Epoch 108/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 10.9103 - val_loss: 9.3726\n",
      "Epoch 109/2500\n",
      "64/64 [==============================] - 0s 346us/step - loss: 10.8007 - val_loss: 9.2663\n",
      "Epoch 110/2500\n",
      "64/64 [==============================] - 0s 619us/step - loss: 10.6920 - val_loss: 9.1611\n",
      "Epoch 111/2500\n",
      "64/64 [==============================] - 0s 298us/step - loss: 10.5840 - val_loss: 9.0570\n",
      "Epoch 112/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 10.4768 - val_loss: 8.9536\n",
      "Epoch 113/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 10.3702 - val_loss: 8.8508\n",
      "Epoch 114/2500\n",
      "64/64 [==============================] - 0s 416us/step - loss: 10.2640 - val_loss: 8.7486\n",
      "Epoch 115/2500\n",
      "64/64 [==============================] - 0s 178us/step - loss: 10.1584 - val_loss: 8.6468\n",
      "Epoch 116/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 10.0531 - val_loss: 8.5457\n",
      "Epoch 117/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 9.9482 - val_loss: 8.4456\n",
      "Epoch 118/2500\n",
      "64/64 [==============================] - 0s 520us/step - loss: 9.8440 - val_loss: 8.3462\n",
      "Epoch 119/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 9.7403 - val_loss: 8.2473\n",
      "Epoch 120/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 9.6368 - val_loss: 8.1488\n",
      "Epoch 121/2500\n",
      "64/64 [==============================] - 0s 245us/step - loss: 9.5336 - val_loss: 8.0509\n",
      "Epoch 122/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 9.4306 - val_loss: 7.9533\n",
      "Epoch 123/2500\n",
      "64/64 [==============================] - 0s 429us/step - loss: 9.3277 - val_loss: 7.8563\n",
      "Epoch 124/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 9.2251 - val_loss: 7.7599\n",
      "Epoch 125/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 9.1228 - val_loss: 7.6644\n",
      "Epoch 126/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 9.0211 - val_loss: 7.5697\n",
      "Epoch 127/2500\n",
      "64/64 [==============================] - 0s 406us/step - loss: 8.9197 - val_loss: 7.4757\n",
      "Epoch 128/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 8.8184 - val_loss: 7.3821\n",
      "Epoch 129/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 8.7171 - val_loss: 7.2892\n",
      "Epoch 130/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 8.6161 - val_loss: 7.1968\n",
      "Epoch 131/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 8.5152 - val_loss: 7.1052\n",
      "Epoch 132/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 8.4143 - val_loss: 7.0139\n",
      "Epoch 133/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 8.3130 - val_loss: 6.9231\n",
      "Epoch 134/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 8.2115 - val_loss: 6.8328\n",
      "Epoch 135/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 8.1096 - val_loss: 6.7429\n",
      "Epoch 136/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 8.0072 - val_loss: 6.6533\n",
      "Epoch 137/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 7.9039 - val_loss: 6.5641\n",
      "Epoch 138/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 7.7998 - val_loss: 6.4749\n",
      "Epoch 139/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 7.6944 - val_loss: 6.3857\n",
      "Epoch 140/2500\n",
      "64/64 [==============================] - 0s 381us/step - loss: 7.5876 - val_loss: 6.2965\n",
      "Epoch 141/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 7.4790 - val_loss: 6.2072\n",
      "Epoch 142/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 7.3682 - val_loss: 6.1172\n",
      "Epoch 143/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 7.2549 - val_loss: 6.0274\n",
      "Epoch 144/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 7.1387 - val_loss: 5.9377\n",
      "Epoch 145/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 7.0190 - val_loss: 5.8472\n",
      "Epoch 146/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 6.8950 - val_loss: 5.7562\n",
      "Epoch 147/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 6.7663 - val_loss: 5.6662\n",
      "Epoch 148/2500\n",
      "64/64 [==============================] - 0s 436us/step - loss: 6.6325 - val_loss: 5.5763\n",
      "Epoch 149/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 6.4925 - val_loss: 5.4867\n",
      "Epoch 150/2500\n",
      "64/64 [==============================] - 0s 296us/step - loss: 6.3458 - val_loss: 5.4017\n",
      "Epoch 151/2500\n",
      "64/64 [==============================] - 0s 313us/step - loss: 6.1838 - val_loss: 5.3141\n",
      "Epoch 152/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 6.0308 - val_loss: 5.2591\n",
      "Epoch 153/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 5.8648 - val_loss: 5.1135\n",
      "Epoch 154/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 5.7169 - val_loss: 5.9369\n",
      "Epoch 155/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 5.9925 - val_loss: 5.3329\n",
      "Epoch 156/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 6.2218 - val_loss: 4.9101\n",
      "Epoch 157/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 5.3422 - val_loss: 6.2712\n",
      "Epoch 158/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 6.0483 - val_loss: 4.9588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 5.1585 - val_loss: 5.0707\n",
      "Epoch 160/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 5.7640 - val_loss: 4.7994\n",
      "Epoch 161/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 5.0677 - val_loss: 5.7697\n",
      "Epoch 162/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 5.4324 - val_loss: 5.2762\n",
      "Epoch 163/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 5.0608 - val_loss: 4.7903\n",
      "Epoch 164/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 5.0675 - val_loss: 4.7841\n",
      "Epoch 165/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 5.0823 - val_loss: 4.9413\n",
      "Epoch 166/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 4.7743 - val_loss: 5.4357\n",
      "Epoch 167/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 5.0163 - val_loss: 4.7528\n",
      "Epoch 168/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 4.6447 - val_loss: 4.6002\n",
      "Epoch 169/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 4.8471 - val_loss: 4.5419\n",
      "Epoch 170/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 4.6192 - val_loss: 4.9695\n",
      "Epoch 171/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 4.6328 - val_loss: 4.9823\n",
      "Epoch 172/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 4.6079 - val_loss: 4.5098\n",
      "Epoch 173/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 4.4585 - val_loss: 4.4736\n",
      "Epoch 174/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 4.5558 - val_loss: 4.5404\n",
      "Epoch 175/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 4.3609 - val_loss: 4.8904\n",
      "Epoch 176/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 4.4460 - val_loss: 4.6690\n",
      "Epoch 177/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 4.3234 - val_loss: 4.3896\n",
      "Epoch 178/2500\n",
      "64/64 [==============================] - 0s 666us/step - loss: 4.3112 - val_loss: 4.3511\n",
      "Epoch 179/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 4.2965 - val_loss: 4.4862\n",
      "Epoch 180/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 4.2003 - val_loss: 4.6569\n",
      "Epoch 181/2500\n",
      "64/64 [==============================] - 0s 491us/step - loss: 4.2415 - val_loss: 4.3993\n",
      "Epoch 182/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 4.1354 - val_loss: 4.2366\n",
      "Epoch 183/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 4.1555 - val_loss: 4.2329\n",
      "Epoch 184/2500\n",
      "64/64 [==============================] - 0s 485us/step - loss: 4.0979 - val_loss: 4.3912\n",
      "Epoch 185/2500\n",
      "64/64 [==============================] - 0s 451us/step - loss: 4.0628 - val_loss: 4.4369\n",
      "Epoch 186/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 4.0576 - val_loss: 4.2286\n",
      "Epoch 187/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 3.9909 - val_loss: 4.1283\n",
      "Epoch 188/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 3.9993 - val_loss: 4.1460\n",
      "Epoch 189/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 3.9435 - val_loss: 4.2665\n",
      "Epoch 190/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 3.9291 - val_loss: 4.2413\n",
      "Epoch 191/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 3.9045 - val_loss: 4.0767\n",
      "Epoch 192/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 3.8640 - val_loss: 4.0055\n",
      "Epoch 193/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 3.8579 - val_loss: 4.0356\n",
      "Epoch 194/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 3.8138 - val_loss: 4.1196\n",
      "Epoch 195/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 3.8030 - val_loss: 4.0710\n",
      "Epoch 196/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 3.7737 - val_loss: 3.9510\n",
      "Epoch 197/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 3.7477 - val_loss: 3.9073\n",
      "Epoch 198/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 3.7333 - val_loss: 3.9442\n",
      "Epoch 199/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 3.7001 - val_loss: 3.9958\n",
      "Epoch 200/2500\n",
      "64/64 [==============================] - 0s 292us/step - loss: 3.6882 - val_loss: 3.9384\n",
      "Epoch 201/2500\n",
      "64/64 [==============================] - 0s 217us/step - loss: 3.6606 - val_loss: 3.8471\n",
      "Epoch 202/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 3.6413 - val_loss: 3.8186\n",
      "Epoch 203/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 3.6231 - val_loss: 3.8522\n",
      "Epoch 204/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 3.5977 - val_loss: 3.8776\n",
      "Epoch 205/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 3.5835 - val_loss: 3.8206\n",
      "Epoch 206/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 3.5590 - val_loss: 3.7535\n",
      "Epoch 207/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 3.5426 - val_loss: 3.7390\n",
      "Epoch 208/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 3.5236 - val_loss: 3.7683\n",
      "Epoch 209/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 3.5035 - val_loss: 3.7751\n",
      "Epoch 210/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 3.4881 - val_loss: 3.7224\n",
      "Epoch 211/2500\n",
      "64/64 [==============================] - 0s 339us/step - loss: 3.4670 - val_loss: 3.6741\n",
      "Epoch 212/2500\n",
      "64/64 [==============================] - 0s 270us/step - loss: 3.4519 - val_loss: 3.6690\n",
      "Epoch 213/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 3.4331 - val_loss: 3.6905\n",
      "Epoch 214/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 3.4164 - val_loss: 3.6820\n",
      "Epoch 215/2500\n",
      "64/64 [==============================] - 0s 383us/step - loss: 3.4006 - val_loss: 3.6346\n",
      "Epoch 216/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 3.3827 - val_loss: 3.6008\n",
      "Epoch 217/2500\n",
      "64/64 [==============================] - 0s 305us/step - loss: 3.3681 - val_loss: 3.6018\n",
      "Epoch 218/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 3.3510 - val_loss: 3.6139\n",
      "Epoch 219/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 3.3362 - val_loss: 3.5956\n",
      "Epoch 220/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 3.3204 - val_loss: 3.5561\n",
      "Epoch 221/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 3.3049 - val_loss: 3.5340\n",
      "Epoch 222/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 3.2906 - val_loss: 3.5371\n",
      "Epoch 223/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 3.2751 - val_loss: 3.5393\n",
      "Epoch 224/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 3.2611 - val_loss: 3.5159\n",
      "Epoch 225/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 3.2439 - val_loss: 3.4844\n",
      "Epoch 226/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 3.2325 - val_loss: 3.4710\n",
      "Epoch 227/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 3.2188 - val_loss: 3.4735\n",
      "Epoch 228/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 3.2046 - val_loss: 3.4680\n",
      "Epoch 229/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 3.1914 - val_loss: 3.4434\n",
      "Epoch 230/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 3.1778 - val_loss: 3.4197\n",
      "Epoch 231/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 3.1649 - val_loss: 3.4121\n",
      "Epoch 232/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 3.1517 - val_loss: 3.4118\n",
      "Epoch 233/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 3.1387 - val_loss: 3.4006\n",
      "Epoch 234/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 3.1240 - val_loss: 3.3778\n",
      "Epoch 235/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 3.1134 - val_loss: 3.3608\n",
      "Epoch 236/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 3.1011 - val_loss: 3.3560\n",
      "Epoch 237/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 3.0886 - val_loss: 3.3516\n",
      "Epoch 238/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 3.0766 - val_loss: 3.3365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 3.0647 - val_loss: 3.3171\n",
      "Epoch 240/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 3.0531 - val_loss: 3.3055\n",
      "Epoch 241/2500\n",
      "64/64 [==============================] - 0s 767us/step - loss: 3.0417 - val_loss: 3.3006\n",
      "Epoch 242/2500\n",
      "64/64 [==============================] - 0s 379us/step - loss: 3.0303 - val_loss: 3.2922\n",
      "Epoch 243/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 3.0189 - val_loss: 3.2765\n",
      "Epoch 244/2500\n",
      "64/64 [==============================] - 0s 436us/step - loss: 3.0076 - val_loss: 3.2618\n",
      "Epoch 245/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 2.9965 - val_loss: 3.2541\n",
      "Epoch 246/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 2.9857 - val_loss: 3.2486\n",
      "Epoch 247/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 2.9750 - val_loss: 3.2375\n",
      "Epoch 248/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.9641 - val_loss: 3.2228\n",
      "Epoch 249/2500\n",
      "64/64 [==============================] - 0s 469us/step - loss: 2.9535 - val_loss: 3.2118\n",
      "Epoch 250/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.9432 - val_loss: 3.2054\n",
      "Epoch 251/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 2.9329 - val_loss: 3.1980\n",
      "Epoch 252/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.9227 - val_loss: 3.1863\n",
      "Epoch 253/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 2.9127 - val_loss: 3.1743\n",
      "Epoch 254/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.9027 - val_loss: 3.1662\n",
      "Epoch 255/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.8928 - val_loss: 3.1598\n",
      "Epoch 256/2500\n",
      "64/64 [==============================] - 0s 308us/step - loss: 2.8830 - val_loss: 3.1511\n",
      "Epoch 257/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.8733 - val_loss: 3.1397\n",
      "Epoch 258/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 2.8637 - val_loss: 3.1295\n",
      "Epoch 259/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 2.8541 - val_loss: 3.1216\n",
      "Epoch 260/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.8444 - val_loss: 3.1141\n",
      "Epoch 261/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 2.8350 - val_loss: 3.1048\n",
      "Epoch 262/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 2.8259 - val_loss: 3.0947\n",
      "Epoch 263/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 2.8166 - val_loss: 3.0865\n",
      "Epoch 264/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.8074 - val_loss: 3.0797\n",
      "Epoch 265/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 2.7986 - val_loss: 3.0715\n",
      "Epoch 266/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.7899 - val_loss: 3.0621\n",
      "Epoch 267/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.7811 - val_loss: 3.0534\n",
      "Epoch 268/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 2.7723 - val_loss: 3.0462\n",
      "Epoch 269/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.7638 - val_loss: 3.0390\n",
      "Epoch 270/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 2.7554 - val_loss: 3.0305\n",
      "Epoch 271/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.7471 - val_loss: 3.0217\n",
      "Epoch 272/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 2.7388 - val_loss: 3.0140\n",
      "Epoch 273/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.7304 - val_loss: 3.0072\n",
      "Epoch 274/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 2.7223 - val_loss: 2.9997\n",
      "Epoch 275/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.7142 - val_loss: 2.9915\n",
      "Epoch 276/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 2.7062 - val_loss: 2.9836\n",
      "Epoch 277/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 2.6981 - val_loss: 2.9765\n",
      "Epoch 278/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 2.6903 - val_loss: 2.9694\n",
      "Epoch 279/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 2.6825 - val_loss: 2.9619\n",
      "Epoch 280/2500\n",
      "64/64 [==============================] - 0s 254us/step - loss: 2.6748 - val_loss: 2.9547\n",
      "Epoch 281/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.6672 - val_loss: 2.9480\n",
      "Epoch 282/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.6596 - val_loss: 2.9414\n",
      "Epoch 283/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.6521 - val_loss: 2.9342\n",
      "Epoch 284/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 2.6445 - val_loss: 2.9269\n",
      "Epoch 285/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 2.6372 - val_loss: 2.9197\n",
      "Epoch 286/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 2.6299 - val_loss: 2.9130\n",
      "Epoch 287/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.6226 - val_loss: 2.9064\n",
      "Epoch 288/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.6154 - val_loss: 2.8999\n",
      "Epoch 289/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 2.6084 - val_loss: 2.8934\n",
      "Epoch 290/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.6015 - val_loss: 2.8869\n",
      "Epoch 291/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.5944 - val_loss: 2.8804\n",
      "Epoch 292/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.5873 - val_loss: 2.8737\n",
      "Epoch 293/2500\n",
      "64/64 [==============================] - 0s 373us/step - loss: 2.5803 - val_loss: 2.8672\n",
      "Epoch 294/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.5735 - val_loss: 2.8610\n",
      "Epoch 295/2500\n",
      "64/64 [==============================] - 0s 309us/step - loss: 2.5669 - val_loss: 2.8545\n",
      "Epoch 296/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 2.5601 - val_loss: 2.8484\n",
      "Epoch 297/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.5535 - val_loss: 2.8425\n",
      "Epoch 298/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.5469 - val_loss: 2.8365\n",
      "Epoch 299/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 2.5404 - val_loss: 2.8301\n",
      "Epoch 300/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.5339 - val_loss: 2.8236\n",
      "Epoch 301/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.5275 - val_loss: 2.8176\n",
      "Epoch 302/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 2.5212 - val_loss: 2.8120\n",
      "Epoch 303/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.5150 - val_loss: 2.8063\n",
      "Epoch 304/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.5087 - val_loss: 2.8003\n",
      "Epoch 305/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.5024 - val_loss: 2.7945\n",
      "Epoch 306/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.4963 - val_loss: 2.7891\n",
      "Epoch 307/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 2.4903 - val_loss: 2.7835\n",
      "Epoch 308/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.4843 - val_loss: 2.7778\n",
      "Epoch 309/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 2.4783 - val_loss: 2.7721\n",
      "Epoch 310/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.4723 - val_loss: 2.7667\n",
      "Epoch 311/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 2.4665 - val_loss: 2.7614\n",
      "Epoch 312/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 2.4606 - val_loss: 2.7559\n",
      "Epoch 313/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 2.4548 - val_loss: 2.7505\n",
      "Epoch 314/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 2.4492 - val_loss: 2.7453\n",
      "Epoch 315/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.4435 - val_loss: 2.7404\n",
      "Epoch 316/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 2.4371 - val_loss: 2.7351\n",
      "Epoch 317/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 2.4323 - val_loss: 2.7295\n",
      "Epoch 318/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.4267 - val_loss: 2.7243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/2500\n",
      "64/64 [==============================] - 0s 441us/step - loss: 2.4211 - val_loss: 2.7195\n",
      "Epoch 320/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.4156 - val_loss: 2.7146\n",
      "Epoch 321/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 2.4102 - val_loss: 2.7092\n",
      "Epoch 322/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.4047 - val_loss: 2.7038\n",
      "Epoch 323/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.3992 - val_loss: 2.6988\n",
      "Epoch 324/2500\n",
      "64/64 [==============================] - 0s 210us/step - loss: 2.3938 - val_loss: 2.6940\n",
      "Epoch 325/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 2.3885 - val_loss: 2.6892\n",
      "Epoch 326/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 2.3833 - val_loss: 2.6844\n",
      "Epoch 327/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 2.3782 - val_loss: 2.6796\n",
      "Epoch 328/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.3730 - val_loss: 2.6752\n",
      "Epoch 329/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.3678 - val_loss: 2.6706\n",
      "Epoch 330/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 2.3627 - val_loss: 2.6660\n",
      "Epoch 331/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.3578 - val_loss: 2.6614\n",
      "Epoch 332/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.3528 - val_loss: 2.6568\n",
      "Epoch 333/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 2.3479 - val_loss: 2.6523\n",
      "Epoch 334/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 2.3432 - val_loss: 2.6477\n",
      "Epoch 335/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.3383 - val_loss: 2.6432\n",
      "Epoch 336/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.3333 - val_loss: 2.6388\n",
      "Epoch 337/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 2.3286 - val_loss: 2.6344\n",
      "Epoch 338/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.3239 - val_loss: 2.6299\n",
      "Epoch 339/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.3192 - val_loss: 2.6253\n",
      "Epoch 340/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.3144 - val_loss: 2.6214\n",
      "Epoch 341/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.3097 - val_loss: 2.6174\n",
      "Epoch 342/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 2.3051 - val_loss: 2.6130\n",
      "Epoch 343/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.3005 - val_loss: 2.6081\n",
      "Epoch 344/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.2957 - val_loss: 2.6036\n",
      "Epoch 345/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 2.2912 - val_loss: 2.5999\n",
      "Epoch 346/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 2.2867 - val_loss: 2.5955\n",
      "Epoch 347/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.2822 - val_loss: 2.5907\n",
      "Epoch 348/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.2775 - val_loss: 2.5865\n",
      "Epoch 349/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 2.2731 - val_loss: 2.5828\n",
      "Epoch 350/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 2.2687 - val_loss: 2.5789\n",
      "Epoch 351/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 2.2645 - val_loss: 2.5743\n",
      "Epoch 352/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.2602 - val_loss: 2.5697\n",
      "Epoch 353/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 2.2557 - val_loss: 2.5656\n",
      "Epoch 354/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.2513 - val_loss: 2.5621\n",
      "Epoch 355/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.2471 - val_loss: 2.5580\n",
      "Epoch 356/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.2429 - val_loss: 2.5536\n",
      "Epoch 357/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.2386 - val_loss: 2.5496\n",
      "Epoch 358/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.2345 - val_loss: 2.5462\n",
      "Epoch 359/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.2303 - val_loss: 2.5429\n",
      "Epoch 360/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 2.2261 - val_loss: 2.5394\n",
      "Epoch 361/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.2220 - val_loss: 2.5356\n",
      "Epoch 362/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 2.2180 - val_loss: 2.5319\n",
      "Epoch 363/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.2141 - val_loss: 2.5286\n",
      "Epoch 364/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.2101 - val_loss: 2.5252\n",
      "Epoch 365/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 2.2061 - val_loss: 2.5214\n",
      "Epoch 366/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.2020 - val_loss: 2.5180\n",
      "Epoch 367/2500\n",
      "64/64 [==============================] - 0s 291us/step - loss: 2.1982 - val_loss: 2.5150\n",
      "Epoch 368/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 2.1942 - val_loss: 2.5115\n",
      "Epoch 369/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.1903 - val_loss: 2.5075\n",
      "Epoch 370/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 2.1865 - val_loss: 2.5038\n",
      "Epoch 371/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 2.1826 - val_loss: 2.5007\n",
      "Epoch 372/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.1787 - val_loss: 2.4973\n",
      "Epoch 373/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 2.1749 - val_loss: 2.4929\n",
      "Epoch 374/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.1712 - val_loss: 2.4891\n",
      "Epoch 375/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 2.1676 - val_loss: 2.4858\n",
      "Epoch 376/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.1639 - val_loss: 2.4828\n",
      "Epoch 377/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.1602 - val_loss: 2.4792\n",
      "Epoch 378/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 2.1565 - val_loss: 2.4752\n",
      "Epoch 379/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.1528 - val_loss: 2.4720\n",
      "Epoch 380/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 2.1492 - val_loss: 2.4692\n",
      "Epoch 381/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 2.1456 - val_loss: 2.4658\n",
      "Epoch 382/2500\n",
      "64/64 [==============================] - 0s 311us/step - loss: 2.1421 - val_loss: 2.4615\n",
      "Epoch 383/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.1385 - val_loss: 2.4577\n",
      "Epoch 384/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 2.1349 - val_loss: 2.4549\n",
      "Epoch 385/2500\n",
      "64/64 [==============================] - 0s 378us/step - loss: 2.1312 - val_loss: 2.4522\n",
      "Epoch 386/2500\n",
      "64/64 [==============================] - 0s 424us/step - loss: 2.1278 - val_loss: 2.4486\n",
      "Epoch 387/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 2.1243 - val_loss: 2.4449\n",
      "Epoch 388/2500\n",
      "64/64 [==============================] - 0s 332us/step - loss: 2.1207 - val_loss: 2.4420\n",
      "Epoch 389/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 2.1174 - val_loss: 2.4393\n",
      "Epoch 390/2500\n",
      "64/64 [==============================] - 0s 316us/step - loss: 2.1140 - val_loss: 2.4360\n",
      "Epoch 391/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 2.1106 - val_loss: 2.4327\n",
      "Epoch 392/2500\n",
      "64/64 [==============================] - 0s 323us/step - loss: 2.1073 - val_loss: 2.4295\n",
      "Epoch 393/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 2.1039 - val_loss: 2.4268\n",
      "Epoch 394/2500\n",
      "64/64 [==============================] - 0s 311us/step - loss: 2.1004 - val_loss: 2.4235\n",
      "Epoch 395/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 2.0973 - val_loss: 2.4195\n",
      "Epoch 396/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 2.0939 - val_loss: 2.4163\n",
      "Epoch 397/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 2.0905 - val_loss: 2.4136\n",
      "Epoch 398/2500\n",
      "64/64 [==============================] - 0s 362us/step - loss: 2.0871 - val_loss: 2.4109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.0839 - val_loss: 2.4078\n",
      "Epoch 400/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 2.0803 - val_loss: 2.4051\n",
      "Epoch 401/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 2.0776 - val_loss: 2.4029\n",
      "Epoch 402/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.0744 - val_loss: 2.4002\n",
      "Epoch 403/2500\n",
      "64/64 [==============================] - 0s 385us/step - loss: 2.0711 - val_loss: 2.3974\n",
      "Epoch 404/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.0680 - val_loss: 2.3946\n",
      "Epoch 405/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 2.0649 - val_loss: 2.3921\n",
      "Epoch 406/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.0618 - val_loss: 2.3894\n",
      "Epoch 407/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 2.0588 - val_loss: 2.3863\n",
      "Epoch 408/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 2.0555 - val_loss: 2.3831\n",
      "Epoch 409/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.0525 - val_loss: 2.3805\n",
      "Epoch 410/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 2.0496 - val_loss: 2.3779\n",
      "Epoch 411/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 2.0466 - val_loss: 2.3749\n",
      "Epoch 412/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.0435 - val_loss: 2.3721\n",
      "Epoch 413/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 2.0405 - val_loss: 2.3697\n",
      "Epoch 414/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 2.0376 - val_loss: 2.3670\n",
      "Epoch 415/2500\n",
      "64/64 [==============================] - 0s 429us/step - loss: 2.0347 - val_loss: 2.3635\n",
      "Epoch 416/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.0318 - val_loss: 2.3603\n",
      "Epoch 417/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 2.0289 - val_loss: 2.3576\n",
      "Epoch 418/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 2.0260 - val_loss: 2.3550\n",
      "Epoch 419/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.0230 - val_loss: 2.3523\n",
      "Epoch 420/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 2.0200 - val_loss: 2.3498\n",
      "Epoch 421/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 2.0172 - val_loss: 2.3471\n",
      "Epoch 422/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 2.0144 - val_loss: 2.3446\n",
      "Epoch 423/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 2.0116 - val_loss: 2.3423\n",
      "Epoch 424/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 2.0088 - val_loss: 2.3399\n",
      "Epoch 425/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 2.0061 - val_loss: 2.3376\n",
      "Epoch 426/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 2.0034 - val_loss: 2.3352\n",
      "Epoch 427/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 2.0006 - val_loss: 2.3326\n",
      "Epoch 428/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 1.9978 - val_loss: 2.3296\n",
      "Epoch 429/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.9950 - val_loss: 2.3268\n",
      "Epoch 430/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.9925 - val_loss: 2.3244\n",
      "Epoch 431/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.9896 - val_loss: 2.3220\n",
      "Epoch 432/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.9868 - val_loss: 2.3195\n",
      "Epoch 433/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.9841 - val_loss: 2.3171\n",
      "Epoch 434/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.9814 - val_loss: 2.3148\n",
      "Epoch 435/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.9789 - val_loss: 2.3120\n",
      "Epoch 436/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.9762 - val_loss: 2.3093\n",
      "Epoch 437/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.9735 - val_loss: 2.3066\n",
      "Epoch 438/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.9707 - val_loss: 2.3043\n",
      "Epoch 439/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.9681 - val_loss: 2.3021\n",
      "Epoch 440/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.9655 - val_loss: 2.2999\n",
      "Epoch 441/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.9630 - val_loss: 2.2976\n",
      "Epoch 442/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.9606 - val_loss: 2.2949\n",
      "Epoch 443/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.9580 - val_loss: 2.2924\n",
      "Epoch 444/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.9552 - val_loss: 2.2900\n",
      "Epoch 445/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.9526 - val_loss: 2.2875\n",
      "Epoch 446/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.9502 - val_loss: 2.2851\n",
      "Epoch 447/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.9478 - val_loss: 2.2829\n",
      "Epoch 448/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.9451 - val_loss: 2.2808\n",
      "Epoch 449/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.9426 - val_loss: 2.2782\n",
      "Epoch 450/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.9402 - val_loss: 2.2758\n",
      "Epoch 451/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.9378 - val_loss: 2.2741\n",
      "Epoch 452/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.9354 - val_loss: 2.2722\n",
      "Epoch 453/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.9329 - val_loss: 2.2698\n",
      "Epoch 454/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.9306 - val_loss: 2.2672\n",
      "Epoch 455/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.9281 - val_loss: 2.2653\n",
      "Epoch 456/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.9257 - val_loss: 2.2638\n",
      "Epoch 457/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.9233 - val_loss: 2.2616\n",
      "Epoch 458/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.9210 - val_loss: 2.2591\n",
      "Epoch 459/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.9185 - val_loss: 2.2572\n",
      "Epoch 460/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.9161 - val_loss: 2.2552\n",
      "Epoch 461/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.9138 - val_loss: 2.2525\n",
      "Epoch 462/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.9114 - val_loss: 2.2500\n",
      "Epoch 463/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.9091 - val_loss: 2.2479\n",
      "Epoch 464/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.9066 - val_loss: 2.2461\n",
      "Epoch 465/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.9043 - val_loss: 2.2436\n",
      "Epoch 466/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.9021 - val_loss: 2.2409\n",
      "Epoch 467/2500\n",
      "64/64 [==============================] - 0s 457us/step - loss: 1.8999 - val_loss: 2.2388\n",
      "Epoch 468/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.8975 - val_loss: 2.2365\n",
      "Epoch 469/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.8952 - val_loss: 2.2338\n",
      "Epoch 470/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.8929 - val_loss: 2.2313\n",
      "Epoch 471/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.8908 - val_loss: 2.2297\n",
      "Epoch 472/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.8885 - val_loss: 2.2278\n",
      "Epoch 473/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.8862 - val_loss: 2.2253\n",
      "Epoch 474/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.8839 - val_loss: 2.2230\n",
      "Epoch 475/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.8818 - val_loss: 2.2212\n",
      "Epoch 476/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 1.8797 - val_loss: 2.2197\n",
      "Epoch 477/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 1.8774 - val_loss: 2.2177\n",
      "Epoch 478/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8753 - val_loss: 2.2156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.8732 - val_loss: 2.2142\n",
      "Epoch 480/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.8710 - val_loss: 2.2131\n",
      "Epoch 481/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.8689 - val_loss: 2.2111\n",
      "Epoch 482/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.8667 - val_loss: 2.2087\n",
      "Epoch 483/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.8646 - val_loss: 2.2069\n",
      "Epoch 484/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.8626 - val_loss: 2.2054\n",
      "Epoch 485/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.8605 - val_loss: 2.2032\n",
      "Epoch 486/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.8584 - val_loss: 2.2010\n",
      "Epoch 487/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8563 - val_loss: 2.1990\n",
      "Epoch 488/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.8542 - val_loss: 2.1970\n",
      "Epoch 489/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.8520 - val_loss: 2.1948\n",
      "Epoch 490/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.8501 - val_loss: 2.1928\n",
      "Epoch 491/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.8481 - val_loss: 2.1907\n",
      "Epoch 492/2500\n",
      "64/64 [==============================] - 0s 276us/step - loss: 1.8460 - val_loss: 2.1888\n",
      "Epoch 493/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.8439 - val_loss: 2.1866\n",
      "Epoch 494/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.8417 - val_loss: 2.1848\n",
      "Epoch 495/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.8398 - val_loss: 2.1832\n",
      "Epoch 496/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.8378 - val_loss: 2.1815\n",
      "Epoch 497/2500\n",
      "64/64 [==============================] - 0s 358us/step - loss: 1.8358 - val_loss: 2.1795\n",
      "Epoch 498/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.8337 - val_loss: 2.1773\n",
      "Epoch 499/2500\n",
      "64/64 [==============================] - 0s 348us/step - loss: 1.8318 - val_loss: 2.1756\n",
      "Epoch 500/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.8297 - val_loss: 2.1742\n",
      "Epoch 501/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.8278 - val_loss: 2.1722\n",
      "Epoch 502/2500\n",
      "64/64 [==============================] - 0s 504us/step - loss: 1.8259 - val_loss: 2.1699\n",
      "Epoch 503/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.8240 - val_loss: 2.1684\n",
      "Epoch 504/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.8220 - val_loss: 2.1670\n",
      "Epoch 505/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.8202 - val_loss: 2.1648\n",
      "Epoch 506/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.8182 - val_loss: 2.1621\n",
      "Epoch 507/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.8162 - val_loss: 2.1600\n",
      "Epoch 508/2500\n",
      "64/64 [==============================] - 0s 421us/step - loss: 1.8143 - val_loss: 2.1581\n",
      "Epoch 509/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.8123 - val_loss: 2.1562\n",
      "Epoch 510/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.8104 - val_loss: 2.1544\n",
      "Epoch 511/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.8085 - val_loss: 2.1524\n",
      "Epoch 512/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 1.8066 - val_loss: 2.1504\n",
      "Epoch 513/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.8046 - val_loss: 2.1490\n",
      "Epoch 514/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.8029 - val_loss: 2.1469\n",
      "Epoch 515/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.8010 - val_loss: 2.1448\n",
      "Epoch 516/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.7991 - val_loss: 2.1435\n",
      "Epoch 517/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 1.7972 - val_loss: 2.1426\n",
      "Epoch 518/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.7953 - val_loss: 2.1412\n",
      "Epoch 519/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7936 - val_loss: 2.1393\n",
      "Epoch 520/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.7918 - val_loss: 2.1379\n",
      "Epoch 521/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.7900 - val_loss: 2.1365\n",
      "Epoch 522/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.7882 - val_loss: 2.1348\n",
      "Epoch 523/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.7865 - val_loss: 2.1331\n",
      "Epoch 524/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7847 - val_loss: 2.1315\n",
      "Epoch 525/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7829 - val_loss: 2.1296\n",
      "Epoch 526/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7812 - val_loss: 2.1280\n",
      "Epoch 527/2500\n",
      "64/64 [==============================] - 0s 307us/step - loss: 1.7795 - val_loss: 2.1264\n",
      "Epoch 528/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7776 - val_loss: 2.1248\n",
      "Epoch 529/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7758 - val_loss: 2.1232\n",
      "Epoch 530/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7742 - val_loss: 2.1219\n",
      "Epoch 531/2500\n",
      "64/64 [==============================] - 0s 249us/step - loss: 1.7725 - val_loss: 2.1202\n",
      "Epoch 532/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.7707 - val_loss: 2.1181\n",
      "Epoch 533/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.7690 - val_loss: 2.1164\n",
      "Epoch 534/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.7673 - val_loss: 2.1150\n",
      "Epoch 535/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 1.7656 - val_loss: 2.1130\n",
      "Epoch 536/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.7639 - val_loss: 2.1110\n",
      "Epoch 537/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.7622 - val_loss: 2.1095\n",
      "Epoch 538/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7605 - val_loss: 2.1082\n",
      "Epoch 539/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7589 - val_loss: 2.1062\n",
      "Epoch 540/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.7571 - val_loss: 2.1041\n",
      "Epoch 541/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.7554 - val_loss: 2.1028\n",
      "Epoch 542/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.7537 - val_loss: 2.1014\n",
      "Epoch 543/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.7521 - val_loss: 2.0995\n",
      "Epoch 544/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7504 - val_loss: 2.0975\n",
      "Epoch 545/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.7486 - val_loss: 2.0964\n",
      "Epoch 546/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.7471 - val_loss: 2.0948\n",
      "Epoch 547/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.7455 - val_loss: 2.0928\n",
      "Epoch 548/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.7437 - val_loss: 2.0912\n",
      "Epoch 549/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.7420 - val_loss: 2.0897\n",
      "Epoch 550/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.7405 - val_loss: 2.0883\n",
      "Epoch 551/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 1.7390 - val_loss: 2.0869\n",
      "Epoch 552/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.7374 - val_loss: 2.0856\n",
      "Epoch 553/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7357 - val_loss: 2.0842\n",
      "Epoch 554/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7341 - val_loss: 2.0827\n",
      "Epoch 555/2500\n",
      "64/64 [==============================] - 0s 210us/step - loss: 1.7326 - val_loss: 2.0813\n",
      "Epoch 556/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.7309 - val_loss: 2.0797\n",
      "Epoch 557/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.7293 - val_loss: 2.0787\n",
      "Epoch 558/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.7279 - val_loss: 2.0778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 559/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.7263 - val_loss: 2.0765\n",
      "Epoch 560/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.7246 - val_loss: 2.0751\n",
      "Epoch 561/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.7231 - val_loss: 2.0735\n",
      "Epoch 562/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7216 - val_loss: 2.0718\n",
      "Epoch 563/2500\n",
      "64/64 [==============================] - 0s 314us/step - loss: 1.7201 - val_loss: 2.0701\n",
      "Epoch 564/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.7185 - val_loss: 2.0683\n",
      "Epoch 565/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.7170 - val_loss: 2.0668\n",
      "Epoch 566/2500\n",
      "64/64 [==============================] - 0s 273us/step - loss: 1.7154 - val_loss: 2.0658\n",
      "Epoch 567/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.7139 - val_loss: 2.0643\n",
      "Epoch 568/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.7124 - val_loss: 2.0621\n",
      "Epoch 569/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.7110 - val_loss: 2.0602\n",
      "Epoch 570/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.7095 - val_loss: 2.0586\n",
      "Epoch 571/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.7080 - val_loss: 2.0570\n",
      "Epoch 572/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.7066 - val_loss: 2.0555\n",
      "Epoch 573/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.7050 - val_loss: 2.0544\n",
      "Epoch 574/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.7035 - val_loss: 2.0533\n",
      "Epoch 575/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.7020 - val_loss: 2.0518\n",
      "Epoch 576/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.7005 - val_loss: 2.0502\n",
      "Epoch 577/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.6990 - val_loss: 2.0492\n",
      "Epoch 578/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6977 - val_loss: 2.0479\n",
      "Epoch 579/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.6962 - val_loss: 2.0461\n",
      "Epoch 580/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.6946 - val_loss: 2.0448\n",
      "Epoch 581/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.6932 - val_loss: 2.0440\n",
      "Epoch 582/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.6916 - val_loss: 2.0428\n",
      "Epoch 583/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6902 - val_loss: 2.0413\n",
      "Epoch 584/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.6887 - val_loss: 2.0401\n",
      "Epoch 585/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6873 - val_loss: 2.0389\n",
      "Epoch 586/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.6859 - val_loss: 2.0374\n",
      "Epoch 587/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6846 - val_loss: 2.0356\n",
      "Epoch 588/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.6831 - val_loss: 2.0342\n",
      "Epoch 589/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.6817 - val_loss: 2.0329\n",
      "Epoch 590/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6803 - val_loss: 2.0315\n",
      "Epoch 591/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.6790 - val_loss: 2.0304\n",
      "Epoch 592/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6776 - val_loss: 2.0292\n",
      "Epoch 593/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.6762 - val_loss: 2.0279\n",
      "Epoch 594/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.6750 - val_loss: 2.0263\n",
      "Epoch 595/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.6736 - val_loss: 2.0251\n",
      "Epoch 596/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.6721 - val_loss: 2.0240\n",
      "Epoch 597/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.6708 - val_loss: 2.0223\n",
      "Epoch 598/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.6695 - val_loss: 2.0211\n",
      "Epoch 599/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.6682 - val_loss: 2.0205\n",
      "Epoch 600/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.6668 - val_loss: 2.0194\n",
      "Epoch 601/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.6654 - val_loss: 2.0178\n",
      "Epoch 602/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6642 - val_loss: 2.0171\n",
      "Epoch 603/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 1.6629 - val_loss: 2.0163\n",
      "Epoch 604/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.6615 - val_loss: 2.0147\n",
      "Epoch 605/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.6603 - val_loss: 2.0131\n",
      "Epoch 606/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.6591 - val_loss: 2.0121\n",
      "Epoch 607/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.6578 - val_loss: 2.0107\n",
      "Epoch 608/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.6564 - val_loss: 2.0090\n",
      "Epoch 609/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.6552 - val_loss: 2.0074\n",
      "Epoch 610/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.6539 - val_loss: 2.0067\n",
      "Epoch 611/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6527 - val_loss: 2.0052\n",
      "Epoch 612/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6514 - val_loss: 2.0034\n",
      "Epoch 613/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.6501 - val_loss: 2.0028\n",
      "Epoch 614/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.6488 - val_loss: 2.0021\n",
      "Epoch 615/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.6477 - val_loss: 2.0006\n",
      "Epoch 616/2500\n",
      "64/64 [==============================] - 0s 256us/step - loss: 1.6465 - val_loss: 1.9992\n",
      "Epoch 617/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.6452 - val_loss: 1.9977\n",
      "Epoch 618/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.6439 - val_loss: 1.9963\n",
      "Epoch 619/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6427 - val_loss: 1.9955\n",
      "Epoch 620/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.6414 - val_loss: 1.9946\n",
      "Epoch 621/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.6403 - val_loss: 1.9937\n",
      "Epoch 622/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6391 - val_loss: 1.9928\n",
      "Epoch 623/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6378 - val_loss: 1.9917\n",
      "Epoch 624/2500\n",
      "64/64 [==============================] - 0s 437us/step - loss: 1.6367 - val_loss: 1.9907\n",
      "Epoch 625/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 1.6356 - val_loss: 1.9901\n",
      "Epoch 626/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.6345 - val_loss: 1.9892\n",
      "Epoch 627/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6333 - val_loss: 1.9879\n",
      "Epoch 628/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.6320 - val_loss: 1.9871\n",
      "Epoch 629/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.6309 - val_loss: 1.9857\n",
      "Epoch 630/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.6298 - val_loss: 1.9840\n",
      "Epoch 631/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.6286 - val_loss: 1.9831\n",
      "Epoch 632/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6274 - val_loss: 1.9821\n",
      "Epoch 633/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.6261 - val_loss: 1.9805\n",
      "Epoch 634/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.6249 - val_loss: 1.9793\n",
      "Epoch 635/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.6239 - val_loss: 1.9779\n",
      "Epoch 636/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.6226 - val_loss: 1.9765\n",
      "Epoch 637/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.6215 - val_loss: 1.9755\n",
      "Epoch 638/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.6203 - val_loss: 1.9744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/2500\n",
      "64/64 [==============================] - 0s 419us/step - loss: 1.6191 - val_loss: 1.9736\n",
      "Epoch 640/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.6178 - val_loss: 1.9729\n",
      "Epoch 641/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 1.6170 - val_loss: 1.9717\n",
      "Epoch 642/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.6158 - val_loss: 1.9705\n",
      "Epoch 643/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.6146 - val_loss: 1.9693\n",
      "Epoch 644/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.6134 - val_loss: 1.9684\n",
      "Epoch 645/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.6124 - val_loss: 1.9676\n",
      "Epoch 646/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.6114 - val_loss: 1.9665\n",
      "Epoch 647/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.6103 - val_loss: 1.9650\n",
      "Epoch 648/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.6091 - val_loss: 1.9635\n",
      "Epoch 649/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.6080 - val_loss: 1.9627\n",
      "Epoch 650/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.6070 - val_loss: 1.9616\n",
      "Epoch 651/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.6059 - val_loss: 1.9605\n",
      "Epoch 652/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.6048 - val_loss: 1.9593\n",
      "Epoch 653/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.6036 - val_loss: 1.9582\n",
      "Epoch 654/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.6025 - val_loss: 1.9577\n",
      "Epoch 655/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.6015 - val_loss: 1.9565\n",
      "Epoch 656/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.6004 - val_loss: 1.9555\n",
      "Epoch 657/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.5993 - val_loss: 1.9551\n",
      "Epoch 658/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5983 - val_loss: 1.9541\n",
      "Epoch 659/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5974 - val_loss: 1.9521\n",
      "Epoch 660/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 1.5961 - val_loss: 1.9514\n",
      "Epoch 661/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5951 - val_loss: 1.9508\n",
      "Epoch 662/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.5941 - val_loss: 1.9496\n",
      "Epoch 663/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5931 - val_loss: 1.9489\n",
      "Epoch 664/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5920 - val_loss: 1.9483\n",
      "Epoch 665/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.5910 - val_loss: 1.9471\n",
      "Epoch 666/2500\n",
      "64/64 [==============================] - 0s 334us/step - loss: 1.5900 - val_loss: 1.9458\n",
      "Epoch 667/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.5890 - val_loss: 1.9450\n",
      "Epoch 668/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.5878 - val_loss: 1.9442\n",
      "Epoch 669/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.5867 - val_loss: 1.9434\n",
      "Epoch 670/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5858 - val_loss: 1.9424\n",
      "Epoch 671/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.5848 - val_loss: 1.9412\n",
      "Epoch 672/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5836 - val_loss: 1.9401\n",
      "Epoch 673/2500\n",
      "64/64 [==============================] - 0s 269us/step - loss: 1.5826 - val_loss: 1.9388\n",
      "Epoch 674/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5816 - val_loss: 1.9376\n",
      "Epoch 675/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.5807 - val_loss: 1.9364\n",
      "Epoch 676/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.5796 - val_loss: 1.9352\n",
      "Epoch 677/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 1.5786 - val_loss: 1.9340\n",
      "Epoch 678/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.5776 - val_loss: 1.9334\n",
      "Epoch 679/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.5766 - val_loss: 1.9325\n",
      "Epoch 680/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5757 - val_loss: 1.9313\n",
      "Epoch 681/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.5747 - val_loss: 1.9306\n",
      "Epoch 682/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.5737 - val_loss: 1.9296\n",
      "Epoch 683/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.5726 - val_loss: 1.9283\n",
      "Epoch 684/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 1.5717 - val_loss: 1.9279\n",
      "Epoch 685/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.5708 - val_loss: 1.9268\n",
      "Epoch 686/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5698 - val_loss: 1.9257\n",
      "Epoch 687/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.5689 - val_loss: 1.9255\n",
      "Epoch 688/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.5679 - val_loss: 1.9247\n",
      "Epoch 689/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.5669 - val_loss: 1.9232\n",
      "Epoch 690/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.5658 - val_loss: 1.9224\n",
      "Epoch 691/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.5649 - val_loss: 1.9215\n",
      "Epoch 692/2500\n",
      "64/64 [==============================] - 0s 378us/step - loss: 1.5638 - val_loss: 1.9196\n",
      "Epoch 693/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.5627 - val_loss: 1.9184\n",
      "Epoch 694/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5618 - val_loss: 1.9175\n",
      "Epoch 695/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.5609 - val_loss: 1.9166\n",
      "Epoch 696/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.5599 - val_loss: 1.9158\n",
      "Epoch 697/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5589 - val_loss: 1.9155\n",
      "Epoch 698/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.5582 - val_loss: 1.9142\n",
      "Epoch 699/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 1.5572 - val_loss: 1.9130\n",
      "Epoch 700/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5561 - val_loss: 1.9125\n",
      "Epoch 701/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.5552 - val_loss: 1.9121\n",
      "Epoch 702/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.5544 - val_loss: 1.9110\n",
      "Epoch 703/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5536 - val_loss: 1.9104\n",
      "Epoch 704/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.5526 - val_loss: 1.9101\n",
      "Epoch 705/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.5517 - val_loss: 1.9095\n",
      "Epoch 706/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.5508 - val_loss: 1.9086\n",
      "Epoch 707/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.5500 - val_loss: 1.9076\n",
      "Epoch 708/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.5490 - val_loss: 1.9068\n",
      "Epoch 709/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.5481 - val_loss: 1.9057\n",
      "Epoch 710/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.5472 - val_loss: 1.9050\n",
      "Epoch 711/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5464 - val_loss: 1.9043\n",
      "Epoch 712/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.5456 - val_loss: 1.9030\n",
      "Epoch 713/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.5445 - val_loss: 1.9017\n",
      "Epoch 714/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.5437 - val_loss: 1.9009\n",
      "Epoch 715/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.5428 - val_loss: 1.9000\n",
      "Epoch 716/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.5420 - val_loss: 1.8984\n",
      "Epoch 717/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.5411 - val_loss: 1.8975\n",
      "Epoch 718/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.5402 - val_loss: 1.8966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/2500\n",
      "64/64 [==============================] - 0s 400us/step - loss: 1.5394 - val_loss: 1.8952\n",
      "Epoch 720/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.5384 - val_loss: 1.8947\n",
      "Epoch 721/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.5376 - val_loss: 1.8943\n",
      "Epoch 722/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.5366 - val_loss: 1.8933\n",
      "Epoch 723/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.5357 - val_loss: 1.8926\n",
      "Epoch 724/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.5349 - val_loss: 1.8921\n",
      "Epoch 725/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5340 - val_loss: 1.8909\n",
      "Epoch 726/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 1.5331 - val_loss: 1.8900\n",
      "Epoch 727/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5323 - val_loss: 1.8899\n",
      "Epoch 728/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.5315 - val_loss: 1.8887\n",
      "Epoch 729/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.5307 - val_loss: 1.8876\n",
      "Epoch 730/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.5297 - val_loss: 1.8870\n",
      "Epoch 731/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.5289 - val_loss: 1.8866\n",
      "Epoch 732/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.5281 - val_loss: 1.8855\n",
      "Epoch 733/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 1.5273 - val_loss: 1.8845\n",
      "Epoch 734/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.5265 - val_loss: 1.8840\n",
      "Epoch 735/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.5257 - val_loss: 1.8831\n",
      "Epoch 736/2500\n",
      "64/64 [==============================] - 0s 336us/step - loss: 1.5249 - val_loss: 1.8817\n",
      "Epoch 737/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.5240 - val_loss: 1.8817\n",
      "Epoch 738/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 1.5233 - val_loss: 1.8811\n",
      "Epoch 739/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.5224 - val_loss: 1.8801\n",
      "Epoch 740/2500\n",
      "64/64 [==============================] - 0s 305us/step - loss: 1.5216 - val_loss: 1.8792\n",
      "Epoch 741/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5209 - val_loss: 1.8784\n",
      "Epoch 742/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.5201 - val_loss: 1.8776\n",
      "Epoch 743/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.5193 - val_loss: 1.8767\n",
      "Epoch 744/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5184 - val_loss: 1.8762\n",
      "Epoch 745/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.5177 - val_loss: 1.8758\n",
      "Epoch 746/2500\n",
      "64/64 [==============================] - 0s 267us/step - loss: 1.5169 - val_loss: 1.8747\n",
      "Epoch 747/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.5162 - val_loss: 1.8739\n",
      "Epoch 748/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.5152 - val_loss: 1.8730\n",
      "Epoch 749/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5143 - val_loss: 1.8717\n",
      "Epoch 750/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.5135 - val_loss: 1.8708\n",
      "Epoch 751/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.5127 - val_loss: 1.8702\n",
      "Epoch 752/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.5119 - val_loss: 1.8694\n",
      "Epoch 753/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.5111 - val_loss: 1.8685\n",
      "Epoch 754/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.5103 - val_loss: 1.8677\n",
      "Epoch 755/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5097 - val_loss: 1.8672\n",
      "Epoch 756/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5088 - val_loss: 1.8662\n",
      "Epoch 757/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5079 - val_loss: 1.8653\n",
      "Epoch 758/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.5071 - val_loss: 1.8646\n",
      "Epoch 759/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.5064 - val_loss: 1.8639\n",
      "Epoch 760/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.5056 - val_loss: 1.8631\n",
      "Epoch 761/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.5050 - val_loss: 1.8620\n",
      "Epoch 762/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.5041 - val_loss: 1.8613\n",
      "Epoch 763/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.5033 - val_loss: 1.8606\n",
      "Epoch 764/2500\n",
      "64/64 [==============================] - 0s 287us/step - loss: 1.5025 - val_loss: 1.8593\n",
      "Epoch 765/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.5017 - val_loss: 1.8590\n",
      "Epoch 766/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.5011 - val_loss: 1.8585\n",
      "Epoch 767/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.5004 - val_loss: 1.8568\n",
      "Epoch 768/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4995 - val_loss: 1.8568\n",
      "Epoch 769/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4986 - val_loss: 1.8567\n",
      "Epoch 770/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.4981 - val_loss: 1.8555\n",
      "Epoch 771/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4973 - val_loss: 1.8548\n",
      "Epoch 772/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4964 - val_loss: 1.8546\n",
      "Epoch 773/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4956 - val_loss: 1.8532\n",
      "Epoch 774/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4949 - val_loss: 1.8528\n",
      "Epoch 775/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4942 - val_loss: 1.8526\n",
      "Epoch 776/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.4934 - val_loss: 1.8519\n",
      "Epoch 777/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4926 - val_loss: 1.8513\n",
      "Epoch 778/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4920 - val_loss: 1.8507\n",
      "Epoch 779/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.4913 - val_loss: 1.8495\n",
      "Epoch 780/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4904 - val_loss: 1.8485\n",
      "Epoch 781/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4896 - val_loss: 1.8478\n",
      "Epoch 782/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.4889 - val_loss: 1.8470\n",
      "Epoch 783/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.4882 - val_loss: 1.8468\n",
      "Epoch 784/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.4875 - val_loss: 1.8453\n",
      "Epoch 785/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4867 - val_loss: 1.8441\n",
      "Epoch 786/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4860 - val_loss: 1.8438\n",
      "Epoch 787/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4854 - val_loss: 1.8426\n",
      "Epoch 788/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4846 - val_loss: 1.8414\n",
      "Epoch 789/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.4837 - val_loss: 1.8406\n",
      "Epoch 790/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4831 - val_loss: 1.8402\n",
      "Epoch 791/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4824 - val_loss: 1.8403\n",
      "Epoch 792/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.4818 - val_loss: 1.8401\n",
      "Epoch 793/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.4810 - val_loss: 1.8386\n",
      "Epoch 794/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4803 - val_loss: 1.8378\n",
      "Epoch 795/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4796 - val_loss: 1.8372\n",
      "Epoch 796/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4789 - val_loss: 1.8362\n",
      "Epoch 797/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4782 - val_loss: 1.8357\n",
      "Epoch 798/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.4774 - val_loss: 1.8358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.4767 - val_loss: 1.8346\n",
      "Epoch 800/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4761 - val_loss: 1.8341\n",
      "Epoch 801/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4753 - val_loss: 1.8337\n",
      "Epoch 802/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4746 - val_loss: 1.8326\n",
      "Epoch 803/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4739 - val_loss: 1.8320\n",
      "Epoch 804/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.4732 - val_loss: 1.8309\n",
      "Epoch 805/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4726 - val_loss: 1.8302\n",
      "Epoch 806/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4718 - val_loss: 1.8296\n",
      "Epoch 807/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.4712 - val_loss: 1.8284\n",
      "Epoch 808/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4704 - val_loss: 1.8280\n",
      "Epoch 809/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.4697 - val_loss: 1.8277\n",
      "Epoch 810/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.4691 - val_loss: 1.8266\n",
      "Epoch 811/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4684 - val_loss: 1.8259\n",
      "Epoch 812/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.4676 - val_loss: 1.8249\n",
      "Epoch 813/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4670 - val_loss: 1.8240\n",
      "Epoch 814/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4663 - val_loss: 1.8235\n",
      "Epoch 815/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.4657 - val_loss: 1.8227\n",
      "Epoch 816/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4649 - val_loss: 1.8224\n",
      "Epoch 817/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4643 - val_loss: 1.8219\n",
      "Epoch 818/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4637 - val_loss: 1.8212\n",
      "Epoch 819/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4629 - val_loss: 1.8202\n",
      "Epoch 820/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.4622 - val_loss: 1.8192\n",
      "Epoch 821/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.4616 - val_loss: 1.8194\n",
      "Epoch 822/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4610 - val_loss: 1.8188\n",
      "Epoch 823/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4603 - val_loss: 1.8183\n",
      "Epoch 824/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4596 - val_loss: 1.8169\n",
      "Epoch 825/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4589 - val_loss: 1.8161\n",
      "Epoch 826/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.4583 - val_loss: 1.8153\n",
      "Epoch 827/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4577 - val_loss: 1.8140\n",
      "Epoch 828/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.4569 - val_loss: 1.8143\n",
      "Epoch 829/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4562 - val_loss: 1.8141\n",
      "Epoch 830/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4555 - val_loss: 1.8132\n",
      "Epoch 831/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.4550 - val_loss: 1.8133\n",
      "Epoch 832/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4543 - val_loss: 1.8121\n",
      "Epoch 833/2500\n",
      "64/64 [==============================] - 0s 1ms/step - loss: 1.4535 - val_loss: 1.8109\n",
      "Epoch 834/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 1.4528 - val_loss: 1.8107\n",
      "Epoch 835/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4523 - val_loss: 1.8097\n",
      "Epoch 836/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.4517 - val_loss: 1.8088\n",
      "Epoch 837/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.4509 - val_loss: 1.8086\n",
      "Epoch 838/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.4503 - val_loss: 1.8075\n",
      "Epoch 839/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.4497 - val_loss: 1.8070\n",
      "Epoch 840/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.4490 - val_loss: 1.8072\n",
      "Epoch 841/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4484 - val_loss: 1.8063\n",
      "Epoch 842/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.4478 - val_loss: 1.8059\n",
      "Epoch 843/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4473 - val_loss: 1.8050\n",
      "Epoch 844/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.4465 - val_loss: 1.8042\n",
      "Epoch 845/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4459 - val_loss: 1.8042\n",
      "Epoch 846/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.4453 - val_loss: 1.8032\n",
      "Epoch 847/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4448 - val_loss: 1.8026\n",
      "Epoch 848/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4441 - val_loss: 1.8023\n",
      "Epoch 849/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4433 - val_loss: 1.8011\n",
      "Epoch 850/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.4427 - val_loss: 1.8002\n",
      "Epoch 851/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4421 - val_loss: 1.7998\n",
      "Epoch 852/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4414 - val_loss: 1.7992\n",
      "Epoch 853/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4408 - val_loss: 1.7985\n",
      "Epoch 854/2500\n",
      "64/64 [==============================] - 0s 517us/step - loss: 1.4402 - val_loss: 1.7983\n",
      "Epoch 855/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.4396 - val_loss: 1.7974\n",
      "Epoch 856/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4389 - val_loss: 1.7966\n",
      "Epoch 857/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4384 - val_loss: 1.7960\n",
      "Epoch 858/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.4378 - val_loss: 1.7952\n",
      "Epoch 859/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.4372 - val_loss: 1.7943\n",
      "Epoch 860/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4366 - val_loss: 1.7939\n",
      "Epoch 861/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4359 - val_loss: 1.7935\n",
      "Epoch 862/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.4353 - val_loss: 1.7931\n",
      "Epoch 863/2500\n",
      "64/64 [==============================] - 0s 306us/step - loss: 1.4347 - val_loss: 1.7924\n",
      "Epoch 864/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.4341 - val_loss: 1.7918\n",
      "Epoch 865/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4336 - val_loss: 1.7917\n",
      "Epoch 866/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.4331 - val_loss: 1.7915\n",
      "Epoch 867/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4325 - val_loss: 1.7901\n",
      "Epoch 868/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.4319 - val_loss: 1.7900\n",
      "Epoch 869/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.4313 - val_loss: 1.7890\n",
      "Epoch 870/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4306 - val_loss: 1.7879\n",
      "Epoch 871/2500\n",
      "64/64 [==============================] - 0s 407us/step - loss: 1.4302 - val_loss: 1.7879\n",
      "Epoch 872/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.4297 - val_loss: 1.7872\n",
      "Epoch 873/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 1.4289 - val_loss: 1.7867\n",
      "Epoch 874/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.4283 - val_loss: 1.7868\n",
      "Epoch 875/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 1.4279 - val_loss: 1.7862\n",
      "Epoch 876/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.4273 - val_loss: 1.7851\n",
      "Epoch 877/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4268 - val_loss: 1.7847\n",
      "Epoch 878/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.4261 - val_loss: 1.7841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/2500\n",
      "64/64 [==============================] - 0s 481us/step - loss: 1.4254 - val_loss: 1.7836\n",
      "Epoch 880/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4248 - val_loss: 1.7827\n",
      "Epoch 881/2500\n",
      "64/64 [==============================] - 0s 360us/step - loss: 1.4243 - val_loss: 1.7827\n",
      "Epoch 882/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.4237 - val_loss: 1.7821\n",
      "Epoch 883/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.4232 - val_loss: 1.7811\n",
      "Epoch 884/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.4226 - val_loss: 1.7813\n",
      "Epoch 885/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4219 - val_loss: 1.7797\n",
      "Epoch 886/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.4215 - val_loss: 1.7786\n",
      "Epoch 887/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.4211 - val_loss: 1.7791\n",
      "Epoch 888/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4202 - val_loss: 1.7770\n",
      "Epoch 889/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4196 - val_loss: 1.7775\n",
      "Epoch 890/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.4192 - val_loss: 1.7771\n",
      "Epoch 891/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.4186 - val_loss: 1.7754\n",
      "Epoch 892/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4180 - val_loss: 1.7760\n",
      "Epoch 893/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.4174 - val_loss: 1.7754\n",
      "Epoch 894/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4169 - val_loss: 1.7741\n",
      "Epoch 895/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.4165 - val_loss: 1.7752\n",
      "Epoch 896/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.4160 - val_loss: 1.7731\n",
      "Epoch 897/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.4153 - val_loss: 1.7724\n",
      "Epoch 898/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.4147 - val_loss: 1.7736\n",
      "Epoch 899/2500\n",
      "64/64 [==============================] - 0s 134us/step - loss: 1.4143 - val_loss: 1.7718\n",
      "Epoch 900/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.4137 - val_loss: 1.7716\n",
      "Epoch 901/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4133 - val_loss: 1.7718\n",
      "Epoch 902/2500\n",
      "64/64 [==============================] - 0s 692us/step - loss: 1.4127 - val_loss: 1.7700\n",
      "Epoch 903/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.4121 - val_loss: 1.7705\n",
      "Epoch 904/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.4116 - val_loss: 1.7702\n",
      "Epoch 905/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.4112 - val_loss: 1.7691\n",
      "Epoch 906/2500\n",
      "64/64 [==============================] - 0s 383us/step - loss: 1.4106 - val_loss: 1.7698\n",
      "Epoch 907/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.4101 - val_loss: 1.7681\n",
      "Epoch 908/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.4095 - val_loss: 1.7670\n",
      "Epoch 909/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.4089 - val_loss: 1.7674\n",
      "Epoch 910/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.4084 - val_loss: 1.7662\n",
      "Epoch 911/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.4080 - val_loss: 1.7660\n",
      "Epoch 912/2500\n",
      "64/64 [==============================] - 0s 259us/step - loss: 1.4075 - val_loss: 1.7658\n",
      "Epoch 913/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.4068 - val_loss: 1.7641\n",
      "Epoch 914/2500\n",
      "64/64 [==============================] - 0s 258us/step - loss: 1.4063 - val_loss: 1.7645\n",
      "Epoch 915/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.4059 - val_loss: 1.7634\n",
      "Epoch 916/2500\n",
      "64/64 [==============================] - 0s 471us/step - loss: 1.4054 - val_loss: 1.7625\n",
      "Epoch 917/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.4048 - val_loss: 1.7627\n",
      "Epoch 918/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.4042 - val_loss: 1.7607\n",
      "Epoch 919/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.4037 - val_loss: 1.7608\n",
      "Epoch 920/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.4031 - val_loss: 1.7605\n",
      "Epoch 921/2500\n",
      "64/64 [==============================] - 0s 400us/step - loss: 1.4026 - val_loss: 1.7585\n",
      "Epoch 922/2500\n",
      "64/64 [==============================] - 0s 536us/step - loss: 1.4022 - val_loss: 1.7597\n",
      "Epoch 923/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.4018 - val_loss: 1.7587\n",
      "Epoch 924/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.4012 - val_loss: 1.7579\n",
      "Epoch 925/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.4007 - val_loss: 1.7595\n",
      "Epoch 926/2500\n",
      "64/64 [==============================] - 0s 172us/step - loss: 1.4003 - val_loss: 1.7576\n",
      "Epoch 927/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.3998 - val_loss: 1.7577\n",
      "Epoch 928/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.3992 - val_loss: 1.7579\n",
      "Epoch 929/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3987 - val_loss: 1.7564\n",
      "Epoch 930/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3983 - val_loss: 1.7563\n",
      "Epoch 931/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 1.3977 - val_loss: 1.7561\n",
      "Epoch 932/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3972 - val_loss: 1.7541\n",
      "Epoch 933/2500\n",
      "64/64 [==============================] - 0s 564us/step - loss: 1.3967 - val_loss: 1.7544\n",
      "Epoch 934/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.3962 - val_loss: 1.7534\n",
      "Epoch 935/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3957 - val_loss: 1.7523\n",
      "Epoch 936/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3952 - val_loss: 1.7533\n",
      "Epoch 937/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 1.3947 - val_loss: 1.7519\n",
      "Epoch 938/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.3942 - val_loss: 1.7516\n",
      "Epoch 939/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 1.3937 - val_loss: 1.7512\n",
      "Epoch 940/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.3932 - val_loss: 1.7498\n",
      "Epoch 941/2500\n",
      "64/64 [==============================] - 0s 216us/step - loss: 1.3926 - val_loss: 1.7501\n",
      "Epoch 942/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.3921 - val_loss: 1.7488\n",
      "Epoch 943/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3917 - val_loss: 1.7484\n",
      "Epoch 944/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 1.3912 - val_loss: 1.7481\n",
      "Epoch 945/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3907 - val_loss: 1.7475\n",
      "Epoch 946/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.3902 - val_loss: 1.7480\n",
      "Epoch 947/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.3898 - val_loss: 1.7475\n",
      "Epoch 948/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3892 - val_loss: 1.7468\n",
      "Epoch 949/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3886 - val_loss: 1.7463\n",
      "Epoch 950/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.3883 - val_loss: 1.7460\n",
      "Epoch 951/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.3878 - val_loss: 1.7442\n",
      "Epoch 952/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3873 - val_loss: 1.7444\n",
      "Epoch 953/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3868 - val_loss: 1.7438\n",
      "Epoch 954/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3862 - val_loss: 1.7435\n",
      "Epoch 955/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.3858 - val_loss: 1.7438\n",
      "Epoch 956/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3853 - val_loss: 1.7428\n",
      "Epoch 957/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3849 - val_loss: 1.7419\n",
      "Epoch 958/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3845 - val_loss: 1.7409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3840 - val_loss: 1.7402\n",
      "Epoch 960/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3834 - val_loss: 1.7395\n",
      "Epoch 961/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3830 - val_loss: 1.7399\n",
      "Epoch 962/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.3827 - val_loss: 1.7395\n",
      "Epoch 963/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3821 - val_loss: 1.7386\n",
      "Epoch 964/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3817 - val_loss: 1.7390\n",
      "Epoch 965/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3812 - val_loss: 1.7381\n",
      "Epoch 966/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3806 - val_loss: 1.7375\n",
      "Epoch 967/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3804 - val_loss: 1.7381\n",
      "Epoch 968/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.3799 - val_loss: 1.7355\n",
      "Epoch 969/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3792 - val_loss: 1.7362\n",
      "Epoch 970/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3788 - val_loss: 1.7354\n",
      "Epoch 971/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.3783 - val_loss: 1.7348\n",
      "Epoch 972/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 1.3778 - val_loss: 1.7352\n",
      "Epoch 973/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.3773 - val_loss: 1.7341\n",
      "Epoch 974/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.3767 - val_loss: 1.7346\n",
      "Epoch 975/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.3763 - val_loss: 1.7332\n",
      "Epoch 976/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.3759 - val_loss: 1.7327\n",
      "Epoch 977/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.3754 - val_loss: 1.7321\n",
      "Epoch 978/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.3749 - val_loss: 1.7314\n",
      "Epoch 979/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 1.3745 - val_loss: 1.7317\n",
      "Epoch 980/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.3741 - val_loss: 1.7307\n",
      "Epoch 981/2500\n",
      "64/64 [==============================] - 0s 487us/step - loss: 1.3736 - val_loss: 1.7299\n",
      "Epoch 982/2500\n",
      "64/64 [==============================] - 0s 370us/step - loss: 1.3731 - val_loss: 1.7299\n",
      "Epoch 983/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3726 - val_loss: 1.7294\n",
      "Epoch 984/2500\n",
      "64/64 [==============================] - 0s 401us/step - loss: 1.3722 - val_loss: 1.7294\n",
      "Epoch 985/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.3719 - val_loss: 1.7295\n",
      "Epoch 986/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.3714 - val_loss: 1.7287\n",
      "Epoch 987/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.3710 - val_loss: 1.7281\n",
      "Epoch 988/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.3704 - val_loss: 1.7288\n",
      "Epoch 989/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3701 - val_loss: 1.7267\n",
      "Epoch 990/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3697 - val_loss: 1.7275\n",
      "Epoch 991/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.3692 - val_loss: 1.7266\n",
      "Epoch 992/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.3687 - val_loss: 1.7259\n",
      "Epoch 993/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3683 - val_loss: 1.7275\n",
      "Epoch 994/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.3680 - val_loss: 1.7254\n",
      "Epoch 995/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.3676 - val_loss: 1.7272\n",
      "Epoch 996/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.3670 - val_loss: 1.7244\n",
      "Epoch 997/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3665 - val_loss: 1.7245\n",
      "Epoch 998/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3662 - val_loss: 1.7228\n",
      "Epoch 999/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.3656 - val_loss: 1.7216\n",
      "Epoch 1000/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.3651 - val_loss: 1.7224\n",
      "Epoch 1001/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3648 - val_loss: 1.7205\n",
      "Epoch 1002/2500\n",
      "64/64 [==============================] - 0s 445us/step - loss: 1.3644 - val_loss: 1.7216\n",
      "Epoch 1003/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3639 - val_loss: 1.7206\n",
      "Epoch 1004/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.3635 - val_loss: 1.7200\n",
      "Epoch 1005/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.3630 - val_loss: 1.7198\n",
      "Epoch 1006/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3627 - val_loss: 1.7188\n",
      "Epoch 1007/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3623 - val_loss: 1.7188\n",
      "Epoch 1008/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.3618 - val_loss: 1.7178\n",
      "Epoch 1009/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.3613 - val_loss: 1.7175\n",
      "Epoch 1010/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3610 - val_loss: 1.7177\n",
      "Epoch 1011/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3606 - val_loss: 1.7165\n",
      "Epoch 1012/2500\n",
      "64/64 [==============================] - 0s 196us/step - loss: 1.3602 - val_loss: 1.7176\n",
      "Epoch 1013/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.3597 - val_loss: 1.7157\n",
      "Epoch 1014/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3592 - val_loss: 1.7160\n",
      "Epoch 1015/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3589 - val_loss: 1.7166\n",
      "Epoch 1016/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.3584 - val_loss: 1.7145\n",
      "Epoch 1017/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3580 - val_loss: 1.7172\n",
      "Epoch 1018/2500\n",
      "64/64 [==============================] - 0s 255us/step - loss: 1.3577 - val_loss: 1.7134\n",
      "Epoch 1019/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3572 - val_loss: 1.7144\n",
      "Epoch 1020/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3566 - val_loss: 1.7124\n",
      "Epoch 1021/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.3563 - val_loss: 1.7128\n",
      "Epoch 1022/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.3559 - val_loss: 1.7136\n",
      "Epoch 1023/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.3555 - val_loss: 1.7121\n",
      "Epoch 1024/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.3551 - val_loss: 1.7142\n",
      "Epoch 1025/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.3546 - val_loss: 1.7112\n",
      "Epoch 1026/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3542 - val_loss: 1.7131\n",
      "Epoch 1027/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.3539 - val_loss: 1.7106\n",
      "Epoch 1028/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.3533 - val_loss: 1.7105\n",
      "Epoch 1029/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.3527 - val_loss: 1.7106\n",
      "Epoch 1030/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3524 - val_loss: 1.7082\n",
      "Epoch 1031/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3520 - val_loss: 1.7106\n",
      "Epoch 1032/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.3516 - val_loss: 1.7062\n",
      "Epoch 1033/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.3511 - val_loss: 1.7091\n",
      "Epoch 1034/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3507 - val_loss: 1.7062\n",
      "Epoch 1035/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3503 - val_loss: 1.7076\n",
      "Epoch 1036/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.3499 - val_loss: 1.7074\n",
      "Epoch 1037/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.3494 - val_loss: 1.7056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1038/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3489 - val_loss: 1.7068\n",
      "Epoch 1039/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3485 - val_loss: 1.7035\n",
      "Epoch 1040/2500\n",
      "64/64 [==============================] - 0s 145us/step - loss: 1.3482 - val_loss: 1.7056\n",
      "Epoch 1041/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.3478 - val_loss: 1.7030\n",
      "Epoch 1042/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3474 - val_loss: 1.7055\n",
      "Epoch 1043/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3470 - val_loss: 1.7039\n",
      "Epoch 1044/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.3466 - val_loss: 1.7043\n",
      "Epoch 1045/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3463 - val_loss: 1.7034\n",
      "Epoch 1046/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3459 - val_loss: 1.7024\n",
      "Epoch 1047/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3455 - val_loss: 1.7028\n",
      "Epoch 1048/2500\n",
      "64/64 [==============================] - 0s 447us/step - loss: 1.3450 - val_loss: 1.7000\n",
      "Epoch 1049/2500\n",
      "64/64 [==============================] - 0s 277us/step - loss: 1.3446 - val_loss: 1.7024\n",
      "Epoch 1050/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3442 - val_loss: 1.6994\n",
      "Epoch 1051/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3438 - val_loss: 1.7019\n",
      "Epoch 1052/2500\n",
      "64/64 [==============================] - 0s 363us/step - loss: 1.3434 - val_loss: 1.6990\n",
      "Epoch 1053/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3429 - val_loss: 1.7005\n",
      "Epoch 1054/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.3425 - val_loss: 1.6985\n",
      "Epoch 1055/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.3422 - val_loss: 1.6986\n",
      "Epoch 1056/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.3417 - val_loss: 1.6973\n",
      "Epoch 1057/2500\n",
      "64/64 [==============================] - 0s 476us/step - loss: 1.3413 - val_loss: 1.6977\n",
      "Epoch 1058/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.3409 - val_loss: 1.6972\n",
      "Epoch 1059/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3404 - val_loss: 1.6978\n",
      "Epoch 1060/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3398 - val_loss: 1.6968\n",
      "Epoch 1061/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.3395 - val_loss: 1.6968\n",
      "Epoch 1062/2500\n",
      "64/64 [==============================] - 0s 214us/step - loss: 1.3391 - val_loss: 1.6949\n",
      "Epoch 1063/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3387 - val_loss: 1.6956\n",
      "Epoch 1064/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.3382 - val_loss: 1.6937\n",
      "Epoch 1065/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3378 - val_loss: 1.6955\n",
      "Epoch 1066/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.3375 - val_loss: 1.6929\n",
      "Epoch 1067/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.3372 - val_loss: 1.6950\n",
      "Epoch 1068/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3366 - val_loss: 1.6919\n",
      "Epoch 1069/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.3361 - val_loss: 1.6938\n",
      "Epoch 1070/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.3358 - val_loss: 1.6907\n",
      "Epoch 1071/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.3355 - val_loss: 1.6935\n",
      "Epoch 1072/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 1.3351 - val_loss: 1.6899\n",
      "Epoch 1073/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3347 - val_loss: 1.6931\n",
      "Epoch 1074/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.3343 - val_loss: 1.6885\n",
      "Epoch 1075/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.3339 - val_loss: 1.6931\n",
      "Epoch 1076/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.3335 - val_loss: 1.6869\n",
      "Epoch 1077/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.3331 - val_loss: 1.6926\n",
      "Epoch 1078/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.3327 - val_loss: 1.6853\n",
      "Epoch 1079/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.3324 - val_loss: 1.6926\n",
      "Epoch 1080/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.3319 - val_loss: 1.6837\n",
      "Epoch 1081/2500\n",
      "64/64 [==============================] - 0s 215us/step - loss: 1.3315 - val_loss: 1.6927\n",
      "Epoch 1082/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3311 - val_loss: 1.6821\n",
      "Epoch 1083/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 1.3308 - val_loss: 1.6938\n",
      "Epoch 1084/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3304 - val_loss: 1.6803\n",
      "Epoch 1085/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3300 - val_loss: 1.6942\n",
      "Epoch 1086/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.3297 - val_loss: 1.6776\n",
      "Epoch 1087/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.3293 - val_loss: 1.6943\n",
      "Epoch 1088/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3290 - val_loss: 1.6756\n",
      "Epoch 1089/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3286 - val_loss: 1.6946\n",
      "Epoch 1090/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.3283 - val_loss: 1.6750\n",
      "Epoch 1091/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.3280 - val_loss: 1.6940\n",
      "Epoch 1092/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.3276 - val_loss: 1.6748\n",
      "Epoch 1093/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3271 - val_loss: 1.6925\n",
      "Epoch 1094/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.3266 - val_loss: 1.6748\n",
      "Epoch 1095/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3263 - val_loss: 1.6901\n",
      "Epoch 1096/2500\n",
      "64/64 [==============================] - 0s 281us/step - loss: 1.3258 - val_loss: 1.6749\n",
      "Epoch 1097/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.3255 - val_loss: 1.6877\n",
      "Epoch 1098/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.3251 - val_loss: 1.6750\n",
      "Epoch 1099/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.3247 - val_loss: 1.6855\n",
      "Epoch 1100/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3242 - val_loss: 1.6754\n",
      "Epoch 1101/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.3237 - val_loss: 1.6852\n",
      "Epoch 1102/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.3234 - val_loss: 1.6748\n",
      "Epoch 1103/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.3231 - val_loss: 1.6858\n",
      "Epoch 1104/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3227 - val_loss: 1.6724\n",
      "Epoch 1105/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.3224 - val_loss: 1.6864\n",
      "Epoch 1106/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.3222 - val_loss: 1.6686\n",
      "Epoch 1107/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3219 - val_loss: 1.6875\n",
      "Epoch 1108/2500\n",
      "64/64 [==============================] - 0s 251us/step - loss: 1.3215 - val_loss: 1.6649\n",
      "Epoch 1109/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3213 - val_loss: 1.6905\n",
      "Epoch 1110/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.3209 - val_loss: 1.6621\n",
      "Epoch 1111/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3208 - val_loss: 1.6937\n",
      "Epoch 1112/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.3206 - val_loss: 1.6588\n",
      "Epoch 1113/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.3203 - val_loss: 1.6940\n",
      "Epoch 1114/2500\n",
      "64/64 [==============================] - 0s 189us/step - loss: 1.3199 - val_loss: 1.6573\n",
      "Epoch 1115/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3197 - val_loss: 1.6914\n",
      "Epoch 1116/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3192 - val_loss: 1.6584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1117/2500\n",
      "64/64 [==============================] - 0s 353us/step - loss: 1.3186 - val_loss: 1.6864\n",
      "Epoch 1118/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.3180 - val_loss: 1.6630\n",
      "Epoch 1119/2500\n",
      "64/64 [==============================] - 0s 279us/step - loss: 1.3174 - val_loss: 1.6799\n",
      "Epoch 1120/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.3168 - val_loss: 1.6685\n",
      "Epoch 1121/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3164 - val_loss: 1.6736\n",
      "Epoch 1122/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 1.3159 - val_loss: 1.6728\n",
      "Epoch 1123/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3156 - val_loss: 1.6680\n",
      "Epoch 1124/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3152 - val_loss: 1.6768\n",
      "Epoch 1125/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.3150 - val_loss: 1.6633\n",
      "Epoch 1126/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3147 - val_loss: 1.6812\n",
      "Epoch 1127/2500\n",
      "64/64 [==============================] - 0s 486us/step - loss: 1.3147 - val_loss: 1.6581\n",
      "Epoch 1128/2500\n",
      "64/64 [==============================] - 0s 580us/step - loss: 1.3143 - val_loss: 1.6849\n",
      "Epoch 1129/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.3141 - val_loss: 1.6532\n",
      "Epoch 1130/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.3141 - val_loss: 1.6886\n",
      "Epoch 1131/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.3139 - val_loss: 1.6498\n",
      "Epoch 1132/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 1.3136 - val_loss: 1.6894\n",
      "Epoch 1133/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.3132 - val_loss: 1.6491\n",
      "Epoch 1134/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.3128 - val_loss: 1.6864\n",
      "Epoch 1135/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3124 - val_loss: 1.6509\n",
      "Epoch 1136/2500\n",
      "64/64 [==============================] - 0s 317us/step - loss: 1.3118 - val_loss: 1.6794\n",
      "Epoch 1137/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.3110 - val_loss: 1.6555\n",
      "Epoch 1138/2500\n",
      "64/64 [==============================] - 0s 198us/step - loss: 1.3105 - val_loss: 1.6726\n",
      "Epoch 1139/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.3101 - val_loss: 1.6612\n",
      "Epoch 1140/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3095 - val_loss: 1.6653\n",
      "Epoch 1141/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.3090 - val_loss: 1.6660\n",
      "Epoch 1142/2500\n",
      "64/64 [==============================] - 0s 471us/step - loss: 1.3087 - val_loss: 1.6598\n",
      "Epoch 1143/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.3084 - val_loss: 1.6701\n",
      "Epoch 1144/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.3081 - val_loss: 1.6546\n",
      "Epoch 1145/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.3079 - val_loss: 1.6731\n",
      "Epoch 1146/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.3077 - val_loss: 1.6508\n",
      "Epoch 1147/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.3075 - val_loss: 1.6761\n",
      "Epoch 1148/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.3072 - val_loss: 1.6486\n",
      "Epoch 1149/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.3069 - val_loss: 1.6786\n",
      "Epoch 1150/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 1.3066 - val_loss: 1.6467\n",
      "Epoch 1151/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.3064 - val_loss: 1.6796\n",
      "Epoch 1152/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.3061 - val_loss: 1.6449\n",
      "Epoch 1153/2500\n",
      "64/64 [==============================] - 0s 382us/step - loss: 1.3057 - val_loss: 1.6781\n",
      "Epoch 1154/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.3053 - val_loss: 1.6446\n",
      "Epoch 1155/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 1.3050 - val_loss: 1.6748\n",
      "Epoch 1156/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.3045 - val_loss: 1.6466\n",
      "Epoch 1157/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.3040 - val_loss: 1.6699\n",
      "Epoch 1158/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.3034 - val_loss: 1.6492\n",
      "Epoch 1159/2500\n",
      "64/64 [==============================] - 0s 242us/step - loss: 1.3029 - val_loss: 1.6655\n",
      "Epoch 1160/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.3026 - val_loss: 1.6512\n",
      "Epoch 1161/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.3023 - val_loss: 1.6621\n",
      "Epoch 1162/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.3018 - val_loss: 1.6525\n",
      "Epoch 1163/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.3014 - val_loss: 1.6592\n",
      "Epoch 1164/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.3010 - val_loss: 1.6531\n",
      "Epoch 1165/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.3008 - val_loss: 1.6579\n",
      "Epoch 1166/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.3006 - val_loss: 1.6541\n",
      "Epoch 1167/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.3003 - val_loss: 1.6576\n",
      "Epoch 1168/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.2998 - val_loss: 1.6532\n",
      "Epoch 1169/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2995 - val_loss: 1.6576\n",
      "Epoch 1170/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2992 - val_loss: 1.6512\n",
      "Epoch 1171/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.2989 - val_loss: 1.6586\n",
      "Epoch 1172/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2986 - val_loss: 1.6477\n",
      "Epoch 1173/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2982 - val_loss: 1.6608\n",
      "Epoch 1174/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2980 - val_loss: 1.6435\n",
      "Epoch 1175/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.2979 - val_loss: 1.6655\n",
      "Epoch 1176/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.2977 - val_loss: 1.6376\n",
      "Epoch 1177/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2976 - val_loss: 1.6723\n",
      "Epoch 1178/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.2978 - val_loss: 1.6301\n",
      "Epoch 1179/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2980 - val_loss: 1.6802\n",
      "Epoch 1180/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.2983 - val_loss: 1.6227\n",
      "Epoch 1181/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2987 - val_loss: 1.6868\n",
      "Epoch 1182/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2989 - val_loss: 1.6186\n",
      "Epoch 1183/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2989 - val_loss: 1.6856\n",
      "Epoch 1184/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2983 - val_loss: 1.6211\n",
      "Epoch 1185/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2974 - val_loss: 1.6727\n",
      "Epoch 1186/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.2960 - val_loss: 1.6323\n",
      "Epoch 1187/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2947 - val_loss: 1.6550\n",
      "Epoch 1188/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2936 - val_loss: 1.6482\n",
      "Epoch 1189/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2931 - val_loss: 1.6399\n",
      "Epoch 1190/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2930 - val_loss: 1.6608\n",
      "Epoch 1191/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2932 - val_loss: 1.6295\n",
      "Epoch 1192/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2934 - val_loss: 1.6679\n",
      "Epoch 1193/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2933 - val_loss: 1.6245\n",
      "Epoch 1194/2500\n",
      "64/64 [==============================] - 0s 265us/step - loss: 1.2932 - val_loss: 1.6695\n",
      "Epoch 1195/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2931 - val_loss: 1.6269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1196/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2927 - val_loss: 1.6645\n",
      "Epoch 1197/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2918 - val_loss: 1.6334\n",
      "Epoch 1198/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.2910 - val_loss: 1.6557\n",
      "Epoch 1199/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2906 - val_loss: 1.6411\n",
      "Epoch 1200/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2899 - val_loss: 1.6459\n",
      "Epoch 1201/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2896 - val_loss: 1.6476\n",
      "Epoch 1202/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.2893 - val_loss: 1.6385\n",
      "Epoch 1203/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2890 - val_loss: 1.6517\n",
      "Epoch 1204/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2887 - val_loss: 1.6334\n",
      "Epoch 1205/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2886 - val_loss: 1.6550\n",
      "Epoch 1206/2500\n",
      "64/64 [==============================] - 0s 338us/step - loss: 1.2884 - val_loss: 1.6307\n",
      "Epoch 1207/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2884 - val_loss: 1.6568\n",
      "Epoch 1208/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.2881 - val_loss: 1.6286\n",
      "Epoch 1209/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2878 - val_loss: 1.6556\n",
      "Epoch 1210/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.2875 - val_loss: 1.6279\n",
      "Epoch 1211/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2872 - val_loss: 1.6534\n",
      "Epoch 1212/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 1.2868 - val_loss: 1.6292\n",
      "Epoch 1213/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.2863 - val_loss: 1.6507\n",
      "Epoch 1214/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2859 - val_loss: 1.6321\n",
      "Epoch 1215/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.2856 - val_loss: 1.6475\n",
      "Epoch 1216/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2852 - val_loss: 1.6338\n",
      "Epoch 1217/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2849 - val_loss: 1.6436\n",
      "Epoch 1218/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2845 - val_loss: 1.6346\n",
      "Epoch 1219/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.2841 - val_loss: 1.6401\n",
      "Epoch 1220/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2838 - val_loss: 1.6365\n",
      "Epoch 1221/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2835 - val_loss: 1.6382\n",
      "Epoch 1222/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.2831 - val_loss: 1.6384\n",
      "Epoch 1223/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2830 - val_loss: 1.6367\n",
      "Epoch 1224/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.2827 - val_loss: 1.6390\n",
      "Epoch 1225/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2823 - val_loss: 1.6342\n",
      "Epoch 1226/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2821 - val_loss: 1.6393\n",
      "Epoch 1227/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 1.2819 - val_loss: 1.6326\n",
      "Epoch 1228/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.2816 - val_loss: 1.6404\n",
      "Epoch 1229/2500\n",
      "64/64 [==============================] - 0s 359us/step - loss: 1.2812 - val_loss: 1.6299\n",
      "Epoch 1230/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2809 - val_loss: 1.6422\n",
      "Epoch 1231/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2808 - val_loss: 1.6259\n",
      "Epoch 1232/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 1.2806 - val_loss: 1.6464\n",
      "Epoch 1233/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 1.2803 - val_loss: 1.6199\n",
      "Epoch 1234/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2803 - val_loss: 1.6530\n",
      "Epoch 1235/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.2805 - val_loss: 1.6127\n",
      "Epoch 1236/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2808 - val_loss: 1.6614\n",
      "Epoch 1237/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2811 - val_loss: 1.6053\n",
      "Epoch 1238/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2816 - val_loss: 1.6700\n",
      "Epoch 1239/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.2820 - val_loss: 1.5986\n",
      "Epoch 1240/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.2823 - val_loss: 1.6728\n",
      "Epoch 1241/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2822 - val_loss: 1.5975\n",
      "Epoch 1242/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.2817 - val_loss: 1.6644\n",
      "Epoch 1243/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2804 - val_loss: 1.6062\n",
      "Epoch 1244/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.2788 - val_loss: 1.6459\n",
      "Epoch 1245/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2774 - val_loss: 1.6224\n",
      "Epoch 1246/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.2765 - val_loss: 1.6270\n",
      "Epoch 1247/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2763 - val_loss: 1.6388\n",
      "Epoch 1248/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2761 - val_loss: 1.6130\n",
      "Epoch 1249/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2763 - val_loss: 1.6497\n",
      "Epoch 1250/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.2767 - val_loss: 1.6055\n",
      "Epoch 1251/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2769 - val_loss: 1.6527\n",
      "Epoch 1252/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2767 - val_loss: 1.6060\n",
      "Epoch 1253/2500\n",
      "64/64 [==============================] - 0s 122us/step - loss: 1.2762 - val_loss: 1.6486\n",
      "Epoch 1254/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.2755 - val_loss: 1.6130\n",
      "Epoch 1255/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2748 - val_loss: 1.6399\n",
      "Epoch 1256/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 1.2742 - val_loss: 1.6225\n",
      "Epoch 1257/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2736 - val_loss: 1.6300\n",
      "Epoch 1258/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2732 - val_loss: 1.6310\n",
      "Epoch 1259/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2729 - val_loss: 1.6211\n",
      "Epoch 1260/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.2726 - val_loss: 1.6362\n",
      "Epoch 1261/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2726 - val_loss: 1.6144\n",
      "Epoch 1262/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2725 - val_loss: 1.6389\n",
      "Epoch 1263/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.2723 - val_loss: 1.6108\n",
      "Epoch 1264/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2721 - val_loss: 1.6406\n",
      "Epoch 1265/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2720 - val_loss: 1.6105\n",
      "Epoch 1266/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2716 - val_loss: 1.6401\n",
      "Epoch 1267/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2714 - val_loss: 1.6112\n",
      "Epoch 1268/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.2711 - val_loss: 1.6364\n",
      "Epoch 1269/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.2706 - val_loss: 1.6126\n",
      "Epoch 1270/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2702 - val_loss: 1.6313\n",
      "Epoch 1271/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.2699 - val_loss: 1.6153\n",
      "Epoch 1272/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2695 - val_loss: 1.6268\n",
      "Epoch 1273/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2691 - val_loss: 1.6181\n",
      "Epoch 1274/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2687 - val_loss: 1.6237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1275/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2684 - val_loss: 1.6208\n",
      "Epoch 1276/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.2681 - val_loss: 1.6206\n",
      "Epoch 1277/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2678 - val_loss: 1.6225\n",
      "Epoch 1278/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2675 - val_loss: 1.6172\n",
      "Epoch 1279/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.2674 - val_loss: 1.6244\n",
      "Epoch 1280/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2672 - val_loss: 1.6134\n",
      "Epoch 1281/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2670 - val_loss: 1.6271\n",
      "Epoch 1282/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2668 - val_loss: 1.6114\n",
      "Epoch 1283/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.2666 - val_loss: 1.6305\n",
      "Epoch 1284/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.2664 - val_loss: 1.6079\n",
      "Epoch 1285/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2664 - val_loss: 1.6333\n",
      "Epoch 1286/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.2663 - val_loss: 1.6029\n",
      "Epoch 1287/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.2663 - val_loss: 1.6373\n",
      "Epoch 1288/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.2662 - val_loss: 1.5975\n",
      "Epoch 1289/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2663 - val_loss: 1.6426\n",
      "Epoch 1290/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2664 - val_loss: 1.5943\n",
      "Epoch 1291/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2665 - val_loss: 1.6464\n",
      "Epoch 1292/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 1.2665 - val_loss: 1.5915\n",
      "Epoch 1293/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2663 - val_loss: 1.6458\n",
      "Epoch 1294/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.2660 - val_loss: 1.5915\n",
      "Epoch 1295/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2657 - val_loss: 1.6405\n",
      "Epoch 1296/2500\n",
      "64/64 [==============================] - 0s 274us/step - loss: 1.2651 - val_loss: 1.5953\n",
      "Epoch 1297/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.2643 - val_loss: 1.6308\n",
      "Epoch 1298/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.2635 - val_loss: 1.6029\n",
      "Epoch 1299/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2629 - val_loss: 1.6207\n",
      "Epoch 1300/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2623 - val_loss: 1.6104\n",
      "Epoch 1301/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2619 - val_loss: 1.6128\n",
      "Epoch 1302/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.2615 - val_loss: 1.6168\n",
      "Epoch 1303/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.2615 - val_loss: 1.6069\n",
      "Epoch 1304/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2614 - val_loss: 1.6221\n",
      "Epoch 1305/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2611 - val_loss: 1.6017\n",
      "Epoch 1306/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.2612 - val_loss: 1.6280\n",
      "Epoch 1307/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2613 - val_loss: 1.5977\n",
      "Epoch 1308/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2612 - val_loss: 1.6326\n",
      "Epoch 1309/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.2611 - val_loss: 1.5936\n",
      "Epoch 1310/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.2611 - val_loss: 1.6353\n",
      "Epoch 1311/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.2610 - val_loss: 1.5909\n",
      "Epoch 1312/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2609 - val_loss: 1.6353\n",
      "Epoch 1313/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 1.2606 - val_loss: 1.5905\n",
      "Epoch 1314/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2603 - val_loss: 1.6329\n",
      "Epoch 1315/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.2599 - val_loss: 1.5927\n",
      "Epoch 1316/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2596 - val_loss: 1.6279\n",
      "Epoch 1317/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.2590 - val_loss: 1.5962\n",
      "Epoch 1318/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2585 - val_loss: 1.6207\n",
      "Epoch 1319/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2578 - val_loss: 1.6007\n",
      "Epoch 1320/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2574 - val_loss: 1.6148\n",
      "Epoch 1321/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 1.2571 - val_loss: 1.6044\n",
      "Epoch 1322/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2569 - val_loss: 1.6100\n",
      "Epoch 1323/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2566 - val_loss: 1.6070\n",
      "Epoch 1324/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.2563 - val_loss: 1.6072\n",
      "Epoch 1325/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2561 - val_loss: 1.6090\n",
      "Epoch 1326/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2559 - val_loss: 1.6042\n",
      "Epoch 1327/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2557 - val_loss: 1.6109\n",
      "Epoch 1328/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.2555 - val_loss: 1.6012\n",
      "Epoch 1329/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2552 - val_loss: 1.6135\n",
      "Epoch 1330/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2549 - val_loss: 1.5984\n",
      "Epoch 1331/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.2548 - val_loss: 1.6184\n",
      "Epoch 1332/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2548 - val_loss: 1.5936\n",
      "Epoch 1333/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2547 - val_loss: 1.6234\n",
      "Epoch 1334/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2547 - val_loss: 1.5867\n",
      "Epoch 1335/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2550 - val_loss: 1.6307\n",
      "Epoch 1336/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.2552 - val_loss: 1.5792\n",
      "Epoch 1337/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2557 - val_loss: 1.6388\n",
      "Epoch 1338/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2561 - val_loss: 1.5727\n",
      "Epoch 1339/2500\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.2566 - val_loss: 1.6442\n",
      "Epoch 1340/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2568 - val_loss: 1.5701\n",
      "Epoch 1341/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2569 - val_loss: 1.6423\n",
      "Epoch 1342/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2562 - val_loss: 1.5735\n",
      "Epoch 1343/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2551 - val_loss: 1.6293\n",
      "Epoch 1344/2500\n",
      "64/64 [==============================] - 0s 163us/step - loss: 1.2537 - val_loss: 1.5841\n",
      "Epoch 1345/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2525 - val_loss: 1.6117\n",
      "Epoch 1346/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2516 - val_loss: 1.5985\n",
      "Epoch 1347/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2511 - val_loss: 1.5959\n",
      "Epoch 1348/2500\n",
      "64/64 [==============================] - 0s 221us/step - loss: 1.2507 - val_loss: 1.6107\n",
      "Epoch 1349/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2508 - val_loss: 1.5847\n",
      "Epoch 1350/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.2510 - val_loss: 1.6206\n",
      "Epoch 1351/2500\n",
      "64/64 [==============================] - 0s 200us/step - loss: 1.2513 - val_loss: 1.5794\n",
      "Epoch 1352/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2515 - val_loss: 1.6256\n",
      "Epoch 1353/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2514 - val_loss: 1.5789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1354/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.2512 - val_loss: 1.6241\n",
      "Epoch 1355/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.2507 - val_loss: 1.5823\n",
      "Epoch 1356/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2501 - val_loss: 1.6170\n",
      "Epoch 1357/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.2495 - val_loss: 1.5890\n",
      "Epoch 1358/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2490 - val_loss: 1.6081\n",
      "Epoch 1359/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2484 - val_loss: 1.5961\n",
      "Epoch 1360/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.2480 - val_loss: 1.5997\n",
      "Epoch 1361/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2478 - val_loss: 1.6025\n",
      "Epoch 1362/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2476 - val_loss: 1.5926\n",
      "Epoch 1363/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.2475 - val_loss: 1.6067\n",
      "Epoch 1364/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2473 - val_loss: 1.5872\n",
      "Epoch 1365/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2472 - val_loss: 1.6104\n",
      "Epoch 1366/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2471 - val_loss: 1.5844\n",
      "Epoch 1367/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2470 - val_loss: 1.6121\n",
      "Epoch 1368/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2468 - val_loss: 1.5817\n",
      "Epoch 1369/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.2466 - val_loss: 1.6116\n",
      "Epoch 1370/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.2464 - val_loss: 1.5805\n",
      "Epoch 1371/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.2461 - val_loss: 1.6101\n",
      "Epoch 1372/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2458 - val_loss: 1.5817\n",
      "Epoch 1373/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2455 - val_loss: 1.6085\n",
      "Epoch 1374/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 1.2451 - val_loss: 1.5835\n",
      "Epoch 1375/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.2449 - val_loss: 1.6067\n",
      "Epoch 1376/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2446 - val_loss: 1.5846\n",
      "Epoch 1377/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2443 - val_loss: 1.6035\n",
      "Epoch 1378/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2441 - val_loss: 1.5851\n",
      "Epoch 1379/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.2438 - val_loss: 1.6009\n",
      "Epoch 1380/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2435 - val_loss: 1.5863\n",
      "Epoch 1381/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.2433 - val_loss: 1.6009\n",
      "Epoch 1382/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2432 - val_loss: 1.5867\n",
      "Epoch 1383/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2429 - val_loss: 1.6010\n",
      "Epoch 1384/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2426 - val_loss: 1.5849\n",
      "Epoch 1385/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2425 - val_loss: 1.6018\n",
      "Epoch 1386/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 1.2422 - val_loss: 1.5818\n",
      "Epoch 1387/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2422 - val_loss: 1.6046\n",
      "Epoch 1388/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2420 - val_loss: 1.5787\n",
      "Epoch 1389/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2418 - val_loss: 1.6089\n",
      "Epoch 1390/2500\n",
      "64/64 [==============================] - 0s 261us/step - loss: 1.2419 - val_loss: 1.5737\n",
      "Epoch 1391/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2420 - val_loss: 1.6130\n",
      "Epoch 1392/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2420 - val_loss: 1.5671\n",
      "Epoch 1393/2500\n",
      "64/64 [==============================] - 0s 298us/step - loss: 1.2422 - val_loss: 1.6184\n",
      "Epoch 1394/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2425 - val_loss: 1.5622\n",
      "Epoch 1395/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2427 - val_loss: 1.6231\n",
      "Epoch 1396/2500\n",
      "64/64 [==============================] - 0s 235us/step - loss: 1.2427 - val_loss: 1.5594\n",
      "Epoch 1397/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2429 - val_loss: 1.6249\n",
      "Epoch 1398/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2426 - val_loss: 1.5599\n",
      "Epoch 1399/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2421 - val_loss: 1.6192\n",
      "Epoch 1400/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2414 - val_loss: 1.5653\n",
      "Epoch 1401/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.2406 - val_loss: 1.6068\n",
      "Epoch 1402/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2396 - val_loss: 1.5744\n",
      "Epoch 1403/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2388 - val_loss: 1.5926\n",
      "Epoch 1404/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2381 - val_loss: 1.5854\n",
      "Epoch 1405/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2379 - val_loss: 1.5821\n",
      "Epoch 1406/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.2378 - val_loss: 1.5953\n",
      "Epoch 1407/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2378 - val_loss: 1.5743\n",
      "Epoch 1408/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2378 - val_loss: 1.6025\n",
      "Epoch 1409/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.2378 - val_loss: 1.5683\n",
      "Epoch 1410/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.2380 - val_loss: 1.6083\n",
      "Epoch 1411/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.2380 - val_loss: 1.5654\n",
      "Epoch 1412/2500\n",
      "64/64 [==============================] - 0s 303us/step - loss: 1.2381 - val_loss: 1.6110\n",
      "Epoch 1413/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.2379 - val_loss: 1.5649\n",
      "Epoch 1414/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.2376 - val_loss: 1.6091\n",
      "Epoch 1415/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2373 - val_loss: 1.5670\n",
      "Epoch 1416/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2367 - val_loss: 1.6037\n",
      "Epoch 1417/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.2363 - val_loss: 1.5711\n",
      "Epoch 1418/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.2357 - val_loss: 1.5961\n",
      "Epoch 1419/2500\n",
      "64/64 [==============================] - 0s 277us/step - loss: 1.2352 - val_loss: 1.5753\n",
      "Epoch 1420/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.2346 - val_loss: 1.5881\n",
      "Epoch 1421/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2343 - val_loss: 1.5796\n",
      "Epoch 1422/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.2340 - val_loss: 1.5825\n",
      "Epoch 1423/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2338 - val_loss: 1.5851\n",
      "Epoch 1424/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2336 - val_loss: 1.5781\n",
      "Epoch 1425/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.2335 - val_loss: 1.5887\n",
      "Epoch 1426/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2335 - val_loss: 1.5733\n",
      "Epoch 1427/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2334 - val_loss: 1.5918\n",
      "Epoch 1428/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2331 - val_loss: 1.5688\n",
      "Epoch 1429/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.2330 - val_loss: 1.5960\n",
      "Epoch 1430/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2331 - val_loss: 1.5651\n",
      "Epoch 1431/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.2331 - val_loss: 1.6009\n",
      "Epoch 1432/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 1.2331 - val_loss: 1.5614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1433/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2331 - val_loss: 1.6048\n",
      "Epoch 1434/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.2331 - val_loss: 1.5586\n",
      "Epoch 1435/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2331 - val_loss: 1.6064\n",
      "Epoch 1436/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.2330 - val_loss: 1.5568\n",
      "Epoch 1437/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.2329 - val_loss: 1.6045\n",
      "Epoch 1438/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2326 - val_loss: 1.5570\n",
      "Epoch 1439/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2321 - val_loss: 1.6000\n",
      "Epoch 1440/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.2314 - val_loss: 1.5608\n",
      "Epoch 1441/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2311 - val_loss: 1.5950\n",
      "Epoch 1442/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.2307 - val_loss: 1.5662\n",
      "Epoch 1443/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2302 - val_loss: 1.5888\n",
      "Epoch 1444/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.2298 - val_loss: 1.5698\n",
      "Epoch 1445/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2294 - val_loss: 1.5824\n",
      "Epoch 1446/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2290 - val_loss: 1.5724\n",
      "Epoch 1447/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.2290 - val_loss: 1.5787\n",
      "Epoch 1448/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2287 - val_loss: 1.5744\n",
      "Epoch 1449/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.2283 - val_loss: 1.5775\n",
      "Epoch 1450/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2281 - val_loss: 1.5764\n",
      "Epoch 1451/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 1.2280 - val_loss: 1.5765\n",
      "Epoch 1452/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2277 - val_loss: 1.5767\n",
      "Epoch 1453/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.2274 - val_loss: 1.5751\n",
      "Epoch 1454/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2272 - val_loss: 1.5771\n",
      "Epoch 1455/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2271 - val_loss: 1.5736\n",
      "Epoch 1456/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.2269 - val_loss: 1.5775\n",
      "Epoch 1457/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2267 - val_loss: 1.5718\n",
      "Epoch 1458/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2264 - val_loss: 1.5793\n",
      "Epoch 1459/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.2262 - val_loss: 1.5702\n",
      "Epoch 1460/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2261 - val_loss: 1.5814\n",
      "Epoch 1461/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2260 - val_loss: 1.5658\n",
      "Epoch 1462/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2259 - val_loss: 1.5847\n",
      "Epoch 1463/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 1.2257 - val_loss: 1.5591\n",
      "Epoch 1464/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2257 - val_loss: 1.5909\n",
      "Epoch 1465/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2260 - val_loss: 1.5516\n",
      "Epoch 1466/2500\n",
      "64/64 [==============================] - 0s 212us/step - loss: 1.2265 - val_loss: 1.6014\n",
      "Epoch 1467/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2270 - val_loss: 1.5426\n",
      "Epoch 1468/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 1.2277 - val_loss: 1.6143\n",
      "Epoch 1469/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.2287 - val_loss: 1.5341\n",
      "Epoch 1470/2500\n",
      "64/64 [==============================] - 0s 492us/step - loss: 1.2297 - val_loss: 1.6239\n",
      "Epoch 1471/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2304 - val_loss: 1.5295\n",
      "Epoch 1472/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.2307 - val_loss: 1.6200\n",
      "Epoch 1473/2500\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.2296 - val_loss: 1.5338\n",
      "Epoch 1474/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.2279 - val_loss: 1.5986\n",
      "Epoch 1475/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.2256 - val_loss: 1.5518\n",
      "Epoch 1476/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2237 - val_loss: 1.5725\n",
      "Epoch 1477/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.2227 - val_loss: 1.5768\n",
      "Epoch 1478/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2228 - val_loss: 1.5522\n",
      "Epoch 1479/2500\n",
      "64/64 [==============================] - 0s 397us/step - loss: 1.2232 - val_loss: 1.5945\n",
      "Epoch 1480/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2239 - val_loss: 1.5409\n",
      "Epoch 1481/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.2246 - val_loss: 1.5995\n",
      "Epoch 1482/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.2246 - val_loss: 1.5412\n",
      "Epoch 1483/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2239 - val_loss: 1.5917\n",
      "Epoch 1484/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.2231 - val_loss: 1.5524\n",
      "Epoch 1485/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.2221 - val_loss: 1.5779\n",
      "Epoch 1486/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2213 - val_loss: 1.5676\n",
      "Epoch 1487/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.2209 - val_loss: 1.5649\n",
      "Epoch 1488/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.2207 - val_loss: 1.5804\n",
      "Epoch 1489/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2207 - val_loss: 1.5550\n",
      "Epoch 1490/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.2209 - val_loss: 1.5874\n",
      "Epoch 1491/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2210 - val_loss: 1.5496\n",
      "Epoch 1492/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2209 - val_loss: 1.5865\n",
      "Epoch 1493/2500\n",
      "64/64 [==============================] - 0s 422us/step - loss: 1.2205 - val_loss: 1.5503\n",
      "Epoch 1494/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.2202 - val_loss: 1.5818\n",
      "Epoch 1495/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.2198 - val_loss: 1.5560\n",
      "Epoch 1496/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2193 - val_loss: 1.5740\n",
      "Epoch 1497/2500\n",
      "64/64 [==============================] - 0s 282us/step - loss: 1.2189 - val_loss: 1.5619\n",
      "Epoch 1498/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.2187 - val_loss: 1.5656\n",
      "Epoch 1499/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.2184 - val_loss: 1.5669\n",
      "Epoch 1500/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2180 - val_loss: 1.5582\n",
      "Epoch 1501/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.2178 - val_loss: 1.5718\n",
      "Epoch 1502/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.2179 - val_loss: 1.5544\n",
      "Epoch 1503/2500\n",
      "64/64 [==============================] - 0s 222us/step - loss: 1.2179 - val_loss: 1.5755\n",
      "Epoch 1504/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2177 - val_loss: 1.5526\n",
      "Epoch 1505/2500\n",
      "64/64 [==============================] - 0s 488us/step - loss: 1.2175 - val_loss: 1.5761\n",
      "Epoch 1506/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 1.2173 - val_loss: 1.5516\n",
      "Epoch 1507/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.2172 - val_loss: 1.5744\n",
      "Epoch 1508/2500\n",
      "64/64 [==============================] - 0s 499us/step - loss: 1.2170 - val_loss: 1.5521\n",
      "Epoch 1509/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.2167 - val_loss: 1.5724\n",
      "Epoch 1510/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2164 - val_loss: 1.5550\n",
      "Epoch 1511/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2161 - val_loss: 1.5704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1512/2500\n",
      "64/64 [==============================] - 0s 248us/step - loss: 1.2159 - val_loss: 1.5568\n",
      "Epoch 1513/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.2157 - val_loss: 1.5670\n",
      "Epoch 1514/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.2154 - val_loss: 1.5570\n",
      "Epoch 1515/2500\n",
      "64/64 [==============================] - 0s 228us/step - loss: 1.2152 - val_loss: 1.5641\n",
      "Epoch 1516/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 1.2150 - val_loss: 1.5579\n",
      "Epoch 1517/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.2148 - val_loss: 1.5633\n",
      "Epoch 1518/2500\n",
      "64/64 [==============================] - 0s 409us/step - loss: 1.2146 - val_loss: 1.5592\n",
      "Epoch 1519/2500\n",
      "64/64 [==============================] - 0s 381us/step - loss: 1.2144 - val_loss: 1.5626\n",
      "Epoch 1520/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.2142 - val_loss: 1.5593\n",
      "Epoch 1521/2500\n",
      "64/64 [==============================] - 0s 409us/step - loss: 1.2140 - val_loss: 1.5617\n",
      "Epoch 1522/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.2139 - val_loss: 1.5584\n",
      "Epoch 1523/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.2135 - val_loss: 1.5607\n",
      "Epoch 1524/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.2133 - val_loss: 1.5572\n",
      "Epoch 1525/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2132 - val_loss: 1.5613\n",
      "Epoch 1526/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2130 - val_loss: 1.5556\n",
      "Epoch 1527/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.2129 - val_loss: 1.5626\n",
      "Epoch 1528/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.2127 - val_loss: 1.5527\n",
      "Epoch 1529/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2124 - val_loss: 1.5648\n",
      "Epoch 1530/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2122 - val_loss: 1.5499\n",
      "Epoch 1531/2500\n",
      "64/64 [==============================] - 0s 204us/step - loss: 1.2122 - val_loss: 1.5686\n",
      "Epoch 1532/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2122 - val_loss: 1.5453\n",
      "Epoch 1533/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2122 - val_loss: 1.5734\n",
      "Epoch 1534/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 1.2121 - val_loss: 1.5389\n",
      "Epoch 1535/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.2124 - val_loss: 1.5801\n",
      "Epoch 1536/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2125 - val_loss: 1.5321\n",
      "Epoch 1537/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.2129 - val_loss: 1.5887\n",
      "Epoch 1538/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 1.2134 - val_loss: 1.5255\n",
      "Epoch 1539/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.2140 - val_loss: 1.5954\n",
      "Epoch 1540/2500\n",
      "64/64 [==============================] - 0s 260us/step - loss: 1.2143 - val_loss: 1.5207\n",
      "Epoch 1541/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.2147 - val_loss: 1.5962\n",
      "Epoch 1542/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.2143 - val_loss: 1.5214\n",
      "Epoch 1543/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 1.2136 - val_loss: 1.5879\n",
      "Epoch 1544/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.2126 - val_loss: 1.5303\n",
      "Epoch 1545/2500\n",
      "64/64 [==============================] - 0s 387us/step - loss: 1.2114 - val_loss: 1.5720\n",
      "Epoch 1546/2500\n",
      "64/64 [==============================] - 0s 446us/step - loss: 1.2103 - val_loss: 1.5439\n",
      "Epoch 1547/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.2095 - val_loss: 1.5550\n",
      "Epoch 1548/2500\n",
      "64/64 [==============================] - 0s 267us/step - loss: 1.2090 - val_loss: 1.5570\n",
      "Epoch 1549/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2088 - val_loss: 1.5424\n",
      "Epoch 1550/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2090 - val_loss: 1.5683\n",
      "Epoch 1551/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.2092 - val_loss: 1.5337\n",
      "Epoch 1552/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.2095 - val_loss: 1.5759\n",
      "Epoch 1553/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.2097 - val_loss: 1.5300\n",
      "Epoch 1554/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.2097 - val_loss: 1.5788\n",
      "Epoch 1555/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.2097 - val_loss: 1.5306\n",
      "Epoch 1556/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.2093 - val_loss: 1.5756\n",
      "Epoch 1557/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.2088 - val_loss: 1.5355\n",
      "Epoch 1558/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.2082 - val_loss: 1.5684\n",
      "Epoch 1559/2500\n",
      "64/64 [==============================] - 0s 275us/step - loss: 1.2077 - val_loss: 1.5424\n",
      "Epoch 1560/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.2070 - val_loss: 1.5590\n",
      "Epoch 1561/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2066 - val_loss: 1.5490\n",
      "Epoch 1562/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.2064 - val_loss: 1.5510\n",
      "Epoch 1563/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.2061 - val_loss: 1.5543\n",
      "Epoch 1564/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.2060 - val_loss: 1.5448\n",
      "Epoch 1565/2500\n",
      "64/64 [==============================] - 0s 705us/step - loss: 1.2058 - val_loss: 1.5578\n",
      "Epoch 1566/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2057 - val_loss: 1.5396\n",
      "Epoch 1567/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.2057 - val_loss: 1.5615\n",
      "Epoch 1568/2500\n",
      "64/64 [==============================] - 0s 472us/step - loss: 1.2056 - val_loss: 1.5358\n",
      "Epoch 1569/2500\n",
      "64/64 [==============================] - 0s 285us/step - loss: 1.2055 - val_loss: 1.5649\n",
      "Epoch 1570/2500\n",
      "64/64 [==============================] - 0s 402us/step - loss: 1.2054 - val_loss: 1.5330\n",
      "Epoch 1571/2500\n",
      "64/64 [==============================] - 0s 349us/step - loss: 1.2054 - val_loss: 1.5661\n",
      "Epoch 1572/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.2053 - val_loss: 1.5305\n",
      "Epoch 1573/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2052 - val_loss: 1.5659\n",
      "Epoch 1574/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.2050 - val_loss: 1.5310\n",
      "Epoch 1575/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.2048 - val_loss: 1.5652\n",
      "Epoch 1576/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2045 - val_loss: 1.5325\n",
      "Epoch 1577/2500\n",
      "64/64 [==============================] - 0s 355us/step - loss: 1.2042 - val_loss: 1.5629\n",
      "Epoch 1578/2500\n",
      "64/64 [==============================] - 0s 421us/step - loss: 1.2039 - val_loss: 1.5346\n",
      "Epoch 1579/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2036 - val_loss: 1.5594\n",
      "Epoch 1580/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 1.2034 - val_loss: 1.5365\n",
      "Epoch 1581/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.2031 - val_loss: 1.5552\n",
      "Epoch 1582/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.2028 - val_loss: 1.5384\n",
      "Epoch 1583/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.2025 - val_loss: 1.5521\n",
      "Epoch 1584/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.2023 - val_loss: 1.5406\n",
      "Epoch 1585/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.2021 - val_loss: 1.5502\n",
      "Epoch 1586/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2020 - val_loss: 1.5421\n",
      "Epoch 1587/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.2019 - val_loss: 1.5495\n",
      "Epoch 1588/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.2017 - val_loss: 1.5425\n",
      "Epoch 1589/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.2013 - val_loss: 1.5488\n",
      "Epoch 1590/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.2010 - val_loss: 1.5408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1591/2500\n",
      "64/64 [==============================] - 0s 185us/step - loss: 1.2009 - val_loss: 1.5491\n",
      "Epoch 1592/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.2008 - val_loss: 1.5379\n",
      "Epoch 1593/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.2006 - val_loss: 1.5514\n",
      "Epoch 1594/2500\n",
      "64/64 [==============================] - 0s 202us/step - loss: 1.2005 - val_loss: 1.5352\n",
      "Epoch 1595/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.2004 - val_loss: 1.5550\n",
      "Epoch 1596/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.2003 - val_loss: 1.5309\n",
      "Epoch 1597/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.2002 - val_loss: 1.5601\n",
      "Epoch 1598/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.2003 - val_loss: 1.5243\n",
      "Epoch 1599/2500\n",
      "64/64 [==============================] - 0s 213us/step - loss: 1.2004 - val_loss: 1.5666\n",
      "Epoch 1600/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2007 - val_loss: 1.5166\n",
      "Epoch 1601/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.2013 - val_loss: 1.5743\n",
      "Epoch 1602/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.2018 - val_loss: 1.5106\n",
      "Epoch 1603/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2023 - val_loss: 1.5817\n",
      "Epoch 1604/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.2026 - val_loss: 1.5078\n",
      "Epoch 1605/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.2027 - val_loss: 1.5826\n",
      "Epoch 1606/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.2026 - val_loss: 1.5088\n",
      "Epoch 1607/2500\n",
      "64/64 [==============================] - 0s 377us/step - loss: 1.2020 - val_loss: 1.5725\n",
      "Epoch 1608/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.2007 - val_loss: 1.5160\n",
      "Epoch 1609/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1995 - val_loss: 1.5559\n",
      "Epoch 1610/2500\n",
      "64/64 [==============================] - 0s 272us/step - loss: 1.1985 - val_loss: 1.5298\n",
      "Epoch 1611/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1977 - val_loss: 1.5401\n",
      "Epoch 1612/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1974 - val_loss: 1.5443\n",
      "Epoch 1613/2500\n",
      "64/64 [==============================] - 0s 319us/step - loss: 1.1972 - val_loss: 1.5284\n",
      "Epoch 1614/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1972 - val_loss: 1.5560\n",
      "Epoch 1615/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1977 - val_loss: 1.5206\n",
      "Epoch 1616/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1979 - val_loss: 1.5634\n",
      "Epoch 1617/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1982 - val_loss: 1.5166\n",
      "Epoch 1618/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1982 - val_loss: 1.5644\n",
      "Epoch 1619/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1979 - val_loss: 1.5180\n",
      "Epoch 1620/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 1.1976 - val_loss: 1.5606\n",
      "Epoch 1621/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1971 - val_loss: 1.5237\n",
      "Epoch 1622/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1966 - val_loss: 1.5532\n",
      "Epoch 1623/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.1961 - val_loss: 1.5306\n",
      "Epoch 1624/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1957 - val_loss: 1.5440\n",
      "Epoch 1625/2500\n",
      "64/64 [==============================] - 0s 117us/step - loss: 1.1954 - val_loss: 1.5362\n",
      "Epoch 1626/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.1951 - val_loss: 1.5359\n",
      "Epoch 1627/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1949 - val_loss: 1.5405\n",
      "Epoch 1628/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1947 - val_loss: 1.5294\n",
      "Epoch 1629/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1946 - val_loss: 1.5446\n",
      "Epoch 1630/2500\n",
      "64/64 [==============================] - 0s 246us/step - loss: 1.1946 - val_loss: 1.5251\n",
      "Epoch 1631/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1945 - val_loss: 1.5490\n",
      "Epoch 1632/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1945 - val_loss: 1.5223\n",
      "Epoch 1633/2500\n",
      "64/64 [==============================] - 0s 150us/step - loss: 1.1944 - val_loss: 1.5520\n",
      "Epoch 1634/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1943 - val_loss: 1.5202\n",
      "Epoch 1635/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1943 - val_loss: 1.5530\n",
      "Epoch 1636/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1941 - val_loss: 1.5179\n",
      "Epoch 1637/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1940 - val_loss: 1.5519\n",
      "Epoch 1638/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1938 - val_loss: 1.5181\n",
      "Epoch 1639/2500\n",
      "64/64 [==============================] - 0s 184us/step - loss: 1.1936 - val_loss: 1.5502\n",
      "Epoch 1640/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1933 - val_loss: 1.5207\n",
      "Epoch 1641/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1930 - val_loss: 1.5482\n",
      "Epoch 1642/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1928 - val_loss: 1.5234\n",
      "Epoch 1643/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 1.1926 - val_loss: 1.5448\n",
      "Epoch 1644/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1924 - val_loss: 1.5249\n",
      "Epoch 1645/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1920 - val_loss: 1.5407\n",
      "Epoch 1646/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1918 - val_loss: 1.5261\n",
      "Epoch 1647/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1918 - val_loss: 1.5383\n",
      "Epoch 1648/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.1915 - val_loss: 1.5277\n",
      "Epoch 1649/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1913 - val_loss: 1.5380\n",
      "Epoch 1650/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1911 - val_loss: 1.5280\n",
      "Epoch 1651/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1909 - val_loss: 1.5377\n",
      "Epoch 1652/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1908 - val_loss: 1.5263\n",
      "Epoch 1653/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1907 - val_loss: 1.5379\n",
      "Epoch 1654/2500\n",
      "64/64 [==============================] - 0s 223us/step - loss: 1.1905 - val_loss: 1.5238\n",
      "Epoch 1655/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1903 - val_loss: 1.5402\n",
      "Epoch 1656/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1901 - val_loss: 1.5211\n",
      "Epoch 1657/2500\n",
      "64/64 [==============================] - 0s 376us/step - loss: 1.1903 - val_loss: 1.5445\n",
      "Epoch 1658/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1903 - val_loss: 1.5167\n",
      "Epoch 1659/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.1903 - val_loss: 1.5488\n",
      "Epoch 1660/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1904 - val_loss: 1.5107\n",
      "Epoch 1661/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1905 - val_loss: 1.5546\n",
      "Epoch 1662/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.1907 - val_loss: 1.5045\n",
      "Epoch 1663/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 1.1911 - val_loss: 1.5615\n",
      "Epoch 1664/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1915 - val_loss: 1.4999\n",
      "Epoch 1665/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1918 - val_loss: 1.5668\n",
      "Epoch 1666/2500\n",
      "64/64 [==============================] - 0s 135us/step - loss: 1.1921 - val_loss: 1.4974\n",
      "Epoch 1667/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1922 - val_loss: 1.5659\n",
      "Epoch 1668/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1918 - val_loss: 1.4990\n",
      "Epoch 1669/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1911 - val_loss: 1.5566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1670/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1901 - val_loss: 1.5071\n",
      "Epoch 1671/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1892 - val_loss: 1.5428\n",
      "Epoch 1672/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1883 - val_loss: 1.5194\n",
      "Epoch 1673/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1877 - val_loss: 1.5290\n",
      "Epoch 1674/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1873 - val_loss: 1.5307\n",
      "Epoch 1675/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1872 - val_loss: 1.5175\n",
      "Epoch 1676/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1872 - val_loss: 1.5399\n",
      "Epoch 1677/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1874 - val_loss: 1.5097\n",
      "Epoch 1678/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1877 - val_loss: 1.5471\n",
      "Epoch 1679/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1877 - val_loss: 1.5055\n",
      "Epoch 1680/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.1878 - val_loss: 1.5516\n",
      "Epoch 1681/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1879 - val_loss: 1.5053\n",
      "Epoch 1682/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1879 - val_loss: 1.5508\n",
      "Epoch 1683/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1875 - val_loss: 1.5080\n",
      "Epoch 1684/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1872 - val_loss: 1.5456\n",
      "Epoch 1685/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1867 - val_loss: 1.5122\n",
      "Epoch 1686/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1863 - val_loss: 1.5389\n",
      "Epoch 1687/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1860 - val_loss: 1.5179\n",
      "Epoch 1688/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1856 - val_loss: 1.5318\n",
      "Epoch 1689/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1853 - val_loss: 1.5227\n",
      "Epoch 1690/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1850 - val_loss: 1.5258\n",
      "Epoch 1691/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1849 - val_loss: 1.5269\n",
      "Epoch 1692/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.1847 - val_loss: 1.5211\n",
      "Epoch 1693/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1846 - val_loss: 1.5297\n",
      "Epoch 1694/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.1845 - val_loss: 1.5170\n",
      "Epoch 1695/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1845 - val_loss: 1.5320\n",
      "Epoch 1696/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.1845 - val_loss: 1.5131\n",
      "Epoch 1697/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.1843 - val_loss: 1.5347\n",
      "Epoch 1698/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1842 - val_loss: 1.5111\n",
      "Epoch 1699/2500\n",
      "64/64 [==============================] - 0s 335us/step - loss: 1.1842 - val_loss: 1.5374\n",
      "Epoch 1700/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1842 - val_loss: 1.5092\n",
      "Epoch 1701/2500\n",
      "64/64 [==============================] - 0s 278us/step - loss: 1.1840 - val_loss: 1.5395\n",
      "Epoch 1702/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1840 - val_loss: 1.5071\n",
      "Epoch 1703/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1839 - val_loss: 1.5401\n",
      "Epoch 1704/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1838 - val_loss: 1.5052\n",
      "Epoch 1705/2500\n",
      "64/64 [==============================] - 0s 263us/step - loss: 1.1838 - val_loss: 1.5407\n",
      "Epoch 1706/2500\n",
      "64/64 [==============================] - 0s 229us/step - loss: 1.1837 - val_loss: 1.5046\n",
      "Epoch 1707/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1837 - val_loss: 1.5406\n",
      "Epoch 1708/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1835 - val_loss: 1.5050\n",
      "Epoch 1709/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1832 - val_loss: 1.5390\n",
      "Epoch 1710/2500\n",
      "64/64 [==============================] - 0s 236us/step - loss: 1.1829 - val_loss: 1.5057\n",
      "Epoch 1711/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1827 - val_loss: 1.5372\n",
      "Epoch 1712/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1825 - val_loss: 1.5069\n",
      "Epoch 1713/2500\n",
      "64/64 [==============================] - 0s 446us/step - loss: 1.1824 - val_loss: 1.5353\n",
      "Epoch 1714/2500\n",
      "64/64 [==============================] - 0s 455us/step - loss: 1.1823 - val_loss: 1.5072\n",
      "Epoch 1715/2500\n",
      "64/64 [==============================] - 0s 186us/step - loss: 1.1822 - val_loss: 1.5334\n",
      "Epoch 1716/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1819 - val_loss: 1.5076\n",
      "Epoch 1717/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1817 - val_loss: 1.5324\n",
      "Epoch 1718/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1815 - val_loss: 1.5079\n",
      "Epoch 1719/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.1813 - val_loss: 1.5318\n",
      "Epoch 1720/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1811 - val_loss: 1.5074\n",
      "Epoch 1721/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1811 - val_loss: 1.5316\n",
      "Epoch 1722/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1810 - val_loss: 1.5062\n",
      "Epoch 1723/2500\n",
      "64/64 [==============================] - 0s 252us/step - loss: 1.1809 - val_loss: 1.5332\n",
      "Epoch 1724/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1808 - val_loss: 1.5046\n",
      "Epoch 1725/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1806 - val_loss: 1.5359\n",
      "Epoch 1726/2500\n",
      "64/64 [==============================] - 0s 395us/step - loss: 1.1806 - val_loss: 1.5021\n",
      "Epoch 1727/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1809 - val_loss: 1.5392\n",
      "Epoch 1728/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.1808 - val_loss: 1.4984\n",
      "Epoch 1729/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1810 - val_loss: 1.5420\n",
      "Epoch 1730/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1811 - val_loss: 1.4950\n",
      "Epoch 1731/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1812 - val_loss: 1.5436\n",
      "Epoch 1732/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1810 - val_loss: 1.4931\n",
      "Epoch 1733/2500\n",
      "64/64 [==============================] - 0s 123us/step - loss: 1.1810 - val_loss: 1.5437\n",
      "Epoch 1734/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1807 - val_loss: 1.4939\n",
      "Epoch 1735/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1805 - val_loss: 1.5412\n",
      "Epoch 1736/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1802 - val_loss: 1.4967\n",
      "Epoch 1737/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1799 - val_loss: 1.5354\n",
      "Epoch 1738/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1795 - val_loss: 1.5007\n",
      "Epoch 1739/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1790 - val_loss: 1.5285\n",
      "Epoch 1740/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1784 - val_loss: 1.5057\n",
      "Epoch 1741/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1782 - val_loss: 1.5231\n",
      "Epoch 1742/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1780 - val_loss: 1.5098\n",
      "Epoch 1743/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1778 - val_loss: 1.5186\n",
      "Epoch 1744/2500\n",
      "64/64 [==============================] - 0s 225us/step - loss: 1.1775 - val_loss: 1.5122\n",
      "Epoch 1745/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1774 - val_loss: 1.5157\n",
      "Epoch 1746/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1773 - val_loss: 1.5143\n",
      "Epoch 1747/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1772 - val_loss: 1.5151\n",
      "Epoch 1748/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1770 - val_loss: 1.5162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1749/2500\n",
      "64/64 [==============================] - 0s 129us/step - loss: 1.1769 - val_loss: 1.5146\n",
      "Epoch 1750/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1769 - val_loss: 1.5174\n",
      "Epoch 1751/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1767 - val_loss: 1.5126\n",
      "Epoch 1752/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1766 - val_loss: 1.5178\n",
      "Epoch 1753/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1764 - val_loss: 1.5100\n",
      "Epoch 1754/2500\n",
      "64/64 [==============================] - 0s 159us/step - loss: 1.1763 - val_loss: 1.5201\n",
      "Epoch 1755/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1763 - val_loss: 1.5068\n",
      "Epoch 1756/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1762 - val_loss: 1.5237\n",
      "Epoch 1757/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1761 - val_loss: 1.5024\n",
      "Epoch 1758/2500\n",
      "64/64 [==============================] - 0s 233us/step - loss: 1.1760 - val_loss: 1.5287\n",
      "Epoch 1759/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1761 - val_loss: 1.4958\n",
      "Epoch 1760/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1763 - val_loss: 1.5357\n",
      "Epoch 1761/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1767 - val_loss: 1.4883\n",
      "Epoch 1762/2500\n",
      "64/64 [==============================] - 0s 527us/step - loss: 1.1773 - val_loss: 1.5441\n",
      "Epoch 1763/2500\n",
      "64/64 [==============================] - 0s 467us/step - loss: 1.1777 - val_loss: 1.4808\n",
      "Epoch 1764/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 1.1784 - val_loss: 1.5521\n",
      "Epoch 1765/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1790 - val_loss: 1.4756\n",
      "Epoch 1766/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1794 - val_loss: 1.5544\n",
      "Epoch 1767/2500\n",
      "64/64 [==============================] - 0s 257us/step - loss: 1.1794 - val_loss: 1.4768\n",
      "Epoch 1768/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1788 - val_loss: 1.5458\n",
      "Epoch 1769/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1777 - val_loss: 1.4851\n",
      "Epoch 1770/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1763 - val_loss: 1.5286\n",
      "Epoch 1771/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1752 - val_loss: 1.5000\n",
      "Epoch 1772/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1744 - val_loss: 1.5116\n",
      "Epoch 1773/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1739 - val_loss: 1.5149\n",
      "Epoch 1774/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1739 - val_loss: 1.4980\n",
      "Epoch 1775/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1741 - val_loss: 1.5263\n",
      "Epoch 1776/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.1744 - val_loss: 1.4895\n",
      "Epoch 1777/2500\n",
      "64/64 [==============================] - 0s 199us/step - loss: 1.1748 - val_loss: 1.5341\n",
      "Epoch 1778/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1750 - val_loss: 1.4873\n",
      "Epoch 1779/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1749 - val_loss: 1.5352\n",
      "Epoch 1780/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1748 - val_loss: 1.4897\n",
      "Epoch 1781/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1744 - val_loss: 1.5298\n",
      "Epoch 1782/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1740 - val_loss: 1.4954\n",
      "Epoch 1783/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1735 - val_loss: 1.5213\n",
      "Epoch 1784/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1730 - val_loss: 1.5034\n",
      "Epoch 1785/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 1.1726 - val_loss: 1.5131\n",
      "Epoch 1786/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1725 - val_loss: 1.5098\n",
      "Epoch 1787/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.1723 - val_loss: 1.5054\n",
      "Epoch 1788/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1721 - val_loss: 1.5148\n",
      "Epoch 1789/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1720 - val_loss: 1.5002\n",
      "Epoch 1790/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1722 - val_loss: 1.5195\n",
      "Epoch 1791/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1722 - val_loss: 1.4962\n",
      "Epoch 1792/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1720 - val_loss: 1.5224\n",
      "Epoch 1793/2500\n",
      "64/64 [==============================] - 0s 162us/step - loss: 1.1720 - val_loss: 1.4926\n",
      "Epoch 1794/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1720 - val_loss: 1.5239\n",
      "Epoch 1795/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1721 - val_loss: 1.4913\n",
      "Epoch 1796/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1720 - val_loss: 1.5238\n",
      "Epoch 1797/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1718 - val_loss: 1.4915\n",
      "Epoch 1798/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1715 - val_loss: 1.5216\n",
      "Epoch 1799/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.1714 - val_loss: 1.4928\n",
      "Epoch 1800/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1711 - val_loss: 1.5179\n",
      "Epoch 1801/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1710 - val_loss: 1.4960\n",
      "Epoch 1802/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1708 - val_loss: 1.5147\n",
      "Epoch 1803/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1706 - val_loss: 1.4990\n",
      "Epoch 1804/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1703 - val_loss: 1.5117\n",
      "Epoch 1805/2500\n",
      "64/64 [==============================] - 0s 133us/step - loss: 1.1702 - val_loss: 1.5001\n",
      "Epoch 1806/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1699 - val_loss: 1.5092\n",
      "Epoch 1807/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1698 - val_loss: 1.5013\n",
      "Epoch 1808/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1698 - val_loss: 1.5084\n",
      "Epoch 1809/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1696 - val_loss: 1.5021\n",
      "Epoch 1810/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1693 - val_loss: 1.5083\n",
      "Epoch 1811/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1693 - val_loss: 1.5018\n",
      "Epoch 1812/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1692 - val_loss: 1.5084\n",
      "Epoch 1813/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.1690 - val_loss: 1.5005\n",
      "Epoch 1814/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1689 - val_loss: 1.5089\n",
      "Epoch 1815/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1688 - val_loss: 1.4989\n",
      "Epoch 1816/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1686 - val_loss: 1.5105\n",
      "Epoch 1817/2500\n",
      "64/64 [==============================] - 0s 121us/step - loss: 1.1686 - val_loss: 1.4957\n",
      "Epoch 1818/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1687 - val_loss: 1.5132\n",
      "Epoch 1819/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1685 - val_loss: 1.4916\n",
      "Epoch 1820/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1686 - val_loss: 1.5179\n",
      "Epoch 1821/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.1687 - val_loss: 1.4871\n",
      "Epoch 1822/2500\n",
      "64/64 [==============================] - 0s 142us/step - loss: 1.1688 - val_loss: 1.5235\n",
      "Epoch 1823/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1689 - val_loss: 1.4815\n",
      "Epoch 1824/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1692 - val_loss: 1.5297\n",
      "Epoch 1825/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1696 - val_loss: 1.4766\n",
      "Epoch 1826/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1701 - val_loss: 1.5354\n",
      "Epoch 1827/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1704 - val_loss: 1.4723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1828/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1706 - val_loss: 1.5371\n",
      "Epoch 1829/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1705 - val_loss: 1.4712\n",
      "Epoch 1830/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1702 - val_loss: 1.5330\n",
      "Epoch 1831/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1696 - val_loss: 1.4762\n",
      "Epoch 1832/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1689 - val_loss: 1.5239\n",
      "Epoch 1833/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1681 - val_loss: 1.4858\n",
      "Epoch 1834/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1674 - val_loss: 1.5115\n",
      "Epoch 1835/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1668 - val_loss: 1.4952\n",
      "Epoch 1836/2500\n",
      "64/64 [==============================] - 0s 505us/step - loss: 1.1666 - val_loss: 1.5005\n",
      "Epoch 1837/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.1664 - val_loss: 1.5029\n",
      "Epoch 1838/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1662 - val_loss: 1.4922\n",
      "Epoch 1839/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1662 - val_loss: 1.5097\n",
      "Epoch 1840/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 1.1662 - val_loss: 1.4869\n",
      "Epoch 1841/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1664 - val_loss: 1.5164\n",
      "Epoch 1842/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1665 - val_loss: 1.4837\n",
      "Epoch 1843/2500\n",
      "64/64 [==============================] - 0s 139us/step - loss: 1.1666 - val_loss: 1.5206\n",
      "Epoch 1844/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1666 - val_loss: 1.4817\n",
      "Epoch 1845/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1666 - val_loss: 1.5215\n",
      "Epoch 1846/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1666 - val_loss: 1.4811\n",
      "Epoch 1847/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1664 - val_loss: 1.5199\n",
      "Epoch 1848/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1662 - val_loss: 1.4825\n",
      "Epoch 1849/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1660 - val_loss: 1.5164\n",
      "Epoch 1850/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1657 - val_loss: 1.4854\n",
      "Epoch 1851/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1654 - val_loss: 1.5112\n",
      "Epoch 1852/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1650 - val_loss: 1.4885\n",
      "Epoch 1853/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1647 - val_loss: 1.5063\n",
      "Epoch 1854/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1646 - val_loss: 1.4914\n",
      "Epoch 1855/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1645 - val_loss: 1.5023\n",
      "Epoch 1856/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1643 - val_loss: 1.4934\n",
      "Epoch 1857/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1640 - val_loss: 1.4994\n",
      "Epoch 1858/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1640 - val_loss: 1.4955\n",
      "Epoch 1859/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1638 - val_loss: 1.4976\n",
      "Epoch 1860/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1637 - val_loss: 1.4970\n",
      "Epoch 1861/2500\n",
      "64/64 [==============================] - 0s 167us/step - loss: 1.1635 - val_loss: 1.4961\n",
      "Epoch 1862/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1635 - val_loss: 1.4982\n",
      "Epoch 1863/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1634 - val_loss: 1.4945\n",
      "Epoch 1864/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1632 - val_loss: 1.4988\n",
      "Epoch 1865/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1630 - val_loss: 1.4933\n",
      "Epoch 1866/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1629 - val_loss: 1.5011\n",
      "Epoch 1867/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1631 - val_loss: 1.4916\n",
      "Epoch 1868/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1629 - val_loss: 1.5029\n",
      "Epoch 1869/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1626 - val_loss: 1.4885\n",
      "Epoch 1870/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1626 - val_loss: 1.5054\n",
      "Epoch 1871/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1625 - val_loss: 1.4849\n",
      "Epoch 1872/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1625 - val_loss: 1.5094\n",
      "Epoch 1873/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1626 - val_loss: 1.4805\n",
      "Epoch 1874/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1627 - val_loss: 1.5137\n",
      "Epoch 1875/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1629 - val_loss: 1.4748\n",
      "Epoch 1876/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1632 - val_loss: 1.5195\n",
      "Epoch 1877/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1633 - val_loss: 1.4696\n",
      "Epoch 1878/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.1636 - val_loss: 1.5258\n",
      "Epoch 1879/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1639 - val_loss: 1.4654\n",
      "Epoch 1880/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1643 - val_loss: 1.5294\n",
      "Epoch 1881/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1645 - val_loss: 1.4634\n",
      "Epoch 1882/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.1645 - val_loss: 1.5273\n",
      "Epoch 1883/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1641 - val_loss: 1.4658\n",
      "Epoch 1884/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1635 - val_loss: 1.5192\n",
      "Epoch 1885/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1629 - val_loss: 1.4732\n",
      "Epoch 1886/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1622 - val_loss: 1.5077\n",
      "Epoch 1887/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1615 - val_loss: 1.4831\n",
      "Epoch 1888/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1609 - val_loss: 1.4963\n",
      "Epoch 1889/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1605 - val_loss: 1.4916\n",
      "Epoch 1890/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1603 - val_loss: 1.4870\n",
      "Epoch 1891/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1603 - val_loss: 1.4990\n",
      "Epoch 1892/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1604 - val_loss: 1.4808\n",
      "Epoch 1893/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1603 - val_loss: 1.5052\n",
      "Epoch 1894/2500\n",
      "64/64 [==============================] - 0s 179us/step - loss: 1.1603 - val_loss: 1.4775\n",
      "Epoch 1895/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1605 - val_loss: 1.5111\n",
      "Epoch 1896/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1606 - val_loss: 1.4755\n",
      "Epoch 1897/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1607 - val_loss: 1.5135\n",
      "Epoch 1898/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.1606 - val_loss: 1.4737\n",
      "Epoch 1899/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1605 - val_loss: 1.5121\n",
      "Epoch 1900/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1603 - val_loss: 1.4733\n",
      "Epoch 1901/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1601 - val_loss: 1.5091\n",
      "Epoch 1902/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1598 - val_loss: 1.4757\n",
      "Epoch 1903/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 1.1596 - val_loss: 1.5057\n",
      "Epoch 1904/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1593 - val_loss: 1.4798\n",
      "Epoch 1905/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1590 - val_loss: 1.5014\n",
      "Epoch 1906/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 1.1589 - val_loss: 1.4827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1907/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1586 - val_loss: 1.4964\n",
      "Epoch 1908/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1584 - val_loss: 1.4847\n",
      "Epoch 1909/2500\n",
      "64/64 [==============================] - 0s 351us/step - loss: 1.1583 - val_loss: 1.4927\n",
      "Epoch 1910/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1582 - val_loss: 1.4868\n",
      "Epoch 1911/2500\n",
      "64/64 [==============================] - 0s 290us/step - loss: 1.1580 - val_loss: 1.4896\n",
      "Epoch 1912/2500\n",
      "64/64 [==============================] - 0s 509us/step - loss: 1.1579 - val_loss: 1.4882\n",
      "Epoch 1913/2500\n",
      "64/64 [==============================] - 0s 156us/step - loss: 1.1578 - val_loss: 1.4881\n",
      "Epoch 1914/2500\n",
      "64/64 [==============================] - 0s 403us/step - loss: 1.1577 - val_loss: 1.4895\n",
      "Epoch 1915/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1575 - val_loss: 1.4880\n",
      "Epoch 1916/2500\n",
      "64/64 [==============================] - 0s 435us/step - loss: 1.1575 - val_loss: 1.4908\n",
      "Epoch 1917/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1573 - val_loss: 1.4873\n",
      "Epoch 1918/2500\n",
      "64/64 [==============================] - 0s 300us/step - loss: 1.1572 - val_loss: 1.4911\n",
      "Epoch 1919/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1572 - val_loss: 1.4854\n",
      "Epoch 1920/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1570 - val_loss: 1.4918\n",
      "Epoch 1921/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1568 - val_loss: 1.4837\n",
      "Epoch 1922/2500\n",
      "64/64 [==============================] - 0s 253us/step - loss: 1.1569 - val_loss: 1.4944\n",
      "Epoch 1923/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1569 - val_loss: 1.4808\n",
      "Epoch 1924/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1567 - val_loss: 1.4971\n",
      "Epoch 1925/2500\n",
      "64/64 [==============================] - 0s 176us/step - loss: 1.1566 - val_loss: 1.4764\n",
      "Epoch 1926/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.1567 - val_loss: 1.5016\n",
      "Epoch 1927/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1569 - val_loss: 1.4706\n",
      "Epoch 1928/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.1569 - val_loss: 1.5076\n",
      "Epoch 1929/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1570 - val_loss: 1.4645\n",
      "Epoch 1930/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1575 - val_loss: 1.5158\n",
      "Epoch 1931/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1580 - val_loss: 1.4584\n",
      "Epoch 1932/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.1586 - val_loss: 1.5227\n",
      "Epoch 1933/2500\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.1589 - val_loss: 1.4537\n",
      "Epoch 1934/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1592 - val_loss: 1.5244\n",
      "Epoch 1935/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1592 - val_loss: 1.4533\n",
      "Epoch 1936/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.1589 - val_loss: 1.5186\n",
      "Epoch 1937/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1582 - val_loss: 1.4598\n",
      "Epoch 1938/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.1573 - val_loss: 1.5058\n",
      "Epoch 1939/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1563 - val_loss: 1.4714\n",
      "Epoch 1940/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1556 - val_loss: 1.4910\n",
      "Epoch 1941/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1550 - val_loss: 1.4840\n",
      "Epoch 1942/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1548 - val_loss: 1.4793\n",
      "Epoch 1943/2500\n",
      "64/64 [==============================] - 0s 230us/step - loss: 1.1547 - val_loss: 1.4941\n",
      "Epoch 1944/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1550 - val_loss: 1.4703\n",
      "Epoch 1945/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1551 - val_loss: 1.5015\n",
      "Epoch 1946/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1553 - val_loss: 1.4660\n",
      "Epoch 1947/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1556 - val_loss: 1.5063\n",
      "Epoch 1948/2500\n",
      "64/64 [==============================] - 0s 146us/step - loss: 1.1556 - val_loss: 1.4656\n",
      "Epoch 1949/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1553 - val_loss: 1.5054\n",
      "Epoch 1950/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1551 - val_loss: 1.4675\n",
      "Epoch 1951/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1549 - val_loss: 1.5002\n",
      "Epoch 1952/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1546 - val_loss: 1.4714\n",
      "Epoch 1953/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.1542 - val_loss: 1.4937\n",
      "Epoch 1954/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1539 - val_loss: 1.4775\n",
      "Epoch 1955/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1535 - val_loss: 1.4877\n",
      "Epoch 1956/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1533 - val_loss: 1.4831\n",
      "Epoch 1957/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1532 - val_loss: 1.4826\n",
      "Epoch 1958/2500\n",
      "64/64 [==============================] - 0s 523us/step - loss: 1.1531 - val_loss: 1.4865\n",
      "Epoch 1959/2500\n",
      "64/64 [==============================] - 0s 218us/step - loss: 1.1530 - val_loss: 1.4773\n",
      "Epoch 1960/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1528 - val_loss: 1.4880\n",
      "Epoch 1961/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1528 - val_loss: 1.4738\n",
      "Epoch 1962/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1528 - val_loss: 1.4902\n",
      "Epoch 1963/2500\n",
      "64/64 [==============================] - 0s 295us/step - loss: 1.1527 - val_loss: 1.4722\n",
      "Epoch 1964/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1526 - val_loss: 1.4923\n",
      "Epoch 1965/2500\n",
      "64/64 [==============================] - 0s 364us/step - loss: 1.1526 - val_loss: 1.4708\n",
      "Epoch 1966/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1526 - val_loss: 1.4933\n",
      "Epoch 1967/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1526 - val_loss: 1.4689\n",
      "Epoch 1968/2500\n",
      "64/64 [==============================] - 0s 378us/step - loss: 1.1524 - val_loss: 1.4941\n",
      "Epoch 1969/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1522 - val_loss: 1.4682\n",
      "Epoch 1970/2500\n",
      "64/64 [==============================] - 0s 345us/step - loss: 1.1523 - val_loss: 1.4951\n",
      "Epoch 1971/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1523 - val_loss: 1.4674\n",
      "Epoch 1972/2500\n",
      "64/64 [==============================] - 0s 370us/step - loss: 1.1522 - val_loss: 1.4946\n",
      "Epoch 1973/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1520 - val_loss: 1.4669\n",
      "Epoch 1974/2500\n",
      "64/64 [==============================] - 0s 531us/step - loss: 1.1518 - val_loss: 1.4944\n",
      "Epoch 1975/2500\n",
      "64/64 [==============================] - 0s 300us/step - loss: 1.1518 - val_loss: 1.4673\n",
      "Epoch 1976/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1516 - val_loss: 1.4936\n",
      "Epoch 1977/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1514 - val_loss: 1.4674\n",
      "Epoch 1978/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1513 - val_loss: 1.4922\n",
      "Epoch 1979/2500\n",
      "64/64 [==============================] - 0s 311us/step - loss: 1.1512 - val_loss: 1.4676\n",
      "Epoch 1980/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1511 - val_loss: 1.4918\n",
      "Epoch 1981/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1510 - val_loss: 1.4673\n",
      "Epoch 1982/2500\n",
      "64/64 [==============================] - 0s 280us/step - loss: 1.1509 - val_loss: 1.4916\n",
      "Epoch 1983/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1508 - val_loss: 1.4671\n",
      "Epoch 1984/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1507 - val_loss: 1.4915\n",
      "Epoch 1985/2500\n",
      "64/64 [==============================] - 0s 160us/step - loss: 1.1506 - val_loss: 1.4663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1986/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1504 - val_loss: 1.4913\n",
      "Epoch 1987/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1504 - val_loss: 1.4657\n",
      "Epoch 1988/2500\n",
      "64/64 [==============================] - 0s 349us/step - loss: 1.1504 - val_loss: 1.4915\n",
      "Epoch 1989/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.1502 - val_loss: 1.4647\n",
      "Epoch 1990/2500\n",
      "64/64 [==============================] - 0s 161us/step - loss: 1.1501 - val_loss: 1.4924\n",
      "Epoch 1991/2500\n",
      "64/64 [==============================] - 0s 99us/step - loss: 1.1500 - val_loss: 1.4637\n",
      "Epoch 1992/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1500 - val_loss: 1.4938\n",
      "Epoch 1993/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1501 - val_loss: 1.4619\n",
      "Epoch 1994/2500\n",
      "64/64 [==============================] - 0s 315us/step - loss: 1.1500 - val_loss: 1.4947\n",
      "Epoch 1995/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1500 - val_loss: 1.4597\n",
      "Epoch 1996/2500\n",
      "64/64 [==============================] - 0s 331us/step - loss: 1.1499 - val_loss: 1.4961\n",
      "Epoch 1997/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1498 - val_loss: 1.4582\n",
      "Epoch 1998/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1498 - val_loss: 1.4970\n",
      "Epoch 1999/2500\n",
      "64/64 [==============================] - 0s 165us/step - loss: 1.1498 - val_loss: 1.4576\n",
      "Epoch 2000/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1497 - val_loss: 1.4971\n",
      "Epoch 2001/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1496 - val_loss: 1.4577\n",
      "Epoch 2002/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1496 - val_loss: 1.4960\n",
      "Epoch 2003/2500\n",
      "64/64 [==============================] - 0s 412us/step - loss: 1.1494 - val_loss: 1.4585\n",
      "Epoch 2004/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1491 - val_loss: 1.4936\n",
      "Epoch 2005/2500\n",
      "64/64 [==============================] - 0s 455us/step - loss: 1.1490 - val_loss: 1.4600\n",
      "Epoch 2006/2500\n",
      "64/64 [==============================] - 0s 398us/step - loss: 1.1488 - val_loss: 1.4903\n",
      "Epoch 2007/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1487 - val_loss: 1.4623\n",
      "Epoch 2008/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1484 - val_loss: 1.4872\n",
      "Epoch 2009/2500\n",
      "64/64 [==============================] - 0s 363us/step - loss: 1.1480 - val_loss: 1.4654\n",
      "Epoch 2010/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1478 - val_loss: 1.4846\n",
      "Epoch 2011/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 1.1477 - val_loss: 1.4664\n",
      "Epoch 2012/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1476 - val_loss: 1.4817\n",
      "Epoch 2013/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 1.1474 - val_loss: 1.4671\n",
      "Epoch 2014/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1473 - val_loss: 1.4812\n",
      "Epoch 2015/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1471 - val_loss: 1.4681\n",
      "Epoch 2016/2500\n",
      "64/64 [==============================] - 0s 386us/step - loss: 1.1470 - val_loss: 1.4818\n",
      "Epoch 2017/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1470 - val_loss: 1.4673\n",
      "Epoch 2018/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1469 - val_loss: 1.4821\n",
      "Epoch 2019/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 1.1468 - val_loss: 1.4644\n",
      "Epoch 2020/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1467 - val_loss: 1.4834\n",
      "Epoch 2021/2500\n",
      "64/64 [==============================] - 0s 314us/step - loss: 1.1466 - val_loss: 1.4609\n",
      "Epoch 2022/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1466 - val_loss: 1.4872\n",
      "Epoch 2023/2500\n",
      "64/64 [==============================] - 0s 239us/step - loss: 1.1467 - val_loss: 1.4580\n",
      "Epoch 2024/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1468 - val_loss: 1.4922\n",
      "Epoch 2025/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1469 - val_loss: 1.4543\n",
      "Epoch 2026/2500\n",
      "64/64 [==============================] - 0s 302us/step - loss: 1.1471 - val_loss: 1.4965\n",
      "Epoch 2027/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1472 - val_loss: 1.4498\n",
      "Epoch 2028/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1474 - val_loss: 1.4991\n",
      "Epoch 2029/2500\n",
      "64/64 [==============================] - 0s 130us/step - loss: 1.1474 - val_loss: 1.4467\n",
      "Epoch 2030/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.1475 - val_loss: 1.5000\n",
      "Epoch 2031/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1475 - val_loss: 1.4474\n",
      "Epoch 2032/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1472 - val_loss: 1.4969\n",
      "Epoch 2033/2500\n",
      "64/64 [==============================] - 0s 193us/step - loss: 1.1467 - val_loss: 1.4508\n",
      "Epoch 2034/2500\n",
      "64/64 [==============================] - 0s 211us/step - loss: 1.1463 - val_loss: 1.4901\n",
      "Epoch 2035/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1459 - val_loss: 1.4567\n",
      "Epoch 2036/2500\n",
      "64/64 [==============================] - 0s 194us/step - loss: 1.1454 - val_loss: 1.4813\n",
      "Epoch 2037/2500\n",
      "64/64 [==============================] - 0s 154us/step - loss: 1.1449 - val_loss: 1.4638\n",
      "Epoch 2038/2500\n",
      "64/64 [==============================] - 0s 455us/step - loss: 1.1446 - val_loss: 1.4742\n",
      "Epoch 2039/2500\n",
      "64/64 [==============================] - 0s 240us/step - loss: 1.1444 - val_loss: 1.4693\n",
      "Epoch 2040/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1442 - val_loss: 1.4677\n",
      "Epoch 2041/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1441 - val_loss: 1.4739\n",
      "Epoch 2042/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1443 - val_loss: 1.4635\n",
      "Epoch 2043/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1442 - val_loss: 1.4783\n",
      "Epoch 2044/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1441 - val_loss: 1.4602\n",
      "Epoch 2045/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1441 - val_loss: 1.4829\n",
      "Epoch 2046/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1442 - val_loss: 1.4572\n",
      "Epoch 2047/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1443 - val_loss: 1.4864\n",
      "Epoch 2048/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1443 - val_loss: 1.4532\n",
      "Epoch 2049/2500\n",
      "64/64 [==============================] - 0s 371us/step - loss: 1.1443 - val_loss: 1.4887\n",
      "Epoch 2050/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1443 - val_loss: 1.4506\n",
      "Epoch 2051/2500\n",
      "64/64 [==============================] - 0s 419us/step - loss: 1.1443 - val_loss: 1.4904\n",
      "Epoch 2052/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1443 - val_loss: 1.4501\n",
      "Epoch 2053/2500\n",
      "64/64 [==============================] - 0s 232us/step - loss: 1.1442 - val_loss: 1.4904\n",
      "Epoch 2054/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1441 - val_loss: 1.4502\n",
      "Epoch 2055/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1440 - val_loss: 1.4879\n",
      "Epoch 2056/2500\n",
      "64/64 [==============================] - 0s 102us/step - loss: 1.1438 - val_loss: 1.4511\n",
      "Epoch 2057/2500\n",
      "64/64 [==============================] - 0s 180us/step - loss: 1.1435 - val_loss: 1.4837\n",
      "Epoch 2058/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1431 - val_loss: 1.4539\n",
      "Epoch 2059/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1430 - val_loss: 1.4798\n",
      "Epoch 2060/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1428 - val_loss: 1.4570\n",
      "Epoch 2061/2500\n",
      "64/64 [==============================] - 0s 418us/step - loss: 1.1424 - val_loss: 1.4755\n",
      "Epoch 2062/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1422 - val_loss: 1.4597\n",
      "Epoch 2063/2500\n",
      "64/64 [==============================] - 0s 268us/step - loss: 1.1421 - val_loss: 1.4732\n",
      "Epoch 2064/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1419 - val_loss: 1.4619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2065/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1419 - val_loss: 1.4715\n",
      "Epoch 2066/2500\n",
      "64/64 [==============================] - 0s 396us/step - loss: 1.1417 - val_loss: 1.4620\n",
      "Epoch 2067/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1417 - val_loss: 1.4696\n",
      "Epoch 2068/2500\n",
      "64/64 [==============================] - 0s 866us/step - loss: 1.1414 - val_loss: 1.4621\n",
      "Epoch 2069/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1411 - val_loss: 1.4696\n",
      "Epoch 2070/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1411 - val_loss: 1.4629\n",
      "Epoch 2071/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.1410 - val_loss: 1.4712\n",
      "Epoch 2072/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1410 - val_loss: 1.4617\n",
      "Epoch 2073/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1408 - val_loss: 1.4724\n",
      "Epoch 2074/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1407 - val_loss: 1.4583\n",
      "Epoch 2075/2500\n",
      "64/64 [==============================] - 0s 437us/step - loss: 1.1407 - val_loss: 1.4750\n",
      "Epoch 2076/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1409 - val_loss: 1.4541\n",
      "Epoch 2077/2500\n",
      "64/64 [==============================] - 0s 243us/step - loss: 1.1408 - val_loss: 1.4789\n",
      "Epoch 2078/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1408 - val_loss: 1.4495\n",
      "Epoch 2079/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1410 - val_loss: 1.4844\n",
      "Epoch 2080/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1411 - val_loss: 1.4451\n",
      "Epoch 2081/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1412 - val_loss: 1.4894\n",
      "Epoch 2082/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1415 - val_loss: 1.4409\n",
      "Epoch 2083/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1417 - val_loss: 1.4926\n",
      "Epoch 2084/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.1419 - val_loss: 1.4375\n",
      "Epoch 2085/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1419 - val_loss: 1.4922\n",
      "Epoch 2086/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1417 - val_loss: 1.4379\n",
      "Epoch 2087/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1414 - val_loss: 1.4887\n",
      "Epoch 2088/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1410 - val_loss: 1.4423\n",
      "Epoch 2089/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1405 - val_loss: 1.4818\n",
      "Epoch 2090/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1401 - val_loss: 1.4489\n",
      "Epoch 2091/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1396 - val_loss: 1.4731\n",
      "Epoch 2092/2500\n",
      "64/64 [==============================] - 0s 84us/step - loss: 1.1391 - val_loss: 1.4557\n",
      "Epoch 2093/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1388 - val_loss: 1.4657\n",
      "Epoch 2094/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1386 - val_loss: 1.4619\n",
      "Epoch 2095/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1386 - val_loss: 1.4598\n",
      "Epoch 2096/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1385 - val_loss: 1.4661\n",
      "Epoch 2097/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1384 - val_loss: 1.4550\n",
      "Epoch 2098/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1384 - val_loss: 1.4703\n",
      "Epoch 2099/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1385 - val_loss: 1.4519\n",
      "Epoch 2100/2500\n",
      "64/64 [==============================] - 0s 390us/step - loss: 1.1385 - val_loss: 1.4751\n",
      "Epoch 2101/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1386 - val_loss: 1.4496\n",
      "Epoch 2102/2500\n",
      "64/64 [==============================] - 0s 308us/step - loss: 1.1386 - val_loss: 1.4787\n",
      "Epoch 2103/2500\n",
      "64/64 [==============================] - 0s 89us/step - loss: 1.1386 - val_loss: 1.4467\n",
      "Epoch 2104/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.1386 - val_loss: 1.4806\n",
      "Epoch 2105/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1386 - val_loss: 1.4440\n",
      "Epoch 2106/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1386 - val_loss: 1.4815\n",
      "Epoch 2107/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.1386 - val_loss: 1.4427\n",
      "Epoch 2108/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1385 - val_loss: 1.4808\n",
      "Epoch 2109/2500\n",
      "64/64 [==============================] - 0s 231us/step - loss: 1.1382 - val_loss: 1.4430\n",
      "Epoch 2110/2500\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.1381 - val_loss: 1.4791\n",
      "Epoch 2111/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1379 - val_loss: 1.4449\n",
      "Epoch 2112/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1376 - val_loss: 1.4753\n",
      "Epoch 2113/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1374 - val_loss: 1.4470\n",
      "Epoch 2114/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1372 - val_loss: 1.4705\n",
      "Epoch 2115/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1370 - val_loss: 1.4494\n",
      "Epoch 2116/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1368 - val_loss: 1.4658\n",
      "Epoch 2117/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1366 - val_loss: 1.4529\n",
      "Epoch 2118/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1363 - val_loss: 1.4633\n",
      "Epoch 2119/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1363 - val_loss: 1.4565\n",
      "Epoch 2120/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1362 - val_loss: 1.4612\n",
      "Epoch 2121/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1361 - val_loss: 1.4572\n",
      "Epoch 2122/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1360 - val_loss: 1.4599\n",
      "Epoch 2123/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1358 - val_loss: 1.4581\n",
      "Epoch 2124/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 1.1357 - val_loss: 1.4597\n",
      "Epoch 2125/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1356 - val_loss: 1.4592\n",
      "Epoch 2126/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1356 - val_loss: 1.4598\n",
      "Epoch 2127/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1357 - val_loss: 1.4586\n",
      "Epoch 2128/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1355 - val_loss: 1.4591\n",
      "Epoch 2129/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1354 - val_loss: 1.4575\n",
      "Epoch 2130/2500\n",
      "64/64 [==============================] - 0s 144us/step - loss: 1.1352 - val_loss: 1.4589\n",
      "Epoch 2131/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1351 - val_loss: 1.4560\n",
      "Epoch 2132/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1352 - val_loss: 1.4598\n",
      "Epoch 2133/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1350 - val_loss: 1.4539\n",
      "Epoch 2134/2500\n",
      "64/64 [==============================] - 0s 318us/step - loss: 1.1348 - val_loss: 1.4619\n",
      "Epoch 2135/2500\n",
      "64/64 [==============================] - 0s 110us/step - loss: 1.1348 - val_loss: 1.4509\n",
      "Epoch 2136/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1347 - val_loss: 1.4648\n",
      "Epoch 2137/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1347 - val_loss: 1.4471\n",
      "Epoch 2138/2500\n",
      "64/64 [==============================] - 0s 207us/step - loss: 1.1347 - val_loss: 1.4691\n",
      "Epoch 2139/2500\n",
      "64/64 [==============================] - 0s 47us/step - loss: 1.1347 - val_loss: 1.4418\n",
      "Epoch 2140/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1347 - val_loss: 1.4753\n",
      "Epoch 2141/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1350 - val_loss: 1.4356\n",
      "Epoch 2142/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1353 - val_loss: 1.4828\n",
      "Epoch 2143/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1358 - val_loss: 1.4296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2144/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 1.1363 - val_loss: 1.4891\n",
      "Epoch 2145/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1365 - val_loss: 1.4246\n",
      "Epoch 2146/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1369 - val_loss: 1.4924\n",
      "Epoch 2147/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1372 - val_loss: 1.4240\n",
      "Epoch 2148/2500\n",
      "64/64 [==============================] - 0s 148us/step - loss: 1.1371 - val_loss: 1.4889\n",
      "Epoch 2149/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1364 - val_loss: 1.4286\n",
      "Epoch 2150/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1356 - val_loss: 1.4778\n",
      "Epoch 2151/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1348 - val_loss: 1.4390\n",
      "Epoch 2152/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1339 - val_loss: 1.4633\n",
      "Epoch 2153/2500\n",
      "64/64 [==============================] - 0s 289us/step - loss: 1.1332 - val_loss: 1.4512\n",
      "Epoch 2154/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1330 - val_loss: 1.4509\n",
      "Epoch 2155/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1330 - val_loss: 1.4621\n",
      "Epoch 2156/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 1.1332 - val_loss: 1.4414\n",
      "Epoch 2157/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1333 - val_loss: 1.4695\n",
      "Epoch 2158/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1334 - val_loss: 1.4363\n",
      "Epoch 2159/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1335 - val_loss: 1.4742\n",
      "Epoch 2160/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1337 - val_loss: 1.4357\n",
      "Epoch 2161/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.1337 - val_loss: 1.4754\n",
      "Epoch 2162/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1336 - val_loss: 1.4376\n",
      "Epoch 2163/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1334 - val_loss: 1.4714\n",
      "Epoch 2164/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1330 - val_loss: 1.4414\n",
      "Epoch 2165/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1326 - val_loss: 1.4647\n",
      "Epoch 2166/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 1.1323 - val_loss: 1.4460\n",
      "Epoch 2167/2500\n",
      "64/64 [==============================] - 0s 226us/step - loss: 1.1320 - val_loss: 1.4576\n",
      "Epoch 2168/2500\n",
      "64/64 [==============================] - 0s 294us/step - loss: 1.1317 - val_loss: 1.4511\n",
      "Epoch 2169/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1316 - val_loss: 1.4525\n",
      "Epoch 2170/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1316 - val_loss: 1.4559\n",
      "Epoch 2171/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 1.1316 - val_loss: 1.4485\n",
      "Epoch 2172/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1315 - val_loss: 1.4591\n",
      "Epoch 2173/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1313 - val_loss: 1.4445\n",
      "Epoch 2174/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1313 - val_loss: 1.4612\n",
      "Epoch 2175/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1314 - val_loss: 1.4411\n",
      "Epoch 2176/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1313 - val_loss: 1.4628\n",
      "Epoch 2177/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1312 - val_loss: 1.4385\n",
      "Epoch 2178/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1312 - val_loss: 1.4644\n",
      "Epoch 2179/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1312 - val_loss: 1.4385\n",
      "Epoch 2180/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1311 - val_loss: 1.4652\n",
      "Epoch 2181/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1309 - val_loss: 1.4389\n",
      "Epoch 2182/2500\n",
      "64/64 [==============================] - 0s 155us/step - loss: 1.1309 - val_loss: 1.4636\n",
      "Epoch 2183/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1307 - val_loss: 1.4393\n",
      "Epoch 2184/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1305 - val_loss: 1.4610\n",
      "Epoch 2185/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1304 - val_loss: 1.4412\n",
      "Epoch 2186/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1302 - val_loss: 1.4585\n",
      "Epoch 2187/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1302 - val_loss: 1.4440\n",
      "Epoch 2188/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1301 - val_loss: 1.4561\n",
      "Epoch 2189/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1299 - val_loss: 1.4459\n",
      "Epoch 2190/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1296 - val_loss: 1.4544\n",
      "Epoch 2191/2500\n",
      "64/64 [==============================] - 0s 183us/step - loss: 1.1296 - val_loss: 1.4465\n",
      "Epoch 2192/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1296 - val_loss: 1.4525\n",
      "Epoch 2193/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1294 - val_loss: 1.4457\n",
      "Epoch 2194/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1292 - val_loss: 1.4518\n",
      "Epoch 2195/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1291 - val_loss: 1.4459\n",
      "Epoch 2196/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1291 - val_loss: 1.4531\n",
      "Epoch 2197/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1290 - val_loss: 1.4462\n",
      "Epoch 2198/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1289 - val_loss: 1.4541\n",
      "Epoch 2199/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1288 - val_loss: 1.4434\n",
      "Epoch 2200/2500\n",
      "64/64 [==============================] - 0s 157us/step - loss: 1.1287 - val_loss: 1.4544\n",
      "Epoch 2201/2500\n",
      "64/64 [==============================] - 0s 80us/step - loss: 1.1286 - val_loss: 1.4402\n",
      "Epoch 2202/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1285 - val_loss: 1.4569\n",
      "Epoch 2203/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1286 - val_loss: 1.4377\n",
      "Epoch 2204/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1286 - val_loss: 1.4616\n",
      "Epoch 2205/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1286 - val_loss: 1.4340\n",
      "Epoch 2206/2500\n",
      "64/64 [==============================] - 0s 91us/step - loss: 1.1287 - val_loss: 1.4658\n",
      "Epoch 2207/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1290 - val_loss: 1.4291\n",
      "Epoch 2208/2500\n",
      "64/64 [==============================] - 0s 83us/step - loss: 1.1290 - val_loss: 1.4698\n",
      "Epoch 2209/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1292 - val_loss: 1.4253\n",
      "Epoch 2210/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1295 - val_loss: 1.4728\n",
      "Epoch 2211/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1296 - val_loss: 1.4231\n",
      "Epoch 2212/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1294 - val_loss: 1.4731\n",
      "Epoch 2213/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1293 - val_loss: 1.4234\n",
      "Epoch 2214/2500\n",
      "64/64 [==============================] - 0s 224us/step - loss: 1.1291 - val_loss: 1.4700\n",
      "Epoch 2215/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1289 - val_loss: 1.4268\n",
      "Epoch 2216/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1285 - val_loss: 1.4639\n",
      "Epoch 2217/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1280 - val_loss: 1.4326\n",
      "Epoch 2218/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1276 - val_loss: 1.4561\n",
      "Epoch 2219/2500\n",
      "64/64 [==============================] - 0s 120us/step - loss: 1.1273 - val_loss: 1.4385\n",
      "Epoch 2220/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1270 - val_loss: 1.4493\n",
      "Epoch 2221/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1267 - val_loss: 1.4438\n",
      "Epoch 2222/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1267 - val_loss: 1.4447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2223/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1267 - val_loss: 1.4484\n",
      "Epoch 2224/2500\n",
      "64/64 [==============================] - 0s 137us/step - loss: 1.1265 - val_loss: 1.4406\n",
      "Epoch 2225/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1265 - val_loss: 1.4520\n",
      "Epoch 2226/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1266 - val_loss: 1.4376\n",
      "Epoch 2227/2500\n",
      "64/64 [==============================] - 0s 111us/step - loss: 1.1266 - val_loss: 1.4554\n",
      "Epoch 2228/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1265 - val_loss: 1.4343\n",
      "Epoch 2229/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1264 - val_loss: 1.4582\n",
      "Epoch 2230/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1264 - val_loss: 1.4316\n",
      "Epoch 2231/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1265 - val_loss: 1.4606\n",
      "Epoch 2232/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 1.1265 - val_loss: 1.4289\n",
      "Epoch 2233/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1264 - val_loss: 1.4622\n",
      "Epoch 2234/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1264 - val_loss: 1.4276\n",
      "Epoch 2235/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1263 - val_loss: 1.4632\n",
      "Epoch 2236/2500\n",
      "64/64 [==============================] - 0s 205us/step - loss: 1.1263 - val_loss: 1.4273\n",
      "Epoch 2237/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1262 - val_loss: 1.4627\n",
      "Epoch 2238/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1260 - val_loss: 1.4275\n",
      "Epoch 2239/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1259 - val_loss: 1.4601\n",
      "Epoch 2240/2500\n",
      "64/64 [==============================] - 0s 124us/step - loss: 1.1257 - val_loss: 1.4286\n",
      "Epoch 2241/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.1255 - val_loss: 1.4563\n",
      "Epoch 2242/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1253 - val_loss: 1.4301\n",
      "Epoch 2243/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1252 - val_loss: 1.4530\n",
      "Epoch 2244/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1250 - val_loss: 1.4330\n",
      "Epoch 2245/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.1249 - val_loss: 1.4508\n",
      "Epoch 2246/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1247 - val_loss: 1.4354\n",
      "Epoch 2247/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1248 - val_loss: 1.4488\n",
      "Epoch 2248/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1245 - val_loss: 1.4360\n",
      "Epoch 2249/2500\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.1243 - val_loss: 1.4464\n",
      "Epoch 2250/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.1242 - val_loss: 1.4374\n",
      "Epoch 2251/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1241 - val_loss: 1.4466\n",
      "Epoch 2252/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1241 - val_loss: 1.4387\n",
      "Epoch 2253/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1239 - val_loss: 1.4464\n",
      "Epoch 2254/2500\n",
      "64/64 [==============================] - 0s 174us/step - loss: 1.1237 - val_loss: 1.4380\n",
      "Epoch 2255/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1237 - val_loss: 1.4467\n",
      "Epoch 2256/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1236 - val_loss: 1.4359\n",
      "Epoch 2257/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1234 - val_loss: 1.4481\n",
      "Epoch 2258/2500\n",
      "64/64 [==============================] - 0s 181us/step - loss: 1.1235 - val_loss: 1.4334\n",
      "Epoch 2259/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1235 - val_loss: 1.4507\n",
      "Epoch 2260/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1234 - val_loss: 1.4300\n",
      "Epoch 2261/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1235 - val_loss: 1.4541\n",
      "Epoch 2262/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1235 - val_loss: 1.4258\n",
      "Epoch 2263/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.1236 - val_loss: 1.4584\n",
      "Epoch 2264/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1237 - val_loss: 1.4212\n",
      "Epoch 2265/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1239 - val_loss: 1.4634\n",
      "Epoch 2266/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1241 - val_loss: 1.4177\n",
      "Epoch 2267/2500\n",
      "64/64 [==============================] - 0s 97us/step - loss: 1.1244 - val_loss: 1.4664\n",
      "Epoch 2268/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1244 - val_loss: 1.4147\n",
      "Epoch 2269/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1243 - val_loss: 1.4660\n",
      "Epoch 2270/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1242 - val_loss: 1.4149\n",
      "Epoch 2271/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 1.1241 - val_loss: 1.4628\n",
      "Epoch 2272/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1236 - val_loss: 1.4194\n",
      "Epoch 2273/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1232 - val_loss: 1.4568\n",
      "Epoch 2274/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1227 - val_loss: 1.4262\n",
      "Epoch 2275/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1224 - val_loss: 1.4483\n",
      "Epoch 2276/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1219 - val_loss: 1.4320\n",
      "Epoch 2277/2500\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.1217 - val_loss: 1.4411\n",
      "Epoch 2278/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1216 - val_loss: 1.4367\n",
      "Epoch 2279/2500\n",
      "64/64 [==============================] - 0s 96us/step - loss: 1.1215 - val_loss: 1.4358\n",
      "Epoch 2280/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1214 - val_loss: 1.4407\n",
      "Epoch 2281/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 1.1213 - val_loss: 1.4329\n",
      "Epoch 2282/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1214 - val_loss: 1.4450\n",
      "Epoch 2283/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1214 - val_loss: 1.4309\n",
      "Epoch 2284/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1213 - val_loss: 1.4486\n",
      "Epoch 2285/2500\n",
      "64/64 [==============================] - 0s 46us/step - loss: 1.1211 - val_loss: 1.4277\n",
      "Epoch 2286/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1212 - val_loss: 1.4511\n",
      "Epoch 2287/2500\n",
      "64/64 [==============================] - 0s 166us/step - loss: 1.1214 - val_loss: 1.4240\n",
      "Epoch 2288/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1213 - val_loss: 1.4524\n",
      "Epoch 2289/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 1.1211 - val_loss: 1.4211\n",
      "Epoch 2290/2500\n",
      "64/64 [==============================] - 0s 182us/step - loss: 1.1212 - val_loss: 1.4547\n",
      "Epoch 2291/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1212 - val_loss: 1.4209\n",
      "Epoch 2292/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.1212 - val_loss: 1.4551\n",
      "Epoch 2293/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1210 - val_loss: 1.4202\n",
      "Epoch 2294/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1209 - val_loss: 1.4532\n",
      "Epoch 2295/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.1208 - val_loss: 1.4206\n",
      "Epoch 2296/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1207 - val_loss: 1.4502\n",
      "Epoch 2297/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1205 - val_loss: 1.4223\n",
      "Epoch 2298/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1202 - val_loss: 1.4472\n",
      "Epoch 2299/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1200 - val_loss: 1.4252\n",
      "Epoch 2300/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1200 - val_loss: 1.4447\n",
      "Epoch 2301/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1198 - val_loss: 1.4277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2302/2500\n",
      "64/64 [==============================] - 0s 112us/step - loss: 1.1195 - val_loss: 1.4417\n",
      "Epoch 2303/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1193 - val_loss: 1.4292\n",
      "Epoch 2304/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1192 - val_loss: 1.4404\n",
      "Epoch 2305/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1192 - val_loss: 1.4304\n",
      "Epoch 2306/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1191 - val_loss: 1.4397\n",
      "Epoch 2307/2500\n",
      "64/64 [==============================] - 0s 169us/step - loss: 1.1191 - val_loss: 1.4303\n",
      "Epoch 2308/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1189 - val_loss: 1.4396\n",
      "Epoch 2309/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1188 - val_loss: 1.4297\n",
      "Epoch 2310/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1186 - val_loss: 1.4403\n",
      "Epoch 2311/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1187 - val_loss: 1.4286\n",
      "Epoch 2312/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1186 - val_loss: 1.4422\n",
      "Epoch 2313/2500\n",
      "64/64 [==============================] - 0s 190us/step - loss: 1.1184 - val_loss: 1.4260\n",
      "Epoch 2314/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 1.1185 - val_loss: 1.4447\n",
      "Epoch 2315/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1185 - val_loss: 1.4226\n",
      "Epoch 2316/2500\n",
      "64/64 [==============================] - 0s 168us/step - loss: 1.1185 - val_loss: 1.4469\n",
      "Epoch 2317/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1185 - val_loss: 1.4186\n",
      "Epoch 2318/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1185 - val_loss: 1.4501\n",
      "Epoch 2319/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1186 - val_loss: 1.4148\n",
      "Epoch 2320/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1187 - val_loss: 1.4537\n",
      "Epoch 2321/2500\n",
      "64/64 [==============================] - 0s 52us/step - loss: 1.1188 - val_loss: 1.4122\n",
      "Epoch 2322/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1190 - val_loss: 1.4569\n",
      "Epoch 2323/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1190 - val_loss: 1.4099\n",
      "Epoch 2324/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1190 - val_loss: 1.4573\n",
      "Epoch 2325/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1189 - val_loss: 1.4094\n",
      "Epoch 2326/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.1188 - val_loss: 1.4551\n",
      "Epoch 2327/2500\n",
      "64/64 [==============================] - 0s 187us/step - loss: 1.1187 - val_loss: 1.4123\n",
      "Epoch 2328/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1182 - val_loss: 1.4505\n",
      "Epoch 2329/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1177 - val_loss: 1.4173\n",
      "Epoch 2330/2500\n",
      "64/64 [==============================] - 0s 131us/step - loss: 1.1174 - val_loss: 1.4441\n",
      "Epoch 2331/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1173 - val_loss: 1.4219\n",
      "Epoch 2332/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1169 - val_loss: 1.4368\n",
      "Epoch 2333/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1166 - val_loss: 1.4264\n",
      "Epoch 2334/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1165 - val_loss: 1.4323\n",
      "Epoch 2335/2500\n",
      "64/64 [==============================] - 0s 389us/step - loss: 1.1164 - val_loss: 1.4312\n",
      "Epoch 2336/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1164 - val_loss: 1.4295\n",
      "Epoch 2337/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1162 - val_loss: 1.4347\n",
      "Epoch 2338/2500\n",
      "64/64 [==============================] - 0s 347us/step - loss: 1.1161 - val_loss: 1.4267\n",
      "Epoch 2339/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1161 - val_loss: 1.4375\n",
      "Epoch 2340/2500\n",
      "64/64 [==============================] - 0s 283us/step - loss: 1.1161 - val_loss: 1.4235\n",
      "Epoch 2341/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1160 - val_loss: 1.4402\n",
      "Epoch 2342/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1159 - val_loss: 1.4203\n",
      "Epoch 2343/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1160 - val_loss: 1.4428\n",
      "Epoch 2344/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.1159 - val_loss: 1.4169\n",
      "Epoch 2345/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1160 - val_loss: 1.4455\n",
      "Epoch 2346/2500\n",
      "64/64 [==============================] - 0s 104us/step - loss: 1.1161 - val_loss: 1.4142\n",
      "Epoch 2347/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1162 - val_loss: 1.4485\n",
      "Epoch 2348/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1162 - val_loss: 1.4114\n",
      "Epoch 2349/2500\n",
      "64/64 [==============================] - 0s 279us/step - loss: 1.1162 - val_loss: 1.4496\n",
      "Epoch 2350/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1161 - val_loss: 1.4097\n",
      "Epoch 2351/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1161 - val_loss: 1.4490\n",
      "Epoch 2352/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1160 - val_loss: 1.4104\n",
      "Epoch 2353/2500\n",
      "64/64 [==============================] - 0s 304us/step - loss: 1.1159 - val_loss: 1.4472\n",
      "Epoch 2354/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1156 - val_loss: 1.4122\n",
      "Epoch 2355/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1154 - val_loss: 1.4434\n",
      "Epoch 2356/2500\n",
      "64/64 [==============================] - 0s 197us/step - loss: 1.1151 - val_loss: 1.4146\n",
      "Epoch 2357/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1149 - val_loss: 1.4388\n",
      "Epoch 2358/2500\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.1146 - val_loss: 1.4183\n",
      "Epoch 2359/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1144 - val_loss: 1.4353\n",
      "Epoch 2360/2500\n",
      "64/64 [==============================] - 0s 264us/step - loss: 1.1143 - val_loss: 1.4218\n",
      "Epoch 2361/2500\n",
      "64/64 [==============================] - 0s 116us/step - loss: 1.1141 - val_loss: 1.4329\n",
      "Epoch 2362/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1141 - val_loss: 1.4244\n",
      "Epoch 2363/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1139 - val_loss: 1.4308\n",
      "Epoch 2364/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1138 - val_loss: 1.4252\n",
      "Epoch 2365/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1137 - val_loss: 1.4295\n",
      "Epoch 2366/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1136 - val_loss: 1.4251\n",
      "Epoch 2367/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1137 - val_loss: 1.4291\n",
      "Epoch 2368/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1136 - val_loss: 1.4243\n",
      "Epoch 2369/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1133 - val_loss: 1.4299\n",
      "Epoch 2370/2500\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.1131 - val_loss: 1.4236\n",
      "Epoch 2371/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1132 - val_loss: 1.4318\n",
      "Epoch 2372/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1131 - val_loss: 1.4212\n",
      "Epoch 2373/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1131 - val_loss: 1.4338\n",
      "Epoch 2374/2500\n",
      "64/64 [==============================] - 0s 192us/step - loss: 1.1129 - val_loss: 1.4171\n",
      "Epoch 2375/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1130 - val_loss: 1.4371\n",
      "Epoch 2376/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1131 - val_loss: 1.4126\n",
      "Epoch 2377/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1132 - val_loss: 1.4417\n",
      "Epoch 2378/2500\n",
      "64/64 [==============================] - 0s 77us/step - loss: 1.1133 - val_loss: 1.4077\n",
      "Epoch 2379/2500\n",
      "64/64 [==============================] - 0s 93us/step - loss: 1.1135 - val_loss: 1.4468\n",
      "Epoch 2380/2500\n",
      "64/64 [==============================] - 0s 92us/step - loss: 1.1136 - val_loss: 1.4032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2381/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1137 - val_loss: 1.4512\n",
      "Epoch 2382/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1139 - val_loss: 1.4000\n",
      "Epoch 2383/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1141 - val_loss: 1.4533\n",
      "Epoch 2384/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1140 - val_loss: 1.3995\n",
      "Epoch 2385/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1139 - val_loss: 1.4510\n",
      "Epoch 2386/2500\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.1137 - val_loss: 1.4025\n",
      "Epoch 2387/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1135 - val_loss: 1.4448\n",
      "Epoch 2388/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1129 - val_loss: 1.4085\n",
      "Epoch 2389/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1124 - val_loss: 1.4359\n",
      "Epoch 2390/2500\n",
      "64/64 [==============================] - 0s 48us/step - loss: 1.1120 - val_loss: 1.4164\n",
      "Epoch 2391/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1117 - val_loss: 1.4276\n",
      "Epoch 2392/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1114 - val_loss: 1.4224\n",
      "Epoch 2393/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 1.1112 - val_loss: 1.4208\n",
      "Epoch 2394/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1112 - val_loss: 1.4277\n",
      "Epoch 2395/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1112 - val_loss: 1.4163\n",
      "Epoch 2396/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1111 - val_loss: 1.4329\n",
      "Epoch 2397/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1111 - val_loss: 1.4133\n",
      "Epoch 2398/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1112 - val_loss: 1.4376\n",
      "Epoch 2399/2500\n",
      "64/64 [==============================] - 0s 143us/step - loss: 1.1113 - val_loss: 1.4102\n",
      "Epoch 2400/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.1113 - val_loss: 1.4400\n",
      "Epoch 2401/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1113 - val_loss: 1.4071\n",
      "Epoch 2402/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1114 - val_loss: 1.4401\n",
      "Epoch 2403/2500\n",
      "64/64 [==============================] - 0s 244us/step - loss: 1.1114 - val_loss: 1.4058\n",
      "Epoch 2404/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1112 - val_loss: 1.4391\n",
      "Epoch 2405/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1110 - val_loss: 1.4076\n",
      "Epoch 2406/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1109 - val_loss: 1.4375\n",
      "Epoch 2407/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.1108 - val_loss: 1.4100\n",
      "Epoch 2408/2500\n",
      "64/64 [==============================] - 0s 208us/step - loss: 1.1106 - val_loss: 1.4334\n",
      "Epoch 2409/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1102 - val_loss: 1.4117\n",
      "Epoch 2410/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1100 - val_loss: 1.4286\n",
      "Epoch 2411/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1098 - val_loss: 1.4149\n",
      "Epoch 2412/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 1.1097 - val_loss: 1.4257\n",
      "Epoch 2413/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1096 - val_loss: 1.4183\n",
      "Epoch 2414/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1095 - val_loss: 1.4228\n",
      "Epoch 2415/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1095 - val_loss: 1.4196\n",
      "Epoch 2416/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 1.1094 - val_loss: 1.4202\n",
      "Epoch 2417/2500\n",
      "64/64 [==============================] - 0s 153us/step - loss: 1.1092 - val_loss: 1.4207\n",
      "Epoch 2418/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1092 - val_loss: 1.4190\n",
      "Epoch 2419/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1091 - val_loss: 1.4225\n",
      "Epoch 2420/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1090 - val_loss: 1.4184\n",
      "Epoch 2421/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 1.1089 - val_loss: 1.4240\n",
      "Epoch 2422/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 1.1088 - val_loss: 1.4170\n",
      "Epoch 2423/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1088 - val_loss: 1.4251\n",
      "Epoch 2424/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 1.1087 - val_loss: 1.4144\n",
      "Epoch 2425/2500\n",
      "64/64 [==============================] - 0s 45us/step - loss: 1.1087 - val_loss: 1.4266\n",
      "Epoch 2426/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1087 - val_loss: 1.4115\n",
      "Epoch 2427/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 1.1087 - val_loss: 1.4292\n",
      "Epoch 2428/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 1.1086 - val_loss: 1.4089\n",
      "Epoch 2429/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1086 - val_loss: 1.4326\n",
      "Epoch 2430/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 1.1086 - val_loss: 1.4057\n",
      "Epoch 2431/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1087 - val_loss: 1.4359\n",
      "Epoch 2432/2500\n",
      "64/64 [==============================] - 0s 149us/step - loss: 1.1088 - val_loss: 1.4015\n",
      "Epoch 2433/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1089 - val_loss: 1.4389\n",
      "Epoch 2434/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1090 - val_loss: 1.3984\n",
      "Epoch 2435/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1092 - val_loss: 1.4415\n",
      "Epoch 2436/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 1.1092 - val_loss: 1.3971\n",
      "Epoch 2437/2500\n",
      "64/64 [==============================] - 0s 82us/step - loss: 1.1091 - val_loss: 1.4416\n",
      "Epoch 2438/2500\n",
      "64/64 [==============================] - 0s 87us/step - loss: 1.1089 - val_loss: 1.3972\n",
      "Epoch 2439/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1088 - val_loss: 1.4390\n",
      "Epoch 2440/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1085 - val_loss: 1.4001\n",
      "Epoch 2441/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1082 - val_loss: 1.4342\n",
      "Epoch 2442/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1080 - val_loss: 1.4050\n",
      "Epoch 2443/2500\n",
      "64/64 [==============================] - 0s 206us/step - loss: 1.1077 - val_loss: 1.4283\n",
      "Epoch 2444/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.1074 - val_loss: 1.4103\n",
      "Epoch 2445/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1071 - val_loss: 1.4229\n",
      "Epoch 2446/2500\n",
      "64/64 [==============================] - 0s 51us/step - loss: 1.1070 - val_loss: 1.4147\n",
      "Epoch 2447/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1070 - val_loss: 1.4184\n",
      "Epoch 2448/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1068 - val_loss: 1.4174\n",
      "Epoch 2449/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 1.1068 - val_loss: 1.4150\n",
      "Epoch 2450/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1067 - val_loss: 1.4198\n",
      "Epoch 2451/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1067 - val_loss: 1.4127\n",
      "Epoch 2452/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1067 - val_loss: 1.4225\n",
      "Epoch 2453/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1065 - val_loss: 1.4101\n",
      "Epoch 2454/2500\n",
      "64/64 [==============================] - 0s 126us/step - loss: 1.1064 - val_loss: 1.4257\n",
      "Epoch 2455/2500\n",
      "64/64 [==============================] - 0s 119us/step - loss: 1.1065 - val_loss: 1.4075\n",
      "Epoch 2456/2500\n",
      "64/64 [==============================] - 0s 56us/step - loss: 1.1066 - val_loss: 1.4285\n",
      "Epoch 2457/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.1066 - val_loss: 1.4040\n",
      "Epoch 2458/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 1.1066 - val_loss: 1.4314\n",
      "Epoch 2459/2500\n",
      "64/64 [==============================] - 0s 177us/step - loss: 1.1066 - val_loss: 1.4008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2460/2500\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.1066 - val_loss: 1.4346\n",
      "Epoch 2461/2500\n",
      "64/64 [==============================] - 0s 108us/step - loss: 1.1067 - val_loss: 1.3980\n",
      "Epoch 2462/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 1.1069 - val_loss: 1.4371\n",
      "Epoch 2463/2500\n",
      "64/64 [==============================] - 0s 147us/step - loss: 1.1071 - val_loss: 1.3955\n",
      "Epoch 2464/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1071 - val_loss: 1.4367\n",
      "Epoch 2465/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1069 - val_loss: 1.3949\n",
      "Epoch 2466/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1068 - val_loss: 1.4352\n",
      "Epoch 2467/2500\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.1067 - val_loss: 1.3968\n",
      "Epoch 2468/2500\n",
      "64/64 [==============================] - 0s 140us/step - loss: 1.1065 - val_loss: 1.4319\n",
      "Epoch 2469/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1061 - val_loss: 1.4000\n",
      "Epoch 2470/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 1.1059 - val_loss: 1.4279\n",
      "Epoch 2471/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1058 - val_loss: 1.4041\n",
      "Epoch 2472/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.1055 - val_loss: 1.4232\n",
      "Epoch 2473/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1052 - val_loss: 1.4073\n",
      "Epoch 2474/2500\n",
      "64/64 [==============================] - 0s 76us/step - loss: 1.1050 - val_loss: 1.4192\n",
      "Epoch 2475/2500\n",
      "64/64 [==============================] - 0s 64us/step - loss: 1.1049 - val_loss: 1.4100\n",
      "Epoch 2476/2500\n",
      "64/64 [==============================] - 0s 101us/step - loss: 1.1049 - val_loss: 1.4165\n",
      "Epoch 2477/2500\n",
      "64/64 [==============================] - 0s 164us/step - loss: 1.1048 - val_loss: 1.4127\n",
      "Epoch 2478/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1047 - val_loss: 1.4143\n",
      "Epoch 2479/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1045 - val_loss: 1.4147\n",
      "Epoch 2480/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 1.1045 - val_loss: 1.4126\n",
      "Epoch 2481/2500\n",
      "64/64 [==============================] - 0s 113us/step - loss: 1.1045 - val_loss: 1.4165\n",
      "Epoch 2482/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1044 - val_loss: 1.4113\n",
      "Epoch 2483/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 1.1043 - val_loss: 1.4177\n",
      "Epoch 2484/2500\n",
      "64/64 [==============================] - 0s 57us/step - loss: 1.1042 - val_loss: 1.4096\n",
      "Epoch 2485/2500\n",
      "64/64 [==============================] - 0s 44us/step - loss: 1.1043 - val_loss: 1.4184\n",
      "Epoch 2486/2500\n",
      "64/64 [==============================] - 0s 54us/step - loss: 1.1043 - val_loss: 1.4074\n",
      "Epoch 2487/2500\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.1044 - val_loss: 1.4195\n",
      "Epoch 2488/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 1.1042 - val_loss: 1.4051\n",
      "Epoch 2489/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1040 - val_loss: 1.4217\n",
      "Epoch 2490/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1040 - val_loss: 1.4025\n",
      "Epoch 2491/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 1.1040 - val_loss: 1.4245\n",
      "Epoch 2492/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 1.1040 - val_loss: 1.3988\n",
      "Epoch 2493/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.1041 - val_loss: 1.4283\n",
      "Epoch 2494/2500\n",
      "64/64 [==============================] - 0s 55us/step - loss: 1.1041 - val_loss: 1.3949\n",
      "Epoch 2495/2500\n",
      "64/64 [==============================] - 0s 60us/step - loss: 1.1043 - val_loss: 1.4332\n",
      "Epoch 2496/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 1.1046 - val_loss: 1.3902\n",
      "Epoch 2497/2500\n",
      "64/64 [==============================] - 0s 58us/step - loss: 1.1049 - val_loss: 1.4370\n",
      "Epoch 2498/2500\n",
      "64/64 [==============================] - 0s 132us/step - loss: 1.1050 - val_loss: 1.3869\n",
      "Epoch 2499/2500\n",
      "64/64 [==============================] - 0s 68us/step - loss: 1.1051 - val_loss: 1.4385\n",
      "Epoch 2500/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.1051 - val_loss: 1.3869\n"
     ]
    }
   ],
   "source": [
    "model_L1 = models.Sequential()\n",
    "\n",
    "model_L1.add(layers.Dense(N, input_dim=input_dim, kernel_initializer='normal', activation='tanh', \n",
    "                          kernel_regularizer=regularizers.l1(alpha)))\n",
    "\n",
    "for h in range(num_layers):\n",
    "    model_L1.add(layers.Dense(N, activation='tanh', kernel_regularizer=regularizers.l1(alpha)))\n",
    "    \n",
    "model_L1.add(layers.Dense(1, activation='linear', kernel_regularizer=regularizers.l1(alpha)))\n",
    "\n",
    "model_L1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "L1_reg = model_L1.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2)\n",
    "\n",
    "X_val_L1 = L1_reg.validation_data[0]\n",
    "Y_val_L1 = L1_reg.validation_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use our model to predict in the range we want\n",
    "X_range = np.linspace(0.0, 5, 1000)\n",
    "y_pred_L2 = model_L2.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(20,14), sharex=True)\n",
    "\n",
    "ax[0].plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax[0].plot(X_train, Y_train, '.', label='Training data')\n",
    "ax[0].plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax[0].plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax[0].plot(X_range, y_pred_L2, lw=4, ls='--', color='g', label=r'$L_{2}$ Prediction')\n",
    "\n",
    "ax[0].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[0].tick_params(labelsize=20)\n",
    "\n",
    "ax[0].legend(loc=1, fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_L1 = model_L1.predict(X_range)\n",
    "\n",
    "ax[1].plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax[1].plot(X_train, Y_train, '.', label='Training data')\n",
    "ax[1].plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax[1].plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax[1].plot(X_range, y_pred_L1, lw=4, ls='--', color='g', label=r'$L_{1}$ Prediction')\n",
    "\n",
    "ax[1].set_xlabel(r'$X$', fontsize=20)\n",
    "ax[1].set_ylabel(r'$Y$', fontsize=20)\n",
    "ax[1].tick_params(labelsize=20)\n",
    "\n",
    "ax[1].legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping\n",
    "The results without any regularization do not look right.  $L_{2}$ and $L_{1}$ regularizaton helped somewhat, but the results still aren't convincing.\n",
    "\n",
    "We can gain some more insight by plotting the loss functions from the training and validation set.  Let's use a `log-log` scale to enhance any discrepancies between the two curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a reminder.\n",
    "\n",
    "Remember that the `fit` method can store the history of the model.  For the unregularized model we stored all the history in the name `no_reg`.  Let's see what attributes are in that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'epoch',\n",
       " 'history',\n",
       " 'model',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'params',\n",
       " 'set_model',\n",
       " 'set_params',\n",
       " 'validation_data']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(no_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of stuff; most of it we're not interested in.  However, at the very end of the list, we see some useful keys.  Let's access some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no_reg.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `history` is a dictionary.  Let's take a look at it's keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_reg.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very cool.  There is a `validation` and `training` loss.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the one we'll want to use right now, but we can look at the other attributes too just to get a feel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no_reg.validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(no_reg.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'epochs', 'steps', 'samples', 'verbose', 'do_validation', 'metrics'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_reg.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_reg.params['batch_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was fun and informative.  But what we're really after is the loss data as a function of epoch number.  Here we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L = no_reg.history['loss']\n",
    "L_val = no_reg.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,6))\n",
    "\n",
    "ax.plot(L, label='Training Loss')\n",
    "ax.plot(L_val, label='Validation Loss')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=1, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow.  That is striking.\n",
    "\n",
    "We used $2500$ epochs, but the validation loss begins to rise at around $50$ epochs and becomes larger than the training loss at around $70$ epochs.  After that, we're basically overfitting.\n",
    "\n",
    "Notice that the training loss keeps decreasing.  We're fitting the training data better and better all the time.  The validation loss is getting larger and larger meaning that we're losing generalizability.\n",
    "\n",
    "We can use this new information to our advantage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### Part 1\n",
    "Train a network without any penalization, but this time stop after $20$ epochs.\n",
    "\n",
    "### Part 2\n",
    "Train a network without any penalization, but this time stop at the \"optimal\" number of epochs (based on the crossing of the loss curves).\n",
    "\n",
    "**Deliverables**\n",
    "* Plot the following on a single figure:\n",
    "  - The true solution\n",
    "  - The model prediction without any regularization (after $2500$ epochs)\n",
    "  - The model prediction without any regularization using $20$ epochs\n",
    "  - The model prediction without any regularization using the optimal number of epochs\n",
    "* You may also want to include the training and validation data on the same plot.  Be careful that the plot doesn't become too cluttered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $20$ epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/20\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 5.6850 - val_loss: 4.3010\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 0s 67us/step - loss: 5.4600 - val_loss: 4.1269\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 0s 52us/step - loss: 5.2882 - val_loss: 3.9646\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 0s 54us/step - loss: 5.1296 - val_loss: 3.8229\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 0s 59us/step - loss: 4.9918 - val_loss: 3.6779\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 0s 133us/step - loss: 4.8523 - val_loss: 3.5362\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 0s 126us/step - loss: 4.7199 - val_loss: 3.4053\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 0s 58us/step - loss: 4.6010 - val_loss: 3.2943\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 0s 57us/step - loss: 4.5073 - val_loss: 3.2126\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 0s 64us/step - loss: 4.4489 - val_loss: 3.1737\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 0s 108us/step - loss: 4.4384 - val_loss: 3.1768\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 0s 53us/step - loss: 4.4700 - val_loss: 3.1884\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 0s 66us/step - loss: 4.5015 - val_loss: 3.1776\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 0s 73us/step - loss: 4.4974 - val_loss: 3.1414\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 0s 51us/step - loss: 4.4564 - val_loss: 3.0945\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 0s 47us/step - loss: 4.3962 - val_loss: 3.0535\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 0s 117us/step - loss: 4.3386 - val_loss: 3.0278\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 0s 278us/step - loss: 4.2957 - val_loss: 3.0182\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 0s 61us/step - loss: 4.2706 - val_loss: 3.0184\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 0s 103us/step - loss: 4.2581 - val_loss: 3.0194\n"
     ]
    }
   ],
   "source": [
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "no_reg_20 = model.fit(X_train, Y_train, epochs=20, batch_size=64, validation_split=0.2)\n",
    "\n",
    "X_range = np.linspace(0.0, 5, 1000)\n",
    "y_pred_20 = model.predict(X_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Optimal\" epochs\n",
    "This probably isn't the optimal value.  But eye-balling the loss curves, I'm guess that $65$ epochs is the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/65\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 5.5357 - val_loss: 4.0898\n",
      "Epoch 2/65\n",
      "64/64 [==============================] - 0s 65us/step - loss: 5.2513 - val_loss: 3.8842\n",
      "Epoch 3/65\n",
      "64/64 [==============================] - 0s 86us/step - loss: 5.0513 - val_loss: 3.6725\n",
      "Epoch 4/65\n",
      "64/64 [==============================] - 0s 57us/step - loss: 4.8482 - val_loss: 3.4794\n",
      "Epoch 5/65\n",
      "64/64 [==============================] - 0s 67us/step - loss: 4.6677 - val_loss: 3.3187\n",
      "Epoch 6/65\n",
      "64/64 [==============================] - 0s 91us/step - loss: 4.5251 - val_loss: 3.2050\n",
      "Epoch 7/65\n",
      "64/64 [==============================] - 0s 57us/step - loss: 4.4375 - val_loss: 3.1540\n",
      "Epoch 8/65\n",
      "64/64 [==============================] - 0s 70us/step - loss: 4.4211 - val_loss: 3.1654\n",
      "Epoch 9/65\n",
      "64/64 [==============================] - 0s 89us/step - loss: 4.4679 - val_loss: 3.1821\n",
      "Epoch 10/65\n",
      "64/64 [==============================] - 0s 122us/step - loss: 4.5066 - val_loss: 3.1579\n",
      "Epoch 11/65\n",
      "64/64 [==============================] - 0s 181us/step - loss: 4.4845 - val_loss: 3.1044\n",
      "Epoch 12/65\n",
      "64/64 [==============================] - 0s 122us/step - loss: 4.4181 - val_loss: 3.0521\n",
      "Epoch 13/65\n",
      "64/64 [==============================] - 0s 127us/step - loss: 4.3459 - val_loss: 3.0206\n",
      "Epoch 14/65\n",
      "64/64 [==============================] - 0s 144us/step - loss: 4.2932 - val_loss: 3.0126\n",
      "Epoch 15/65\n",
      "64/64 [==============================] - 0s 158us/step - loss: 4.2656 - val_loss: 3.0192\n",
      "Epoch 16/65\n",
      "64/64 [==============================] - 0s 66us/step - loss: 4.2566 - val_loss: 3.0281\n",
      "Epoch 17/65\n",
      "64/64 [==============================] - 0s 96us/step - loss: 4.2541 - val_loss: 3.0283\n",
      "Epoch 18/65\n",
      "64/64 [==============================] - 0s 213us/step - loss: 4.2465 - val_loss: 3.0131\n",
      "Epoch 19/65\n",
      "64/64 [==============================] - 0s 107us/step - loss: 4.2266 - val_loss: 2.9825\n",
      "Epoch 20/65\n",
      "64/64 [==============================] - 0s 80us/step - loss: 4.1941 - val_loss: 2.9392\n",
      "Epoch 21/65\n",
      "64/64 [==============================] - 0s 96us/step - loss: 4.1518 - val_loss: 2.8889\n",
      "Epoch 22/65\n",
      "64/64 [==============================] - 0s 155us/step - loss: 4.1054 - val_loss: 2.8372\n",
      "Epoch 23/65\n",
      "64/64 [==============================] - 0s 91us/step - loss: 4.0582 - val_loss: 2.7892\n",
      "Epoch 24/65\n",
      "64/64 [==============================] - 0s 77us/step - loss: 4.0155 - val_loss: 2.7496\n",
      "Epoch 25/65\n",
      "64/64 [==============================] - 0s 89us/step - loss: 3.9811 - val_loss: 2.7180\n",
      "Epoch 26/65\n",
      "64/64 [==============================] - 0s 162us/step - loss: 3.9508 - val_loss: 2.6915\n",
      "Epoch 27/65\n",
      "64/64 [==============================] - 0s 66us/step - loss: 3.9187 - val_loss: 2.6645\n",
      "Epoch 28/65\n",
      "64/64 [==============================] - 0s 69us/step - loss: 3.8780 - val_loss: 2.6362\n",
      "Epoch 29/65\n",
      "64/64 [==============================] - 0s 98us/step - loss: 3.8264 - val_loss: 2.6123\n",
      "Epoch 30/65\n",
      "64/64 [==============================] - 0s 237us/step - loss: 3.7705 - val_loss: 2.5943\n",
      "Epoch 31/65\n",
      "64/64 [==============================] - 0s 370us/step - loss: 3.7159 - val_loss: 2.5828\n",
      "Epoch 32/65\n",
      "64/64 [==============================] - 0s 68us/step - loss: 3.6679 - val_loss: 2.5695\n",
      "Epoch 33/65\n",
      "64/64 [==============================] - 0s 93us/step - loss: 3.6214 - val_loss: 2.5439\n",
      "Epoch 34/65\n",
      "64/64 [==============================] - 0s 277us/step - loss: 3.5684 - val_loss: 2.5010\n",
      "Epoch 35/65\n",
      "64/64 [==============================] - 0s 66us/step - loss: 3.5027 - val_loss: 2.4490\n",
      "Epoch 36/65\n",
      "64/64 [==============================] - 0s 84us/step - loss: 3.4313 - val_loss: 2.3920\n",
      "Epoch 37/65\n",
      "64/64 [==============================] - 0s 72us/step - loss: 3.3586 - val_loss: 2.3385\n",
      "Epoch 38/65\n",
      "64/64 [==============================] - 0s 97us/step - loss: 3.2893 - val_loss: 2.2897\n",
      "Epoch 39/65\n",
      "64/64 [==============================] - 0s 57us/step - loss: 3.2196 - val_loss: 2.2424\n",
      "Epoch 40/65\n",
      "64/64 [==============================] - 0s 76us/step - loss: 3.1407 - val_loss: 2.1970\n",
      "Epoch 41/65\n",
      "64/64 [==============================] - 0s 65us/step - loss: 3.0577 - val_loss: 2.1546\n",
      "Epoch 42/65\n",
      "64/64 [==============================] - 0s 126us/step - loss: 2.9783 - val_loss: 2.1079\n",
      "Epoch 43/65\n",
      "64/64 [==============================] - 0s 91us/step - loss: 2.9005 - val_loss: 2.0452\n",
      "Epoch 44/65\n",
      "64/64 [==============================] - 0s 76us/step - loss: 2.8147 - val_loss: 1.9742\n",
      "Epoch 45/65\n",
      "64/64 [==============================] - 0s 128us/step - loss: 2.7296 - val_loss: 1.9043\n",
      "Epoch 46/65\n",
      "64/64 [==============================] - 0s 122us/step - loss: 2.6464 - val_loss: 1.8368\n",
      "Epoch 47/65\n",
      "64/64 [==============================] - 0s 71us/step - loss: 2.5556 - val_loss: 1.7750\n",
      "Epoch 48/65\n",
      "64/64 [==============================] - 0s 70us/step - loss: 2.4697 - val_loss: 1.7032\n",
      "Epoch 49/65\n",
      "64/64 [==============================] - 0s 92us/step - loss: 2.3801 - val_loss: 1.6181\n",
      "Epoch 50/65\n",
      "64/64 [==============================] - 0s 209us/step - loss: 2.2840 - val_loss: 1.5401\n",
      "Epoch 51/65\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.1924 - val_loss: 1.4784\n",
      "Epoch 52/65\n",
      "64/64 [==============================] - 0s 58us/step - loss: 2.0985 - val_loss: 1.4170\n",
      "Epoch 53/65\n",
      "64/64 [==============================] - 0s 115us/step - loss: 2.0054 - val_loss: 1.3380\n",
      "Epoch 54/65\n",
      "64/64 [==============================] - 0s 100us/step - loss: 1.9091 - val_loss: 1.2747\n",
      "Epoch 55/65\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.8162 - val_loss: 1.2312\n",
      "Epoch 56/65\n",
      "64/64 [==============================] - 0s 61us/step - loss: 1.7307 - val_loss: 1.1560\n",
      "Epoch 57/65\n",
      "64/64 [==============================] - 0s 59us/step - loss: 1.6501 - val_loss: 1.1591\n",
      "Epoch 58/65\n",
      "64/64 [==============================] - 0s 125us/step - loss: 1.5717 - val_loss: 1.0721\n",
      "Epoch 59/65\n",
      "64/64 [==============================] - 0s 136us/step - loss: 1.4964 - val_loss: 1.2028\n",
      "Epoch 60/65\n",
      "64/64 [==============================] - 0s 321us/step - loss: 1.4385 - val_loss: 1.0001\n",
      "Epoch 61/65\n",
      "64/64 [==============================] - 0s 105us/step - loss: 1.4161 - val_loss: 1.3528\n",
      "Epoch 62/65\n",
      "64/64 [==============================] - 0s 107us/step - loss: 1.3564 - val_loss: 1.1312\n",
      "Epoch 63/65\n",
      "64/64 [==============================] - 0s 192us/step - loss: 1.2428 - val_loss: 1.0524\n",
      "Epoch 64/65\n",
      "64/64 [==============================] - 0s 106us/step - loss: 1.2403 - val_loss: 1.5237\n",
      "Epoch 65/65\n",
      "64/64 [==============================] - 0s 86us/step - loss: 1.2275 - val_loss: 1.1995\n"
     ]
    }
   ],
   "source": [
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "no_reg_opt = model.fit(X_train, Y_train, epochs=65, batch_size=64, validation_split=0.2)\n",
    "\n",
    "y_pred_opt = model.predict(X_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12,8))\n",
    "\n",
    "ax.plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax.plot(X_train, Y_train, '.', label='Training data')\n",
    "ax.plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax.plot(X_range, y_pred_20, lw=4, ls='--', color='g', label=r'$20$ Epochs')\n",
    "ax.plot(X_range, y_pred_opt, lw=4, ls=':', color='m', label=r'\"Optimal\" Epochs')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=3, ncol=2, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to do things more systematically.\n",
    "\n",
    "How do you think early stopping should be implemented?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do early stopping in `Keras`, you specify the `EarlyStopping` [*callback*](https://keras.io/callbacks/).  From the documentation:\n",
    "> A callback is a set of functions to be applied at given stages of the training procedure.\n",
    "\n",
    "Callbacks can be used to view internal states and statistics of the model during training.\n",
    "\n",
    "Right now, we'll use one to monitor the validation loss function.  When the validation loss starts to go up, the training process will stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Syntax\n",
    "To specify a callback, you just pass a `callbacks` list into the model `fit()` method, like this:\n",
    "```python\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2, \n",
    "          callbacks=[EarlyStopping(monitor='val_loss', patience=5)])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Fit the model using the early stopping technique.  Try different values for `patience` to see which one gives you the lowest validation loss.\n",
    "\n",
    "How many epochs are needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/2500\n",
      "64/64 [==============================] - 1s 16ms/step - loss: 5.8866 - val_loss: 4.5283\n",
      "Epoch 2/2500\n",
      "64/64 [==============================] - 0s 201us/step - loss: 5.6857 - val_loss: 4.4078\n",
      "Epoch 3/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 5.5673 - val_loss: 4.3148\n",
      "Epoch 4/2500\n",
      "64/64 [==============================] - 0s 53us/step - loss: 5.4747 - val_loss: 4.2364\n",
      "Epoch 5/2500\n",
      "64/64 [==============================] - 0s 67us/step - loss: 5.3953 - val_loss: 4.1535\n",
      "Epoch 6/2500\n",
      "64/64 [==============================] - 0s 88us/step - loss: 5.3136 - val_loss: 4.0609\n",
      "Epoch 7/2500\n",
      "64/64 [==============================] - 0s 50us/step - loss: 5.2227 - val_loss: 3.9631\n",
      "Epoch 8/2500\n",
      "64/64 [==============================] - 0s 601us/step - loss: 5.1263 - val_loss: 3.8575\n",
      "Epoch 9/2500\n",
      "64/64 [==============================] - 0s 115us/step - loss: 5.0245 - val_loss: 3.7409\n",
      "Epoch 10/2500\n",
      "64/64 [==============================] - 0s 66us/step - loss: 4.9120 - val_loss: 3.6234\n",
      "Epoch 11/2500\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 4.8007 - val_loss: 3.5013\n",
      "Epoch 12/2500\n",
      "64/64 [==============================] - 0s 128us/step - loss: 4.6871 - val_loss: 3.3917\n",
      "Epoch 13/2500\n",
      "64/64 [==============================] - 0s 241us/step - loss: 4.5887 - val_loss: 3.2994\n",
      "Epoch 14/2500\n",
      "64/64 [==============================] - 0s 103us/step - loss: 4.5122 - val_loss: 3.2330\n",
      "Epoch 15/2500\n",
      "64/64 [==============================] - 0s 152us/step - loss: 4.4663 - val_loss: 3.2021\n",
      "Epoch 16/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 4.4600 - val_loss: 3.2029\n",
      "Epoch 17/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 4.4855 - val_loss: 3.2096\n",
      "Epoch 18/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 4.5105 - val_loss: 3.1950\n",
      "Epoch 19/2500\n",
      "64/64 [==============================] - 0s 138us/step - loss: 4.5023 - val_loss: 3.1562\n",
      "Epoch 20/2500\n",
      "64/64 [==============================] - 0s 171us/step - loss: 4.4579 - val_loss: 3.1075\n",
      "Epoch 21/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 4.3958 - val_loss: 3.0649\n",
      "Epoch 22/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 4.3359 - val_loss: 3.0379\n",
      "Epoch 23/2500\n",
      "64/64 [==============================] - 0s 220us/step - loss: 4.2904 - val_loss: 3.0269\n",
      "Epoch 24/2500\n",
      "64/64 [==============================] - 0s 94us/step - loss: 4.2622 - val_loss: 3.0246\n",
      "Epoch 25/2500\n",
      "64/64 [==============================] - 0s 362us/step - loss: 4.2455 - val_loss: 3.0217\n",
      "Epoch 26/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 4.2310 - val_loss: 3.0116\n",
      "Epoch 27/2500\n",
      "64/64 [==============================] - 0s 314us/step - loss: 4.2120 - val_loss: 2.9902\n",
      "Epoch 28/2500\n",
      "64/64 [==============================] - 0s 79us/step - loss: 4.1842 - val_loss: 2.9585\n",
      "Epoch 29/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 4.1484 - val_loss: 2.9164\n",
      "Epoch 30/2500\n",
      "64/64 [==============================] - 0s 170us/step - loss: 4.1042 - val_loss: 2.8670\n",
      "Epoch 31/2500\n",
      "64/64 [==============================] - 0s 127us/step - loss: 4.0546 - val_loss: 2.8139\n",
      "Epoch 32/2500\n",
      "64/64 [==============================] - 0s 237us/step - loss: 4.0022 - val_loss: 2.7643\n",
      "Epoch 33/2500\n",
      "64/64 [==============================] - 0s 175us/step - loss: 3.9534 - val_loss: 2.7195\n",
      "Epoch 34/2500\n",
      "64/64 [==============================] - 0s 411us/step - loss: 3.9089 - val_loss: 2.6801\n",
      "Epoch 35/2500\n",
      "64/64 [==============================] - 0s 109us/step - loss: 3.8678 - val_loss: 2.6431\n",
      "Epoch 36/2500\n",
      "64/64 [==============================] - 0s 391us/step - loss: 3.8197 - val_loss: 2.6081\n",
      "Epoch 37/2500\n",
      "64/64 [==============================] - 0s 360us/step - loss: 3.7652 - val_loss: 2.5733\n",
      "Epoch 38/2500\n",
      "64/64 [==============================] - 0s 391us/step - loss: 3.7039 - val_loss: 2.5396\n",
      "Epoch 39/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 3.6384 - val_loss: 2.5084\n",
      "Epoch 40/2500\n",
      "64/64 [==============================] - 0s 95us/step - loss: 3.5726 - val_loss: 2.4784\n",
      "Epoch 41/2500\n",
      "64/64 [==============================] - 0s 277us/step - loss: 3.5077 - val_loss: 2.4442\n",
      "Epoch 42/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 3.4409 - val_loss: 2.3997\n",
      "Epoch 43/2500\n",
      "64/64 [==============================] - 0s 369us/step - loss: 3.3675 - val_loss: 2.3421\n",
      "Epoch 44/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 3.2847 - val_loss: 2.2756\n",
      "Epoch 45/2500\n",
      "64/64 [==============================] - 0s 70us/step - loss: 3.1959 - val_loss: 2.2081\n",
      "Epoch 46/2500\n",
      "64/64 [==============================] - 0s 49us/step - loss: 3.1070 - val_loss: 2.1434\n",
      "Epoch 47/2500\n",
      "64/64 [==============================] - 0s 74us/step - loss: 3.0197 - val_loss: 2.0804\n",
      "Epoch 48/2500\n",
      "64/64 [==============================] - 0s 78us/step - loss: 2.9312 - val_loss: 2.0136\n",
      "Epoch 49/2500\n",
      "64/64 [==============================] - 0s 114us/step - loss: 2.8357 - val_loss: 1.9476\n",
      "Epoch 50/2500\n",
      "64/64 [==============================] - 0s 81us/step - loss: 2.7379 - val_loss: 1.8891\n",
      "Epoch 51/2500\n",
      "64/64 [==============================] - 0s 59us/step - loss: 2.6497 - val_loss: 1.8248\n",
      "Epoch 52/2500\n",
      "64/64 [==============================] - 0s 72us/step - loss: 2.5638 - val_loss: 1.7435\n",
      "Epoch 53/2500\n",
      "64/64 [==============================] - 0s 69us/step - loss: 2.4686 - val_loss: 1.6600\n",
      "Epoch 54/2500\n",
      "64/64 [==============================] - 0s 151us/step - loss: 2.3774 - val_loss: 1.5875\n",
      "Epoch 55/2500\n",
      "64/64 [==============================] - 0s 173us/step - loss: 2.2895 - val_loss: 1.5321\n",
      "Epoch 56/2500\n",
      "64/64 [==============================] - 0s 65us/step - loss: 2.1949 - val_loss: 1.4995\n",
      "Epoch 57/2500\n",
      "64/64 [==============================] - 0s 73us/step - loss: 2.1119 - val_loss: 1.4366\n",
      "Epoch 58/2500\n",
      "64/64 [==============================] - 0s 141us/step - loss: 2.0247 - val_loss: 1.3505\n",
      "Epoch 59/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.9433 - val_loss: 1.3040\n",
      "Epoch 60/2500\n",
      "64/64 [==============================] - 0s 71us/step - loss: 1.8666 - val_loss: 1.3053\n",
      "Epoch 61/2500\n",
      "64/64 [==============================] - 0s 118us/step - loss: 1.7961 - val_loss: 1.2765\n",
      "Epoch 62/2500\n",
      "64/64 [==============================] - 0s 98us/step - loss: 1.7298 - val_loss: 1.2031\n",
      "Epoch 63/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.6697 - val_loss: 1.2210\n",
      "Epoch 64/2500\n",
      "64/64 [==============================] - 0s 85us/step - loss: 1.6070 - val_loss: 1.2957\n",
      "Epoch 65/2500\n",
      "64/64 [==============================] - 0s 62us/step - loss: 1.5604 - val_loss: 1.1952\n",
      "Epoch 66/2500\n",
      "64/64 [==============================] - 0s 63us/step - loss: 1.5095 - val_loss: 1.2815\n",
      "Epoch 67/2500\n",
      "64/64 [==============================] - 0s 191us/step - loss: 1.4578 - val_loss: 1.3676\n",
      "Epoch 68/2500\n",
      "64/64 [==============================] - 0s 90us/step - loss: 1.4202 - val_loss: 1.2461\n",
      "Epoch 69/2500\n",
      "64/64 [==============================] - 0s 75us/step - loss: 1.3945 - val_loss: 1.5314\n",
      "Epoch 70/2500\n",
      "64/64 [==============================] - 0s 158us/step - loss: 1.3634 - val_loss: 1.3522\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu'))\n",
    "    \n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit model\n",
    "no_reg_ES = model.fit(X_train, Y_train, epochs=2500, batch_size=64, validation_split=0.2, \n",
    "                     callbacks=[EarlyStopping(monitor='val_loss', patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_ES = model.predict(X_range)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,8))\n",
    "\n",
    "ax.plot(X_true, Y_true, color='k', ls='-.', lw=4, label='True function')\n",
    "ax.plot(X_train, Y_train, '.', label='Training data')\n",
    "ax.plot(X_test, Y_test, ls='', marker='^',  ms=12, label='Test data')\n",
    "ax.plot(X_range, y_pred, lw=4, color='r', label='Prediction')\n",
    "ax.plot(X_range, y_pred_opt, lw=4, ls=':', color='m', label=r'\"Optimal\" Epochs')\n",
    "ax.plot(X_range, y_pred_ES, lw=4, ls='--', color='b', label=r'Early Stopping')\n",
    "\n",
    "ax.set_xlabel(r'$X$', fontsize=20)\n",
    "ax.set_ylabel(r'$Y$', fontsize=20)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "ax.legend(loc=3, ncol=2, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution should looks pretty good.  Of course, we had to play with the `patience` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "The basic idea behind the dropout technique is to randomly remove (i.e drop) at unit from the network including all of its connections.  Why would we want to do such a thing?  Because we want to avoid overfitting.  An intuitive way of seeing this is that by randomly dropping units at each iteration, we are actually training an ensemble of models.  This ensemble may be more robust to different scenarios than a single model.\n",
    "\n",
    "One usually needs to figure out how many units to drop in each layer.  Of course, this introduces a new hyperparameter to tune.  However, at least empirically, it appears that choosing a dropout rate of $0.5$ in the hidden layers and $0.8$ in the input layers works well.  Note that here the term \"dropout rate\" means \"the probability of retention of each node in the layer\".\n",
    "\n",
    "Dropout usually works best on large networks.  We will use it on our small lab network today just to understand some of the mechanics.\n",
    "\n",
    "The original paper on dropout has some nice explanations of the technique and also some really nice practical advice on using the technique:  [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "\n",
    "num_layers = 5\n",
    "N = 100\n",
    "\n",
    "input_dim = 1\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(N, input_dim=input_dim, activation='relu'))\n",
    "\n",
    "# Create hidden layers\n",
    "for h in range(num_layers):\n",
    "    model.add(layers.Dense(N, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fit model\n",
    "no_reg_dropout = model.fit(X_train, Y_train, epochs=250, batch_size=64, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
